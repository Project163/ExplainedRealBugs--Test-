{"project_id": "Alacritty", "bug_id": "1", "source_type": "github", "confidence": 0.75, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Scrolling vim in tmux while a separate pane is printing causes corruption\n[Symptom]:\nGiven this setup\n\n[Image: image]\n\nScrolling a vim split **while the middle left pane is printing** will cause vim to become corrupt as shown in this screenshot:\n\n[Image: image]\n\nI have a theory that this is because writing to the _pty_ is not synchronized at all. The input thread simply writes to the file descriptor when it has data to write. The only way to test if this is true would be implementing an actual event loop for I/O. The easiest way to do that is dropping mio into the pty thread and sending all writes from the input handling over the mio channel.\n\n[Context/Logs]:\n- I actually managed to reproduce it with a slightly simpler tmux arrangement. It did not seem to be an issue when there was not a vertical split on the bottom. This may suggest that it's not concurrent read + write that's an issue but instead something to do with printing data while not in a scrolling region.\n\n[Image: image]"}
{"project_id": "Alacritty", "bug_id": "2", "source_type": "github", "confidence": 0.7, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Resizing doesn't work properly on macOS\n[Symptom]:\nThe out-of-band resize events on macOS don't trigger a refresh. Need to make it possible to kick the event loop from that resize handler.\n"}
{"project_id": "Alacritty", "bug_id": "3", "source_type": "github", "confidence": 0.7, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Doesn't shutdown properly from EOF on macOS\n[Symptom]:\nJust open Alacritty and hit ` ` to repro\n"}
{"project_id": "Alacritty", "bug_id": "4", "source_type": "github", "confidence": 0.6, "label": "Other", "llm_input_text": "[Title]: Sometimes reading from pty doesn't trigger a draw\n[Symptom]:\nSeems to have happened since the last major refactor.\n"}
{"project_id": "Alacritty", "bug_id": "5", "source_type": "github", "confidence": 0.85, "label": "Function :: Access Control (CWE-284)", "llm_input_text": "[Title]: Use XDG_CONFIG_PATH value\n[Symptom]:\nCurrently hardcoded to `$HOME/.config`, but that's not necessarily correct. [URL]\n"}
{"project_id": "Alacritty", "bug_id": "6", "source_type": "github", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: UK keyboard layout: '#' and '~' key not working on Linux with x11\n[Symptom]:\nI've just quickly followed the dependencies for keyboard input. It looks like alacritty depends on [Link: glutin] which for linux depends on [Link: winit] and I found the following lines are commented out in the most recent version [Link: src/api/x11/events.rs#L177] and [Link: src/api/x11/events.rs#L270].\r\n\r\nThis seems to be relevant to my issue but I am unsure why it has been commented out. If this is the reason then the layout of my keyboard is irrelevant and most likely other linux users would have the same problem.\r\n\r\nHaving encountered the issue while using alacritty I'm submitting an issue here but should I also post an issue on winit? Or is there another reason for this issue?\n\n[Context/Logs]:\n- This problem would need to be fixed upstream in `winit` as you've suggested. Alacritty is actually on an older for of `glutin` from before the split, and so there would still be some work here to get an upstream patch.\n- I'll see if I can fix it tomorrow. Any particular reason you are using an older version of `glutin`? Is it changing too often?\n- ... [Middle Discussions Snipped for Brevity] ...\n- Can we confirm this is fixed ? If so, the issue can be closed\n- if you  can see the mentioned PR isn't yet landed."}
{"project_id": "Alacritty", "bug_id": "7", "source_type": "github", "confidence": 0.4, "label": "Other", "llm_input_text": "[Title]: PgUp and PgDown don't work\n[Symptom]:\n\n"}
{"project_id": "Alacritty", "bug_id": "8", "source_type": "github", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: `alt` key don't work\n[Symptom]:\nexample:\r\n\r\n```\npython\r\nimport curses\r\n\r\ndef Main(screen):\r\n   while True:\r\n... [Log Snipped] ...\n\r\ncurses.wrapper(Main)\n```\r\n\r\n<img width=\"556\" alt=\"screenshot_20170103_151940\" src=\"[URL]\n\n[Context/Logs]:\n- I had no idea this was a thing. I've looked into this a bit, and ALT seems to be quite a special case for terminal emulators. When there's a key pressed with alt, the terminal emulator should send the escape character (`27` or `\\033` or `\\x1b`) followed by the character that was pressed.\n- Should be fixed :smile:\n- Also, thanks a lot for the curses script; it was very helpful!"}
{"project_id": "Alacritty", "bug_id": "9", "source_type": "github", "confidence": 0.7, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Scrolling should not write to the pty when one of the mouse modes isn't active\n[Symptom]:\n\n"}
{"project_id": "Alacritty", "bug_id": "10", "source_type": "github", "confidence": 0.85, "label": "Checking :: Missing Check (CWE-754)", "llm_input_text": "[Title]: Improve error handling for font loading\n[Symptom]:\nCurrently there's a failing assertion that the user sees as a backtrace. cc #21\n\n[Context/Logs]:\n- Refactored fontconfig usage to not panic. Still need to have some better error handling when fonts are not found."}
{"project_id": "Alacritty", "bug_id": "11", "source_type": "github", "confidence": 0.85, "label": "Function :: Logic Mismatch (CWE-573)", "llm_input_text": "[Title]: alacritty does not draw background color for (some) invisible characters\n[Symptom]:\nFor example in htop.\r\n[Image: alacritty_bg_example]\r\nEasily visible in this command:\r\n```zsh\r\nyes \"$(seq 16 231)\" | while read i; do printf \"\\x1b[48;5;${i}m\\n\"; sleep .02; done\r\n```\r\nbecause it is entirely invisible in alacritty, but visible in other terminal emulators\n\n[Context/Logs]:\n- Thanks for the report! This should be relatively easy to fix as soon as I can make some time.\n- @jwilm Duplicate issue #123 logged. Hopefully this will provide some extra testing scenarios.\r\n\r\nWould it be possible to point to the general direction where this sort of thing is handled in the alacritty codebase? Maybe as a beginner task that is easy to fix?\n- ... [Middle Discussions Snipped for Brevity] ...\n- Actually the gif I posted above explains this quite nicely. You can see the `linefeed` debug being printed out even though nothing new is really being rendered. Could this bit of code be to do with moving at all - rather than just rendering \"new\" things on screen?\r\n\r\nEDIT: I think it may be easier to see this and find the code responsible with a step through debugger. I'm heading off for a little bit now - but maybe by the time I get back somebody would've beat me to the bug fix :P\r\n\r\nEDIT EDIT: I'm going to throw a guess out there and say that the easiest place to fix this would be the renderer? Although it would be more desirable to fix it further up the chain where it is easier to unit test. Commenting out loud here :)\n- @CarwynNelson ~~I think I've managed to fix it here: [URL]\r\n\r\nWould you mind trying this commit before I make a PR? ðŸ˜ƒ \r\nAt the moment I'm only fixing '\\t' and '\\n' any other white space chars I should fix?\r\n\r\nEDIT: sorry, some issue with normal linefeed"}
{"project_id": "Alacritty", "bug_id": "12", "source_type": "github", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Scrolling breaks in vim with ttymouse=sgr on Linux\n[Symptom]:\nScrolling always goes down regardless of which way the mouse wheel moves.\n"}
{"project_id": "Alacritty", "bug_id": "13", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: [Ranger] Bright colors do not get transferred correctly to bg color\n[Symptom]:\n[Image: ranger]\r\n\r\nUrxvt top, alacritty bottom.\r\n\r\nWhen using ranger with alacritty I noticed that the colors do not match with the ones I get with urxvt. It seems like ranger uses the current color of the file type to draw the background. However in alacritty it doesn't seem to take into account that the bold text changed the color and instead uses the non bright color to draw the bg strip.\n\n[Context/Logs]:\n- There's a config option to draw bold text with bright colors. Please make sure you've got that enabled and that your bright colors are configured differently than normal colors.\n- If you mean `draw_bold_text_with_bright_colors: true` then I have that activated, yes.\r\n\r\nAs you can see in the screenshot, the bold text has a different color than the bg color with alacritty.\r\nHere is my color settings:\r\n```\n# Colors (Tomorrow Night Bright)\r\ncolors:\r\n  # Default colors\r\n  primary:\r\n    background: ' '\r\n... [Log Snipped] ...\n    cyan:    ' '\r\n    white:   ' '\n```\n- Oh, sorry. I misunderstood. Sounds like a bug.\n- @jwilm It seems like the problem is the \"invert\" color terminal code:\r\n```\r\necho -e \"\\e[32mNormal \\e[7mInverted\\e[27m \\e[1mBold \\e[7mInverted Bold\\e[27m\"\r\n```\r\n\r\nPaste that into your terminal and you will see that the inverted bold is not correctly handled. I did take a look at where the bright color computation happens and I think that it happens too late in the pipeline to be able to handle this.\r\n\r\nBecause as it is now, the fg and bg colors are split of long before the bright check happens. So it is impossible to know if the bg color should be bright or not."}
{"project_id": "Alacritty", "bug_id": "14", "source_type": "github", "confidence": 0.9, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: If a job is running in the background, the terminal won't exit\n[Symptom]:\nIf I do, for example, this:\r\n\r\n    xclock & disown\r\n\r\nand then exit, the terminal gets unresponsive and won't exit; and I have to use my WM's \"destroy\" utility to get rid of it.\n\n[Context/Logs]:\n- In this case, `io_thread.join()` in `main.rs` never actually joins. After `join()` is called, we receive one more event of kind `is_hup()` which (as far as I can see) we should respond to by shutting down the event loop. We currently just loop again, which in turn causes the event loop to wait forever and never allow it to join to the main thread. Hilarity ensues.\n- @lukaslueg I'm not seeing the same thing you are\r\n\r\n```rust\r\nif kind.is_hup() {\r\n    break 'event_loop;\r\n}\r\n```\r\n\r\nThis breaks the outermost loop, and the thread function returns.\n- Yes. My goggles, they do nothing.\r\n\r\nBut `join()` never returns..."}
{"project_id": "Alacritty", "bug_id": "15", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: thread 'main' panicked at 'index 50 out of range for slice of length 48', /checkout/src/libcore/slice.rs:578\n[Symptom]:\n```\nRUST_BACKTRACE=1 alacritty\r\nthread 'main' panicked at 'index 50 out of range for slice of length 48', /checkout/src/libcore/slice.rs:578\r\nstack backtrace:\r\n   0:  \r\n   1:  \r\n... [Log Snipped] ...\n  14: __libc_start_main\r\n  15:  \n```\r\n\r\nArch Linux, `alacritty-git`, happens with both rust stable and nightly from rustup.\n\n[Context/Logs]:\n- I am running into the same problem, it seems to crash in glyph loading :\r\n\r\n```\n7:       - core::slice::slice_index_len_fail::h32dba95666464c4a\r\n                        at /buildslave/rust-buildbot/slave/stable-dist-rustc-linux/build/src/libcore/slice.rs:578\r\n   8:       - font::ft::FreeTypeRasterizer::get_rendered_glyph::h4dec5f9eab2e4824\r\n                        at /buildslave/rust-buildbot/slave/stable-dist-rustc-linux/build/src/libcore/slice.rs:709\r\n                        at /buildslave/rust-buildbot/slave/stable-dist-rustc-linux/build/src/libcore/slice.rs:560\r\n... [Log Snipped] ...\n                        at /home/jc/.local/src/alacritty/font/src/ft/mod.rs:85\r\n  11:       - alacritty::display::Display::new::h59275a39cc7a9c46\n```\r\n\r\nI tried to do a `git bisect` on this, and I found that   is responsible. But this commit does not build : \r\n\r\n```\nCompiling font v0.1.0 (file:///home/jc/.local/src/alacritty/font)\r\nerror: this file contains an un-closed delimiter\r\n   --> font/src/ft/list_fonts.rs:587:2\r\n    |\r\n587 | \r\n... [Log Snipped] ...\n\r\nerror: Could not compile `font`.\n```\n- @gutigen, you still can use 28700ed for the moment but I don't know how to tell it to AUR.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Was testing out Alacritty earlier today and ran into this. Built from master (using Rust 1.16.0), running on Arch Linux, and it only happens when I set the font size to something smaller than `10.0` (though the \"breaking point\" appears to be at `9.5` but I initially wanted to set it to `9.0`).\n- You've got what may be a duplicate bug here: #185 \r\n\r\nI'll cross-post some digging I did (seems to have to do with pitch and width calculations, and perhaps width being larger than pitch?):\r\n\r\nI've run into this issue as well (specifically the 'index 68 out of range for slice of length 64' version of the panic). Here is some gdb info at the point where the panic occurs in font/src/mod.rs:\r\n```\n(gdb) next\r\n212             let mut packed = Vec::with_capacity((bitmap.rows() * bitmap.width()) as usize);\r\n(gdb)\r\n213             for i in 0..bitmap.rows() {\r\n(gdb)\r\n... [Log Snipped] ...\nglyph_key =  \r\nhave_recursed = true\n```\r\nNote that pitch = 4, while the difference between start and end (i.e. bitmap.width()) is 8. On our last iteration, we end up here (some variables omitted):\r\n```\r\n(gdb) info locals\r\nstop = 68\r\nstart = 60\r\ni = 15\r\niter = core::ops::Range  {start: 16, end: 16}\r\npitch = 4\r\nbuf = &[u8] {data_ptr:   \"\\000\", length: 64}\r\nc = 127 '\\x7f'\r\n```\r\nNot sure how best to fix it. My stopgap is to replace line 216 in mod.rs with:\r\n```\r\nlet stop = cmp::min(buf.len() as usize, start + bitmap.width() as usize);\r\n```\r\n...but I'm sure there's a better way. Let me know if there is any other info from the trace you need."}
{"project_id": "Alacritty", "bug_id": "16", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Vim theme background colours not rendered properly\n[Symptom]:\nI have the [Link: gruvbox] theme setup for vim but the background colour does not seem to be rendering properly.\r\n\r\nAlacritty on the left vs iterm2 on the right\r\n\r\n<img width=\"1276\" alt=\"screen shot 2017-01-07 at 00 16 59\" src=\"[URL]\n\n[Context/Logs]:\n- I also have colour issues with vim. I use the solarized dark theme in alacritty and vim. Works in st and gnome-terminal.\r\n\r\n\r\n[Image: vimissue]\n- Thanks @d3rrial I will close this issue and link to it in #85.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Same here. #720 fixes it.\n- #720 fixes it for me too. Thank you! It also fixed the basic background color which was not taking into account outside of Vim. Amazing!\r\n\r\nOn the left is before #720. On the right is with #720.\r\n[Image: selection_010]\r\n\r\nOpening a file in Vim without scrolling\r\n[Image: selection_011]\r\n\r\nOpening a file in Vim, then scrolling down\r\n[Image: selection_012]"}
{"project_id": "Alacritty", "bug_id": "17", "source_type": "github", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: \"out of bounds\" crash - access beyond last row?\n[Symptom]:\nRunning the irssi irc client continuously in tmux on a remote machine causes alacritty to always crash after irregular amounts of time.\r\n\r\nThe window has 81 rows, so it seems something is trying to access rows that don't exist.\r\n\r\nAlacritty version is   from github.\r\n\r\nRun as:\r\n```RUST_LOG=full RUST_BACKTRACE=full ./target/debug/deps/alacritty- ```\r\n\r\nFull backtrace:\r\n```\nthread 'main' panicked at 'index out of bounds: the len is 82 but the index is 82', /Users/travis/build/rust-lang/rust/src/libcollections/vec.rs:1552\r\nstack backtrace:\r\n  0:          - std::sys::imp::backtrace::tracing::imp::unwind_backtrace::h884a721e113c3303\r\n  1:          - std::panicking::default_hook::{{closure}}::h7a7d734b2824d103\r\n  2:          - std::panicking::default_hook::h3eb11bd6cbfdc331\r\n... [Log Snipped] ...\n 29:       - _pthread_body\r\n 30:       - _pthread_start\n```\r\n\r\nThe durations after which crashes have occurred:\r\n```\n14936.222349\r\n72115.422882\r\n43475.226691\r\n25231.261642\r\n31821.904172\r\n... [Log Snipped] ...\n29907.619427\r\n15108.094483\n```\r\n\r\nRunning on OSX 10.11.6.\n\n[Context/Logs]:\n- Added\r\n```\ndiff --git a/src/term/mod.rs b/src/term/mod.rs\r\nindex 59cf6ba..7e6ef7c 100644\r\n--- a/src/term/mod.rs\r\n+++ b/src/term/mod.rs\r\n@@ -235,11 +235,20 @@ impl  RenderableCellsIter  {\r\n... [Log Snipped] ...\n \r\n     fn initialize(mut self, cursor_style: CursorStyle) -> Self {\n```\r\nto see what's going on, and this is the result:\r\n```\n27.766116      Running `target/debug/alacritty -v -v -v -d 222 82`\r\n40.905544 in populate_no_cursor: line: 62/82 col: 66/222\r\n44.834063 in populate_no_cursor: line: 63/82 col: 94/222\r\n348.115005 in populate_no_cursor: line: 5/82 col: 8/222\r\n355.532341 in populate_no_cursor: line: 63/82 col: 23/222\r\n... [Log Snipped] ...\n2905.169103   29:       - _pthread_body\r\n2905.169113   30:       - _pthread_start\n```\r\nso the cursor appears at column 0 one line beyond the screen.\r\nHope it helps in tracking the error down.\r\n\r\nThe error is triggered when my network connection has issues and my ssh session - running irssi in tmux - goes down.\r\n\r\nI'll figure out how to set `cursor.line` to `grid.num_lines() - 1` for now to see what happens.\n- An instance with the solution in   has been running for over a week now without any crashes. Before applying the fix, alacritty would crash several times per day.\r\n\r\nIt can be tested with:\r\n```sh\r\ntput csr 10 20; tput cup 25; for ((i=0; i  but not activated. Maybe it can be done with:\r\n```\ndiff\r\ndiff --git a/tests/ref.rs b/tests/ref.rs\r\nindex cea814e..7b820d3 100644\r\n--- a/tests/ref.rs\r\n+++ b/tests/ref.rs\r\n... [Log Snipped] ...\n     tmux_git_log\r\n     tmux_htop\n```"}
{"project_id": "Alacritty", "bug_id": "18", "source_type": "github", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Problem loading fonts\n[Symptom]:\nHello, I am trying to use this font: [Link: ypn envypn]\r\n\r\nMy configuration looks like this:\r\n\r\n```\nyml\r\nfont:\r\n  normal:\r\n    family: ypn envypn \r\n  bold:\r\n... [Log Snipped] ...\n    y: 0.0\r\n  use_thin_strokes: false\n```\r\n\r\nBut i get the following error:\r\n\r\n```bash\r\nthread 'main' panicked at 'index out of bounds: the len is 0 but the index is 0', src/libcollections/vec.rs:1431\r\nnote: Run with `RUST_BACKTRACE=1` for a backtrace.\r\n```\r\n\r\nDid i miss something? I tried to adjust the size and the offset to see if there would be any difference but it's the same, is this a bug?\n\n[Context/Logs]:\n- Hmm, would you mind running this again with `RUST_BACKTRACE=1 alacritty`? Hard to say what the problem is with the short error.\n- I think that this might be fixed with #590. At least for me, I got the same error when I tried to use bitmap fonts before that was merged. But now it seems to be working nicely :)\n- ... [Middle Discussions Snipped for Brevity] ...\n- [Link: Tamzen] used with `Tamzen for Powerline` works with `size: 9.0` but nothing else\n- I've managed to fix this problem in pull request #776, more testers are welcomed."}
{"project_id": "Alacritty", "bug_id": "19", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Prevent decreasing font size beyond the minimal value\n[Symptom]:\nLinux, X11.\r\nExtracted from [URL]\r\n\r\n-----\r\n\r\nI played with holding  Ctrl +/-  and found a silly issue, posting just in case you can immediately think of a simple fix, otherwise I guess it's not worth looking into:\r\n\r\n- Hold  Ctrl + . The value reaches its maximum value (274 in my case) and stays there, pressing  Ctrl +  further has no effect. Pressing  Ctrl -  once reduces font size to 272.\r\n- Now hold  Ctrl - . The value reaches its minimum value (2 in my case), but further presses of  Ctrl -  change the value to 2, again and again. If I press  Ctrl -  10 times after I already reached the minimal value of 2, then pressing  Ctrl +  once will have no effect - the font size will stay at 2. I have to press  Ctrl +  10 times to compensate for my earlier actions, before further presses of  Ctrl +  begin to actually increase the font.\n\n[Context/Logs]:\n- I can confirm this too.\n- I don't believe that #949 fixed the issue described in [URL]\r\n\r\nThe issue is with this call to Atlas#insert. If the font size is increased until it is too big to fit into a single atlas, Atlas#insert will always return an Err. This leads to load_glyph recursing infinitely, since inserting the glyph into an Atlas will never succeed.\n- @Aaron1011 It does actually fix the issue tho. The issue was never that the glyph was too big for a single atlas. Have you tested it out yourself? With #949 the crash doesn't happen anymore when increasing font size. The problem was that the atlas never changed, so there was never a new atlas that was created.\r\n\r\nIn theory you could run into problems with glyphs being too big for a single atlas, but I don't think that's even possible to happen because of gpu restrictions. I've played around with it a bit myself and the max font size goes up to a limit and then just stops. The worst thing I was able to reconstruct was that a few glyphs didn't show up anymore because my gpu driver was spouting errors about textures being too big. I don't think fitting a single glyph into an empty atlas has ever been the actual issue. Or can you still reproduce the issue after #949.\r\n\r\nI did initially play with changing the recursion strategy, but it turned out for me that after I fixed the obvious problem, all the other issues were resolved too."}
{"project_id": "Alacritty", "bug_id": "20", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Invoking Paste/PasteSelection commands in editor (vim, nano) mangles pasted text with existing text\n[Symptom]:\nA screencast comparing gnome-terminal (left) to alacritty (right) will do better than words:\r\n\r\n[Image: alacritty-paste-in-editor-inserts]\r\n\r\nThe key_binding I invoked is visible on the screencast, it is:\r\n\r\n```\r\n- { key: V,        mods: Control|Shift,    action: Paste               }\r\n```\r\n... and I tried `PasteSelection`, with the same results. Am I doing something wrong or is it a bug?\r\n\r\nThis is alacritty master @   vs. gnome-terminal 3.18.3, no tmux, under Ubuntu 16.04.3 LTS.\n\n[Context/Logs]:\n- Interesting bug, I wondered why I haven't seen it before, apparently I can reproduce it in `nano`, but not in `vi`, `vim` or `nvim`. Curious why...\n- I did some testing and if you have `\\n` you get smashed lines, `\\r\\n` you get doubled lines, `\\r` you get correct lines.\r\n\r\nDemonstration\r\n[Link: [Image: thumbnail]]\r\n\r\nNot sure whether this info helps though.\n- ... [Middle Discussions Snipped for Brevity] ...\n- In case it matters (probably not, but it may spare duplication of efforts):\r\n\r\nI verified (on macOS) that `nano` does *not* set alacaritty in bracketed paste mode (`nvim` does).\r\n\r\nAltering `input.rs` to always force bracketed paste does alter the behaviour in `nano`, but unfortunately the new behaviour, too,  is incorrect.\r\n\r\nUse `echo -e '\\e[?2004h'` if you are curious to test it yourself: no need to alter `input.rs` and recompile (see [URL]\n- Apparently, non-bracketed pasting *is* the issue here.\r\n\r\nWhen the \"enter\" key is hit, a `CR` (`^M`) is generated (see [URL]\r\n\r\nIn non-bracketed mode, `LF`s (`^J`) in pasted data have to be replaced with `CR`s in order to simulate keypresses.\r\n\r\nIn non-bracketed mode, applications have no way of distinguishing if data comes from the keyboard or the clipboard, so it seems sensible that a terminal must simulate keypresses.\r\n\r\nTo me it is not 100% clear to what extent a terminal is supposed to do that (ie: whether octets corresponding to other control characters or maybe to bytes with the high bit set should be processed). Maybe data bytes should be interleaved with `^V`s? Or maybe bracketed mode is how pasting is supposed to work and applications that don't use it are at fault?\r\n\r\nAnyhow, replacing `\\r` with `\\n` seems an improvement and it is what [Link: jediterm] does."}
{"project_id": "Alacritty", "bug_id": "21", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Alacritty's `-v` flag does not work\n[Symptom]:\nAlacritty's `-v` flag is used to help with debugging issues and print what is currently going on in the application. This should provide similar output to `RUST_LOG=... alacritty`.\r\n\r\nHowever with recent versions of alacritty, the output of `-v` is completely empty.\r\n\r\nThis should be fixed so that `-v` outputs debug information again. The different levels of this flag (`-v`, `-vv`, `-vvv`) are all broken and should be fixed to recover the original functionality. So `-v` should print minimal debug information and `-vvv` should print everything we have.\n"}
{"project_id": "Alacritty", "bug_id": "22", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Scrolling region regression\n[Symptom]:\nScrolling regions are broken when there's a fixed bar at top _and_ bottom. This is best demonstrated by `htop`.\n\n[Context/Logs]:\n- This is most easily reproduced by opening two buffers in vim using the tabbed layout which should cause a fixed line to appear at top and bottom of screen. Next, hit control up/down in one of the open buffers (assuming it's got lots of lines), and half the screen should remain empty."}
{"project_id": "Alacritty", "bug_id": "23", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Cursor disappears on first column in vim\n[Symptom]:\nMoving the cursor down in vim while on the first column causes the cursor to disappear until moved to the second column of a non-empty line. This is on macOS or Linux, vim or neovim, on the scrollback branch at  .\r\n\r\nReproduce: `vim <(echo 'one\\ntwo\\n\\nthree')` and scroll down.\n\n[Context/Logs]:\n- Thanks for filing the issue! I also noticed a problem of the cursor disappearing when using vim-fugitive and `:Gblame`.\n- This was fixed."}
{"project_id": "Alacritty", "bug_id": "24", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Scrollback: `reset` Still Allows Scrollback\n[Symptom]:\nSystem: X11 on Arch Linux\r\n\r\nUsing the latest scrollback branch, `reset` still allows me to scroll up afterwards, assuming you initially activate the scrollback ability by entering enough text vertically.\r\n\r\nOn a related note, `clear` may also need to be looked at, but I'm unsure if there's a spec for it, as both `xterm` and `urxvt` handle it differently. On `urxvt`, I'm able to scroll back up assuming I've filled the vertical space enough to allow scrolling, while `xterm` seems to never allow me to scroll back, regardless of the amount of text entered.\n"}
{"project_id": "Alacritty", "bug_id": "25", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Scrollback: `reset` Still Allows Scrollback\n[Symptom]:\nSystem: X11 on Arch Linux\r\n\r\nUsing the latest scrollback branch, `reset` still allows me to scroll up afterwards, assuming you initially activate the scrollback ability by entering enough text vertically.\r\n\r\nOn a related note, `clear` may also need to be looked at, but I'm unsure if there's a spec for it, as both `xterm` and `urxvt` handle it differently. On `urxvt`, I'm able to scroll back up assuming I've filled the vertical space enough to allow scrolling, while `xterm` seems to never allow me to scroll back, regardless of the amount of text entered.\n"}
{"project_id": "Alacritty", "bug_id": "26", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: scrollback: thread 'pty reader' panicked at 'attempt to subtract with overflow', src/index.rs:168:28\n[Symptom]:\nalacritty @ scrollback , 8e8ecdd, debug build \r\n\r\n\r\n```\n`\r\nRUST_BACKTRACE=full target/debug/alacritty  -vvvvvvvvvvvvvv\r\n...\r\n[unhandled] execute byte=06\r\n[unhandled] execute byte=1f\r\n... [Log Snipped] ...\n  19:       - _start\r\n  20:                0x0 -  \n````\r\n\r\nin the new debug alacritty window:\r\n````\r\ncat /dev/urandom\r\n[prints random chars]\r\nwait until crash\r\n````\n\n[Context/Logs]:\n- This probably only happens in alacritty verbose mode.\n- I can reproduce it both with and without verbose output. However it only happens in debug mode for me, not in release mode.\r\n\r\nI'll be looking into it, thanks for the report.\n- This bug's origin is [Link: here] and can be reproduced by running `printf '\\e[1000L'`. I'll look into writing up a quick fix."}
{"project_id": "Alacritty", "bug_id": "27", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Invert escape sequence incorrect\n[Symptom]:\nThe command `echo -e \"Normal \\e[101;91mTest \\e[7mInverted\"` will print `Inverted` with the default foreground color as background and the default background color as foreground.\r\nThe correct behavior would be to print it the same as `Test`.\r\n\r\nThis bug is due to the following code:\r\n[URL]\n\n[Context/Logs]:\n- The current behavior _should_ match urxvt. Is this a case we didn't cover?\n- This [Link: script] should check every combination\r\n\r\nEdit: inlined\r\n\r\n```\nsh\r\nprintf \"Fg=Black,     Bg=Background          \\e[30;49mTEST\\e[m\\n\"\r\nprintf \"Fg=Black,     Bg=Black               \\e[30;40mTEST\\e[m\\n\"\r\nprintf \"Fg=Foreground,Bg=Background          \\e[39;49mTEST\\e[m\\n\"\r\nprintf \"Fg=Foreground,Bg=Black               \\e[39;40mTEST\\e[m\\n\"\r\n... [Log Snipped] ...\nprintf \"Fg=Foreground,Bg=White,      Inverse \\e[7;39;47mTEST\\e[m\\n\"\r\nprintf \"Fg=White,     Bg=Foreground, Inverse \\e[7;37;39mTEST\\e[m\\n\"\n```\n- ... [Middle Discussions Snipped for Brevity] ...\n- btw, did you test with transparency? Some of our logic is specifically around handling that properly.\n- I did not, but that's a great point, I'll throw that in too."}
{"project_id": "Alacritty", "bug_id": "28", "source_type": "github", "confidence": 0.7, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: [Regression] broken `htop` display\n[Symptom]:\ncurrently affected master: 715d4f8\r\n\r\nworking revision: 82c9235\r\n\r\n[Image: spectacle qq8577]\r\n\r\nSteps to reproduce:\r\n\r\n1. `htop`\r\n2. wait a few seconds\r\n\r\nbisect:\r\n\r\n  is the first bad commit\r\n```\r\ncommit  \r\nAuthor: Anders Rasmussen  \r\nDate:   Mon Feb 27 19:12:04 2017 +1100\r\n\r\n    Update cell to cursor template when adding a tab.\r\n\r\n:040000 040000     M\tsrc\r\n```\n\n[Context/Logs]:\n- @zetok, I can't reproduce this on the latest master.  Can you retest?  If it's still occurring, are you running this under Linux or Mac?  (Could be render system dependent.)\n- I did test against latest master.\r\n\r\n\r\nLinux.\n- ... [Middle Discussions Snipped for Brevity] ...\n- @maximbaz what's your terminfo file for tmux-256color look like? Seems like it might be declaring a feature that tmux doesn't support.\n- Hm, is this the file `/usr/share/terminfo/t/tmux-256color`? It consists of a bunch of escape sequences, I'm certain I haven't modified it ðŸ™‚\r\n\r\nI've just tried tmux with the default config (where $TERM is `screen`) and the default config with just one override (`set -g default-terminal xterm-256color`, which makes $TERM `xterm-256color`), in both cases I see that same refreshing issue in htop."}
{"project_id": "Alacritty", "bug_id": "29", "source_type": "github", "confidence": 0.75, "label": "Function :: Logic Mismatch (CWE-573)", "llm_input_text": "[Title]: Terminal alternate mode is toggled, not set.\n[Symptom]:\nTry running `tput smcup` or `tput rmcup`. Both do the same thing. **Toggle** alternate mode.\r\n\r\n`smcup` is supposed to activate, and `rmcup` disable.\n"}
{"project_id": "Alacritty", "bug_id": "30", "source_type": "github", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Touchpad scrolling is janky\n[Symptom]:\nI don't know exactly what's going on, but when I scroll with the touchpad it requires me to scroll a lot before it will even register, and then it scrolls a ton at once.\n\n[Context/Logs]:\n- According to hwinfo it's a \"ETPS/2 Elantech Touchpad\", if that helps at all\n- Could you run alacritty with `alacritty --print-events`, try scrolling, and pastebin the log? My initial guess is that we are getting funny data out of winit.\n- ... [Middle Discussions Snipped for Brevity] ...\n- 8a65870 fixes this. I'm unfamiliar both with Rust and with alacritty's structure, so this is indubitably the wrong way to do it (the state is getting passed all over the place, I used terrible names, and it's largely just a result of changing stuff until the compiler was happy without really knowing what I was doing). A review of how I should have done this would be very welcome :)\n- @lheckemann not a new issue, but I don't think a lot of people were likely to encounter it. It requires running x11 on a laptop with a trackpad that generates fractional line deltas in an application that supports scrolling with someone who uses the mouse in terminal. Probably why is hasn't been reported until recently.\r\n\r\nLove that you've put together a patch for it! I would be happy to provide feedback. Would you mind putting up a PR so we can use the GitHub review tool on it?"}
{"project_id": "Closure", "bug_id": "1", "source_type": "google", "confidence": 0.85, "label": "Other", "llm_input_text": "[Title]: JSC_REFERENCE_BEFORE_DECLARE - spurious warnings\n[Symptom]:\nCompile this code with [URL]\r\n--------------------------------------------\r\n// ==ClosureCompiler==\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// @formatting pretty_print\r\n// ==/ClosureCompiler==\r\n\r\nalert(Foo());\r\n\r\nfunction Foo()\r\n{\r\n  return &quot;test&quot;;\r\n}\r\n--------------------------------------------\r\n\r\nResults in a WARNING:\r\n\r\nJSC_REFERENCE_BEFORE_DECLARE: Variable referenced before declaration: Foo\r\nat line 1 character 6\r\nalert(Foo());\r\n\r\nExpect: no WARNING.\r\n\r\nI believe it is quite common and correct for forward references to function\r\ndeclaration in the same scope (global or within a function).  I'm finding\r\nthis type of error is producing a lot of noise in the warning stream when\r\ncompiling larger libraries.\n\n[Context/Logs]:\n- FYI\r\n\r\nthis is fixed in the command-line tool. pending integration into the web service.\n- The webservice has been updated. Pleas verify."}
{"project_id": "Closure", "bug_id": "2", "source_type": "google", "confidence": 0.85, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: Exception thrown from com.google.javascript.jscomp.CollapseProperties.addStubsForUndeclaredProperties\n[Symptom]:\nThe attached javascript file results in a Java exception being thrown when compiling with ADVANCED_OPTIMIZATIONS\r\n\r\n[~/Projects/Music Theory/trunk] # java -jar ./ext/closure-compiler/compiler.jar --js /tmp/musictheory.net/v2/js/core.js --compilation_level \r\nADVANCED_OPTIMIZATIONS\r\njava.lang.RuntimeException: java.lang.IllegalArgumentException\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCompilerRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCompilerRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CompilerRunner.main(Unknown Source)\r\nCaused by: java.lang.IllegalArgumentException\r\n\tat com.google.common.base.Preconditions.checkArgument(Preconditions.java:71)\r\n\tat com.google.javascript.jscomp.CollapseProperties.addStubsForUndeclaredProperties(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.updateObjLitOrFunctionDeclarationAtAssignNode(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.updateObjLitOrFunctionDeclaration(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.collapseDeclarationOfNameAndDescendants(Unknown Source)\r\n\tat com.google.javascript.jscomp.CollapseProperties.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$PassFactoryDelegate.processInternal(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer$NamedPass.process(Unknown Source)\r\n\tat com.google.javascript.jscomp.PhaseOptimizer.process(Unknown Source)\r\n\n...[Description Truncated]...\n\n[Context/Logs]:\n- Workaround:\r\n\r\nIf I add:\r\ngoog.exportSymbol(\"muth\", muth);\r\ngoog.exportSymbol(\"muth.core\", muth.core);\r\ngoog.exportSymbol(\"muth.core.dom\", muth.core.dom);\r\ngoog.exportSymbol(\"muth.core.util\", muth.core.util);\r\n\r\nbefore the other exportSymbol calls, it works.\n- Here's a minimal reduction:\r\ngoog.provide(\"a\");a.b = function(){},a.b()\r\n\r\nThe function call after the comma isn't important, just about any valid expression there \r\nwill trigger the bug."}
{"project_id": "Closure", "bug_id": "3", "source_type": "google", "confidence": 0.85, "label": "Assignment :: Type/Cast Error (CWE-704)", "llm_input_text": "[Title]: Error trying to fold var statement inside an if\n[Symptom]:\nThe following js input to the compiler will raise an exception (I think trying to turn the left hand side \r\nof the expression in the else into a string):\r\n\r\nif (a) { var b = 1; } else { a.b = 1; }\r\n\r\nThe error is raised at, calling the getString on name2:\r\n\r\n[URL]\r\ncompiler/source/browse/trunk/src/com/google/javascript/jscomp/FoldConstants.java#792\n\n[Context/Logs]:\n- Fixed pending integration"}
{"project_id": "Closure", "bug_id": "4", "source_type": "google", "confidence": 0.85, "label": "Build :: Dependency (CWE-1357)", "llm_input_text": "[Title]: Internal compiler error\n[Symptom]:\nWhat steps will reproduce the problem? \n1. Put the following one line of code into a file foo.js (without the quotes): &quot;function({}) {};&quot;\r\n2. Compile it with &quot;java -jar compiler.jar --js=foo.js&quot;.\r\n\r\n What is the expected output? What do you see instead? \nI get an internal compiler error.  The full output is included below.\r\n\r\n What version of the product are you using? On what operating system? \nI'm running version compiler-20091203 on OS X.  (BTW, how am I supposed to know what \r\nversion I am running?)\r\n\r\n----------\r\nfoo.js:1: ERROR - Parse error. destructuring assignment forbidden\r\nfunction({}) {};\r\n^\r\n\r\n1 error(s), 0 warning(s)\r\njava.lang.RuntimeException: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nOBJECTLIT 1 is not a string node\r\n\tat com.google.javascript.jscomp.Compiler.runInCompilerThread(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.Compiler.compile(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCompilerRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCompilerRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CompilerRunner.main(Unknown Source)\r\nCaused by: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nOBJECTLIT 1 is not a string node\r\n\tat com.google.javascript.rhino.Node.getString(Unknown Source)\r\n\tat com.google.javascript.jscomp.CodingConventionAnnotator.visit(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(Unknown Source)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(Unknown Source)\r\n\tat com.google.javascript.jscomp.CodingConventionAnnotator.process(Unknown \r\nSource)\r\n\tat com.google.javascript.jscomp.Compiler.annotateCodingConvention(Unknown \r\nSource)\r\n\tat co\n...[Description Truncated]...\n\n[Context/Logs]:\n- Fix pending integration"}
{"project_id": "Closure", "bug_id": "5", "source_type": "google", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Indexing into an Array with a String shouldn't be an error\n[Symptom]:\nThe JSC_INVALID_GETELEM_INDEX_ERROR is a huge fallacy.  It would be fine if it was a warning, but \r\nas an error it keeps perfectly fine JavaScript from compiling.\r\n\r\nRaphael.js doesn't compile because it uses strings to improve minification, such as [Link: 1,2][push] \r\nwhere the push variable was defined earlier.\r\n\r\nAlso, simple code like this won't compile:\r\n[Link: 1,2][i ? 'push' : 'unshift'];\r\n\r\nAs you can see, these are very valid uses of JavaScript and should *not* throw errors.\n\n[Context/Logs]:\n- I was not able to reproduce this. Can you give more detailed repro steps?\n- oh, now i see it. ya, that's just a bug.\n- ... [Middle Discussions Snipped for Brevity] ...\n- That's good to note, but I didn't write Raphael, I'd just like to compile it.  :-)\r\n\r\nThanks a lot for the quick response!\n- this should be fixed as of r34. (i'll mark it fixed when we cut a real release)."}
{"project_id": "Closure", "bug_id": "6", "source_type": "google", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: @inheritDoc doesn't play well with interfaces\n[Symptom]:\nIf I use interface inheritance with @inheritDoc, the compiler doesn't \r\nknow about the types used in the method signature.\r\n\r\nSample code:\r\n\r\n/**\r\n * Interface\r\n * @interface\r\n */\r\nA = function() {};\r\n\r\n/**\r\n * @param {string} a\r\n */\r\nA.prototype.foo = function(a) {};\r\n\r\n/**\r\n * @constructor\r\n * @implements {A}\r\n */\r\nB = function() {};\r\n\r\n/**\r\n * @inheritDoc\r\n */\r\nB.prototype.foo = function(a) {\r\n  alert(a.substring(0));   //  ERROR - could not determine the type of \r\nthis expression\r\n};\n\n[Context/Logs]:\n- I should add, this only shows up with --report_unknown_types turned on.\n- should be fixed at head\n- ... [Middle Discussions Snipped for Brevity] ...\n- This is not fixed. Nicolas, could you reopen the bug?\n- If you think this is not fixed, please re-open a bug on github with a repro case. The example here works if you declare A and B rather than leave them as global variables. (You can try it on appspot.)\r\n\r\n/** @interface */\r\nvar A = function() {};\r\n\r\n/** @param {string} a */\r\nA.prototype.foo = function( a) {};\r\n\r\n/**\r\n* @constructor\r\n* @implements {A}\r\n*/\r\nvar B = function() {};\r\n\r\n/** @inheritDoc */\r\nB.prototype.foo = function( a) {\r\nalert(a.substring(0));\r\n};\r\n\r\nvar inst = new B();\r\ninst.foo(1);\r\n\r\n\r\nThe varcheck pass of the compiler, which runs before type checking, warns about global variables in the code."}
{"project_id": "Closure", "bug_id": "7", "source_type": "google", "confidence": 0.7, "label": "Other", "llm_input_text": "[Title]: Ant CompileTask patch\n[Symptom]:\nShoud be a &quot;review request&quot; issue, but seems that I cannot create one since\r\nit needs a valid branch path.\r\n\r\nPurpose of code changes:\r\nTo be able to use Closure Compiler in Ant. Can also be used in other\r\nsystems like Gradle, Buildr and Maven. It's not feature complete, but it's\r\na start. \r\n\r\nAdded a svn patch that includes two java files. Also you need to have\r\nant.jar (1.7.1 but works with older) into the lib directory to compile.\r\n\r\nAn example build.xml script is included.\n\n[Context/Logs]:\n- Cool!\r\n\r\nSo before we start, there's one bit of legal stuff we need to do. We need you to sign a \r\ncontributor license agreement. This agreement basically says \"I own the copyright on \r\nthis code, and it's ok if closure compiler uses it\".\r\n\r\n[URL]\r\n\r\nYou can fill it out online or by mail. Please let me know if anything on that page is \r\nunclear, or if you have any questions about it.\n- Done. Filled out online.\n- ... [Middle Discussions Snipped for Brevity] ...\n- OK, I put the code review up at\r\n[URL]\r\nI haven't figured out how to test it yet, but am willing to take patches and/or \r\nsuggestions on how to do that.\r\n\r\nSo far, I just put the Apache License on it and reformatted to match the style in the \r\nrest of the codebase.\n- Should be in as of revision 65."}
{"project_id": "Closure", "bug_id": "8", "source_type": "google", "confidence": 0.9, "label": "Function :: Access Control (CWE-284)", "llm_input_text": "[Title]: eval function replaced with eval operator\n[Symptom]:\nThe inputs\r\n\r\nwindow['a'] = 'Hello, World!';\r\nwindow['f'] = function f() {\r\n  var a = 'Howdy!';\r\n  var ev = eval;\r\n  ev('alert(a)');\r\n};\r\n\r\nand\r\n\r\nwindow['a'] = 'Hello, World!';\r\nwindow['f'] = function f() {\r\n  var a = 'Howdy!';\r\n  eval('alert(a)');\r\n};\r\n\r\nin advanced mode both compile to\r\n\r\nwindow.a=&quot;Hello, World!&quot;;window.f=function(){eval(&quot;alert(a)&quot;)};\r\n\r\n\r\nbut according to section  .1 of EcmaScript 5 the first should alert \r\n&quot;Hello, World!&quot;, and the second should alert &quot;Howdy!&quot;.\r\n\r\n .1 Direct Call to Eval \r\nA direct call to the eval function is one that is expressed as a \r\nCallExpression that meets the following two \r\nconditions: \r\nThe Reference that is the result of evaluating the MemberExpression in the \r\nCallExpression has an environment \r\nrecord as its base value and its reference name is &quot;eval&quot;. \r\nThe result of calling the abstract operation GetValue with that Reference as \r\nthe argument is the standard built- \r\nin function defined in  . \r\n\r\nAccording to ES5, since the name of the function called in the input is &quot;ev&quot; \r\nthe call has the effect of binding &quot;a&quot; in the global environment, whereas \r\nwhen the name of the function called is &quot;eval&quot;, &quot;a&quot; is bound to the local \r\nvariable.\r\n\r\nChanging a use of the eval function to the eval operator is problematic \r\nunless you can prove that the body of the evaled text does not contain any \r\nreferences to non-global variables.\n\n[Context/Logs]:\n- tangentially, does anyone keep a master table of which js interpreters implement which \r\nparts of ES5, just so that people know how to repro issues like this?\n- This thread is relevant to ES5 implementations:\r\n[URL]\n- ... [Middle Discussions Snipped for Brevity] ...\n- Ah.\r\n\r\n(0, eval)(foo) does something quite similar to (new Function(foo))() with a few \r\ndifferences.  So not having the eval function does not severely limit the set of \r\nexpressible programs.\n- should be fixed in r79"}
{"project_id": "Closure", "bug_id": "9", "source_type": "google", "confidence": 0.9, "label": "Assignment :: Type/Cast Error (CWE-704)", "llm_input_text": "[Title]: Incorrect type annotations in window.setTimeout extern\n[Symptom]:\ndmw/third_party/closure-library/closure/goog/net/jsonp.js:313: WARNING -\r\nFunction goog.global.setTimeout: called with 2 argument(s). Function\r\nrequires at least 3 argument(s) and no more than 3 argument(s).\r\n  goog.global.setTimeout(function() {\r\n\r\n\r\nSince:\r\n\r\n/**\r\n * @param {Function|string} callback\r\n * @param {number} delay\r\n * @param {*} var_args\r\n * @return {number}\r\n * @see [URL]\r\n */\r\nfunction setTimeout(callback, delay, var_args) {}\r\n\r\n\r\nProbably wants to be &quot;{...*}&quot; on line 4.\r\n\r\n\r\n\r\n What version of the product are you using? On what operating system? \n\r\nHEAD\r\n\r\n\r\n Please provide any additional information below.\n\n[Context/Logs]:\n- thanks for the report. this should be fixed at revision 91, courtesy of John.\n- Issue 135 has been merged into this issue."}
{"project_id": "Closure", "bug_id": "10", "source_type": "google", "confidence": 0.75, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: Inheritance not detected when prototype directly assigned\n[Symptom]:\nGiven the following input JS:\r\n//--------------------------\r\n/**\r\n* @constructor\r\n*/\r\nfunction SuperClass () {\r\n}\r\n\r\nSuperClass.prototype.CustomMethod = function() {\r\n}\r\n\r\n/**\r\n* @constructor\r\n* @extends {SuperClass}\r\n*/\r\nfunction SubClass () {\r\n}\r\nSubClass.prototype = new SuperClass();\r\n\r\n/**\r\n* @override\r\n*/\r\nSubClass.prototype.CustomMethod = function() {\r\n\tthis.myProperty = &quot;value&quot;;\r\n}\r\n\r\nwindow['SubClassInstance'] = new SubClass();\r\n//---------------------------------\r\n\r\nWhen compiled with ADVANCED_OPTIMIZATIONS produces the warning:\r\nJSC_UNKNOWN_OVERRIDE: property CustomMethod not defined on any superclass\r\nof SubClass\r\n\r\nThis error has been reproduced in both the downloaded compiler and the\r\nCompiler Service UI.\r\n\r\nWhen the prototype assignment is wrapped in a function, it is correctly\r\ndetected. See below:\r\n//---------------------------------\r\nfunction inherit(Child, Parent) {\r\n    Child.prototype = new Parent();\r\n} \r\ninherit(SubClass, SuperClass);\r\n//---------------------------------\n\n[Context/Logs]:\n- This issue was closed by revision r93.\n- This issue is not fixed. The above code still generates the warning when the\r\nprototype assignment is not inside a function.\n- The test case in r93 disagrees. Can you give a repro case of the warning that you see?\n- Further testing shows the bug only comes into play in very specific circumstances. It\r\nrequires an extern file as well as aliasing the type with @typedef.\r\n\r\nAttached are the 2 files as simple as I can get them and still get the error.\r\n\r\nI should mention that the compiler I'm testing in was built about 2 hours ago against\r\nthe latest SVN source. I also enabled the ambiguateProperties and\r\ndisambiguateProperties passes."}
{"project_id": "Closure", "bug_id": "11", "source_type": "google", "confidence": 0.85, "label": "Checking :: Input Validation (CWE-20)", "llm_input_text": "[Title]: externs/es3.js missing optional flags for Date.UTC - causes warning in closure library.\n[Symptom]:\nUsing closure library, I see:\r\n\r\nclosure-library/closure/goog/i18n/timezone.js:209: WARNING - Function \r\nDate.UTC: called with 5 argument(s). Function requires at least 7 \r\nargument(s) and no more than 7 argument(s).\r\n  var timeInMs = Date.UTC(date.getUTCFullYear(), date.getUTCMonth(),\r\n                         ^\r\n\r\nMozilla documentation says all arguments but year and month are optional.\r\nAdding @param {number=} for the others should do the trick. I do not know if \r\nthe method would take strings, too.\n\n[Context/Logs]:\n- This issue was closed by revision r98."}
{"project_id": "Closure", "bug_id": "12", "source_type": "google", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Array Join Munged Incorrectly\n[Symptom]:\n$.fn.hasClass = function(selector) {\r\n\treturn ( this.length &gt; 0 ? \r\n\t\t\t\t!( ( ['', this[0].className, ''].join(' ') ).indexOf( ['', selector, \r\n''].join(' ') ) == -1 )\r\n\t\t\t\t: false );\r\n};\r\n\r\nmunges into\r\n\r\n$.fn.hasClass=function(a){return this.length&gt;0?\r\n(&quot;&quot;+this[0].className).indexOf(&quot;&quot;+a)!=-1:false};\r\n\r\nwhich is not identical. Looks like there might be an issue with join and ' '.\n\n[Context/Logs]:\n- A simpler example would be:\r\nvar a = ['', 'a', ''].join(' ');\r\n\r\nwhich evaluates to\r\n\" a \"\r\n\r\nBut the compiler converts the code to \r\nvar a=\"a \";\n- I fixed it last night. It'll be pushed out in the next release.\n- This issue was closed by revision r99."}
{"project_id": "Closure", "bug_id": "13", "source_type": "google", "confidence": 0.99, "label": "Documentation :: Wrong Comments (CWE-1116)", "llm_input_text": "[Title]: Typos in externs/html5.js\n[Symptom]:\nLine 354:\r\nCanvasRenderingContext2D.prototype.globalCompositingOperation;\r\n\r\nLine 366:\r\nCanvasRenderingContext2D.prototype.mitreLimit;\r\n\r\nThey should be globalCompositeOperation and miterLimit, respectively.\n\n[Context/Logs]:\n- thanks for catching that. i'll fix it on monday when i'm near a machine that i can edit \r\ncode from.\n- This issue was closed by revision r113."}
{"project_id": "Closure", "bug_id": "14", "source_type": "google", "confidence": 0.95, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Compiler gives false error with respect to unreachable code\n[Symptom]:\nTry compiling the following in the Closure Compiler UI:\r\n\r\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\nfunction instanceOf(value, type) {\r\n  try {\r\n    // first try built-in test -- if it succeeds, we're golden.\r\n    if (value instanceof type) {\r\n      return true;\r\n    }\r\n  } catch (exception) {\r\n    if (exception instanceof TypeError) {\r\n      throw exception; // indicates that &quot;type&quot; is not a type\r\n    }\r\n    // Otherwise, assume the exception was caused by \r\n    // the Firefox 1.0.3 bug.  Work around it.\r\n    return (type === Object);\r\n  }\r\n}\r\n\r\nThe Compiler issues the following warning:\r\n\r\nJSC_UNREACHABLE_CODE: unreachable code at line 7 character 0\r\n  } catch (exception) {\r\n\r\nThis code is from a Firefox extension (Chickenfoot) where (at least\r\nhistorically) calling instanceof in this manner could throw a security\r\nexception (or something else, I forget what -- Chickenfoot has been around\r\nsince Firefox 1.0) which is why the catch blocks is there and is indeed\r\nreachable.\n\n[Context/Logs]:\n- If anyone is in a similar situation, I was able to do the following as a workaround:\r\n\r\n// ==ClosureCompiler==\r\n// @compilation_level SIMPLE_OPTIMIZATIONS\r\n// @output_file_name default.js\r\n// ==/ClosureCompiler==\r\n\r\nfunction instanceOf(value, type) {\r\n  var result;\r\n  try {\r\n    // first try built-in test -- if it succeeds, we're golden.\r\n    result = value instanceof type;\r\n  } catch (exception) {\r\n    if (exception instanceof TypeError) {\r\n      throw exception; // indicates that \"type\" is not a type\r\n    }\r\n    // Otherwise, assume the exception was caused by \r\n    // the Firefox 1.0.3 bug.  Work around it.\r\n    return (type === Object);\r\n  }\r\n  return result;\r\n}\n- Alan, you should be able to fix this pretty easily. Mind taking a look?\n- Fixed and checked in.\r\n\r\nThe fix should be available in the next release.\n- This issue was closed by revision r114."}
{"project_id": "Closure", "bug_id": "15", "source_type": "google", "confidence": 0.85, "label": "Assignment :: Type/Cast Error (CWE-704)", "llm_input_text": "[Title]: compiler assumes that 'arguments' can be shadowed\n[Symptom]:\nThe code:\r\nfunction name() {\r\n   var arguments = Array.prototype.slice.call(arguments, 0);\r\n}\r\n\r\ngets compiled to:\r\nfunction name(){ var c=Array.prototype.slice.call(c,0); }\r\n\r\nThanks to tescosquirrel for the report.\n\n[Context/Logs]:\n- Original report at:\r\n[URL]\r\ndiscuss/browse_thread/thread/ #\n- This issue was closed by revision r117."}
{"project_id": "Closure", "bug_id": "16", "source_type": "google", "confidence": 0.7, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: Update to Google Maps API V3 Extern\n[Symptom]:\nNew release today:\r\n[URL]\r\n\r\nI'll be on vacation all next week, so don't wait on me for responses.\n\n[Context/Logs]:\n- Just found a change I missed. Use this patch instead.\n- Someone emailed me another change yesterday. In case you've already started the code\r\nreview, the only difference is the google.maps.Map.prototype.mapTypes declaration was\r\nchanged to @type {google.maps.MVCObject}\n- I created the code review at\r\n[URL]\r\nAlan, do you have time to take a look?\n- This issue was closed by revision r124."}
{"project_id": "Closure", "bug_id": "17", "source_type": "google", "confidence": 0.85, "label": "Build :: Dependency (CWE-1357)", "llm_input_text": "[Title]: fails to build from source without binary blobs\n[Symptom]:\nThe closure-compiler source contains compiled classes. If these are removed\r\nthe build fails:\r\n\r\n$ rm --force lib/google_common_deploy.jar\r\nlib/google_compiled_protos_deploy.jar lib/junit.jar\r\nlib/libtrunk_rhino_parser_jarjared.jar tools/FlagProcessorFactory_deploy.jar\r\n$ ant jar\r\n    [...]\r\n    [javac] [...]: package com.google.common.annotations does not exist\r\n    [javac] [...]: package com.google.common.base does not exist\r\n    [javac] [...]: package com.google.common.collect does not exist\r\n    [javac] [...]: package com.google.common.flags does not exist\r\n    [javac] [...]: package com.google.common.io does not exist\r\n    [javac] [...]: package com.google.javascript.jscomp.mozilla.rhino does\r\nnot exist\r\n    [...]\r\n\r\nThanks,\r\n\r\nNicholas\n\n[Context/Logs]:\n- Closure Compiler depends on 2 major libraries:\r\n\r\nGuava\r\n[URL]\r\n\r\nand Rhino\r\n[URL]\r\n\r\nThe maintainers of those libraries asked us to include the compiled JARs, and not the \r\nsource code, in our repository. (We depend on some new things in Rhino trunk, and \r\nthey aren't in any compiled release). I'll try to clarify this more in the README.\r\n\r\nIs there some other reason you need to remove the binary blobs?\n- Hi, thanks for your comments.\r\n\r\n\r\nI intend to package this software for the Debian project. This will require the full\r\nsource for the compiler and all its dependencies, and all scripts necessary to build\r\nfrom source. As I understand it, closure-compiler depends on guava-libraries, which\r\ndepends on google-collections, which depends on google-web-toolkit, which depends on\r\n\"prerequisite tools and third-party libraries\", which includes a lot of precompiled\r\nclasses and shared objects.\r\n\r\nThanks,\r\n\r\nNicholas\n- ... [Middle Discussions Snipped for Brevity] ...\n- Neither of those are complicated classes. The Guava people told me months ago that they \r\nwill be open-sourced \"asap\". I've since lost faith in their definition of \"soon\". :(\r\n\r\n(I don't actively look at what's in their public repository; I just look at their \r\nprivate one.)\r\n\r\nI'll see if I can get StringUtil and Tracer out today. flags may be a bit more messy...\n- This issue was closed by revision r128."}
{"project_id": "Closure", "bug_id": "18", "source_type": "google", "confidence": 0.85, "label": "Checking :: Missing Check (CWE-754)", "llm_input_text": "[Title]: Override annotations in default \texterns\n[Symptom]:\nWhen compiling a JavaScript file with enabled override annotation check\r\nthen the compiler complains about some missing annotations in the default\r\nexterns file.\r\n\r\nI have attached a patch which corrects this.\n\n[Context/Logs]:\n- This issue was closed by revision r138."}
{"project_id": "Closure", "bug_id": "19", "source_type": "google", "confidence": 0.85, "label": "Assignment :: Type/Cast Error (CWE-704)", "llm_input_text": "[Title]: $super is replaced when it should not be replaced\n[Symptom]:\nWhat steps will reproduce the problem? \n1. Have javascript using prototype's $super\r\n2. Compile with advanced_optimizations\r\n3. See that $super is replaced by for example $super$$4\r\n\r\n What is the expected output? What do you see instead? \n$super should not be renamed as it is used by prototype.\r\n\r\n What version of the product are you using? On what operating system? \nLatest from svn.\r\n\r\n Please provide any additional information below. \nPersonally I made a quick fix in MakeDeclaredNamesUnique.java line 79:\r\nif (t.getCompiler().getCodingConvention().isExported(name)) { continue; }\r\nThis fixed it for me, but not sure if that's the right place or method to\r\nsolve this, as I am unfamiliar with the project.\n\n[Context/Logs]:\n- Quick question: Are you building from the command line, or using Closure Compiler programmatically?  What \r\ndoes your command line to the compiler look like?\n- I am building from the command line, here's what the command looks like:\r\n\r\njava -jar /Users/jochen/closure/build/compiler.jar --compilation_level\r\nADVANCED_OPTIMIZATIONS --js share.js --module share:1 --js main.js --module main:1\r\n--js recording.js --module recording:1 --js comments.form.js --module commentsform:1\r\n--js facebook.share.js --module facebookshare:1 --externs prototype.js\r\n--module_output_path_prefix /Users/jochen/ruby/karaoke/public/javascripts/compiled/\n- ... [Middle Discussions Snipped for Brevity] ...\n- To make my comment clear, one of the points of the normalization is to make it easier\r\nfor passes if the \"x\" they saw is the same \"x\" they saw earlier (without needing to\r\ntrack scope).  This makes things much easier for code motion because you don't need\r\nto worry about masking a variable of the same name.  If you change it \"$super\" is not\r\nunique the results would be unpredictable. After renaming it doesn't matter if the\r\nname is unique as the normalization is expected as renaming by design creates as many\r\nnon-unique names as possible.\n- This issue was closed by revision r139."}
{"project_id": "Closure", "bug_id": "20", "source_type": "google", "confidence": 0.9, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Invalid JSC_DETERMINISTIC_TEST\n[Symptom]:\nWhat steps will reproduce the problem? \n\r\n1. Compile following code:\r\n\r\n// ==ClosureCompiler==\r\n// @output_file_name default.js\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// ==/ClosureCompiler==\r\n\r\nvar t = null;\r\n\r\nwindow.test = function()\r\n{\r\n    if (t != null)\r\n    {\r\n       t = null;\r\n    }\r\n\r\n    t = 1;\r\n};\r\n\r\n What is the expected output? What do you see instead? \n\r\nCode should be compiled without warnings, but I see \r\n&quot;JSC_DETERMINISTIC_TEST: condition always evaluates to false&quot;.\n\n[Context/Logs]:\n- thanks for the report.\r\n\r\nthe immediate work around is to have a @type {?number} annotation on the global \r\nvariable.\n- This issue was closed by revision r142."}
{"project_id": "Closure", "bug_id": "21", "source_type": "google", "confidence": 0.9, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Invalid JSC_DETERMINISTIC_TEST\n[Symptom]:\nWhat steps will reproduce the problem? \n\r\n1. Compile following code:\r\n\r\n// ==ClosureCompiler==\r\n// @output_file_name default.js\r\n// @compilation_level ADVANCED_OPTIMIZATIONS\r\n// ==/ClosureCompiler==\r\n\r\nvar t = null;\r\n\r\nwindow.test = function()\r\n{\r\n    if (t != null)\r\n    {\r\n       t = null;\r\n    }\r\n\r\n    t = 1;\r\n};\r\n\r\n What is the expected output? What do you see instead? \n\r\nCode should be compiled without warnings, but I see \r\n&quot;JSC_DETERMINISTIC_TEST: condition always evaluates to false&quot;.\n\n[Context/Logs]:\n- thanks for the report.\r\n\r\nthe immediate work around is to have a @type {?number} annotation on the global \r\nvariable.\n- This issue was closed by revision r142."}
{"project_id": "Closure", "bug_id": "22", "source_type": "google", "confidence": 0.85, "label": "Build :: Dependency (CWE-1357)", "llm_input_text": "[Title]: Redefinition of a function in third party code can be miscompiled\n[Symptom]:\nWhat steps will reproduce the problem? \n1. Run this code snippet and observe that it doesn't raise an error:\r\n\r\nfunction assert(b) {if (!b) throw &quot;error&quot;}\r\n\r\nassert(f() === 1)\r\nvar f = function() {return 2;}\r\nassert(f() === 2)\r\n\r\nfunction f() {return 1;}\r\n\r\n2. Compile it as third_party:\r\n3. Observe that the first definition of f has been changed from an assignment to a declaration, and that the code now raises an error.\r\n\r\n What version of the product are you using? On what operating system? \nr8\r\n\r\n Please provide any additional information below. \n\r\nThis bug is originally from a blog comment[1], I don't know if it has hit anyone in the wild yet.\r\n\r\n1) [URL]\n\n[Context/Logs]:\n- CollapseAnonymousFunctions has been turned off for simple mode.  This problem surfaced \r\nas a result of allowing redefinitions of functions.\r\n\r\nTo reproduce this, use the webservice or the command-line with the --third_party \r\noption.\n- Issue 39 has been merged into this issue.\n- I think the thing to do, is modify the scope builder so that the named function is\r\nthe declaration.  The \"var\" from \"var f\" should be removed anyway.\n- This issue was closed by revision r148."}
{"project_id": "Closure", "bug_id": "23", "source_type": "google", "confidence": 0.9, "label": "Build :: Configuration (CWE-16)", "llm_input_text": "[Title]: --process_closure_primitives can't be set to false\n[Symptom]:\nWhat steps will reproduce the problem? \n1. compile a file with &quot;--process_closure_primitives false&quot;\r\n2. compile a file with &quot;--process_closure_primitives true&quot; (default)\r\n3. result: primitives are processed in both cases.\r\n\r\n What is the expected output? What do you see instead? \nThe file should still have its goog.provide/require tags in place.\r\nInstead they are processed.\r\n\r\n What version of the product are you using? On what operating system? \ncurrent SVN (also tried two of the preceding binary releases with same \r\nresult)\r\n\r\n Please provide any additional information below. \nFlag can't be set to false due to a missing &quot;else&quot; in the command-line \r\nparser.\n\n[Context/Logs]:\n- This issue was closed by revision r152."}
{"project_id": "Closure", "bug_id": "24", "source_type": "google", "confidence": 0.85, "label": "Other", "llm_input_text": "[Title]: Exception in FoldConstants while inspect if statements.\n[Symptom]:\nHere is the test case:\r\n\r\nfunction foo() {\r\n      if(sections.length != 1)children[i] = 0;\r\n      else var selectedid = children[i]\r\n} \r\n\r\nHere is the stack trace:\r\n\r\n23: java.lang.RuntimeException: INTERNAL COMPILER ERROR.\r\nPlease report this problem.\r\nGETELEM 2 is not a string node\r\n  Node: Input_0:2:6\r\n      if(sections.length != 1)children[i] = 0;\r\n  Parent: Input_0:1:15\r\nfunction foo() {\r\n\r\n\tat com.google.javascript.rhino.Node.getString(Node.java:847)\r\n\tat com.google.javascript.jscomp.FoldConstants.tryMinimizeIf(FoldConstants.java:813)\r\n\tat com.google.javascript.jscomp.FoldConstants.visit(FoldConstants.java:275)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:463)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:456)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseFunction(NodeTraversal.java:490)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:448)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:456)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverseBranch(NodeTraversal.java:456)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(NodeTraversal.java:245)\r\n\tat com.google.javascript.jscomp.NodeTraversal.traverse(NodeTraversal.java:412)\r\n\tat com.google.javascript.jscomp.FoldConstants.process(FoldConstants.java:87)\n\n[Context/Logs]:\n- Fixed pending integration"}
{"project_id": "Closure", "bug_id": "25", "source_type": "google", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Internet Explorer runtime error after compilation.\n[Symptom]:\nWhat steps will reproduce the problem? \nSee attached HTML file in IE6+ (does not work in IE8 unless Compatibility View is turned *on* for \r\nsome reason).\r\n\r\n What is the expected output? What do you see instead? \nExpected output is on the left-hand side of the page (it is generated by the raw source). Google \r\nClosure's output is on the right-hand side of the page.\r\n\r\n What version of the product are you using? On what operating system? \nI downloaded compiler-latest.zip today (Nov. 24, 2009, ~ 12:00 PM EST)\r\n\r\n Please provide any additional information below. \nThere is a variable called &quot;threshold&quot; which is used to generate an array of arrays in the attached \r\nHTML file. If it is a small number, IE seems to pass arrays into the sort method (sorting an array \r\nof arrays) by value like all other browsers do. But when threshold is large enough (on my \r\nmachine that happens around 250) IE starts passing the arrays in by value. Google Closure \r\ncompiler has changed my original source from making local copies to modifying the arguments \r\nbeing passed into the sort comparator ... but as a result of this IE behavior the Closure compiled \r\ncode breaks.\n\n[Context/Logs]:\n- So after looking into this some more, I've learned that arrays are always passed by reference, but that only \r\nmeans you can change attributes and individual items in an array. So for example:\r\n\r\nvar a = [1, 2, 3, 4];\r\nvar f = function(x){x = null;};\r\nf(a);\r\n// the value of a will remain [1, 2, 3, 4]\r\n// but if instead:\r\nvar g = function(x){x[0] = null;};\r\ng(a);\r\n// the value of a is now [null, 2, 3, 4]\r\n\r\nIn the attached example, the Google Closure compiled version is akin to the function f above, which means \r\nthat the value of the arrays should *not* be changing. In IE, if the threshold is set high enough, however, they \r\ndo indeed change. So the original report may not be accurate, but this is a real issue.\n- There is definitely something odd occurring here, running it under the debugger with \r\nIE7, it reports \"Number expected\".\r\n\r\nAdding a \"Debug.writeln(\"blah\")\" in the \"right\" spot and the problem goes away:\r\n    var g_test=function(f,c){\r\n        var g=[\"aaaaaa\",\"bbbbbb\"];\r\n        c=(function(a,b){\r\n          for(var d=[],e=0;e b)});\r\n        f.innerHTML=typeof c[0]+\" \"+c.join(\" --- \")\r\n     };\n- ... [Middle Discussions Snipped for Brevity] ...\n- Perhaps a @nocoalesce JSDoc tag?\n- fixed by r171"}
{"project_id": "Closure", "bug_id": "26", "source_type": "google", "confidence": 0.9, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: @define does not support strings\n[Symptom]:\n$ java -jar compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS --define='test.VERSION=1.0.0' --js_output_file \r\ntest-min.js --js test.js\r\njava.lang.RuntimeException: --define flag syntax invalid: test.VERSION=1.0.0\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.createDefineReplacements(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.initOptionsFromFlags(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.createOptions(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.doRun(Unknown Source)\r\n\tat com.google.javascript.jscomp.AbstractCommandLineRunner.run(Unknown Source)\r\n\tat com.google.javascript.jscomp.CommandLineRunner.main(Unknown Source)\r\n\r\ntest.js:\r\n/** @define {string} */\r\ntest.VERSION = &quot;&quot;;\r\n\r\n\r\nI have tried both of these:\r\n--define='test.VERSION=1.0.0'\r\n--define='test.VERSION=&quot;1.0.0&quot;'\r\n\r\nBoth generate the same error.\n\n[Context/Logs]:\n- What OS and shell are you using? Can you escape your quotes? Something like this:\r\n\r\njava -jar compiler.jar --compilation_level ADVANCED_OPTIMIZATIONS\r\n--define=\\'test.VERSION=1.0.0\\' --js_output_file\n- These work:\r\n--define=test.VERSION=\\'1.0.0\\'\r\n--define=\"test.VERSION='1.0.0'\"\r\n\r\nI didn't expect it to require single-quotes instead of double-quotes around the \r\nstring. ;-)\n- This issue was closed by revision r173.\n- Thanks for the update to support both single and double quotes. ;-)"}
{"project_id": "Closure", "bug_id": "27", "source_type": "google", "confidence": 0.95, "label": "Documentation :: Wrong Comments (CWE-1116)", "llm_input_text": "[Title]: '\"--help\" is not a valid option'\n[Symptom]:\nWhat steps will reproduce the problem? \n1. java -jar compiler.jar --help\r\n\r\n What is the expected output? What do you see instead? \nExpected help text. Help text about the flags are displayed, but initially \r\ncompiler claims: '&quot;--help&quot; is not a valid option'.\r\n\r\n What version of the product are you using? On what operating system? \nClosure 20100330 release, Windows Vista.\r\n\r\n Please provide any additional information below. \nI also noticed the structure of the help text is also different from \r\nprevious releases(?). Also &quot;--help&quot; is not listed among the flags.\r\n\r\n// Fredrik\n\n[Context/Logs]:\n- This issue was closed by revision r175."}
{"project_id": "Closure", "bug_id": "28", "source_type": "google", "confidence": 0.9, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: incorrect extern annotation for Option\n[Symptom]:\nWhat steps will reproduce the problem? \n1. var opt = new Option('hello', 1); // or some other nr of params != 4\r\n2. compile\r\n\r\nWhat is the expected output? \r\nNo warning. All parameters in the constructor are optional.\r\n\r\nWhat do you see instead?\r\n&quot;WARNING - Function Option: called with 2 argument(s). Function requires at \r\nleast 4 argument(s) and no more than 4 argument(s).&quot;\r\n\r\n What version of the product are you using? On what operating system? \nWindows Vista. Closure 20100330 release\r\n\r\n Please provide any additional information below. \nsee for example [URL]\r\n\r\n// Fredrik\n\n[Context/Logs]:\n- Patch. this is the new annotation that should be attached to Option in the \r\nexterns/deprecated.js file.\r\n-------------------------------\r\n/**\r\n * @param {string=} opt_text\r\n * @param {string=} opt_value\r\n * @param {boolean=} opt_defaultSelected\r\n * @param {boolean=} opt_selected\r\n * @constructor\r\n * @extends {Element}\r\n */\r\nfunction Option(opt_text, opt_value, opt_defaultSelected, opt_selected) {}\r\n--------------------------------------\n- This issue was closed by revision r178.\n- thanks! don't worry, we got it. it just got batched with some other changes."}
{"project_id": "Closure", "bug_id": "29", "source_type": "google", "confidence": 0.95, "label": "Documentation :: Wrong Comments (CWE-1116)", "llm_input_text": "[Title]: Unnesesary parenthese inserted\n[Symptom]:\nSteps:\r\nIn simple mode compile:\r\n  a?b=1:c=2\r\n\r\nThe output will be:\r\n  a?(b=1):(c=2)\r\n\r\nThis is a very common pattern due to the translation of &quot;if&quot; to &quot;?:&quot; by the\r\ncompiler.\n\n[Context/Logs]:\n- Fixed in r243."}
{"project_id": "Closure", "bug_id": "30", "source_type": "google", "confidence": 0.9, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: var_args not portable for setTimeout and setInterval\n[Symptom]:\n(reposting as suggested from discuss)\r\n\r\nCurrently externs/window.js has setTimeout as\r\n\r\n/**\r\n * @param {Function|string} callback\r\n * @param {number} delay\r\n * @param {...*} var_args\r\n * @return {number}\r\n * @see [URL]\r\n */\r\nfunction setTimeout(callback, delay, var_args) {}\r\n\r\nsetInterval is similar.\r\n\r\nThe var_args are passed in to the callback when it is called.  I've\r\ntested this behavior under Chrome, Safari, and Firefox.  However,\r\nMicrosoft's documentation on the method has only an optional third\r\nparameter indicating the language that the callback should be\r\ninterpreted as[1].  W3 Schools also documents this[2].\r\n\r\nI don't have IE handy to test this behavior, but if it behaves\r\ninconsistently I think we should remove the var_args for both\r\nsetTimeout and setInterval, so that folks at least get a warning.\r\n\r\n1] [URL]\r\n2] [URL]\n\n[Context/Logs]:\n- i've confirmed that this is inconsistent with IE8.\n- The externs have been updated to use the common definition of setTimeout and setInterval."}
{"project_id": "Csv", "bug_id": "1", "source_type": "jira", "confidence": 0.75, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: CSVParser.iterator().remove() should throw throw new UnsupportedOperationException()\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- If you want, but the iterator is really there for the convenience of using for each loops. What happens when remove() is called doesn't matter much."}
{"project_id": "Csv", "bug_id": "2", "source_type": "jira", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: UnicodeUnescapeReader should not be applied before parsing\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Good point but I'm not sure it actually happens. So far the only application I have found supporting unicode escapes is HSQLDB. It can read them but doesn't write them (I checked HSQL 1.8, I'll look at 2.x). I believe these unicode escapes are typically created by a program like native2ascii which converts only non ascii characters, so I believe the line separators are safe. \n\n I agree on removing the unicode escape setting from CSVFormat. I would prefer submitting the reader to  &#91;io&#93;  than making it public in  &#91;csv&#93;  though.\n- OK, I'm working on removing it and moving the reader class to IO for a future release."}
{"project_id": "Csv", "bug_id": "3", "source_type": "jira", "confidence": 0.75, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: ExtendedBufferReader does not handle EOL consistently\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I added a test demonstrating the issue. \n\n I wonder if the line counting should be handled by the lexer instead.\n- Yes, perhaps it should be done by the lexer. But the quickest fix would be to patch the reader. \n\n I wonder whether ExtendedBufferReader is actually necessary; lookAhead() could easily be provided by the Lexer class. \nAnd I'm not sure that readAgain() is really necessary.\n- Enabled new test and added patch to fix it. \nBut we should still consider if ExtendedBufferReader is really necessary."}
{"project_id": "Csv", "bug_id": "4", "source_type": "jira", "confidence": 0.9, "label": "Documentation :: Wrong Comments (CWE-1116)", "llm_input_text": "[Title]: CSVFormat.isCommentingDisabled() is confusing/confused\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Renamed method to isCommentingEnabled"}
{"project_id": "Csv", "bug_id": "5", "source_type": "jira", "confidence": 0.85, "label": "Assignment :: Initialization (CWE-665)", "llm_input_text": "[Title]: CSVLexer.nextToken does not need wsBuf\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Removal of the buffer improves performance by about 25%"}
{"project_id": "Csv", "bug_id": "6", "source_type": "jira", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: RFC 4180 (DEFAULT) format is wrong; should not ignore spaces or blank lines\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Section 2.4 relates to a field value, but a blank line doesn't contain any field. I agree this is open to interpretation. \n\n Ignoring blank lines is probably the best default behavior. I often see csv files with leading blank lines (because they were generated by a JSP for example) or trailing blank lines. Getting an empty record in these cases is never desirable. \n\n Regarding the trimming of values, I agree this should not be part of the default format.\n- I agree that ignoring blank lines is probably better than returning empty records. \n\n However RFC 4180 does not allow blank lines. \nSo it is wrong to equate DEFAULT with RFC 4180.\n- ... [Middle Discussions Snipped for Brevity] ...\n- I think we should keep the strict RFC4180 definition.\n- What's the point of adding a useless constant? It bloats the API for no purpose."}
{"project_id": "Csv", "bug_id": "7", "source_type": "jira", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Confusing semantic of the ignore leading/trailing spaces parameters\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I suggest replacing  leading/trailingSpacesIgnored  with two parameters: \n \n\t  interleavedSpacesIgnored : this will ignore the spaces between the delimiter and the opening quote, and between the closing quote and the next delimiter. \n\t  trimmedSpaces : this will remove the spaces around the values, on the left and on the right. I don't see the need to trim only on one side and not the other.\n- I'm not sure I would expect any space removal to ever occur within quoted values. \nSurely that's one of the reasons why values are quoted - to prevent removal of spaces.\n- The reason for enclosing the values into quotes is to put a delimiter or a line separator in the value. Spaces are always part of the value, quoted or not. At least that's how it's specified in RFC 4180.\n- Definitely better to drop the separate leading/trailing space options. \n\n However, I think \"interleavedSpacesIgnored\" should apply for both quoted and unquoted values. \nAs far as I can tell, that is the expectation in the CSV format specs I've seen. \n\n The \"trimmedSpaces\" setting would then be identical to \"interleavedSpacesIgnored\" for unquoted values. \nFor quoted values it would also trim the enclosed value; not sure that's particularly useful to provide as part of CSV. \nIt's easy enough for the application to trim the fields, so I'm not sure the setting is necessary. \nSeems like it is straying away from the basic purpose of CSV. \n\n However, if/when CSV is updated support creating Java Beans, value trimming would be much more appropriate there, as it would be on a per-column basis. \n\n Let's keep the initial parsing simple."}
{"project_id": "Csv", "bug_id": "8", "source_type": "jira", "confidence": 0.75, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: ExtendedBufferReader does not handle EOL consistently\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I added a test demonstrating the issue. \n\n I wonder if the line counting should be handled by the lexer instead.\n- Yes, perhaps it should be done by the lexer. But the quickest fix would be to patch the reader. \n\n I wonder whether ExtendedBufferReader is actually necessary; lookAhead() could easily be provided by the Lexer class. \nAnd I'm not sure that readAgain() is really necessary.\n- Enabled new test and added patch to fix it. \nBut we should still consider if ExtendedBufferReader is really necessary."}
{"project_id": "Csv", "bug_id": "9", "source_type": "jira", "confidence": 0.75, "label": "Assignment :: Initialization (CWE-665)", "llm_input_text": "[Title]: CSVParser.getRecords() returns null rather than empty List at EOF\n[Symptom]:\nThis file is an XML representation of an issue\n"}
{"project_id": "Csv", "bug_id": "10", "source_type": "jira", "confidence": 0.75, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: ExtendedBufferReader does not handle EOL consistently\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I added a test demonstrating the issue. \n\n I wonder if the line counting should be handled by the lexer instead.\n- Yes, perhaps it should be done by the lexer. But the quickest fix would be to patch the reader. \n\n I wonder whether ExtendedBufferReader is actually necessary; lookAhead() could easily be provided by the Lexer class. \nAnd I'm not sure that readAgain() is really necessary.\n- Enabled new test and added patch to fix it. \nBut we should still consider if ExtendedBufferReader is really necessary."}
{"project_id": "Csv", "bug_id": "11", "source_type": "jira", "confidence": 0.75, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: ExtendedBufferReader does not handle EOL consistently\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I added a test demonstrating the issue. \n\n I wonder if the line counting should be handled by the lexer instead.\n- Yes, perhaps it should be done by the lexer. But the quickest fix would be to patch the reader. \n\n I wonder whether ExtendedBufferReader is actually necessary; lookAhead() could easily be provided by the Lexer class. \nAnd I'm not sure that readAgain() is really necessary.\n- Enabled new test and added patch to fix it. \nBut we should still consider if ExtendedBufferReader is really necessary."}
{"project_id": "Csv", "bug_id": "12", "source_type": "jira", "confidence": 0.75, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Escaped line separators are not supported\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- What should happen in the case of &lt;escape&gt;CRLF? \nI presume only the CR should be subject to the escape. \nIf an application wants to include CRLF in a field, then the application should generate &lt;escape&gt;CR&lt;escape&gt;LF.\n- The Lexer does currently (r1036896) handle &lt;esc&gt;LF and &lt;esc&gt;CR. \n\n The code currently treats &lt;esc&gt;CRLF as &lt;esc&gt;CR followed by LF. The LF is handled as EOL.\n- ... [Middle Discussions Snipped for Brevity] ...\n- I've asked the ML to to comment on this fix.\n- As discussed on the ML, I'm moving this to 1.x, so we can release 1.0.  &#91;1&#93;  \n\n I've implemented logic that makes sure only record separators, we can handle are used. \n\n  &#91;1&#93;   [URL]"}
{"project_id": "Csv", "bug_id": "13", "source_type": "jira", "confidence": 0.7, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: CSVFormat isEscaping/isEncapsulating are not public\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Likewise there could be a public version of getHeader(). \nIt would need to clone the array."}
{"project_id": "Csv", "bug_id": "14", "source_type": "jira", "confidence": 0.85, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: Not possible to create a CSVFormat from scratch\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- +0 for a no arg constructor equivalent to the default format. \n\n -1 for more constructors or making PRISTINE public. More constructors defeats the purpose of the fluent API, and PRISTINE is useless as a base format because all properties have to be defined.\n- +0 for a no arg constructor equivalent to the default format.  \n\n If you mean the DEFAULT format here then that achieves nothing, as the user would have to override any unwanted settings - and the use would have to know which ones to override. If the DEFAULT format were ever later updated, that could invalidate the user's format. \n\n I meant that the ctor should be equivalent to PRISTINE or perhaps PRISTINE + CRLF. \n\n To fit in with the fluent API, there needs to be a static method.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Good points, must ponder some more... with adding back the DISABLED nastiness.\n- I think it's now sorted: \n\n Added ctor with single char delimiter parameter; that solves the original issue, and also allows PRISTINE to be private. \n\n Restored DISABLED char, but as a private constant only used in the PRISTINE constant. \n\n The DISABLED char is now not needed externally."}
{"project_id": "Csv", "bug_id": "15", "source_type": "jira", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Unescape handling needs rethinking\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Are you sure? The unicode escape sequences are transformed before reaching the parser.\n- If unicode parsing is not selected, the unicode sequences lose their escape character so cannot then be parsed later. \n\n This is really about more than just unicode escape sequences, though that is what alerted me to the issue. \n\n The whole business of escape handling needs to be very carefully documented (and tested!) to ensure predictable behaviour.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Those tests only check the unescaping, i.e. the parsing. \n\n What happens when the same format is used to create a new record? \n\n The format should be symmetric, i.e. it should be able to do round-trip conversion.\n- I now think that only meta-characters (and the record-separator) should be unescaped, because only meta-characters need to be unescaped on output. All other escapes should be left as-is, and should be handled separately (probably by the application). \n\n However, this may cause some issues with multi-char record separators - needs further investigation. \nMore complications may occur if the RS can be specified as a list of strings. \nIt may be necessary to restrict the RS to a single string."}
{"project_id": "Csv", "bug_id": "16", "source_type": "jira", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Unescape handling needs rethinking\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Are you sure? The unicode escape sequences are transformed before reaching the parser.\n- If unicode parsing is not selected, the unicode sequences lose their escape character so cannot then be parsed later. \n\n This is really about more than just unicode escape sequences, though that is what alerted me to the issue. \n\n The whole business of escape handling needs to be very carefully documented (and tested!) to ensure predictable behaviour.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Those tests only check the unescaping, i.e. the parsing. \n\n What happens when the same format is used to create a new record? \n\n The format should be symmetric, i.e. it should be able to do round-trip conversion.\n- I now think that only meta-characters (and the record-separator) should be unescaped, because only meta-characters need to be unescaped on output. All other escapes should be left as-is, and should be handled separately (probably by the application). \n\n However, this may cause some issues with multi-char record separators - needs further investigation. \nMore complications may occur if the RS can be specified as a list of strings. \nIt may be necessary to restrict the RS to a single string."}
{"project_id": "Csv", "bug_id": "17", "source_type": "jira", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: CSVRecord does not verify that the length of the header mapping matches the number of values\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I'm not sure if CSVRecord's ctor is the right place for checking if the header mapping length is correct. This may lead to a lot of over head because everytime a CSVRecord is created we would have to do something like: \n\n  \n  if (mappings !=  null  &amp;&amp; mapping.size() != values.length) {\n    throw  Exception\n}\n \n  \n\n For very big files, this may be an issue. Would be better to just test this when the first record is created by the parser.\n- So is this a matter of which exception to throw?\n- ... [Middle Discussions Snipped for Brevity] ...\n- Right, each record is independent.\n- Has been fixed by wrapping the ArrayOutOfBoundsException into an IllegalArgumentException."}
{"project_id": "Csv", "bug_id": "18", "source_type": "jira", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: CSVRecord does not verify that the length of the header mapping matches the number of values\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I'm not sure if CSVRecord's ctor is the right place for checking if the header mapping length is correct. This may lead to a lot of over head because everytime a CSVRecord is created we would have to do something like: \n\n  \n  if (mappings !=  null  &amp;&amp; mapping.size() != values.length) {\n    throw  Exception\n}\n \n  \n\n For very big files, this may be an issue. Would be better to just test this when the first record is created by the parser.\n- So is this a matter of which exception to throw?\n- ... [Middle Discussions Snipped for Brevity] ...\n- Right, each record is independent.\n- Has been fixed by wrapping the ArrayOutOfBoundsException into an IllegalArgumentException."}
{"project_id": "Csv", "bug_id": "19", "source_type": "jira", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Allow the String value for null to be customized for the CSV printer\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- commit -m \"[CSV-97] Allow the String value for null to be customized for the CSV printer.\" C:/svn/org/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVPrinter.java C:/svn/org/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVFormat.java C:/svn/org/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVPrinterTest.java C:/svn/org/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVFormatBuilderTest.java C:/svn/org/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVParser.java\n    Sending        C:/svn/org/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVFormat.java\n    Sending        C:/svn/org/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVParser.java\n    Sending        C:/svn/org/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVPrinter.java\n    Sending        C:/svn/org/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVFormatBuilderTest.java\n    Sending        C:/svn/org/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVPrinterTest.java\n    Transmitting file data ...\n    Committed revision 1465768."}
{"project_id": "Csv", "bug_id": "20", "source_type": "jira", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Unescape handling needs rethinking\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Are you sure? The unicode escape sequences are transformed before reaching the parser.\n- If unicode parsing is not selected, the unicode sequences lose their escape character so cannot then be parsed later. \n\n This is really about more than just unicode escape sequences, though that is what alerted me to the issue. \n\n The whole business of escape handling needs to be very carefully documented (and tested!) to ensure predictable behaviour.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Those tests only check the unescaping, i.e. the parsing. \n\n What happens when the same format is used to create a new record? \n\n The format should be symmetric, i.e. it should be able to do round-trip conversion.\n- I now think that only meta-characters (and the record-separator) should be unescaped, because only meta-characters need to be unescaped on output. All other escapes should be left as-is, and should be handled separately (probably by the application). \n\n However, this may cause some issues with multi-char record separators - needs further investigation. \nMore complications may occur if the RS can be specified as a list of strings. \nIt may be necessary to restrict the RS to a single string."}
{"project_id": "Csv", "bug_id": "21", "source_type": "jira", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Unescape handling needs rethinking\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Are you sure? The unicode escape sequences are transformed before reaching the parser.\n- If unicode parsing is not selected, the unicode sequences lose their escape character so cannot then be parsed later. \n\n This is really about more than just unicode escape sequences, though that is what alerted me to the issue. \n\n The whole business of escape handling needs to be very carefully documented (and tested!) to ensure predictable behaviour.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Those tests only check the unescaping, i.e. the parsing. \n\n What happens when the same format is used to create a new record? \n\n The format should be symmetric, i.e. it should be able to do round-trip conversion.\n- I now think that only meta-characters (and the record-separator) should be unescaped, because only meta-characters need to be unescaped on output. All other escapes should be left as-is, and should be handled separately (probably by the application). \n\n However, this may cause some issues with multi-char record separators - needs further investigation. \nMore complications may occur if the RS can be specified as a list of strings. \nIt may be necessary to restrict the RS to a single string."}
{"project_id": "Csv", "bug_id": "22", "source_type": "jira", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Line number counting is confusing\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Resolved by adjusting the EOL count if reader is currently processing a line and has yet to reach EOL. \n\n Renamed the methods and adjusted the single test case that relied on the odd numbering scheme. \n\n URL:  [URL]\nLog: \n  CSV-98    Line number counting is confusing \n\n Modified: \n    commons/proper/csv/trunk/src/main/java/org/apache/commons/csv/CSVLexer.java \n    commons/proper/csv/trunk/src/main/java/org/apache/commons/csv/CSVParser.java \n    commons/proper/csv/trunk/src/main/java/org/apache/commons/csv/ExtendedBufferedReader.java \n    commons/proper/csv/trunk/src/main/java/org/apache/commons/csv/Lexer.java \n    commons/proper/csv/trunk/src/test/java/org/apache/commons/csv/CSVLexer1.java \n    commons/proper/csv/trunk/src/test/java/org/apache/commons/csv/CSVLexer1306663.java \n    commons/proper/csv/trunk/src/test/java/org/apache/commons/csv/CSVLexer1306667.java \n    commons/proper/csv/trunk/src/test/java/org/apache/commons/csv/CSVLexer3.java \n    commons/proper/csv/trunk/src/test/java/org/apache/commons/csv/CSVParserTest.java \n    commons/proper/csv/trunk/src/test/java/org/apache/commons/csv/ExtendedBufferedReaderTest.java"}
{"project_id": "Csv", "bug_id": "23", "source_type": "jira", "confidence": 0.95, "label": "Checking :: Missing Check (CWE-754)", "llm_input_text": "[Title]: CSVParser: getHeaderMap throws NPE\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- commit -m \"[CSV-100] CSVParser: getHeaderMap throws NPE.\" C:/vcs/svn/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVParser.java C:/vcs/svn/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVParserTest.java\n    Sending        C:/vcs/svn/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVParser.java\n    Sending        C:/vcs/svn/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVParserTest.java\n    Transmitting file data ...\n    Committed revision 1524435."}
{"project_id": "Csv", "bug_id": "24", "source_type": "jira", "confidence": 0.85, "label": "Function :: Logic Mismatch (CWE-573)", "llm_input_text": "[Title]: CSVFormat.format allways append null\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- I can see how your example would do that. I'll address it am done with the flu...\n- Thank you for the report. Keep them coming!   \n\n  \n commit -m \"[CSV-106] CSVFormat.format always append null.\" C:/vcs/svn/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVFormatTest.java C:/vcs/svn/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVPrinter.java\n    Sending        C:/vcs/svn/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVPrinter.java\n    Sending        C:/vcs/svn/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVFormatTest.java\n    Transmitting file data ...\n    Committed revision 1577011."}
{"project_id": "Csv", "bug_id": "25", "source_type": "jira", "confidence": 0.7, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: CSVFormat.EXCEL.parse should handle byte order marks\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Can you attach a sample file and tell us how you created it?\n- I used this url to fetch the content: \n [URL]\n\n which produced the vod.csv file.\n- ... [Middle Discussions Snipped for Brevity] ...\n- I'm OK with no code changes for 1.0 and adding docs, which I just did. See the site xdocs and feel free to move/change.\n- The fix is documented at \n\n  [URL]"}
{"project_id": "Csv", "bug_id": "26", "source_type": "jira", "confidence": 0.7, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: CSVFormat.EXCEL.parse should handle byte order marks\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Can you attach a sample file and tell us how you created it?\n- I used this url to fetch the content: \n [URL]\n\n which produced the vod.csv file.\n- ... [Middle Discussions Snipped for Brevity] ...\n- I'm OK with no code changes for 1.0 and adding docs, which I just did. See the site xdocs and feel free to move/change.\n- The fix is documented at \n\n  [URL]"}
{"project_id": "Csv", "bug_id": "27", "source_type": "jira", "confidence": 0.7, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: CSVFormat.EXCEL.parse should handle byte order marks\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- Can you attach a sample file and tell us how you created it?\n- I used this url to fetch the content: \n [URL]\n\n which produced the vod.csv file.\n- ... [Middle Discussions Snipped for Brevity] ...\n- I'm OK with no code changes for 1.0 and adding docs, which I just did. See the site xdocs and feel free to move/change.\n- The fix is documented at \n\n  [URL]"}
{"project_id": "Csv", "bug_id": "28", "source_type": "jira", "confidence": 0.95, "label": "Function :: Logic Mismatch (CWE-573)", "llm_input_text": "[Title]: CSVRecord.toMap() fails if row length shorter than header length\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- commit -m \"[CSV-111] CSVRecord.toMap() fails if row length shorter than header length.\" C:/vcs/svn/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVRecord.java C:/vcs/svn/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVRecordTest.java\n    Sending        C:/vcs/svn/apache/commons/trunks-proper/csv/src/main/java/org/apache/commons/csv/CSVRecord.java\n    Sending        C:/vcs/svn/apache/commons/trunks-proper/csv/src/test/java/org/apache/commons/csv/CSVRecordTest.java\n    Transmitting file data ...\n    Committed revision 1589281."}
{"project_id": "Csv", "bug_id": "29", "source_type": "jira", "confidence": 0.85, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: HeaderMap is inconsistent when it is parsed from an input with duplicate columns names\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- The problem is, that we provide a key based access to the values of a  CSVRecord  using the  get(String)  method. How should that method behave if there are duplicate column names? \n\n Throwing an exception seems reasonable here.\n- I guess handling this would imply too many changes in the API.\n- Fixed in revision 1592371. An IllegalStateException is now thrown when an inconsistent header is parsed from the input."}
{"project_id": "Csv", "bug_id": "30", "source_type": "jira", "confidence": 0.85, "label": "Checking :: Input Validation (CWE-20)", "llm_input_text": "[Title]: CSVFormat constructor should reject a header array with duplicate entries\n[Symptom]:\nThis file is an XML representation of an issue\n\n[Context/Logs]:\n- CSVFormat currently checks the header when validate() is called by the Parser/Printer. I agree, that this is too late and should be done when withHeader is called.\n- Fixed in r1593076"}
{"project_id": "Electron", "bug_id": "1", "source_type": "github", "confidence": 0.95, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Crash when BrowserWindow is garbaged collected\n[Symptom]:\nI'm trying to create a child process in the renderer process and communicate with it throught stdin/stdout.\nI'm able to receive messages, but it crashed automatically when I leave the app without doing anything.\n\nThe dump is attached below, I saw `IdleNotification` and `~Window` there, but I'm not sure what's going on.\n\nThe specific code I'm using is here: [URL]\n\nWhat could it be?\n\n```\nThread 0 Crashed:: CrBrowserMain  Dispatch queue: com.apple.main-thread\n0   libsystem_kernel.dylib            __pthread_kill + 10\n1   libsystem_pthread.dylib           pthread_kill + 92\n2   libsystem_c.dylib                 abort + 125\n3   com.github.AtomFramework          node::MakeCallback(node::Environment*, v8::Handle , v8::Handle , int, v8::Handle *) + 91\n... [Log Snipped] ...\n49  com.github.AtomFramework          AtomMain + 72\n50  libdyld.dylib                     start + 1\n```\n\n[Context/Logs]:\n- This crash happens because your `BrowserWindow` object is garbage collected, in your case you can make your `win` object global to fix it:\n[URL]\n\nI'm keeping this open since it should not crash the whole process.\n- That seems to fixe the crash. Thanks!"}
{"project_id": "Electron", "bug_id": "2", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Print API crash Electron with dev-tool opening.\n[Symptom]:\nAppear in v0.27.3 on Windows. Reproduce steps:\n1. Launch Electron, and open dev-tool\n2. Type `window.print()`\n3. A system dialog shows up and click `cancel`\n4. Close the Electron Window, then Electron Crashes.\n\nIf we close the dev-tool before closing browser window, it quit finely.\n\nBelow is stacktrace:\n\n```\nelectron.exe!std::_Tree_unchecked_const_iterator  > > >,std::_Iterator_base0>::operator++() Line 62 C++\n    electron.exe!std::_Tree_const_iterator  > > > >::operator++() Line 272  C++\n    electron.exe!std::_Tree_iterator  > > > >::operator++() Line 413    C++\n    content.dll!content::WebContentsImpl::~WebContentsImpl() Line 414   C++\n... [Log Snipped] ...\n    content.dll!content::RenderViewHostImpl::OnMessageReceived(const IPC::Message & msg) Line 867   C++\n    content.dll!content::RenderProcessHostImpl::OnMessageReceived(const IPC::Message & msg) Line 1539   C++\n```\n"}
{"project_id": "Electron", "bug_id": "3", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Crash after IPC connection failure\n[Symptom]:\nI created a connection to a IPC file on mac using the node native `net` module. When the connection creation fails due to `NSURLErrorDomain -1004` (Note that the errors before are logged from the net.on('error') event).\n\nThis happens when i try to open two connections over the same IPC socket file.\n\n```\nERROR { [Error: This socket has been ended by the other party] code: 'EPIPE' } Error: This socket has been ended by the other party\nERROR { [Error: This socket has been ended by the other party] code: 'EPIPE' } Error: This socket has been ended by the other party\nERROR { [Error: This socket has been ended by the other party] code: 'EPIPE' } Error: This socket has been ended by the other party\nERROR { [Error: This socket has been ended by the other party] code: 'EPIPE' } Error: This socket has been ended by the other party\n[0626/111521:ERROR:http_transport_mac.mm(186)] Could not connect to the server. (NSURLErrorDomain -1004)\n```\n\nElectron crashes with the following log: [URL]\n\n[Context/Logs]:\n- I figured that it only crashes when i use an incoming sendSync IPC connection, to forward to the `net` socket.\n\nA simplified example looks like this:\n\n```\njs\nvar syncEvents = {};\n\n// create connection on \"ipcSocket\"\n\n... [Log Snipped] ...\n    syncEvents['xyz'] = event;\n});\n```\n\nWhen i set the return value, it crashes.\nIf you do the same async, it works fine.\nHope that helps.\n- Can you provide a demo app? I'm unable to reproduce according to your descriptions.\n- I figured out what causes the issue, and also created a repro app here: [URL]\n\nThis one seems to be related to my other issue: [URL]\n\nWhat happens is that i try to re-connect when the net error event is fired, as it could be the the socket was closed from the otherside and i want to reconnect.\n\nThe demo app itself, creates a web view, which then creates a IPC connection to the main process and starts a IPC connection using the `net` package to whatever IPC socket (doesn't need to work, to test the crash)\n\nBut because the web view, or window is closed it seems that the connect failure of the net package kills electron.\n\n**To try for yourself:**\nRun the demo app and then close the window (tested on mac osx).\nIt will then after ~1 sec it will kill electron.\n\nThe main line here is `/ipcProvidorBackend.js:86`\n\nIdeally this error should be handled in a way that it doesn't cause electron to crash. And stop the net processes automatically, if possible.\n- This issue is actually rather critical as it always crashes electron, when the `Could not connect to the server. (NSURLErrorDomain -1004)` error appears. And there is now way to catch it."}
{"project_id": "Electron", "bug_id": "4", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: BrowserWindow 'title-bar-style': 'hidden-inset' option causes crash on OS X 10.9\n[Symptom]:\nFrom: [URL]\n\n``` js\nconst win = new BrowserWindow({\n        'width': 800,\n        'height': 600,\n        'title-bar-style': 'hidden-inset'\n});\n```\n\nThis throws on OS X 10.9 with Electron 0.32.3.\n\n[Image: image]\n\n[Context/Logs]:\n- I see the issue on OS X 10.10.5 too.\n- This is strange. I now reviewed and tested the Chromium implementation of `IsOSYosemiteOrLater` and it looks correct. It should guard against that method running. @sindresorhus and @ssreekanth what does `uname -r` (from command line) return on your Mavericks system?\n- ... [Middle Discussions Snipped for Brevity] ...\n- @jaanus Running `uname -r` on Mavericks returns: `13.4.0`.\n- @jaanus I just published my [Link: app] if you need a testcase."}
{"project_id": "Electron", "bug_id": "5", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Segmentation fault after calling Screen.getPrimaryDisplay() on Ubuntu 14.04\n[Symptom]:\nOn Ubuntu 14.04 calling `Screen.getPrimaryDisplay()` leads to crash on v0.19.5. Before update on v0.15.9 the same code worked successfully.\n\nExample code:\n\n```\njs\nvar BrowserWindow, Screen, app, mainWindow;\n\napp = require(\"app\");\nScreen = require(\"screen\");\n... [Log Snipped] ...\n  });\n});\n```\n\nWithout the `var  workArea = Screen.getPrimaryDisplay().workArea;` the code works as expected.\n\nConsole:\n\n```\nconsole\nCrash dump id: 0434e4e2-a3f4-4c32-b993-05fbeb80c759\nSegmentation fault (core dumped)\nWarning: Command failed: [31263:1209/190734:ERROR:browser_main_loop.cc(162)] Running without the SUID sandbox! See [URL] for more information on developing with the sandbox on.\nCrash dump id: 0434e4e2-a3f4-4c32-b993-05fbeb80c759\n... [Log Snipped] ...\n\nAborted due to warnings.\n```\n\nVersion 0.19.5\n\n[Context/Logs]:\n- Happens in windows too !\n- Windows 8.1 to be precise."}
{"project_id": "Electron", "bug_id": "6", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: 0.30.6 - Crash when closing dev tools\n[Symptom]:\nI was running specs in Atom, and then closed the dev tools. The main process crashed.\n\nFull output: [URL]\n\n```\nException Type:        EXC_BAD_ACCESS (SIGSEGV)\nException Codes:       KERN_INVALID_ADDRESS at  \n\nThread 0 Crashed:: CrBrowserMain  Dispatch queue: com.apple.main-thread\n0   Electron Framework                brightray::InspectableWebContentsImpl::CallClientFunction(std::__1::basic_string , std::__1::allocator  > const&, base::Value const*, base::Value const*, base::Value const*) + 305\n... [Log Snipped] ...\n28  com.github.atom                   main + 58\n29  libdyld.dylib                     start + 1\n```\n"}
{"project_id": "Electron", "bug_id": "7", "source_type": "github", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: Setting long tooltip on Windows causes abrupt crash\n[Symptom]:\nOn `google-music-electron`, we got a report about issues with abrupt crashes when playing certain songs. After some triaging, we discovered it was caused by going over 127 characters on Windows.\n\n[URL]\n\nWe have created a proof of concept gist to reproduce the issue. We are using Windows 7 from `ievms` but the initial report was on Windows 10 so that should work as well.\n\n[URL]\n\nWe aren't sure whether this is something that `electron` can resolve or not. But at the very least, we think it should be documented.\n\nIn the meantime, we will be adding truncation in `google-music-electron` to avoid future issues.\n\n[Context/Logs]:\n- [Link: This StackOverflow question] says [Link: MSDN] specifies that limit:\n\nTesting on OSX 10.10.5 it doesn't crash with long strings, but the tooltip doesn't get shown if `message.length` is larger than 4800.\n\nThe `setToolTip` function should handle those issues in each platform."}
{"project_id": "Electron", "bug_id": "8", "source_type": "github", "confidence": 0.85, "label": "Function :: Access Control (CWE-284)", "llm_input_text": "[Title]: Segmentation fault after closing the last window on OS X\n[Symptom]:\nThis is a dupe of #321, please have a look at it.\nOccurs on OSX, atom-shell version 19.1.\nJust like what @marcbachmann said in #321, sometimes we just get a short notice \"segmentation fault\".\n\n[Context/Logs]:\n- Looks like the problem lies here:\n\nCode Example:\n\nmainWindow.on('closed', function() {\n    app.quit();\n}\n\nAfter we closed this mainWindow, if we call app.quit(), it will emit signals trying to close this mainWindow again. But this window is already closed. \n\nThis issue only occurs on Mac OS.\n\nSo app.quit() is a little bit dangerous.\nSuggest to attach it to only \"window-all-closed\" event.\n\nOr you may be able to update the logic of app.quit() on MAC? @zcbenz"}
{"project_id": "Electron", "bug_id": "9", "source_type": "github", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Electron 'Permissions Context' potentially causing Renderer Crash\n[Symptom]:\nI'm using the Web MIDI API within an Electron app and trying to send Sysex messages (System Exclusive) in order to send/receive a MIDI device device-specific-messages like ID Requests, etc. The Web MIDI API requires a secure connection when sending Sysex messages and the protocol within an Electron app appears to be 'file:' \nAttempting to send the message crashes the Electron renderer. All other MIDI messages and the Web MIDI API seem to work as expected and sending/receiving Sysex is successful in the Chrome browser (with https).\n\nI've filed a bug with [Link: Chromium] and it's looking like this could be a Electron issue instead. The latest response to that issue is below:\n\n[Context/Logs]:\n- This is a shot in the dark but have you tried playing with the security options? Specifically the 2 registerUrlScheme methods mentioned in [Link: web-frame]. If that doesn't work you can try disabling websecurity completely by setting `web-security` to false in BrowserWindow initialization (see [Link: here]).\n- I did try and use the web-security object in BrowserWindow to no effect. I will try the two web-frame methods, is there more documentation on web-frame and using these two methods? Is there a different way that Electron(libchromiumcontent) handles permissions compared with Chromium?\n\nIt's unclear as to what the issue is. I'm not prompted to allow permission to use sysex, like i am in Chrome, which seems fine, but it does seem that a requirement to sending sysex messages is the secure protocol 'https:'\n- ... [Middle Discussions Snipped for Brevity] ...\n- Sent a pull request to atom/brightray.\n- Thanks for working on this [Link: toyoshim], looking forward to using Web MIDI in Electron."}
{"project_id": "Electron", "bug_id": "10", "source_type": "github", "confidence": 0.4, "label": "Other", "llm_input_text": "[Title]: Crash on Yosemite\n[Symptom]:\n```\njavascript\nProcess:               Prepros [8704]\nPath:                  /Users/USER/*/Prepros.app/Contents/MacOS/Prepros\nIdentifier:            com.alphapixels.prepros\nVersion:               {{version}}\n... [Log Snipped] ...\nUSB Device: iPhone\nThunderbolt Bus: MacBook Pro, Apple Inc., 17.1\n```\n\n[Context/Logs]:\n- With Yosemite poised to hit the shelves within the next couple of weeks, has there been any update on this?"}
{"project_id": "Electron", "bug_id": "11", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Atom crashes on Electron v0.36.0\n[Symptom]:\nTo repro:\n1. Upgrade Atom on Windows to 0.36.0 of Electron\n2. Open a file\n3. Renderer crash:\n\n```\n# ChildEBP RetAddr  \n00 0018dbf8 777f492e ntdll!NtTerminateProcess+0xc\n01 0018dcd0 74ee7b42 ntdll!RtlExitUserProcess+0x9e\n02 0018dce4 6d173fac KERNEL32!ExitProcessImplementation+0x12\n03 0018dcf0 6d17427d MSVCR120!__crtExitProcess+0x15 [f:\\dd\\vctools\\crt\\crtw32\\startup\\crt0dat.c @ 774]\n... [Log Snipped] ...\n7d 0018fa1c 7780568e ntdll!__RtlUserThreadStart+0x2f\n7e 0018fa2c 00000000 ntdll!_RtlUserThreadStart+0x1b\n```\n\nThis check is failing:\n\n```\nc++\nvoid CallbackInfo::WeakCallback(Isolate* isolate, Local  object) {\n  CHECK(object->IsArrayBuffer());    /******** Kerplowie *********/\n  Local  buf = object.As ();\n  ArrayBuffer::Contents obj_c = buf->GetContents();\n... [Log Snipped] ...\n  delete this;\n}\n```\n\n[Context/Logs]:\n- I think that my problem is related to this issue. Can't run my app on Electron 0.36.0 because the renderer-process crashes instantly after rendering its first frame. Works fine on Electron 0.35.x\n- This is fixed by #3792.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Does this bug [when fixed and validated] alone deserve to cause a new minor version of electron being released?\n- @ducky427 I think so, because of this bug electron completely crashes when it's writing files in my application."}
{"project_id": "Electron", "bug_id": "12", "source_type": "github", "confidence": 0.95, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: App Crash in OS X when using showSaveDialog with filter with no extensions\n[Symptom]:\nWhen trying to use `showSaveDialog` or `showOpenDialog` in OS X, if you pass in a filter object to `options` that has an empty `extensions` array, Electron crashes.\n\n```\njs\nvar remote = require('remote');\nvar dialog = remote.require('dialog');\ndialog.showSaveDialog(remote.getCurrentWindow(), {\n    filters: [{\n... [Log Snipped] ...\n    }]\n});\n```\n\nThis is working in Windows and Linux.\n"}
{"project_id": "Electron", "bug_id": "13", "source_type": "github", "confidence": 0.4, "label": "Other", "llm_input_text": "[Title]: Crash on Windows\n[Symptom]:\n```\nOperating system: Windows NT\n                  10.0.10586 \nCPU: x86\n     GenuineIntel family 6 model 42 stepping 7\n     4 CPUs\n... [Log Snipped] ...\n    eip =     esp =     ebp =  \n    Found by: call frame info with scanning\n```\n"}
{"project_id": "Electron", "bug_id": "14", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Bug: process.exit and app.exit Overflow On Windows\n[Symptom]:\nCurrent versions of atom/apm fail to exit cleanly on Windows when process.exit or app.exit are used (e.g. [URL]\n\n``` coffeescript\nexitWithStatusCode = (status) ->\n  console.log('Exiting With Status Code:' + status)\n  remote.require('app').emit('will-quit')\n  process.exit(status)\n```\n\n```\nC:\\Users\\vagrant\\github\\go-runtime>atom --dev --test c:\\Users\\vagrant\\github\\go-\nruntime\\spec\n\nWindow load time: 711ms\n...................................\n... [Log Snipped] ...\nC:\\Users\\vagrant\\github\\go-runtime>echo %errorlevel%\n-1073740940\n```\n\nUsing app.exit exhibits the same behavior:\n\n``` coffeescript\nexitWithStatusCode = (status) ->\n  console.log('Exiting With Status Code:' + status)\n  app = remote.require('app')\n  app.emit('will-quit')\n  app.exit(status)\n```\n\napp.quit() results in an exit code of 0 **always** for obvious reasons, as it does not accept an exit code. But it does not overflow!\n\n```\nexitWithStatusCode = (status) ->\n  console.log('Exiting With Status Code:' + status)\n  app = remote.require('app')\n  app.emit('will-quit')\n  app.quit()\n```\n\n```\nC:\\Users\\vagrant\\github\\go-runtime>atom --dev --test c:\\Users\\vagrant\\github\\go-\nruntime\\spec\n\nWindow load time: 2270ms\n.......F...........................\n... [Log Snipped] ...\nC:\\Users\\vagrant\\github\\go-runtime>echo %errorlevel%\n0\n```\n\n/cc @nathansobo @zcbenz @50Wliu @thomasjo\n\n[Context/Logs]:\n- Happy to adjust our test window code if any workarounds exist in the meantime."}
{"project_id": "Electron", "bug_id": "15", "source_type": "github", "confidence": 0.75, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Rendering crashes (white screen) when FontAwesome is used (Archlinux)\n[Symptom]:\nWith version 0.36.7 on Archlinux, if the html contains any glyph from FontAwesome, the rendering crashes and gives a white screen.\n\nThis only happens if the glyph is actually rendered, i.e. not hidden by CSS.\n\nThis can be reproduced using this example :\n&lt;!DOCTYPE html&gt;\n\n&lt;html lang=&quot;en&quot;&gt;\n&lt;head&gt;\n    &lt;meta charset=&quot;utf-8&quot; /&gt;\n    &lt;title&gt;Font Awesome Crash&lt;/title&gt;\n    &lt;link href=&quot;css/font-awesome.css&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;i class=&quot;fa fa-trash-o&quot;&gt;&lt;/i&gt;\n    &lt;!-- Remove the line above and the rendering works fine --&gt;\n    Hello World !\n&lt;/body&gt;\n&lt;/html&gt;\n\n[Context/Logs]:\n- I'm unable to reproduce on Ubuntu, probably a distribution specific problem.\n- That's my feeling too.\n- ... [Middle Discussions Snipped for Brevity] ...\n- There's a trace here:\n[URL]\n\nI think I've seen this before and it's similar to [URL] Which harfbuzz version does electron ship?\n- @heftig is it possible for you to rebuild FreeType with debugging symbols on, and then reproduce that stacktrace? (I'll admit I don't know how to do that.) I think that would help lemzwerg track down what's going on.\n\nEdit: Oops my bad :)"}
{"project_id": "Electron", "bug_id": "16", "source_type": "github", "confidence": 0.75, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Fatal error on exit electron app\n[Symptom]:\n```\n[7136:0129/081452:FATAL:scoped_handle.cc(44)] Check failed: false.\nBacktrace:\n        (No symbol) [ ]\n        (No symbol) [ ]\n        (No symbol) [ ]\n... [Log Snipped] ...\n        v8::Locker::IsLocked [ +804588]\n        v8::Locker::IsLocked [ +816029]\n```\n\nSteps to reproduce\n\n```\n$ npm install -g iron-node;\n$ iron-node;\n#press Ctrl+w\n```\n\nJust tried to reproduce but this happens only in distributed version.\n\nWindows 10 . Electron 0.36.5.\n\nref.: [URL]\n\n[Context/Logs]:\n- I also get a renderer crash when quitting my app, on windows 10 with electron 0.36.6 (0.36.5 was working well)\n\n```\n[8320:0129/150532:FATAL:scoped_handle.cc(44)] Check failed: false.\nBacktrace:\n        (No symbol) [ ]\n        (No symbol) [ ]\n        (No symbol) [ ]\n... [Log Snipped] ...\n        v8::Locker::IsLocked [ +1032834]\n        (No symbol) [ ]\n```"}
{"project_id": "Electron", "bug_id": "17", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: memory leak in 1.6.7 when using window.open\n[Symptom]:\n* Electron version: 1.6.7\r\n* Operating system: Mac OS X 10.10.5 and Windows 8.1\r\n\r\nI realize 1.6.7 is still in beta but thought I should report a memory leak I am seeing...  in a simple app that does window.open with every new window opened the memory keeps growing and is never released when the sub-windows get closed.\r\n\r\nThe demo repo is committed here: [URL]\r\n\r\nTo repo.\r\n1. git clone [URL]\r\n2. npm i\r\n3. npm run start\r\n4. in the main window click the open window button 5 times.\r\nNotice: the memory goes very high (approx 500 Mbytes) because each sub-window is allocating a big chunk of memory.\r\n5. now close all the open windows.\r\n\r\nResult: the memory of the renderer process stays very high\r\nExpected: memory to go back to original before all sub-windows were opened.\r\n\r\nNote: This does not happen on electron 1.4.16 but only appears to be a problem in electron 1.6.7.  \r\nNote: Also the problem seems to be related to the having preload enabled\n\n[Context/Logs]:\n- Are you not able to reproduce it using 1.6.6?\n- yes also happens in 1.6.6.  believe it has something to do with preload.  removing preload seems to resolve issue but if you look at sample code there is nothing significant in preload.js - only console.log (and debugger)\n- ... [Middle Discussions Snipped for Brevity] ...\n- I think it is related, there's probably some code there that prevents a context from being freed when a window is closed. I will try to bisect the issue to confirm if that commit is indeed what caused the bug.\n- I confirm that  @lneir test case isn't reproducible before @ , but I believe the actual bug is caused by the remote module and wasn't noticed until now because each non-sandbox has a dedicated process which is killed when the window is closed.\r\n\r\nI will continue investigating."}
{"project_id": "Electron", "bug_id": "18", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Calling BrowserWindow.close in page-title-updated handler crashes electron\n[Symptom]:\nTest program:\n\npackage.json:\n\n``` json\n{\n    \"name\": \"CloseHandlingCrash\",\n    \"productName\": \"CloseHandlingCrash\",\n    \"version\": \"0.1.0\",\n    \"main\": \"main.js\"\n}\n```\n\nmain.js:\n\n```\njavascript\nvar BrowserWindow = require(\"browser-window\");\nvar app = require(\"app\");\n\napp.on(\"ready\", function() {\n... [Log Snipped] ...\n    w.loadUrl(\"file://\" + __dirname + \"/main1.html\");\n});\n```\n\nmain1.html:\n\n``` html\n   window.location = \"main2.html\";   \n```\n\nmain2.html:\n\n``` html\n   main2   \n```\n\nCalling the `BrowserWindow.close()` method in the `page-title-updated` handler crashes Electron.  I noticed that both the `close` and the `closed` handlers are called before the `close()` method returns.  e.g. This test program outputs:\n\n```\npage-title-updated: title=main2\nclose\nclosed\npage-title-updated: returning\n```\n\nIf I understand correctly, once `atom::NativeWindow::TitleWasSet()` has called the `page-title-updated` handlers, it then calls `atom::NativeWindowViews::SetTitle()`, but the window has been destroyed already (deallocated too?).\n\nI have a stack trace from a version of electron compiled with debug info:\n\n```\nProgram received signal SIGSEGV, Segmentation fault.\n  in views::Widget::UpdateWindowTitle() () from /home/rprichard/XXX/electron/out/D/libviews.so\n(gdb) bt\n#0    in views::Widget::UpdateWindowTitle() () from /home/rprichard/XXX/electron/out/D/libviews.so\n#1    in atom::NativeWindowViews::SetTitle (this= , title=...) at ../../atom/browser/native_window_views.cc:475\n... [Log Snipped] ...\n#23   in content::ContentMain(content::ContentMainParams const&) () from /home/rprichard/XXX/electron/out/D/libcontent.so\n#24   in main (argc=2, argv= ) at ../../atom/app/atom_main.cc:179\n```\n\nInterestingly, sometimes `NativeWindow::RequestToClosePage()` decides to close the window immediately and sometimes it decides to defer the decision, based upon the result of `web_contents()->NeedToFireBeforeUnload()`.  I had another test case that assigned to `document.title` instead of changing th\n...[Description Truncated]...\n\n[Context/Logs]:\n- I'm not sure the #3420 fix completely fixed this issue.  I think I can achieve the same effect by also calling `event.preventDefault()` in the `page-title-updated` handler.  Doing that happens to fix my reduced test case, but it does not fix the original application code that I started with.  FWIW, here's the stack trace from my application, after adding `event.preventDefault()`:\n\n```\nProgram received signal SIGSEGV, Segmentation fault.\n  in content::NavigationControllerImpl::GetEntryAtOffset(int) const () from /home/rprichard/XXX/electron/out/D/libcontent.so\n(gdb) bt\n#0    in content::NavigationControllerImpl::GetEntryAtOffset(int) const () from /home/rprichard/XXX/electron/out/D/libcontent.so\n#1    in content::WebContentsImpl::UpdateTitle(content::RenderFrameHost*, int, std::basic_string  > const&, base::i18n::TextDirection) () from /home/rprichard/XXX/electron/out/D/libcontent.so\n... [Log Snipped] ...\n#16   in content::ContentMain(content::ContentMainParams const&) () from /home/rprichard/XXX/electron/out/D/libcontent.so\n#17   in main (argc=2, argv= ) at ../../atom/app/atom_main.cc:179\n```\n\nI suppose I could try to update my test case...\n- @rprichard i am unable to reproduce the crash after the fix with the test case, it would really help if you could reduce your application scenario to a minimal test case, thanks!\n- I was able to create a new test case demonstrating the crash even with `event.preventDefault` -- [URL]  It uses the `request` npm package, so run `npm install\n...[Text Truncated]...\nfore running electron.\n\nI debugged the original test case, and here's what I learned:\n- When the `page-title-updated` handler closes the window in the original test case, it also immediately deallocates the `content::WebContentsImpl` object, which you can see in the original test case's stack backtrace.\n- In the original stack trace, `WebContentsImpl::UpdateTitle` calls `WebContentsImpl::UpdateTitleForEntry`, which ultimately segfaults.\n- In the new stack trace, `WebContentsImpl::UpdateTitle` calls `NavigationControllerImpl::GetEntryAtOffset`, which ultimately segfaults.\n\nHere's the code for `WebContentsImpl::UpdateTitle`:\n\n```\nc++\n...\n  // TODO(evan): make use of title_direction.\n  // [URL]\n  if (!UpdateTitleForEntry(entry, title))\n... [Log Snipped] ...\n    NotifyNavigationStateChanged(INVALIDATE_TYPE_TITLE);\n}\n```\n\nThe `WebContentsImpl` object (i.e. `this`) has been deallocated, so reading the `this->controller_` field is reading dangling memory.\n\nThe fix needs to keep `WebContentsImpl` from being deallocated until the event handler finishes.\n\n(FWIW: to debug the code, I used gdb and placed breakpoints on places such as `content::WebContentsImpl::~WebContentsImpl`.  On Linux, `this` is `$rdx` on method entry.  I also compiled Electron with debug info (-g) by hacking it into the ninja build scripts.  I wanted to build Chromium with debug info, but my computer took too long, and I think the build also failed for some reason.)\n- @zcbenz @deepak1556 \nCould we reopen this issue?"}
{"project_id": "Electron", "bug_id": "19", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: beforeunload event not called on subsequent reloads\n[Symptom]:\n* Electron version: 1.6.3\r\n* Operating system: Linux\r\n\r\n### Expected behavior\r\n\r\nWhen registering a `beforeunload` handler which cancels unloading, I would expect the handler to be called for every `BrowserWindow.reload()`.\r\n\r\n### Actual behavior\r\n\r\nOn 1.6.3, the `beforeunload` handler is called for the first `reload` but not on subsequent calls. Even after removing the event handler, `reload` will not reload the window anymore.\r\n\r\n### How to reproduce\r\n\r\n```\njavascript\r\nconst cancelUnload = e => {\r\n   console.log('cancelUnload called')\r\n   e.returnValue = false\r\n}\r\n... [Log Snipped] ...\n\r\nremote.getCurrentWindow().close()   // [6] -> closes window\n```\r\nI would expect `cancelUnload` to be printed to the console four times and the step at `[5]` to actually reload the window. This is works up to Electron 1.6.2.\r\n\r\nOn Electron 1.6.3 `cancelUnload` is not printed at step `[2]` (nor on any subsequent calls to reload). What's more, event after removing the `beforeunload` handler, `reload` does not work anymore: at step `[5]` the window does not reload (but closing the window at `[6]` works).\n\n[Context/Logs]:\n- I've been running into this problem too in v1.6.6.  \r\n\r\nIt looks this was caused by the changes in #8724.  I don't run into the issue with the v1.6.3 code if I revert the changes from   (or even just comment out one [Link: return statement])."}
{"project_id": "Electron", "bug_id": "20", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Crash in electron 1.6.8 using remote when sandboxed\n[Symptom]:\nCrash in electron remote.\r\n* Electron version: 1.6.8\r\n* Operating system: Mac OSX 10.10.5\r\n\r\nThis is only happening on 1.6.8.  Doesn't happen in 1.6.7.\r\n\r\nRepo:\r\n1. git clone [URL]\r\n2. follow instructions in README\r\n3. crash stack shown below.\r\n\r\nThis demo repo has sandboxing turned on and is using preload script to access remote class.\r\n\r\ncrash stack from renderer console:\r\nUncaught Error: Cannot call constructor on missing remote object 36\r\nError: Cannot call constructor on missing remote object 36\r\n    at throwRPCError (/Users/lneir/IntelliJProjects/tests/electron-remote-issue/node_modules/electron/dist/Electron.app/Contents/Resources/electron.asar/browser/rpc-server.js:143:17)\r\n    at EventEmitter.  (/Users/lneir/IntelliJProjects/tests/electron-remote-issue/node_modules/electron/dist/Electron.app/Contents/Resources/electron.asar/browser/rpc-server.js:303:7)\r\n    at emitThree (events.js:116:13)\r\n    at EventEmitter.emit (events.js:194:7)\r\n    at WebContents.  (/Users/lneir/IntelliJProjects/tests/electron-remote-issue/node_modules/electron/dist/Electron.app/Contents/Resources/electron.asar/browser/api/web-contents.js:256:37)\r\n    at emitTwo (events.js:106:13)\r\n    at WebContents.emit (events.js:191:7)\r\n    at throwRPCError (/Users/lneir/IntelliJProjects/tests/electron-remote-issue/node_modules/electron/dist/Electron.app/Contents/Resources/electron.asar/browser/rpc-server.js:143:17)\r\n    at EventEmitter.  (/Users/lneir/IntelliJProjects/tests/electron-remote-issue/node_modules/electron/dist/Electron.app/Contents/Resources/electron.asar/browser/rpc-server.js:303:7)\r\n    at emitThree (events.js:116:13)\r\n    at EventEmitter.emit (events.js:194:7)\r\n    at WebContents.  (/Users/lneir/IntelliJProjects/tests/electron-remote-issue/node_modules/electron/dist/Electron.app/Contents/Resources/electron.asar/browser/api/web-contents.js:256:37)\r\n    at emitTwo (events.js:106:13)\r\n    at WebContents.emit (events.js:191:7)\r\n    at metaToValue ( :552:13)\r\n    at new remoteFunction ( \n...[Description Truncated]...\n\n[Context/Logs]:\n- Seems like a bug in objects-registry.js\r\n\r\nIt only increases reference count the first time an object is referenced, but this can cause problems with page reload. This sequence of events happened when testing @lneir example:\r\n\r\n- initial load\r\n- hello.js was added to objects-registry and referenced count increased\r\n- reload\r\n- hello.js was added to objects-registry(no reference count increased)\r\n- after a while, garbage collection in renderer process caused the first reference to hello.js to be released\r\n- browser process removes hello.js from object-registry even though it is still being referenced by the second context.\r\n\r\nThis was only noticed in 1.6.8 because of the memory leak fix(previously context were never released)\r\n\r\nPushed #9389 with fix"}
{"project_id": "Electron", "bug_id": "21", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Window submenu causes a crash on OS X\n[Symptom]:\nElectron v0.36.1\nOS X 10.11.2\n\n``` javascript\nconst remote = require('electron').remote;\nconst Menu = remote.Menu;\nconst MenuItem = remote.MenuItem;\n\nvar menu = new Menu();\nmenu.append(new MenuItem({label: 'Window', submenu: new Menu(), type: 'submenu', role: 'window'}));\nMenu.setApplicationMenu(menu);\n```\n\n```\n2015-12-19 23:50:48.555 Electron[8342:713345] *** Assertion failure in -[NSMenu itemAtIndex:], /Library/Caches/com.apple.xbs/Sources/AppKit/AppKit-1404.34/Menus.subproj/NSMenu.m:947\n2015-12-19 23:50:48.558 Electron[8342:713345] An uncaught exception was raised\n2015-12-19 23:50:48.558 Electron[8342:713345] Invalid parameter not satisfying: (index >= 0) && (index   __exceptionPreprocess + 178\n... [Log Snipped] ...\n)\nlibc++abi.dylib: terminating with uncaught exception of type NSException\n```\n"}
{"project_id": "Electron", "bug_id": "22", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: app.makeSingleInstance doesn't work under linux, Electron 1.7.x\n[Symptom]:\n* Electron version: 1.7.x\r\n* Operating system: Linux\r\n\r\nWorks in 1.6.11.\r\n\r\n### Expected behavior\r\n\r\n`app.makeSingleInstance` callback is called when opening an associated file from file manager and application is already opened\r\n\r\n### Actual behavior\r\n\r\n`app.makeSingleInstance` callback is delayed with about 30-60 seconds before being called\r\n\r\n### How to reproduce\r\n\r\nYou could reproduce the problem by downloading [Link: Caret 3.0 .deb] and then following the steps described [Link: here].\r\n\r\nThe issue stops reproducing when releasing the same code with 1.6.11.\n\n[Context/Logs]:\n- We're seeing exactly the same issue here [URL]\n- I've just added a super simple example into git demonstrating the bug...\r\n\r\n```\r\ngit clone [URL]\r\ncd electron-quick-start\r\ngit checkout singleinstance-bug\r\nnpm install\r\nnpm start\r\n```\r\nThen in a new terminal....\r\n```\r\nnpm start\r\n```\n- ... [Middle Discussions Snipped for Brevity] ...\n- @mattridley we're not seeing it with macOS or Windows only linux. Which version of electron did you see it with? Do you see the problem if you try it with the electron-quick-start above? [URL]\n- I saw it with 1.7.5 (reverting back to 1.6.11 fixes the issue). I also have the problem with the quick start (see [URL]"}
{"project_id": "Electron", "bug_id": "23", "source_type": "github", "confidence": 0.75, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Crash in RenderFrameHostImpl::SetNavigationHandle\n[Symptom]:\n* Electron version: 1.6.3\r\n* Operating system: macOS 10.11.6\r\n\r\nWe have a few reports of crashes when waking from sleep. I went ahead & symbolicated one of them and attached it below, in case anything jumps out as an obvious mistake.\r\n\r\n \r\n\r\n```\nProcess:               Slack [88838]\r\nPath:                  /Applications/Slack.app/Contents/MacOS/Slack\r\nIdentifier:            com.tinyspeck.slackmacgap\r\nVersion:               2.6.0-alpha170330eaa48b0 (4101)\r\nCode Type:             X86-64 (Native)\r\n... [Log Snipped] ...\n33  com.tinyspeck.slackmacgap     \t  main + 38\r\n34  libdyld.dylib                 \t  start + 1\n```\r\n\r\n \r\n\r\n### How to reproduce\r\n\r\nWe don't have a guaranteed repro yet. I will update this bug as we get more information.\n\n[Context/Logs]:\n- We are seeing this exact crash! Even we are not able to pinpoint the exact steps. It is not a sleep/wake scenario though.\n- @snene this issue is still in my todo list, its really hard to track the cause without a test case. For the time being I would suggest avoiding any synchronous `loadURL` calls made inside any of the navigation observers like `webContents.on('did-fail-load', () => { webContents.loadURL() })`, as they would be the main cause for this crash.\n- @deepak1556 I think I ran into the same crash while trying to make the pdf viewer more robust. I can reproduce this with this app:\r\n\r\n```\nconst electron = require('electron')\r\nconst app = electron.app\r\nconst BrowserWindow = electron.BrowserWindow\r\n\r\nlet mainWindow\r\n... [Log Snipped] ...\n  }\r\n})\n```\r\n\r\nAlso, if you use the sandbox option, the crash doesn't happen. This is as far as I got with this, I hope it helps. :)\n- We are seeing this in VS Code as well."}
{"project_id": "Electron", "bug_id": "24", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Copying nativeImage to clipboard after crop is crashing program\n[Symptom]:\n* Electron version: 1.4.7\r\n* Operating system: Windows 10 (x64)\r\n\r\n### Expected behavior\r\n\r\nThe image should copy to the clipboard properly after a crop.\r\n\r\n### Actual behavior\r\n\r\nBefore cropping, the image can be copied to the clipboard without any issues. After a crop, copying the image will crash the program and will not be copied to the clipboard. Same behavior on Main and Render processes.\r\n\r\n### How to reproduce\r\n\r\nI have the following code on a render file, but putting it in the main file will yield similar results.\r\n\r\n```\nnode\r\nconst {nativeImage, clipboard} = require('electron');\r\n\r\n// 4592x3056 image (https://images.unsplash.com/photo-1431512284068-4c4002298068)\r\nlet image = nativeImage.createFromPath('./test.jpg');\r\n... [Log Snipped] ...\n// Doesn't work (crashes)\r\nclipboard.writeImage(image);\n```\n\n[Context/Logs]:\n- Here is the stack trace for this crash:\r\n\r\n```\r\nmemcpy() Line 135\r\nui::ClipboardWin::WriteBitmap(const SkBitmap & bitmap) Line 799\r\nui::Clipboard::DispatchObject(ui::Clipboard::ObjectType type, const std::vector  >,std::allocator  > > > & params) Line 118\r\nui::ClipboardWin::WriteObjects(ui::ClipboardType type, const std::map  >,std::allocator  > > >,std::less ,std::allocator  >,std::allocator  > > > > > > & objects) Line 718\r\nui::ScopedClipboardWriter::~ScopedClipboardWriter() Line 24\r\natom::api::Clipboard::WriteImage(const gfx::Image & image, mate::Arguments * args) Line 151\r\nmate::internal::Invoker ,gfx::Image const & __ptr64,mate::Arguments * __ptr64>::DispatchToCallback(base::Callback  callback) Line 202\r\nmate::internal::Dispatcher ::DispatchToCallback(const v8::FunctionCallbackInfo  & info) Line 236\r\n```"}
{"project_id": "Electron", "bug_id": "25", "source_type": "github", "confidence": 0.9, "label": "Assignment :: Initialization (CWE-665)", "llm_input_text": "[Title]: Crashes on webview.loadURL()\n[Symptom]:\n* Electron version: 1.6.5\r\n* Operating system: Windows 10 64bit\r\n\r\n### Actual behavior\r\n\r\nCrashes\r\n\r\n### How to reproduce\r\n```\r\ngit clone [URL]\r\nnpm install\r\nnpm start\r\n```\r\n\r\n1. click \"change\" button\r\n1. click \"hide\" button\r\n1. click \"change\" button\r\n\r\n[URL]\n\n[Context/Logs]:\n- It also happens with Electron **1.6.7**\r\nIt doesnt happen when using **1.6.2**\n- The stack for this crash is:\r\n\r\n\r\n```\nelectron.exe!content::WebContentsViewGuest::CreateViewForWidget(class content::RenderWidgetHost *,bool)\tUnknown\r\nelectron.exe!content::WebContentsImpl::CreateRenderWidgetHostViewForRenderManager(class content::RenderViewHost *)\tUnknown\r\nelectron.exe!content::WebContentsImpl::CreateRenderViewForRenderManager(class content::RenderViewHost *,int,int,struct content::FrameReplicationState const &)\tUnknown\r\nelectron.exe!content::RenderFrameHostManager::InitRenderView(class content::RenderViewHostImpl *,class content::RenderFrameProxyHost *)\tUnknown\r\nelectron.exe!content::RenderFrameHostManager::CreateRenderFrame(class content::SiteInstance *,bool,int *)\tUnknown\r\n... [Log Snipped] ...\nelectron.exe!content::NavigationControllerImpl::LoadURLWithParams(struct content::NavigationController::LoadURLParams const &)\tUnknown\r\nelectron.exe!atom::api::WebContents::LoadURL(const GURL & url, const mate::Dictionary & options) Line 1014\tC++\n```\r\n\r\n@deepak1556 anything jump out to you on this one?\n- ... [Middle Discussions Snipped for Brevity] ...\n- I tracked down this crash to [URL]\r\n```\r\nWebContentsImpl* embedder_web_contents() const {\r\n    return attached_ ? owner_web_contents_ : nullptr;\r\n}\r\n```\r\nWhich results in null pointer access on LoadURL when the view is hidden (Because it's detached).\r\nThis is actually not a matter of race condition. As it's simply enough to hide the webview, then issue LoadURL to crash it.\r\n\r\nThis will avoid the crash by simply refusing to navigate when the view is not attached.\n- I got the same. The webview was hidden via css."}
{"project_id": "Electron", "bug_id": "26", "source_type": "github", "confidence": 0.85, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: Inconsistent behaviors in sandbox mode with iframe\n[Symptom]:\n* Electron version: 1.6.7\r\n* Operating system: Windows 10\r\n\r\nAccording to the activation of the sandbox, Iâ€™m facing inconsistent behaviors with a window containing iframes.\r\n\r\n# 1st. issue\r\n### How to reproduce\r\nHave a preload.js (pretty basic)\r\n```\r\nconst _ipcRenderer = require('electron').ipcRenderer;\r\nwindowLocal.ipcRenderer = _ipcRenderer;\r\nconsole.log(â€˜preload file loadedâ€™);\r\n```\r\nA html page with at least one iframe\r\n\r\n### Actual behavior\r\nWhen loading such page, we have the preload file loaded several times :\r\n-\tone for the top window\r\n-\tone for each iframe\r\nWithout the sandbox the preload file is loaded only once whatever the number of iframes.\r\n\r\n### Expected behavior\r\nIt could make sense to load preload file for each iFrame whatever the mode. We are in position to test in the preload if we are in a iframe (window.frameset) and then adapt our code.\r\n\r\n# 2nd issue \r\n### How to reproduce\r\nIn sandbox mode, from the top window and from each iframe I send a specific message to the master using the ipcRenderer.\r\n\r\nI build a response channel and the message from the window id and frame id\r\n```\r\n    let message = `I'm here from Window '${windowId}'`;\r\n    let responseChannel = `child-response-${windowId}`;\r\n    if (window.frameElement) {\r\n        message += ` Frame '${window.frameElement.id}'`;\r\n        responseChannel += `-${window.frameElement.id}`;\r\n    }\r\n```\r\n\r\nI listen the response on this specific response channel\r\n```\r\n    ipcRenderer.on(responseChannel, (...args) => {\r\n        console.log(â€¦args);\r\n    });\r\n```\r\nI send this specific message to master\r\n`    ipcRenderer.send('child-message', responseChannel, message);\r\n`\r\nThe master looks like\r\n```\r\n        ipcMain.on('child-message', (event: Electron.IpcMainEvent, ...args: any[]) => {\r\n            console.log(...args);\r\n            event.sender.send(args[0], 'I got your message !');\r\n        });\r\n```\r\n\r\n### Actual behavior\r\nMaster receives the expected messages\r\n-\tchild-response-xxx, I'm here from Window 'xx\n...[Description Truncated]...\n\n[Context/Logs]:\n- @tarruda \r\nFor this issue, does it miss a test on the frame in \r\nvoid AtomSandboxedRendererClient::DidCreateScriptContext(\r\n    v8::Handle  context, content::RenderFrame* render_frame) {\r\n++  if (!render_frame->IsMainFrame())\r\n++    return;\r\n\r\n\r\nDo not know if we have to test devTools as well ?\r\n  if (!render_frame->IsMainFrame() && !IsDevToolsExtension(render_frame))\r\n    return;"}
{"project_id": "Electron", "bug_id": "27", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Crash on app quit at atom::AtomCTDelegate::ClearCTExcludedHostsList\n[Symptom]:\n* Electron version: 1.7.1\r\n* Operating system: Windows / Mac\r\n\r\n### Expected behavior\r\nno crash on quit\r\n\r\n### Actual behavior\r\nCrash on app quit\r\n\r\n```\nThread 23 Crashed:: Chrome_IOThread\r\n0   com.github.electron.framework \t  std::__1::__tree , std::__1::allocator  >, std::__1::less , std::__1::allocator  > >, std::__1::allocator , std::__1::allocator  > > >::destroy(std::__1::__tree_node , std::__1::allocator  >, void*>*) + 18 (__tree:1828)\r\n1   com.github.electron.framework \t  std::__1::__tree , std::__1::allocator  >, std::__1::less , std::__1::allocator  > >, std::__1::allocator , std::__1::allocator  > > >::clear() + 23 (__tree:1831)\r\n2   com.github.electron.framework \t  atom::AtomCTDelegate::ClearCTExcludedHostsList() + 13 (atom_ct_delegate.cc:23)\r\n3   com.github.electron.framework \t  atom::AtomCertVerifier::Verify(net::CertVerifier::RequestParams const&, net::CRLSet*, net::CertVerifyResult*, base::Callback  const&, std::__1::unique_ptr  >*, net::NetLogWithSource const&) + 58 (atom_cert_verifier.cc:170)\r\n... [Log Snipped] ...\n21  libsystem_pthread.dylib       \t  _pthread_start + 168\r\n22  libsystem_pthread.dylib       \t  thread_start + 13\n```\r\n\r\n### How to reproduce\r\nNo consistent repro. May be happening after #7651\r\n\r\ncc: @kevinsawicki @deepak1556\n\n[Context/Logs]:\n- This looks identical to #9878 @bpasero fyi\n- Seeing this quite consistently (maybe 5% failure rate?) in our CI jobs"}
{"project_id": "Electron", "bug_id": "28", "source_type": "github", "confidence": 0.75, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: TouchBar: Entries of TouchBarScrubber are all cropped\n[Symptom]:\n* Electron version: 1.7.7\r\n* Operating system: macOS\r\n\r\n### Expected behavior\r\n\r\nEntries of `TouchBarScrubber` show entirely\r\n\r\n### Actual behavior\r\n\r\nEach `ScrubberItem` shows with a \"...\"\r\n\r\n### How to reproduce\r\n\r\nJust create a new `TouchBarScrubber` and fill in some `ScrubberItem` and all entries will get a \"...\":\r\n\r\n[Image: image]\n\n[Context/Logs]:\n- This is a tricky one to solve, by default scrubbers use a [Link: NSScrubberProportialLayout] which tells the scrubber to display X items evenly distributed.\r\n\r\nThe only other built-in alternative is [Link: NSScrubberFlowLayout] which requires that we implement a method that returns the expected width of each item.  Not sure if we can return the expected width of an item given arbitrary text or not.\n- @MarshallOfSound is it possible to have buttons show up in a group that can overflow and allows to swipe left or right to scroll? My challenge currently is that I add lots of items to the touch bar and at one point the available space is not enough to show all unless I hide the \"Control Strip\".\r\n\r\nI noticed that for example Word has support to show many buttons in a group that can overflow with scrollbars, so it must be possible via the native APIs. I wonder if `TouchBarScrubber` is the right thing for that, but then I face the challenges as outlined in this bug that my buttons are all cropped.\n- ... [Middle Discussions Snipped for Brevity] ...\n- @MarshallOfSound can you point me to Electron code where we set the width of these items?\n- The scrubber items?  Currently we don't, the default is that proportional layout, if you wanted to play with setting up a flow layout that would be done somewhere around here:\r\n\r\n[URL]"}
{"project_id": "Electron", "bug_id": "29", "source_type": "github", "confidence": 0.85, "label": "Other", "llm_input_text": "[Title]: Fix \"nativeImage module addRepresentation() ...\" tests\n[Symptom]:\nThey were disabled during the Chromium 61 upgrade. Fix them and enable.\r\n\r\n/cc @alespergl\n\n[Context/Logs]:\n- The tests are fixed, but there is a follow-up task: #11294."}
{"project_id": "Electron", "bug_id": "30", "source_type": "github", "confidence": 0.85, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: Downloads are failing with state 'interrupted' from custom protocols in 1.8.2-beta.3\n[Symptom]:\n* Electron version: 1.8.2-beta.3\r\n* Operating system: MacOS 10.12\r\n\r\n### Expected behavior\r\n\r\nFile downloads from custom protocols should complete without issue.\r\n\r\n### Actual behavior\r\n\r\nBefore even triggering the custom protocol handler, the download-item emits 'done' with a state of 'interrupted'. In my demo linked below, I use the new registerStreamProtocol, but I was able to reproduce using registerHttpProtocol as well.\r\n\r\n### How to reproduce\r\n\r\nUse [URL]\n\n[Context/Logs]:\n- Im booting up my linux box to do some debugging on the electron codebase. Will report what I find (hopefully will be able to PR a fix).\n- This is getting logged by chromium:\r\n\r\n```\r\n[19102:0117/142535.172538:WARNING:url_request_job_manager.cc(90)] Failed to map: custom://foo.com/index.html\r\n```\n- ... [Middle Discussions Snipped for Brevity] ...\n- The fix has landed in `master` (and `2-0-x`) but not in `1-8-x`.\r\n@ckerr, @jkleinsc Do we want to backport it to `1-8-x`?\n- @alexeykuzmin I'll backport to 1-8-x"}
{"project_id": "Redis", "bug_id": "1", "source_type": "github", "confidence": 0.75, "label": "Interface :: API Misuse (CWE-628)", "llm_input_text": "[Title]: Redis Cluster: implement the ASKING command\n[Symptom]:\n(Please see [URL] for full details, here I'm just summarizing the problem with some cut&paste from that thread).\n\nIf you are familiar with the design you know that the key space is split into 4096 parts. \nEvery part is called an \"hash slot\", and every node has a routing table to map every hash slot with a cluster node. \nThis way if a client sends a query to a node that is not responsible for the keys mentioned in the query, it gets a -MOVED message redirecting it to the right node. However we also have the ability to reconfigure the cluster while it \nis running. So for instance I've hash slot 100 that is assigned to node A. And I want to move it to node B. \n\nThis is accomplished (and redis-trib is already able to do it for you automatically) with the following steps. \n\n1) Node A hash slot 100 is marked as \"Migrating to B\" (using the CLUSTER SETSLOT   MIGRATING   command). \n2) Node B hash slot 100 is marked as \"Importing from A\" (using the \nCLUSTER SETSLOT   IMPORTING   command). \n3) An external client, usually redis-trib, starts using the commands \nCLUSTER GETKEYSINSLOT and the MIGRATE command to atomically move keys from A to B.\n\nWhat is interesting is that while the hash slot is set as \"Migrating  to B\", node A will reply to all the requests about this hash slot of keys that are _still_ present in the hash slot, but if a request is about a key that is in hash slot 100 but is not \nfound inside the key space, it generates a \"-ASK\" error, that is like \"-MOVED\" but means: please only ask this exact query to the specified node, but don't update your table about it. Ask new queries about hash \nslot 100 to me again. \n\nThis way all the new keys about hash slot 100 are created directly in B, but A handles all the queries about keys that are still in A. At the same time redis-trib moves keys from A to B. Eventually all the keys are moved and the hash slot configuration is consolidated to the new one, using other CLUSTER SETSLOT subcommands. \nSo far this is pretty cool. But \n...[Description Truncated]...\n\n[Context/Logs]:\n- This was implemented but implementation still to verify. Taking the issue open for now.\n- Implemented a long time ago but issue was not closed, closing."}
{"project_id": "Redis", "bug_id": "2", "source_type": "github", "confidence": 0.85, "label": "Function :: Logic Mismatch (CWE-573)", "llm_input_text": "[Title]: Redis should abort when can't load the RDB file\n[Symptom]:\nWhen Redis can't load an RDB file since the RDB version is wrong or when the file signature does not match a log is emitted and the server starts without loading data, with an empty key space. It should instead abort after logging the error.\nThis was not intentional, and is an error introduced later, but never found since it is not common to have mismatching RDB versions or file signature.\n\n[Context/Logs]:\n- Fixed in 2.4 and unstable. Closing."}
{"project_id": "Redis", "bug_id": "3", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Server crash on failed master/slave sync (refused connection)\n[Symptom]:\nThree of my instances (on server 1 and 2) just crashed when I restarted server 3. Instance A was a master to an instance on server 3. Instances B and C were slaves of two instances on server 3.\n\nI'm sorry that I have to be so vague about this. I just found these stackdumps in my logfiles a few minutes after it happened. I believe, instances A,B,C were trying to do some kind of syncing with server 3, which was being restarted at the time. I assume server 3 refused the connections when the instances were in a state where these exceptions weren't handled.\n\nI'm using the fresh 2.4.1 from this morning on Ubuntu Oneiric. Let me know if you need more input.\n\ninstance 1:\n\n```\n[2710] 17 Oct 16:56:25 * MASTER MODE enabled (user request)\n[2710] 17 Oct 16:56:25 * Slave ask for synchronization\n[2710] 17 Oct 16:56:25 * Starting BGSAVE for SYNC\n[2710] 17 Oct 16:56:25 * Background saving started by pid 4019\n[2710] 17 Oct 16:56:27 - DB 0: 91 keys (0 volatile) in 128 slots HT.\n... [Log Snipped] ...\n[2710] 17 Oct 16:56:30 # /usr/local/bin/redis-server() [ ]\n[4019] 17 Oct 16:56:32 * DB saved on disk\n```\n\ninstance 2:\n\n```\n[2698] 17 Oct 16:56:30 * Non blocking connect for SYNC fired the event.\n[2698] 17 Oct 16:56:30 # I/O error writing to MASTER: Connection refused\n[2698] 17 Oct 16:56:30 * Connecting to MASTER...\n[2698] 17 Oct 16:56:30 # ======= Ooops! Redis 2.4.1 got signal: -11- =======\n[2698] 17 Oct 16:56:30 # redis_version:2.4.1\n... [Log Snipped] ...\n[2698] 17 Oct 16:56:30 # /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xed) [ ]\n[2698] 17 Oct 16:56:30 # /usr/local/bin/redis-server() [ ]\n```\n\ninstance 3:\n\n```\n[2684] 17 Oct 16:56:31 * Non blocking connect for SYNC fired the event.\n[2684] 17 Oct 16:56:31 # I/O error writing to MASTER: Connection refused\n[2684] 17 Oct 16:56:31 * Connecting to MASTER...\n[2684] 17 Oct 16:56:31 # ======= Ooops! Redis 2.4.1 got signal: -11- =======\n[2684] 17 Oct 16:56:31 # redis_version:2.4.1\n... [Log Snipped] ...\n[2684] 17 Oct 16:56:31 # /lib/x86_64-li\n...[Description Truncated]...\n\n[Context/Logs]:\n- Hello Jan,\n\nthanks for reporting, this is an \"interesting\" bug I'll try to get fixed within 24 hours. From the stack trace I believe there is some kind of HA daemon issuing \"SLAVE OF NONE\" to your slave instances when the master is unavailable, is it possible?\nI see this from this line:\n\n[2710] 17 Oct 16:56:25 \\* MASTER MODE enabled (user request)\n\nAt the same time however this instance got a request for another slave to use it as master (however this is unrelated to the bug perhaps, need to check this better).\n\nSo there is a bug for sure, but it is not on slave reconnection. Apparently the bug happens once the slave is elected to master. It still tries to reconnect via non blocking connect.\n\nThis is a big bug I'm glad you found it. More news ASAP.\n- for Jan: please if you can send me more output than this, that is, a few lines more on the top part of the three instances. Thanks!\n- ... [Middle Discussions Snipped for Brevity] ...\n- I ran my test again, and everything runs smoothly. The old slave becomes the new master, and the new slave properly connects and syncs all data.\n\nGreat. Thank you, Salvatore!\n- We won! :) Thanks, closing for now in the hope everything will go smooth even in the next days ;) Otherwise I'm here."}
{"project_id": "Redis", "bug_id": "4", "source_type": "github", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: redis-server crash w/strack trace...\n[Symptom]:\nI haven't quite updated to 2.4.0 yet but was running 2.3.10 in production and lost one earlier.\n\n[17466] 15 Oct 07:05:25 # ======= Ooops! Redis 2.3.10 got signal: -11- =======\n[17466] 15 Oct 07:05:25 # redis_version:2.3.10^M\nredis_git_sha1:00000000^M\nredis_git_dirty:0^M\narch_bits:64^M\nmultiplexing_api:epoll^M\nprocess_id:17466^M\nuptime_in_seconds:1353855^M\nuptime_in_days:15^M\nlru_clock:1845328^M\nused_cpu_sys:8926.23^M\nused_cpu_user:12859.53^M\nused_cpu_sys_children:70.14^M\nused_cpu_user_children:22.71^M\nconnected_clients:1^M\nconnected_slaves:1^M\nclient_longest_output_list:0^M\nclient_biggest_input_buf: ^M\nblocked_clients:0^M\nused_memory:8472278192^M\nused_memory_human:7.89G^M\nused_memory_rss:6308675584^M\nused_memory_peak:8472286720^M\nused_memory_peak_human:7.89G^M\nmem_fragmentation_ratio:0.74^M\nmem_allocator:jemalloc-2.2.1^M\nloading:0^M\naof_enabled:0^M\nchanges_since_last_save:210^M\nbgsave_in_progress:0^M\nlast_save_time:1318611938^M\nbgrewriteaof_in_progress:0^M\n\nlast_save_time:1318611938^M\nbgrewriteaof_in_progress:0^M\ntotal_connections_received:91901^M\ntotal_commands_processed:284065681^M\nexpired_keys:0^M\nevicted_keys:0^M\nkeyspace_hits:97704116^M\nkeyspace_misses:28609668^M\nhash_max_zipmap_entries:512^M\nhash_max_zipmap_value:512^M\npubsub_channels:0^M\npubsub_patterns:0^M\nlatest_fork_usec:242\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(memcpy+0xe1) [ ]\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(memcpy+0xe1) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(sdscatlen+0x54) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(readQueryFromClient+0x33) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(aeProcessEvents+0x16e) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(aeMain+0x2e) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(main+0xf9) [ ]\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(__libc_start_main+0xe6) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server [ ]\n\n[Context/Logs]:\n- Thank you Jeremy,\n\nplease if it is easy for you to obtain it could you send the exact git commit that you were using, and if possible even the redis-server executable itself? Thanks!\n- Argh.  I can get the binary, yes.  But apparently there's a step in the build process I've been using (only when building from the git repo) that removes the git info along the way.  That's fixed now but I can say exactly which 2.3.10 this was.\n\n[URL]\n\nThat's the binary that was running.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Hi Antirez and Jeremy!\n\nToday we faced the same problem on one slave of our prod environment only few minutes after it start:\n\n \n[14532] 21 Nov 11:49:40 # ======= Ooops! Redis 2.4.2 got signal: -11- =======\n[14532] 21 Nov 11:49:40 # redis_version:2.4.2\nredis_git_sha1:00000000\nredis_git_dirty:0\narch_bits:64\nmultiplexing_api:epoll\nprocess_id:14532\nuptime_in_seconds:2385\nuptime_in_days:0\nlru_clock:67042\nused_cpu_sys:127.59\nused_cpu_user:44.75\nused_cpu_sys_children:4.84\nused_cpu_user_children:1.77\nconnected_clients:20\nconnected_slaves:0\nclient_longest_output_list:0\nclient_biggest_input_buf: \nblocked_clients:0\nused_memory:31861605448\nused_memory_human:29.67G\nused_memory_rss:30233288704\nused_memory_peak:31861605448\nused_memory_peak_human:29.67G\nmem_fragmentation_ratio:0.95\nmem_allocator:jemalloc-2.2.1\nloading:0\naof_enabled:0\nchanges_since_last_save:60\nbgsave_in_progress:0\nlast_save_time:1321873795\nbgrewriteaof_in_progress:0\ntotal_connections_received:119\ntotal_comm\n...[Text Truncated]...\n# /lib/libc.so.6(memcpy+0xe1) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(sdscatlen+0x54) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(readQueryFromClient+0x33) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(aeProcessEvents+0x16e) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(aeMain+0x2e) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(main+0xf9) [ ]\n[14532] 21 Nov 11:49:40 # /lib/libc.so.6(__libc_start_main+0xe6) [ ]\n[14532] 21 Nov 11:49:40 # redis-server [ ]\n \n\nAs the crash log shows:\n- We are using Redis 2.4.2.\n- This instance was only a slave (it might have recieved some \"SET\" command from some clients).\n- The input buffer seems to be huge too ^^\n\nI don't know if it can help you, but unlike Jeremy, we are not using ZSet, and we didn't have any monitoring tools on that slave.\nDo not hesitate to ask me if you have any questions about our redis setup.\n\nRegards,\n\nBaptiste.\n- Thanks this is definitely the same bug, but the fact that it is just a slave makes things a bit different.\nAlso it does not help that Redis truncates INFO outputs in stack traces... (fixing that as well, already fixed into unstable).\n\nBtw the changes I'm doing should provide a lot more background when the input or output buffer overflows... doing the changes right now. I'll update this issue soon.\n\nBtw in my reasoning early in this thread I completely missed that even in the Jeremy case the overflow is happening in the INPUT buffer of the client and not in the output buffer, this changes a few things...\n\nMore news soon."}
{"project_id": "Redis", "bug_id": "5", "source_type": "github", "confidence": 0.9, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: maxmemory + evicting policy + slaves = death\n[Symptom]:\nPieter Noordhuis discovered this interesting bug, with the help of an user experiencing strange things in a Redis instance with multiple slaves and maxmemory configured at the same time: when maxmemory was reached the DB on the master was completely erased (thanks to Pieter, Dane and Jemie for the investigation).\n\nThe issue happens for the following reason:\n- Redis reached the configured limit, so it tries to expire keys.\n- Evicting keys turns into explicit DELs sent to slaves, since masters control the eviction of slaves for well known reasons.\n- But this way if there are enough slaves, emitting the protocol in the output buffers will actually take more memory than the amount freed removing keys...\n- So the key eviction process starts to enter into an infinite loop.\n\nUp to a given point the fact that there is a static buffer part in the output queue of every client (including slaves) mitigate this in certain conditions, but once Redis can't use the output buffer but must use the queue of objects the infinite loop is triggered.\n\nI'm working to fix this problem, there are different ways to do this and I'm doing experiments to find the best solution. Among the possible solutions there is to ignore output buffer of slaves when computing max memory, or to call the function that flushes data to the slave while we are inside the eviction loop if we detect that the memory is raising after every deletion instead of decreasing, or to even tolerate the fact that the memory increases inside the loop but up to a certain limit, and break the loop when a few keys are evicted (enough to go under the maxmemory limit, if we subtract the size taken by the slave output buffers).\n\nI'm experimenting with the above solutions, but also improving the memory used generating the protocol by using more shared objects for common parts of the protocol, that helps to make this issue (and the code path resolving it, that should be considered an exception) less likely to be triggered.\n\n**Edit:** U\n...[Description Truncated]...\n\n[Context/Logs]:\n- Note: also when AOF is enabled the same happens with the AOF buffer.\n- Before merging I'm writing here the list of commits I did in this branch, in the chance I'll backport this into 2.4 later:\n- 8b7c345 freeMemoryIfNeeded() minor refactoring\n- c1ef6ff Also remove size of AOF buffers from used memory when doing the math for freeMemoryIfNeeded()\n- f6b32c1 This fixes issue #327, is a very complex fix (unfortunately), details:\n- 355f859 Use less memory when emitting the protocol, by using more shared objects for commonly emitted parts of the protocol.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Fix merged into unstable, there is a 2.4-issue327 branch on github with the fix backported into 2.4, this will be merged before 2.4.8 release.\n- patch merged into 2.4. closing. Thank you."}
{"project_id": "Redis", "bug_id": "6", "source_type": "github", "confidence": 0.85, "label": "Function :: Access Control (CWE-284)", "llm_input_text": "[Title]: Redis silently continues working when RDB persistence fails\n[Symptom]:\nIf you have RDB persistence configured to write your data, for instance, into a directory that is not writable by Redis, the background saving will not work but Redis will continue working as expected. This way the user may think everything is ok but actually no persistence at all is performed by the server: when the server goes down no data wil be available at all.\n\nEither Redis should abort when this happens or should return an error to every client trying to write against the server if Redis was not able to persist the latest time it tried. The error will no longer be reported once a successful BGSAVE/SAVE is performed. Or something like that...\n\n[Context/Logs]:\n- I don't think aborting in this case is the right call.  People should be hooking monitoring and metrics in to the running servers and can easily know whether or not it has been too long since the last successful save.  It should be a warning on startup that the dir isn't writeable or whatever, and then messages to the client/logs after that.  I personally wouldn't feel comfortable knowing that the server will crash if this happens, as I prefer to think of Redis as a stable, long-running, easily monitorable server.\n- I definitely want Redis to refuse to start if it cannot persist and its configuration file says it should. If it ceases being able to persist while running, though, I am not sure what the best thing to do is.\n\nThe options are:\n- Your users see nothing and keep adding data. If the server crashes they lose data.\n- Your users see the service crash and you will be warned ASAP.\n\nI think I prefer the second case but I am not really comfortable with any of those...\n- ... [Middle Discussions Snipped for Brevity] ...\n- Issue fixed, for now I'm not testing if the directory is writable at startup, since there are many other conditions that will lead to inability to save... but at the first BGSAVE the user will know for sure ;)\n\nClosing. It is not clear if this also closes issue #163, I'll check later today. Feedbacks welcomed.\n- It's a good start, but [Link: as I've said a year ago] a database _should not start_ if it cannot take good care of your data in its current configuration. This is going to hurt people one day and I'm sure we have all seen what kind of shitstorm a blog post by a guy that lost some data can create for a database. Please reconsider.\n\nIMO when it starts, if it's configured with a RDB and there RDB isn't there, it should issue a SAVE itself to make sure saving is possible, and create an empty RDB. If it's not working fail hard please."}
{"project_id": "Redis", "bug_id": "7", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: redis 2.4.10 and 2.4.9 may crashed,but redis 2.4.6 looks up working normally\n[Symptom]:\n[4389] 12 Apr 23:24:27 \\* Server started, Redis version 2.4.10\n[4389] 12 Apr 23:24:27 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n[4389] 12 Apr 23:24:27 \\* The server is now ready to accept connections on port 6379\n[4389] 12 Apr 23:25:57 # User requested shutdown...\n[4389] 12 Apr 23:25:57 \\* Saving the final RDB snapshot before exiting.\n[4389] 12 Apr 23:25:57 \\* DB saved on disk\n[4389] 12 Apr 23:25:57 \\* Removing the pid file.\n[4389] 12 Apr 23:25:57 # Redis is now ready to exit, bye bye...\n[4414] 12 Apr 23:25:57 \\* Server started, Redis version 2.4.10\n[4414] 12 Apr 23:25:57 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.\n[4414] 12 Apr 23:25:57 \\* DB loaded from disk: 0 seconds\n[4414] 12 Apr 23:25:57 \\* The server is now ready to accept connections on port 6379\n[4414] 13 Apr 01:19:26 \\* Slave ask for synchronization\n[4414] 13 Apr 01:19:26 \\* Starting BGSAVE for SYNC\n[4414] 13 Apr 01:19:26 \\* Background saving started by pid 4859\n[4859] 13 Apr 01:19:26 \\* DB saved on disk\n[4414] 13 Apr 01:19:26 \\* Background saving terminated with success\n[4414] 13 Apr 01:19:26 \\* Synchronization with slave succeeded\n[4414] 13 Apr 02:01:41 # User requested shutdown...\n[4414] 13 Apr 02:01:41 \\* Saving the final RDB snapshot before exiting.\n[4414] 13 Apr 02:01:41 \\* DB saved on disk\n[4414] 13 Apr 02:01:41 \\* Removing the pid file.\n[4414] 13 Apr 02:01:41 # Redis is now ready to exit, bye bye...\n[5141] 13 Apr 02:10:07 \\* Server started, Redis version 2.4.10\n[5141] 13 Apr 02:10:07 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix\n...[Description Truncated]...\n\n[Context/Logs]:\n- Hi, thanks for reporting, definitely a real bug... I think what it is, and I think it was actually also present in previous versions of Redis (but now 100% sure). More info soon...\n- Hey, this is what happens:\n\nSORT lookup keys for the \"GET\" option using a stack allocated _robj_ structure, however this object in the current 2.4.x implementation is no longer a \"read only\" object, to propagate the expire to the slave we use it to compose the protocol that we send to the slave. But this object can't be shared, as will be destroyed after the function returns. Hence everything crashes apart ;)\n\nWriting a fix. Thanks.\n- ... [Middle Discussions Snipped for Brevity] ...\n- uptime_in_seconds:607630\nuptime_in_days:7\n- It normal to run more than seven days"}
{"project_id": "Redis", "bug_id": "8", "source_type": "github", "confidence": 0.95, "label": "Function :: Logic Mismatch (CWE-573)", "llm_input_text": "[Title]: zinterstore fails when mixing sets and sorted sets\n[Symptom]:\nI have two sets and a single sorted set and I'm trying to use zinterstore to get the scored intersection of all three.  The operation is failing with my production data but succeeding if I substitute a test sorted set it works in some cases but not all and I'm stumped about why.\n\nTo setup the test, add three entries to set \"one\", four entries to set \"two\" - including a signle entry that exists in set \"one\", and four entries in the sorted set - including that same single entry from set \"one\"\n\n```\nsadd one 100 101 102 103 \nsadd two 100 200 201 202\nzadd three 1 500 1 501 1 502 1 503 1 100\n```\n\nNow if you run\n\n```\nzinterstore to_here 3 one two three WEIGHTS 0 0 1\n```\n\nNothing is found to intersect.\n\nCreate a new sort set \"four\":\n\n```\nzadd four 1 600 1 100 \n\nzinterstore to_here 3 one two four WEIGHTS 0 0 1\n```\n\nThere is an intersection on the entry 100!\n\nMy production data isn't so simple but I'm seeing the same result, some intersections appear to work, at least in part, but others fail completely.\n\nThis happens on redis versions 2.4.13 and the latest 2.6 RC.\n\nJosiah Carlson kindly tested this and found that it behaves correctly in earlier versions of redis:\n\n[Context/Logs]:\n- Fixed in 2.4.14, already available for download. Thanks."}
{"project_id": "Redis", "bug_id": "9", "source_type": "github", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: redis-server crash w/strack trace...\n[Symptom]:\nI haven't quite updated to 2.4.0 yet but was running 2.3.10 in production and lost one earlier.\n\n[17466] 15 Oct 07:05:25 # ======= Ooops! Redis 2.3.10 got signal: -11- =======\n[17466] 15 Oct 07:05:25 # redis_version:2.3.10^M\nredis_git_sha1:00000000^M\nredis_git_dirty:0^M\narch_bits:64^M\nmultiplexing_api:epoll^M\nprocess_id:17466^M\nuptime_in_seconds:1353855^M\nuptime_in_days:15^M\nlru_clock:1845328^M\nused_cpu_sys:8926.23^M\nused_cpu_user:12859.53^M\nused_cpu_sys_children:70.14^M\nused_cpu_user_children:22.71^M\nconnected_clients:1^M\nconnected_slaves:1^M\nclient_longest_output_list:0^M\nclient_biggest_input_buf: ^M\nblocked_clients:0^M\nused_memory:8472278192^M\nused_memory_human:7.89G^M\nused_memory_rss:6308675584^M\nused_memory_peak:8472286720^M\nused_memory_peak_human:7.89G^M\nmem_fragmentation_ratio:0.74^M\nmem_allocator:jemalloc-2.2.1^M\nloading:0^M\naof_enabled:0^M\nchanges_since_last_save:210^M\nbgsave_in_progress:0^M\nlast_save_time:1318611938^M\nbgrewriteaof_in_progress:0^M\n\nlast_save_time:1318611938^M\nbgrewriteaof_in_progress:0^M\ntotal_connections_received:91901^M\ntotal_commands_processed:284065681^M\nexpired_keys:0^M\nevicted_keys:0^M\nkeyspace_hits:97704116^M\nkeyspace_misses:28609668^M\nhash_max_zipmap_entries:512^M\nhash_max_zipmap_value:512^M\npubsub_channels:0^M\npubsub_patterns:0^M\nlatest_fork_usec:242\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(memcpy+0xe1) [ ]\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(memcpy+0xe1) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(sdscatlen+0x54) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(readQueryFromClient+0x33) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(aeProcessEvents+0x16e) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(aeMain+0x2e) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(main+0xf9) [ ]\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(__libc_start_main+0xe6) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server [ ]\n\n[Context/Logs]:\n- Thank you Jeremy,\n\nplease if it is easy for you to obtain it could you send the exact git commit that you were using, and if possible even the redis-server executable itself? Thanks!\n- Argh.  I can get the binary, yes.  But apparently there's a step in the build process I've been using (only when building from the git repo) that removes the git info along the way.  That's fixed now but I can say exactly which 2.3.10 this was.\n\n[URL]\n\nThat's the binary that was running.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Hi Antirez and Jeremy!\n\nToday we faced the same problem on one slave of our prod environment only few minutes after it start:\n\n \n[14532] 21 Nov 11:49:40 # ======= Ooops! Redis 2.4.2 got signal: -11- =======\n[14532] 21 Nov 11:49:40 # redis_version:2.4.2\nredis_git_sha1:00000000\nredis_git_dirty:0\narch_bits:64\nmultiplexing_api:epoll\nprocess_id:14532\nuptime_in_seconds:2385\nuptime_in_days:0\nlru_clock:67042\nused_cpu_sys:127.59\nused_cpu_user:44.75\nused_cpu_sys_children:4.84\nused_cpu_user_children:1.77\nconnected_clients:20\nconnected_slaves:0\nclient_longest_output_list:0\nclient_biggest_input_buf: \nblocked_clients:0\nused_memory:31861605448\nused_memory_human:29.67G\nused_memory_rss:30233288704\nused_memory_peak:31861605448\nused_memory_peak_human:29.67G\nmem_fragmentation_ratio:0.95\nmem_allocator:jemalloc-2.2.1\nloading:0\naof_enabled:0\nchanges_since_last_save:60\nbgsave_in_progress:0\nlast_save_time:1321873795\nbgrewriteaof_in_progress:0\ntotal_connections_received:119\ntotal_comm\n...[Text Truncated]...\n# /lib/libc.so.6(memcpy+0xe1) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(sdscatlen+0x54) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(readQueryFromClient+0x33) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(aeProcessEvents+0x16e) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(aeMain+0x2e) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(main+0xf9) [ ]\n[14532] 21 Nov 11:49:40 # /lib/libc.so.6(__libc_start_main+0xe6) [ ]\n[14532] 21 Nov 11:49:40 # redis-server [ ]\n \n\nAs the crash log shows:\n- We are using Redis 2.4.2.\n- This instance was only a slave (it might have recieved some \"SET\" command from some clients).\n- The input buffer seems to be huge too ^^\n\nI don't know if it can help you, but unlike Jeremy, we are not using ZSet, and we didn't have any monitoring tools on that slave.\nDo not hesitate to ask me if you have any questions about our redis setup.\n\nRegards,\n\nBaptiste.\n- Thanks this is definitely the same bug, but the fact that it is just a slave makes things a bit different.\nAlso it does not help that Redis truncates INFO outputs in stack traces... (fixing that as well, already fixed into unstable).\n\nBtw the changes I'm doing should provide a lot more background when the input or output buffer overflows... doing the changes right now. I'll update this issue soon.\n\nBtw in my reasoning early in this thread I completely missed that even in the Jeremy case the overflow is happening in the INPUT buffer of the client and not in the output buffer, this changes a few things...\n\nMore news soon."}
{"project_id": "Redis", "bug_id": "10", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: \"BITOP command 10x speed improvement\" commit causes crash\n[Symptom]:\nBitop-code is exactly what I need, so I've started testing with it. \n\nCurrently that 10x speed up has some special cases that throws \nexception for me again and again. Before that commit \neverything seem to work correctly.\n\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\n[4700] 31 May 16:52:37.235 #     Redis 2.5.9 crashed by signal: 11\n[4700] 31 May 16:52:37.235 #     Failed assertion:   ( :0)\n[4700] 31 May 16:52:37.235 # --- STACK TRACE\n/usr/local/bin/redis-server(logStackTrace+0x75)[ ]\n/usr/local/bin/redis-server(bitopCommand+0x654)[ ]\n/lib64/libpthread.so.0(+ )[ ]\n/usr/local/bin/redis-server(bitopCommand+0x654)[ ]\n/usr/local/bin/redis-server(call+0x5d)[ ]\n/usr/local/bin/redis-server(processCommand+0x375)[ ]\n/usr/local/bin/redis-server(processInputBuffer+0x4f)[ ]\n/usr/local/bin/redis-server(readQueryFromClient+0xa0)[ ]\n/usr/local/bin/redis-server(aeProcessEvents+0x124)[ ]\n/usr/local/bin/redis-server(aeMain+0x2b)[ ]\n/usr/local/bin/redis-server(main+0x2a2)[ ]\n/lib64/libc.so.6(__libc_start_main+0xfd)[ ]\n/usr/local/bin/redis-server[ ]\n[4700] 31 May 16:52:37.236 # --- INFO OUTPUT\n[4700] 31 May 16:52:37.236 # # Server\nredis_version:2.5.9\nredis_git_sha1:473f3090\nredis_git_dirty:1\nos:Linux 2.6.32-220.7.1.el6.x86_64 x86_64\narch_bits:64\nmultiplexing_api:epoll\ngcc_version:4.4.6\nprocess_id:4700\nrun_id: \ntcp_port:6379\nuptime_in_seconds:1367\nuptime_in_days:0\nlru_clock:1726659\n# Clients\n\nconnected_clients:2\nclient_longest_output_list:0\nclient_biggest_input_buf:0\nblocked_clients:0\n# Memory\n\nused_memory:882120\nused_memory_human:861.45K\nused_memory_rss:7729152\nused_memory_peak:1134552\nused_memory_peak_human:1.08M\nused_memory_lua:30720\nmem_fragmentation_ratio:8.76\nmem_allocator:jemalloc-3.0.0\n# Persistence\n\nloading:0\nrdb_changes_since_last_save:383\nrdb_bgsave_in_progress:0\nrdb_last_save_time:1338472083\nrdb_last_bgsave_status:ok\nrdb_last_bgsave_time_sec:0\nrdb_current_bgsave_time_sec:-1\naof_enabled:0\naof_rewrite_in_progress:0\naof_rewrite_scheduled:0\naof_last_rewrite_ti\n...[Description Truncated]...\n\n[Context/Logs]:\n- Thanks, looking into it ASAP. Do you have perhaps a way to simply replicate it? Thanks.\n- flushdb\nset a \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\nbitop or x a b\n- Awesome, I can reproduce it, so it will be trivial to fix ASAP. Thanks.\n- Fixed, thanks!"}
{"project_id": "Redis", "bug_id": "11", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Crash in Redis 2.6 RC4 converting an hash value.\n[Symptom]:\nAs received from Marty Weiner from Pinterest.\n\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\n[10845] 09 Jun 04:42:08.251 # === ASSERTION FAILED ===\n[10845] 09 Jun 04:42:08.251 # ==> t_hash.c:406 'ret == DICT_OK' is not true\n[10845] 09 Jun 04:42:08.251 # (forcing SIGSEGV to print the bug report.)\n[10845] 09 Jun 04:42:08.251 #     Redis 2.5.10 crashed by signal: 11\n[10845] 09 Jun 04:42:08.251 #     Failed assertion: ret == DICT_OK (t_hash.c:406)\n[10845] 09 Jun 04:42:08.252 # --- STACK TRACE\n/usr/bin/redis-server(logStackTrace+0x52)[ ]\n/usr/bin/redis-server(_redisAssert+0x6f)[ ]\n/lib/x86_64-linux-gnu/libpthread.so.0(+ )[ ]\n/usr/bin/redis-server(_redisAssert+0x6f)[ ]\n/usr/bin/redis-server(hashTypeConvertZiplist+0xe0)[ ]\n/usr/bin/redis-server(hsetCommand+0x34)[ ]\n/usr/bin/redis-server(call+0x5d)[ ]\n/usr/bin/redis-server(luaRedisGenericCommand+0x25a)[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server(lua_pcall+0x4f)[ ]\n/usr/bin/redis-server(evalGenericCommand+0x1fc)[ ]\n/usr/bin/redis-server(call+0x5d)[ ]\n/usr/bin/redis-server(processCommand+0x375)[ ]\n/usr/bin/redis-server(processInputBuffer+0x4f)[ ]\n/usr/bin/redis-server(readQueryFromClient+0xa0)[ ]\n/usr/bin/redis-server(aeProcessEvents+0x136)[ ]\n/usr/bin/redis-server(aeMain+0x2b)[ ]\n/usr/bin/redis-server(main+0x2a3)[ ]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xff)[ ]\n/usr/bin/redis-server[ ]\n[10845] 09 Jun 04:42:08.253 # --- INFO OUTPUT\n[10845] 09 Jun 04:42:08.256 # # Server\nredis_version:2.5.10\nredis_git_sha1:1a3e9d95\nredis_git_dirty:0\nos:Linux 2.6.38-14-virtual x86_64\narch_bits:64\nmultiplexing_api:epoll\ngcc_version:4.5.2\nprocess_id:10845\nrun_id: \ntcp_port:6381\nuptime_in_seconds:14583\nuptime_in_days:0\nlru_clock:1801116\n# Clients\n\nconnected_clients:2255\nclient_longest_output_list:0\nclient_biggest_input_buf:0\nblocked_clients:0\n# Memory\n\nused_memory:1632648896\nused_memory_human:1.52G\nused_memory_rss\n...[Description Truncated]...\n\n[Context/Logs]:\n- As a first step I added a new test in commit c0de459 to stress test the ziplist -> hash conversion. So far the test is passing without problems. I'm going to further analyze the bug today.\n\nSince the original posters of this bug saw it multiple times probably it's a good idea to distribute a modified version of Redis that can provide more information when this assert fails.\n- I walked the dictAdd code and haven't found any holes, even around encoding + rehashing occurring concurrently.  \n\nI'm now wondering if the ziplist version of my hashtable has duplicates in it.  RDB load has no protection, nor does save, so if one creeps in I dont think I'd notice until an expansion.  I'm thinking of adding a verification pass that can be switched on during load to watch for duplicates.\n- ... [Middle Discussions Snipped for Brevity] ...\n- redis  :6379[2]> hgetall 17661039738895\n  1) \"947\"\n  2) \", , ,\"\n  3) \"867\"\n  4) \", , ,\"\n  5) \"588\"\n  6) \", , ,\"\n  7) \"52\"\n  8) \", , ,\"\n  9) \"53\"\n 10) \", ,\"\n 11) \"110\"\n 12) \", ,\"\n 13) \"310\"\n 14) \", , , , , , , , , , ,\"\n 15) \"311\"\n 16) \", ,\"\n 17) \"151\"\n 18) \", ,\"\n 19) \"314\"\n 20) \", , , ,\"\n 21) \"9\"\n 22) \", ,\"\n 23) \"435\"\n 24) \", , , , , , , , , , , , , , , ,\"\n 25) \"912\"\n 26) \", ,\"\n 27) \"193\"\n 28) \", ,\"\n 29) \"436\"\n 30) \", , , , , , , , , ,\"\n 31) \"473\"\n 32) \", ,\"\n 33) \"439\"\n 34) \", , ,\"\n 35) \"196\"\n 36) \", , , ,\"\n 37) \"277\"\n 38) \", ,\"\n 39) \"639\"\n 40) \", , ,\"\n 41) \"396\"\n 42) \", , , , ,\"\n 43) \"837\"\n 44) \", , ,\"\n 45) \"397\"\n 46) \", , , , , , ,\"\n 47) \"991\"\n 48) \", \n...[Text Truncated]...\n\", ,\"\n191) \"701\"\n192) \", , ,\"\n193) \"143\"\n194) \", ,\"\n195) \"306\"\n196) \", ,\"\n197) \"621\"\n198) \", , , , , ,\"\n199) \"145\"\n200) \", ,\"\n201) \"146\"\n202) \", ,\"\n203) \"382\"\n204) \", ,\"\n205) \"708\"\n206) \", ,\"\n207) \"862\"\n208) \", ,\"\n209) \"549\"\n210) \", ,\"\n211) \"710\"\n212) \", ,\"\n213) \"967\"\n214) \", , , , , ,\"\n215) \"496\"\n216) \", ,\"\n217) \"497\"\n218) \", ,\"\n219) \"978\"\n220) \", ,\"\n221) \"83\"\n222) \", ,\"\n223) \"85\"\n224) \", ,\"\n225) \"87\"\n226) \", ,\"\n227) \"88\"\n228) \", ,\"\n229) \"421\"\n230) \", ,\"\n231) \"422\"\n232) \", ,\"\n233) \"900\"\n234) \", ,\"\n235) \"109\"\n236) \", ,\"\n237) \"505\"\n238) \", ,\"\n239) \"424\"\n240) \", , ,\"\n241) \"507\"\n242) \", ,\"\n243) \"903\"\n244) \", ,\"\n245) \"426\"\n246) \", ,\"\n247) \"427\"\n248) \", , ,\"\n249) \"823\"\n250) \", ,\"\n251) \"508\"\n252) \", ,\"\n253) \"904\"\n254) \", , ,\"\n255) \"583\"\n256) \", , , , , , ,\"\n257) \"909\"\n258) \", ,\"\n259) \"585\"\n260) \", , , ,\"\n261) \"1011\"\n262) \", , ,\"\n- @martaaay the core is big news! Thanks. No macros to walk the ziplist unfortunately, you may use RESTORE (but you have to fake the CRC64 checksum) in order to re-create the value into a live instance, btw if you can send me an hex-dump of the ziplist I'll happily check the format.\n\nAnother option is to take the hexdump, write a small C program to inject it inside an array of bytes, and then directly use the ziplist API to walk values.\n\nBtw this is a big step forward! Only problem I think we'll have is that we'll need to understand after we get what value is duplicated how it ended there, but should be simple to reproduce once we have the duplicated value."}
{"project_id": "Redis", "bug_id": "12", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Crash in Redis 2.6 RC4 converting an hash value.\n[Symptom]:\nAs received from Marty Weiner from Pinterest.\n\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\n[10845] 09 Jun 04:42:08.251 # === ASSERTION FAILED ===\n[10845] 09 Jun 04:42:08.251 # ==> t_hash.c:406 'ret == DICT_OK' is not true\n[10845] 09 Jun 04:42:08.251 # (forcing SIGSEGV to print the bug report.)\n[10845] 09 Jun 04:42:08.251 #     Redis 2.5.10 crashed by signal: 11\n[10845] 09 Jun 04:42:08.251 #     Failed assertion: ret == DICT_OK (t_hash.c:406)\n[10845] 09 Jun 04:42:08.252 # --- STACK TRACE\n/usr/bin/redis-server(logStackTrace+0x52)[ ]\n/usr/bin/redis-server(_redisAssert+0x6f)[ ]\n/lib/x86_64-linux-gnu/libpthread.so.0(+ )[ ]\n/usr/bin/redis-server(_redisAssert+0x6f)[ ]\n/usr/bin/redis-server(hashTypeConvertZiplist+0xe0)[ ]\n/usr/bin/redis-server(hsetCommand+0x34)[ ]\n/usr/bin/redis-server(call+0x5d)[ ]\n/usr/bin/redis-server(luaRedisGenericCommand+0x25a)[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server(lua_pcall+0x4f)[ ]\n/usr/bin/redis-server(evalGenericCommand+0x1fc)[ ]\n/usr/bin/redis-server(call+0x5d)[ ]\n/usr/bin/redis-server(processCommand+0x375)[ ]\n/usr/bin/redis-server(processInputBuffer+0x4f)[ ]\n/usr/bin/redis-server(readQueryFromClient+0xa0)[ ]\n/usr/bin/redis-server(aeProcessEvents+0x136)[ ]\n/usr/bin/redis-server(aeMain+0x2b)[ ]\n/usr/bin/redis-server(main+0x2a3)[ ]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xff)[ ]\n/usr/bin/redis-server[ ]\n[10845] 09 Jun 04:42:08.253 # --- INFO OUTPUT\n[10845] 09 Jun 04:42:08.256 # # Server\nredis_version:2.5.10\nredis_git_sha1:1a3e9d95\nredis_git_dirty:0\nos:Linux 2.6.38-14-virtual x86_64\narch_bits:64\nmultiplexing_api:epoll\ngcc_version:4.5.2\nprocess_id:10845\nrun_id: \ntcp_port:6381\nuptime_in_seconds:14583\nuptime_in_days:0\nlru_clock:1801116\n# Clients\n\nconnected_clients:2255\nclient_longest_output_list:0\nclient_biggest_input_buf:0\nblocked_clients:0\n# Memory\n\nused_memory:1632648896\nused_memory_human:1.52G\nused_memory_rss\n...[Description Truncated]...\n\n[Context/Logs]:\n- As a first step I added a new test in commit c0de459 to stress test the ziplist -> hash conversion. So far the test is passing without problems. I'm going to further analyze the bug today.\n\nSince the original posters of this bug saw it multiple times probably it's a good idea to distribute a modified version of Redis that can provide more information when this assert fails.\n- I walked the dictAdd code and haven't found any holes, even around encoding + rehashing occurring concurrently.  \n\nI'm now wondering if the ziplist version of my hashtable has duplicates in it.  RDB load has no protection, nor does save, so if one creeps in I dont think I'd notice until an expansion.  I'm thinking of adding a verification pass that can be switched on during load to watch for duplicates.\n- ... [Middle Discussions Snipped for Brevity] ...\n- redis  :6379[2]> hgetall 17661039738895\n  1) \"947\"\n  2) \", , ,\"\n  3) \"867\"\n  4) \", , ,\"\n  5) \"588\"\n  6) \", , ,\"\n  7) \"52\"\n  8) \", , ,\"\n  9) \"53\"\n 10) \", ,\"\n 11) \"110\"\n 12) \", ,\"\n 13) \"310\"\n 14) \", , , , , , , , , , ,\"\n 15) \"311\"\n 16) \", ,\"\n 17) \"151\"\n 18) \", ,\"\n 19) \"314\"\n 20) \", , , ,\"\n 21) \"9\"\n 22) \", ,\"\n 23) \"435\"\n 24) \", , , , , , , , , , , , , , , ,\"\n 25) \"912\"\n 26) \", ,\"\n 27) \"193\"\n 28) \", ,\"\n 29) \"436\"\n 30) \", , , , , , , , , ,\"\n 31) \"473\"\n 32) \", ,\"\n 33) \"439\"\n 34) \", , ,\"\n 35) \"196\"\n 36) \", , , ,\"\n 37) \"277\"\n 38) \", ,\"\n 39) \"639\"\n 40) \", , ,\"\n 41) \"396\"\n 42) \", , , , ,\"\n 43) \"837\"\n 44) \", , ,\"\n 45) \"397\"\n 46) \", , , , , , ,\"\n 47) \"991\"\n 48) \", \n...[Text Truncated]...\n\", ,\"\n191) \"701\"\n192) \", , ,\"\n193) \"143\"\n194) \", ,\"\n195) \"306\"\n196) \", ,\"\n197) \"621\"\n198) \", , , , , ,\"\n199) \"145\"\n200) \", ,\"\n201) \"146\"\n202) \", ,\"\n203) \"382\"\n204) \", ,\"\n205) \"708\"\n206) \", ,\"\n207) \"862\"\n208) \", ,\"\n209) \"549\"\n210) \", ,\"\n211) \"710\"\n212) \", ,\"\n213) \"967\"\n214) \", , , , , ,\"\n215) \"496\"\n216) \", ,\"\n217) \"497\"\n218) \", ,\"\n219) \"978\"\n220) \", ,\"\n221) \"83\"\n222) \", ,\"\n223) \"85\"\n224) \", ,\"\n225) \"87\"\n226) \", ,\"\n227) \"88\"\n228) \", ,\"\n229) \"421\"\n230) \", ,\"\n231) \"422\"\n232) \", ,\"\n233) \"900\"\n234) \", ,\"\n235) \"109\"\n236) \", ,\"\n237) \"505\"\n238) \", ,\"\n239) \"424\"\n240) \", , ,\"\n241) \"507\"\n242) \", ,\"\n243) \"903\"\n244) \", ,\"\n245) \"426\"\n246) \", ,\"\n247) \"427\"\n248) \", , ,\"\n249) \"823\"\n250) \", ,\"\n251) \"508\"\n252) \", ,\"\n253) \"904\"\n254) \", , ,\"\n255) \"583\"\n256) \", , , , , , ,\"\n257) \"909\"\n258) \", ,\"\n259) \"585\"\n260) \", , , ,\"\n261) \"1011\"\n262) \", , ,\"\n- @martaaay the core is big news! Thanks. No macros to walk the ziplist unfortunately, you may use RESTORE (but you have to fake the CRC64 checksum) in order to re-create the value into a live instance, btw if you can send me an hex-dump of the ziplist I'll happily check the format.\n\nAnother option is to take the hexdump, write a small C program to inject it inside an array of bytes, and then directly use the ziplist API to walk values.\n\nBtw this is a big step forward! Only problem I think we'll have is that we'll need to understand after we get what value is duplicated how it ended there, but should be simple to reproduce once we have the duplicated value."}
{"project_id": "Redis", "bug_id": "13", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Bug report, slowlog - EVAL\n[Symptom]:\nBug report output: [URL]\nTo reproduce: use latest github version, run with default options, system is 32 bit\n\nRun: eval \"local a; for b = 1,100000 do redis.call('sadd','set1',b) end return a\" 0\nRun: eval \"local a; for b = 50000,100000 do redis.call('sadd','set2',b) end return a\" 0\n\nSecond command always triggers a crash.\n\nUpdate 1: Changed title from \"Bug report, EVAL\" to include slowlog. It appears it happens during a slow logging of a command. Since above operations are slow, they will hit this code path pretty much every single time. I took the time to compile redis with jemalloc and lib c malloc and it happens just the same. Here is output of  a gdb session:\n\n```\nsudo gdb ./bin/redis-server 9683\nGNU gdb (Ubuntu/Linaro 7.3-0ubuntu2) 7.3-2011.08\nCopyright (C) 2011 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later   in ?? ()\n```\n\nUpdate 2: I've seen it crash with this gdb output as well\n\n```\nsudo gdb ../bin/bin-libc/bin/redis-server 10689\nGNU gdb (Ubuntu/Linaro 7.3-0ubuntu2) 7.3-2011.08\nCopyright (C) 2011 Free Software Foundation, Inc.\nLicense GPLv3+: GNU GPL version 3 or later <[URL]\nThis is free software: you are free to change and redistribute it.\n... [Log Snipped] ...\nfs             0x0  0\ngs             0x33 51\n```\n\n[Context/Logs]:\n- Thank you for reporting. Investigating. Sorry for the missing stack trace during the crash, this is due to two previous commit that broken the stack trace feature, now fixed into unstable (soon into 2.6 as well).\n- Hello again, I tried to reproduce this on different systems without success :(\nAre you able to reproduce this issue easily? Thanks.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Issue fixed, what I was really needing was 8 hours of sleep and not a core ;) From the stack trace it is quite clear what's happening. Please can you confirm that with latest commit everything is fine? Thanks.\n- With commit [URL] , it seems that everything is fine. So far, after several hundred calls to the same test script, server does not exhibit any problems."}
{"project_id": "Redis", "bug_id": "14", "source_type": "github", "confidence": 0.95, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Crash while attempting zinterstore\n[Symptom]:\nThe crash said to report, so I'm reporting. Looks to be related to specifying too high of a value for \"numkeys\". I guess I should have entered 2.\n\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\n[632] 11 Nov 13:25:20.272 # ------------------------------------------------\n[632] 11 Nov 13:25:20.272 # !!! Software Failure. Press left mouse button to continue\n[632] 11 Nov 13:25:20.272 # Guru Meditation: \"OOM\" #redis.c:2452\n[632] 11 Nov 13:25:20.272 # (forcing SIGSEGV in order to print the stack trace)\n[632] 11 Nov 13:25:20.272 # ------------------------------------------------\n[632] 11 Nov 13:25:20.272 #     Redis 2.5.13 crashed by signal: 11\n[632] 11 Nov 13:25:20.272 #     Failed assertion:   ( :0)\n[632] 11 Nov 13:25:20.272 # --- STACK TRACE\n0   redis-server                          logStackTrace + 96\n1   redis-server                          _redisPanic + 174\n2   libsystem_c.dylib                     _sigtramp + 26\n3   ???                                   0x0 +  \n4   redis-server                          redisOutOfMemoryHandler + 53\n5   redis-server                          zcalloc + 40\n6   redis-server                          zunionInterGenericCommand + 150\n7   redis-server                          call + 145\n8   redis-server                          processCommand + 820\n9   redis-server                          processInputBuffer + 31\n10  redis-server                          readQueryFromClient + 380\n11  redis-server                          aeProcessEvents + 616\n12  redis-server                          aeMain + 43\n13  redis-server                          main + 978\n14  libdyld.dylib                         start + 0\n15  ???                                   0x0 + 1\n[632] 11 Nov 13:25:20.275 # --- INFO OUTPUT\n[632] 11 Nov 13:25:20.275 # # Server\nredis_version:2.5.13\nredis_git_sha1:00000000\nredis_git_dirty:0\nos:Darwin 12.2.0 x86_64\narch_bits:64\nmultiplexing_api:kqueue\ngcc_version:4.2.1\nprocess_id:632\nrun_id: \ntcp_port:6379\nuptime_in_seconds:12142\n\n...[Description Truncated]...\n\n[Context/Logs]:\n- Thanks for reporting, yes that's easy to fix but it's good to have this fixed ASAP indeed! (and yes it's just the big number instead of \"2\").\n- Thank you, fixed into unstable and 2.6 branch. The fix will be available in Redis 2.6.5 that will be released today. Issue closed."}
{"project_id": "Redis", "bug_id": "15", "source_type": "github", "confidence": 0.95, "label": "Function :: Access Control (CWE-284)", "llm_input_text": "[Title]: AOF ignores FLUSHALL\n[Symptom]:\nI fill up my Redis instance, issue a FLUSHALL and shortly after that restart the machine (through upstart with SIGTERM). After the reboot, Redis will start and load the AOF. But it will not replay the FLUSHALL command, and therefore report to duty with all the data loaded again.\n\nThe docs say \"When you restart Redis it will re-play the AOF to rebuild the state.\" Therefore I thought it would honor the FLUSHALL command, too, and end up with an empty DB. I have limited memory and just throw away my whole database regularly via FLUSHALL. If it crashes after a while, I'm unable to recover the append-only file because it just contains way too much data. Note, that AOF rewrites don't compact anything here, either.\n\nI am using 2.4.0. All save points are deactivated, I only use appendfsync on everysec. If I deactivate AOF, everything is fine, and the dump.rdb files are empty after I call FLUSHALL, then SAVE, and then restart.\n\nHere's the logfile. Notice how memory usage goes from 87896904 to 717616 because of the FLUSHALL, but then goes back to 87896824:\n\n```\n[977] 16 Oct 23:12:32 - 0 clients connected (0 slaves), 87896904 bytes in use\n[977] 16 Oct 23:12:32 - Accepted  :36209\n[977] 16 Oct 23:12:32 * DB saved on disk\n[977] 16 Oct 23:12:33 - Client closed connection\n[977] 16 Oct 23:12:37 - 0 clients connected (0 slaves), 717616 bytes in use\n... [Log Snipped] ...\n[985] 16 Oct 23:13:37 - DB 0: 820 keys (0 volatile) in 1024 slots HT.\n[985] 16 Oct 23:13:37 - 0 clients connected (0 slaves), 87896824 bytes in use\n```\n\n[Context/Logs]:\n- Confirmed. Very bad... fixing ASAP.\n- Fixed now on git (2.4 and unstable branches). I'll release Redis 2.4.1 ASAP. Thanks for reporting.\n- Thanks for fixing this so fast. Amazing!"}
{"project_id": "Redis", "bug_id": "16", "source_type": "github", "confidence": 0.85, "label": "Checking :: Boundary/Buffer (CWE-119)", "llm_input_text": "[Title]: redis-server crash w/strack trace...\n[Symptom]:\nI haven't quite updated to 2.4.0 yet but was running 2.3.10 in production and lost one earlier.\n\n[17466] 15 Oct 07:05:25 # ======= Ooops! Redis 2.3.10 got signal: -11- =======\n[17466] 15 Oct 07:05:25 # redis_version:2.3.10^M\nredis_git_sha1:00000000^M\nredis_git_dirty:0^M\narch_bits:64^M\nmultiplexing_api:epoll^M\nprocess_id:17466^M\nuptime_in_seconds:1353855^M\nuptime_in_days:15^M\nlru_clock:1845328^M\nused_cpu_sys:8926.23^M\nused_cpu_user:12859.53^M\nused_cpu_sys_children:70.14^M\nused_cpu_user_children:22.71^M\nconnected_clients:1^M\nconnected_slaves:1^M\nclient_longest_output_list:0^M\nclient_biggest_input_buf: ^M\nblocked_clients:0^M\nused_memory:8472278192^M\nused_memory_human:7.89G^M\nused_memory_rss:6308675584^M\nused_memory_peak:8472286720^M\nused_memory_peak_human:7.89G^M\nmem_fragmentation_ratio:0.74^M\nmem_allocator:jemalloc-2.2.1^M\nloading:0^M\naof_enabled:0^M\nchanges_since_last_save:210^M\nbgsave_in_progress:0^M\nlast_save_time:1318611938^M\nbgrewriteaof_in_progress:0^M\n\nlast_save_time:1318611938^M\nbgrewriteaof_in_progress:0^M\ntotal_connections_received:91901^M\ntotal_commands_processed:284065681^M\nexpired_keys:0^M\nevicted_keys:0^M\nkeyspace_hits:97704116^M\nkeyspace_misses:28609668^M\nhash_max_zipmap_entries:512^M\nhash_max_zipmap_value:512^M\npubsub_channels:0^M\npubsub_patterns:0^M\nlatest_fork_usec:242\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(memcpy+0xe1) [ ]\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(memcpy+0xe1) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(sdscatlen+0x54) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(readQueryFromClient+0x33) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(aeProcessEvents+0x16e) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(aeMain+0x2e) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server(main+0xf9) [ ]\n[17466] 15 Oct 07:05:25 # /lib64/libc.so.6(__libc_start_main+0xe6) [ ]\n[17466] 15 Oct 07:05:25 # /usr/bin/redis-server [ ]\n\n[Context/Logs]:\n- Thank you Jeremy,\n\nplease if it is easy for you to obtain it could you send the exact git commit that you were using, and if possible even the redis-server executable itself? Thanks!\n- Argh.  I can get the binary, yes.  But apparently there's a step in the build process I've been using (only when building from the git repo) that removes the git info along the way.  That's fixed now but I can say exactly which 2.3.10 this was.\n\n[URL]\n\nThat's the binary that was running.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Hi Antirez and Jeremy!\n\nToday we faced the same problem on one slave of our prod environment only few minutes after it start:\n\n \n[14532] 21 Nov 11:49:40 # ======= Ooops! Redis 2.4.2 got signal: -11- =======\n[14532] 21 Nov 11:49:40 # redis_version:2.4.2\nredis_git_sha1:00000000\nredis_git_dirty:0\narch_bits:64\nmultiplexing_api:epoll\nprocess_id:14532\nuptime_in_seconds:2385\nuptime_in_days:0\nlru_clock:67042\nused_cpu_sys:127.59\nused_cpu_user:44.75\nused_cpu_sys_children:4.84\nused_cpu_user_children:1.77\nconnected_clients:20\nconnected_slaves:0\nclient_longest_output_list:0\nclient_biggest_input_buf: \nblocked_clients:0\nused_memory:31861605448\nused_memory_human:29.67G\nused_memory_rss:30233288704\nused_memory_peak:31861605448\nused_memory_peak_human:29.67G\nmem_fragmentation_ratio:0.95\nmem_allocator:jemalloc-2.2.1\nloading:0\naof_enabled:0\nchanges_since_last_save:60\nbgsave_in_progress:0\nlast_save_time:1321873795\nbgrewriteaof_in_progress:0\ntotal_connections_received:119\ntotal_comm\n...[Text Truncated]...\n# /lib/libc.so.6(memcpy+0xe1) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(sdscatlen+0x54) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(readQueryFromClient+0x33) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(aeProcessEvents+0x16e) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(aeMain+0x2e) [ ]\n[14532] 21 Nov 11:49:40 # redis-server(main+0xf9) [ ]\n[14532] 21 Nov 11:49:40 # /lib/libc.so.6(__libc_start_main+0xe6) [ ]\n[14532] 21 Nov 11:49:40 # redis-server [ ]\n \n\nAs the crash log shows:\n- We are using Redis 2.4.2.\n- This instance was only a slave (it might have recieved some \"SET\" command from some clients).\n- The input buffer seems to be huge too ^^\n\nI don't know if it can help you, but unlike Jeremy, we are not using ZSet, and we didn't have any monitoring tools on that slave.\nDo not hesitate to ask me if you have any questions about our redis setup.\n\nRegards,\n\nBaptiste.\n- Thanks this is definitely the same bug, but the fact that it is just a slave makes things a bit different.\nAlso it does not help that Redis truncates INFO outputs in stack traces... (fixing that as well, already fixed into unstable).\n\nBtw the changes I'm doing should provide a lot more background when the input or output buffer overflows... doing the changes right now. I'll update this issue soon.\n\nBtw in my reasoning early in this thread I completely missed that even in the Jeremy case the overflow is happening in the INPUT buffer of the client and not in the output buffer, this changes a few things...\n\nMore news soon."}
{"project_id": "Redis", "bug_id": "17", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Crash in Redis 2.6 RC4 converting an hash value.\n[Symptom]:\nAs received from Marty Weiner from Pinterest.\n\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\n[10845] 09 Jun 04:42:08.251 # === ASSERTION FAILED ===\n[10845] 09 Jun 04:42:08.251 # ==> t_hash.c:406 'ret == DICT_OK' is not true\n[10845] 09 Jun 04:42:08.251 # (forcing SIGSEGV to print the bug report.)\n[10845] 09 Jun 04:42:08.251 #     Redis 2.5.10 crashed by signal: 11\n[10845] 09 Jun 04:42:08.251 #     Failed assertion: ret == DICT_OK (t_hash.c:406)\n[10845] 09 Jun 04:42:08.252 # --- STACK TRACE\n/usr/bin/redis-server(logStackTrace+0x52)[ ]\n/usr/bin/redis-server(_redisAssert+0x6f)[ ]\n/lib/x86_64-linux-gnu/libpthread.so.0(+ )[ ]\n/usr/bin/redis-server(_redisAssert+0x6f)[ ]\n/usr/bin/redis-server(hashTypeConvertZiplist+0xe0)[ ]\n/usr/bin/redis-server(hsetCommand+0x34)[ ]\n/usr/bin/redis-server(call+0x5d)[ ]\n/usr/bin/redis-server(luaRedisGenericCommand+0x25a)[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server[ ]\n/usr/bin/redis-server(lua_pcall+0x4f)[ ]\n/usr/bin/redis-server(evalGenericCommand+0x1fc)[ ]\n/usr/bin/redis-server(call+0x5d)[ ]\n/usr/bin/redis-server(processCommand+0x375)[ ]\n/usr/bin/redis-server(processInputBuffer+0x4f)[ ]\n/usr/bin/redis-server(readQueryFromClient+0xa0)[ ]\n/usr/bin/redis-server(aeProcessEvents+0x136)[ ]\n/usr/bin/redis-server(aeMain+0x2b)[ ]\n/usr/bin/redis-server(main+0x2a3)[ ]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xff)[ ]\n/usr/bin/redis-server[ ]\n[10845] 09 Jun 04:42:08.253 # --- INFO OUTPUT\n[10845] 09 Jun 04:42:08.256 # # Server\nredis_version:2.5.10\nredis_git_sha1:1a3e9d95\nredis_git_dirty:0\nos:Linux 2.6.38-14-virtual x86_64\narch_bits:64\nmultiplexing_api:epoll\ngcc_version:4.5.2\nprocess_id:10845\nrun_id: \ntcp_port:6381\nuptime_in_seconds:14583\nuptime_in_days:0\nlru_clock:1801116\n# Clients\n\nconnected_clients:2255\nclient_longest_output_list:0\nclient_biggest_input_buf:0\nblocked_clients:0\n# Memory\n\nused_memory:1632648896\nused_memory_human:1.52G\nused_memory_rss\n...[Description Truncated]...\n\n[Context/Logs]:\n- As a first step I added a new test in commit c0de459 to stress test the ziplist -> hash conversion. So far the test is passing without problems. I'm going to further analyze the bug today.\n\nSince the original posters of this bug saw it multiple times probably it's a good idea to distribute a modified version of Redis that can provide more information when this assert fails.\n- I walked the dictAdd code and haven't found any holes, even around encoding + rehashing occurring concurrently.  \n\nI'm now wondering if the ziplist version of my hashtable has duplicates in it.  RDB load has no protection, nor does save, so if one creeps in I dont think I'd notice until an expansion.  I'm thinking of adding a verification pass that can be switched on during load to watch for duplicates.\n- ... [Middle Discussions Snipped for Brevity] ...\n- redis  :6379[2]> hgetall 17661039738895\n  1) \"947\"\n  2) \", , ,\"\n  3) \"867\"\n  4) \", , ,\"\n  5) \"588\"\n  6) \", , ,\"\n  7) \"52\"\n  8) \", , ,\"\n  9) \"53\"\n 10) \", ,\"\n 11) \"110\"\n 12) \", ,\"\n 13) \"310\"\n 14) \", , , , , , , , , , ,\"\n 15) \"311\"\n 16) \", ,\"\n 17) \"151\"\n 18) \", ,\"\n 19) \"314\"\n 20) \", , , ,\"\n 21) \"9\"\n 22) \", ,\"\n 23) \"435\"\n 24) \", , , , , , , , , , , , , , , ,\"\n 25) \"912\"\n 26) \", ,\"\n 27) \"193\"\n 28) \", ,\"\n 29) \"436\"\n 30) \", , , , , , , , , ,\"\n 31) \"473\"\n 32) \", ,\"\n 33) \"439\"\n 34) \", , ,\"\n 35) \"196\"\n 36) \", , , ,\"\n 37) \"277\"\n 38) \", ,\"\n 39) \"639\"\n 40) \", , ,\"\n 41) \"396\"\n 42) \", , , , ,\"\n 43) \"837\"\n 44) \", , ,\"\n 45) \"397\"\n 46) \", , , , , , ,\"\n 47) \"991\"\n 48) \", \n...[Text Truncated]...\n\", ,\"\n191) \"701\"\n192) \", , ,\"\n193) \"143\"\n194) \", ,\"\n195) \"306\"\n196) \", ,\"\n197) \"621\"\n198) \", , , , , ,\"\n199) \"145\"\n200) \", ,\"\n201) \"146\"\n202) \", ,\"\n203) \"382\"\n204) \", ,\"\n205) \"708\"\n206) \", ,\"\n207) \"862\"\n208) \", ,\"\n209) \"549\"\n210) \", ,\"\n211) \"710\"\n212) \", ,\"\n213) \"967\"\n214) \", , , , , ,\"\n215) \"496\"\n216) \", ,\"\n217) \"497\"\n218) \", ,\"\n219) \"978\"\n220) \", ,\"\n221) \"83\"\n222) \", ,\"\n223) \"85\"\n224) \", ,\"\n225) \"87\"\n226) \", ,\"\n227) \"88\"\n228) \", ,\"\n229) \"421\"\n230) \", ,\"\n231) \"422\"\n232) \", ,\"\n233) \"900\"\n234) \", ,\"\n235) \"109\"\n236) \", ,\"\n237) \"505\"\n238) \", ,\"\n239) \"424\"\n240) \", , ,\"\n241) \"507\"\n242) \", ,\"\n243) \"903\"\n244) \", ,\"\n245) \"426\"\n246) \", ,\"\n247) \"427\"\n248) \", , ,\"\n249) \"823\"\n250) \", ,\"\n251) \"508\"\n252) \", ,\"\n253) \"904\"\n254) \", , ,\"\n255) \"583\"\n256) \", , , , , , ,\"\n257) \"909\"\n258) \", ,\"\n259) \"585\"\n260) \", , , ,\"\n261) \"1011\"\n262) \", , ,\"\n- @martaaay the core is big news! Thanks. No macros to walk the ziplist unfortunately, you may use RESTORE (but you have to fake the CRC64 checksum) in order to re-create the value into a live instance, btw if you can send me an hex-dump of the ziplist I'll happily check the format.\n\nAnother option is to take the hexdump, write a small C program to inject it inside an array of bytes, and then directly use the ziplist API to walk values.\n\nBtw this is a big step forward! Only problem I think we'll have is that we'll need to understand after we get what value is duplicated how it ended there, but should be simple to reproduce once we have the duplicated value."}
{"project_id": "Redis", "bug_id": "18", "source_type": "github", "confidence": 0.95, "label": "Interface :: Data Encoding (CWE-707)", "llm_input_text": "[Title]: lua struct.unpack redis segfault\n[Symptom]:\nThis lua script causes redis (atleast 2.6.9) to segfault:\n\nlocal t={}; for i=1,288 do t[i]=0 end\nredis.call(\"SET\", KEYS[1], struct.pack((\"H\"):rep(288), unpack(t))) \nt = struct.unpack((\"H\"):rep(288), redis.call(\"GET\", KEYS[1]))\n\n[Context/Logs]:\n- Program received signal SIGSEGV, Segmentation fault.\n  in _int_malloc (av= , bytes=129)\n    at malloc.c:4496\n4496    malloc.c: No such file or directory.\n    in malloc.c\n(gdb) bt\n#0    in _int_malloc (av= , bytes=129)\n    at malloc.c:4496\n#1    in _int_realloc (av= , \n    oldp= , oldsize=80, nb=144) at malloc.c:5274\n#2    in *__GI___libc_realloc (oldmem= , \n    bytes=128) at malloc.c:3822\n#3    in luaM_realloc_ ()\n#4    in setarrayvector ()\n#5    in resize ()\n#6    in newkey ()\n#7    in luaV_settable ()\n#8    in luaV_execute ()\n#9    in luaD_call ()\n#10   in luaD_rawrunprotected ()\n#11   in luaD_pcall ()\n#12   in lua_pcall ()\n#13   in evalGenericCommand (c= , \n    evalsha=0) at scripting.c:872\n#14   in call (c= , flags=7)\n    at redis.c:1502\n#15   in processCommand (c= )\n    at redis.c:1677\n#16   in processInputBuffer (c= )\n    at networking.c:1011\n#17   in readQueryFromClient (\n    el= , fd=7, privdata= , \n    mask= ) at networking.c:1074\n#18   in aeProcessEvents (eventLoop= , \n    flags= ) at ae.c:382\n#19   in aeMain (eventLoop= ) at ae.c:425\n#20   in main (argc=1, argv= )\n    at redis.c:2622\n- Thank you for reporting, fixing ASAP.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Hello, confirmed, there is a bug here, fixing ASAP, thank you for reporting.\n- It Was Not My Code (TM)\n\nThe Lua struct library was to blame, I updated the code to latest version of the lib and it seems to be fixed.\n\nClosing the issue but I'll appreciate a feedback after the upgrade (however I tested it manually and via valgrind on two systems).\n\nThanks again for reporting!"}
{"project_id": "Redis", "bug_id": "19", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: [2.9.102] Assertion failed: cluster.c:4641 'n != NULL' is not true\n[Symptom]:\nThis happened upon issuing a manual CLUSTER FAILOVER to the slave. It was the former master where the error occured, the slave is fine and the cluster check reports okay, so hooray for that :)\n\nThis was during a test setup with a client molesting the cluster with a number of SET/MGET. Before the manual failover the cluster looked like this:\n\n```\nConnecting to node  :7001: OK\nConnecting to node  :7003: OK\nConnecting to node  :7002: OK\nConnecting to node  :7004: OK\n... [Log Snipped] ...\n[OK] All 16384 slots covered.\n```\n\nAnd after the manual failover (and crash of node  ) it looked like this:\n\n```\nConnecting to node  :7002: OK\nConnecting to node  :7001: OK\nConnecting to node  :7004: OK\nM:    :7002\n... [Log Snipped] ...\n[OK] All 16384 slots covered.\n```\n\nCrash report:\n\n```\n21402:M 15 Jan 10:23:36.048 # Manual failover requested by slave  .\n21402:M 15 Jan 10:23:36.203 # Failover auth granted to   for epoch 9\n21402:M 15 Jan 10:23:36.204 # Configuration change detected. Reconfiguring myself as a replica of  \n21402:S 15 Jan 10:23:36.204 # Connection with slave  :7004 lost.\n21402:S 15 Jan 10:23:36.204 # \n... [Log Snipped] ...\n21402:S 15 Jan 10:23:36.404 # \n=== REDIS BUG REPORT END. Make sure to include from START to END. ===\n```\n\nThe test script was very simple:\n\n```\nfrom rediscluster.client import RedisCluster\nfrom time import time\n\nstartup_nodes = [\n    {'host': ' ', 'port': '7002'},\n... [Log Snipped] ...\n    duration = time() - t\n    print len(l), \"%f ms\" % (duration * 1000.0)\n```\n\n[Context/Logs]:\n- Hello, thank you for reporting. Checking the code, it makes sense it crashes like that in certain edge conditions. The code pretends that we never dispatch commands if the cluster is logically down (one or more slots uncovered), but this is not the case. The fix will be the same anyway (since handling this in getNodeByQuery() will prevent the next bug similar to that), however I also want to check the exact conditions that trigger it in order to also trap it before, but I've an idea about what the state is. Fixing tomorrow morning CEST giving priority over the doc writing effort, and releasing a new RC. However this is not very critical (it is in the effects, but not conceptually), so the stable release will not be delayed.\n- @ingmar checking the issue I see this happened with Redis 3.0.0-rc2, please note that rc3 fixed several critical bugs so you are likely to run into strange consistency issues in the CLUSTER NODES output and other crashes. This issue itself may be due to the same set of bugs, however whatever this is the case or not, the issue posted contains an hit about an implementation fragility that should be fixed :-)\n- Problem fixed, a few notes:\n1. It's not 100% clear to me, in this exact setup, how the hash slots were unbound. As a result of the configuration update received from the (old) slave I expected the master to have all the hash slots still covered. Maybe it's due to the many RC2 serious memory bugs, fixed by RC3.\n2. Anyway the getNodeByQuery() implementation was fragile. It's not a good idea to assert for `node != NULL`, and in general, to the fact that the cluster state is atomically updated.\n3. And... indeed the cluster state is _not_ atomically updated, so there was a bug here regardless of what exactly caused this instance of the bug. The cluster state is updated in `clusterBeforeSleep()` in a lazy way.\n4. Moreover the `clusterBeforeSleep()` call was misplaced at the end of the chain of the `beforeSleep()` call in `redis.c`. It should be at the top, before processing un blocking clients. This is exactly the reason in the specific instance of the bug as reported, why the state was not updated in time before clients served.\n\nReleasing RC5 in a second. Thank you for reporting!"}
{"project_id": "Redis", "bug_id": "20", "source_type": "github", "confidence": 0.9, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Replication inconsistent issue\n[Symptom]:\nRedis version 2.8 and 3.0.3\n1. Initially, there are individual A and B(Master)->C(Slave)-D(Slave)\n2. In A execute \"set a 1\", in B execute \"set a 2\". Now there is key a with value 2 in B, C and D.\n3. In D execute \"multi\", \"client kill  : \", \"debug sleep 60\", \"exec\" to make D try psync after step 4.\n4. Make B slave of A with slaveof cmd.\n5. Wait D reconnect with C.\n\nExpect Result: value of a is 1 in D\nActual Result: value of a is 2 in D\n\n[Context/Logs]:\n- I think in step 2 C should reset backlog, then D can only full sync with C.\n- Thanks for submitting, I think I found the cause for this issue. Working on a fix right now.\n- Probably it will never be useful again, but given that I wrote it, we can use it to better document the bug for the future: here is the script to reproduce it easily:\n\n```\nsh\n#!/bin/bash\nmkdir -p /tmp/a; rm -rf /tmp/a/*\nmkdir -p /tmp/b; rm -rf /tmp/b/*\nmkdir -p /tmp/c; rm -rf /tmp/c/*\n... [Log Snipped] ...\nredis-cli -p $C SHUTDOWN NOSAVE\nredis-cli -p $D SHUTDOWN NOSAVE\n```\n- I wrote a first patch, than realized that this bug is just a manifestation of a deeper problem. Redis replication code used to do two things:\n1. When a slave lost connection with its master, disconnected the chained slaves ASAP. Which is not needed since after a successful PSYNC with the master, the slaves can continue and don't need to resync in turn.\n2. However after a failed PSYNC the replication backlog was not reset, so a slave was able to PSYNC successfully even if the instance did a full sync with its master, containing now an entirely different data set.\n\nSo I'm writing a different fix that only forces a full SYNC of the connected slaves once the slave has to full SYNC with its master."}
{"project_id": "Redis", "bug_id": "21", "source_type": "github", "confidence": 0.95, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: GEORADIUS returns the same key twice on Redis 3.1.999\n[Symptom]:\n# The bug\n\nA `GEORADIUS` query returns the same key twice. Since `GEORADIUS` [Link: is defined as]:\n\nI assume that having a duplicate in the set is an erroneous behaviour. \n# Steps to reproduce on `redis-cli`\n\n```\n :6379[1]> GEOADD users -47.271613776683807 -54.534504198047678 user_000000\n(integer) 1\n :6379[1]> GEOADD users -47.271613776683807 -54.534504198047678 user_000000\n(integer) 0\n :6379[1]> GEORADIUS users 0 0 50000 km WITHCOORD\n... [Log Snipped] ...\n   2) 1) \"-47.271613776683807\"\n      2) \"-54.534504198047678\"\n```\n# Notes\n## Adding the key multiple times\n\nAdding the same key more than twice seems to add the key only twice:\n\n```\n :6379[2]> GEOADD users -47.271613776683807 -54.534504198047678 user_000000\n(integer) 1\n :6379[2]> GEOADD users -47.271613776683807 -54.534504198047678 user_000000\n(integer) 0\n :6379[2]> GEOADD users -47.271613776683807 -54.534504198047678 user_000000\n... [Log Snipped] ...\n   2) 1) \"-47.271613776683807\"\n      2) \"-54.534504198047678\"\n```\n## Other coordinates\n\nThe bug was not reproduced with other coordinates, e.g.:\n\n```\n :6379[2]> GEOADD users 10 10 'x'\n(integer) 1\n :6379[2]> GEORADIUS users 10 10 500 km WITHCOORD\n1) 1) \"x\"\n   2) 1) \"10.000002086162567\"\n... [Log Snipped] ...\n   2) 1) \"10.000002086162567\"\n      2) \"10.00000092823273\"\n```\n# INFO\n\n```\n :6379[2]> INFO\n# Server\nredis_version:3.1.999\nredis_git_sha1:00000000\nredis_git_dirty:0\n... [Log Snipped] ...\ndb1:keys=1,expires=0,avg_ttl=0\ndb2:keys=1,expires=0,avg_ttl=0\n```\n\n[Context/Logs]:\n- Thanks for reporting, actually you can use a single `GEOADD` command and yet the item will be reported twice. It is a bug with the GEORADIUS implementation and not with the underlying sorted set data structure. I'll fix this tomorrow hopefully.\n- In this specific case the problem is due to the fact that the neighbors squares calculated for north_west and south_west are the same, due probably to the huge radius used. It's a corner case which should be pretty easy to fix AFAIK.\n- Fixed, thanks for reporting."}
{"project_id": "Redis", "bug_id": "22", "source_type": "github", "confidence": 0.75, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Redis 3.0.0 crashed by signal: 11\n[Symptom]:\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\n1718:M 12 Jan 11:20:08.924 #     Redis 3.0.0 crashed by signal: 11\n1718:M 12 Jan 11:20:08.924 #     Failed assertion:   ( :0)\n1718:M 12 Jan 11:20:08.924 # --- STACK TRACE\n/opt/redis/bin/redis-server *:7380 [cluster] - logStackTrace+0x43 [ ]\n/opt/redis/bin/redis-server *:7380 [cluster] - clusterNodeRemoveSlave+0x17 [ ]\n/lib64/libpthread.so.0[ ]\n/opt/redis/bin/redis-server *:7380 [cluster] - clusterNodeRemoveSlave+0x17  [ ]\n/opt/redis/bin/redis-server *:7380 [cluster] - clusterProcessPacket+0x6c3 [ ]\n/opt/redis/bin/redis-server *:7380 [cluster] - clusterReadHandler+0x135 [ ]\n/opt/redis/bin/redis-server *:7380 [cluster] - aeProcessEvents+0x13c [ ]\n/opt/redis/bin/redis-server *:7380 [cluster] - aeMain+0x2b [ ]\n/opt/redis/bin/redis-server *:7380 [cluster] - main+0x2cd - [ ]\n/lib64/libc.so.6 - __libc_start_main+0xfd [ ]\n/opt/redis/bin/redis-server *:7380 [cluster][ ]\n1718:M 12 Jan 11:20:08.963 # --- INFO OUTPUT\n1718:M 12 Jan 11:20:08.963 # # Server\n\nredis_version:3.0.0\n\nredis_git_sha1:00000000\n\nredis_git_dirty:0\n\nredis_build_id: \n\nredis_mode:cluster\n\nos:Linux 2.6.32-220.el6.x86_64 x86_64\n\narch_bits:64\n\nmultiplexing_api:epoll\n\ngcc_version:4.4.6\n\nprocess_id:1718\n\nrun_id: \n\ntcp_port:7380\n\nuptime_in_seconds:12764535\n\nuptime_in_days:147\n\nhz:10\n\nlru_clock:9728232\n\nconfig_file:/opt/bluewhale/ /7380/data/redis.conf\n# Clients\n\nconnected_clients:441\n\nclient_longest_output_list:0\n\nclient_biggest_input_buf:2920\n\nblocked_clients:0\n# Memory\n\nused_memory:5638983200\n\nused_memory_human:5.25G\n\nused_memory_rss:7016611840\n\nused_memory_peak:6767090192\n\nused_memory_peak_human:6.30G\n\nused_memory_lua:46080\n\nmem_fragmentation_ratio:1.24\n\nmem_allocator:jemalloc-3.6.0\n# Persistence\n\nloading:0\n\nrdb_changes_since_last_save:1111973973\n\nrdb_bgsave_in_progress:0\n\nrdb_last_save_time:1443207413\n\nrdb_last_bgsave_status:ok\n\nrdb_last_bgsave_time_sec:51\n\nrdb_current_bgsave_time_sec:-1\n\naof_enabled:0\n\naof_rewrite_in_progress:0\n\naof_rewrite_schedule\n...[Description Truncated]...\n\n[Context/Logs]:\n- Hello, please could you send me the `redis-server` executable that generated this issue? Thanks.\n- Update: tried to fuzz-testing clusterNodeRemoveSlave() and clusterNodeAddSlave() without success, they work as expected apparently for different set of operations, the memmove() looks fine and so forth. Must be something else. The binary and disassembling can definitely provide more hints.\n- ... [Middle Discussions Snipped for Brevity] ...\n- ok, thanks very much for your work, we will pull the code and test it.\n- Thanks, I'm still testing stuff and doing code auditing around this patch and the general mechanism to take n->slaveof and n->slaves synchronized, it's not totally impossible that I'll change the code a bit more, but testing of this patch as provided is very appreciated, thank you."}
{"project_id": "Redis", "bug_id": "23", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Bugs introduced in variadic MIGRATE on errors\n[Symptom]:\nIn looking through the latest commits to the MIGRATE command to make it variadic, Iâ€™ve noticed some problems and am not clear about the expected behavior in error scenarios.\n\n[URL]\n\nFirst, the new lists allocated on 4603 and 4604 are not freed under all error scenarios, for example on lines 4639, 4645, 4647, 4674, leading to memory leaks. Similarly for newargv allocated on 4748 â€“ it is not freed in the socket_err case.\n\nMore concerning, however, is the undefined behavior of migrating multiple keys where they are not all acknowledged by the receiver. In the loop on 4750, we will retry the entire command in some cases on socket errors. This is after we have potentially already queued a reply to the client with an error and potentially already deleted some of the keys from the source. If we retry (or even if we fail out) we never translate the command to a DEL to propagate what has been deleted to the replication/AOF stream. When we retry, if weâ€™ve already deleted the item from the database, we're referencing invalid values, as well as doubly refcounting keys, etc.\n\nFor example, if I issue a MIGRATE dst port â€œâ€ db timeout REPLACE KEY1 KEY2 KEY3 KEY4, we will send a RESTORE command for each of the four keys. Assume we process KEY1 and KEY2 appropriately, and delete them from the database. Letâ€™s say we have trouble reading the response for KEY3 from the socket. Weâ€™ll possibly retry the command (going to try_again mark). We will again try to RESTORE all four keys to the destination. Meanwhile, the values corresponding to KEY1 and KEY2 have been freed.  If weâ€™re able to get successful responses, weâ€™ll try to delete the keys again (L4764). L4770 will increase the refcount of KEY1 and KEY2 a second time, which will result in the key being incorrectly refcounted twice and never freed.\n\nCould you take a look at the error handling here and clarify the expected behavior?\n\n[Context/Logs]:\n- Hello, thank you, this is very helpful. I'll write a complete report as a first thing I do after the weekend (during the weekend if I'll find some time).\n- My comments:\n1. There is no leak on line 4639, just because when KEYS is given, no other arguments are parsed, all the rest is considered to be key names. However that's not the case for the other points where there is an actual leak. All instances of the leak fixed.\n2. The `newargv` leaks should be only on socket errors apparently (as you noted in your comment), since it's otherwise freed by passing the pointer to `replaceClientCommandVector` that takes ownership, or it gets freed. Fixed as well. Now the variable is declared at the top of the function and immediately initialized to NULL so that freeing it if not allocated is not an issue anyway.\n3. About the command retry, it was a totally mess, one of the worse pieces of code I ever wrote... Redesigning it with more obvious semantics, almost finished,  news ASAP in this issue.\n\nThanks for your help!\n- ... [Middle Discussions Snipped for Brevity] ...\n- Hello again, I did an auditing of the new function, I can't find other errors, but modified the code a bit more in order to handle the cleanup of `newargv` in a single place.\n\nIt looks like a trivial way to simplify the function a lot more is to write it as a non retrying version, and wrap it into another function that will retry depending on the returned error. Probably not worth it right now since this is going to be back ported in all the production versions of Redis, and new code is always dangerous... :-)\n- It looks good to me now.  Thanks for the quick resolution!  Feel free to resolve this issue."}
{"project_id": "Redis", "bug_id": "24", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Bugs introduced in variadic MIGRATE on errors\n[Symptom]:\nIn looking through the latest commits to the MIGRATE command to make it variadic, Iâ€™ve noticed some problems and am not clear about the expected behavior in error scenarios.\n\n[URL]\n\nFirst, the new lists allocated on 4603 and 4604 are not freed under all error scenarios, for example on lines 4639, 4645, 4647, 4674, leading to memory leaks. Similarly for newargv allocated on 4748 â€“ it is not freed in the socket_err case.\n\nMore concerning, however, is the undefined behavior of migrating multiple keys where they are not all acknowledged by the receiver. In the loop on 4750, we will retry the entire command in some cases on socket errors. This is after we have potentially already queued a reply to the client with an error and potentially already deleted some of the keys from the source. If we retry (or even if we fail out) we never translate the command to a DEL to propagate what has been deleted to the replication/AOF stream. When we retry, if weâ€™ve already deleted the item from the database, we're referencing invalid values, as well as doubly refcounting keys, etc.\n\nFor example, if I issue a MIGRATE dst port â€œâ€ db timeout REPLACE KEY1 KEY2 KEY3 KEY4, we will send a RESTORE command for each of the four keys. Assume we process KEY1 and KEY2 appropriately, and delete them from the database. Letâ€™s say we have trouble reading the response for KEY3 from the socket. Weâ€™ll possibly retry the command (going to try_again mark). We will again try to RESTORE all four keys to the destination. Meanwhile, the values corresponding to KEY1 and KEY2 have been freed.  If weâ€™re able to get successful responses, weâ€™ll try to delete the keys again (L4764). L4770 will increase the refcount of KEY1 and KEY2 a second time, which will result in the key being incorrectly refcounted twice and never freed.\n\nCould you take a look at the error handling here and clarify the expected behavior?\n\n[Context/Logs]:\n- Hello, thank you, this is very helpful. I'll write a complete report as a first thing I do after the weekend (during the weekend if I'll find some time).\n- My comments:\n1. There is no leak on line 4639, just because when KEYS is given, no other arguments are parsed, all the rest is considered to be key names. However that's not the case for the other points where there is an actual leak. All instances of the leak fixed.\n2. The `newargv` leaks should be only on socket errors apparently (as you noted in your comment), since it's otherwise freed by passing the pointer to `replaceClientCommandVector` that takes ownership, or it gets freed. Fixed as well. Now the variable is declared at the top of the function and immediately initialized to NULL so that freeing it if not allocated is not an issue anyway.\n3. About the command retry, it was a totally mess, one of the worse pieces of code I ever wrote... Redesigning it with more obvious semantics, almost finished,  news ASAP in this issue.\n\nThanks for your help!\n- ... [Middle Discussions Snipped for Brevity] ...\n- Hello again, I did an auditing of the new function, I can't find other errors, but modified the code a bit more in order to handle the cleanup of `newargv` in a single place.\n\nIt looks like a trivial way to simplify the function a lot more is to write it as a non retrying version, and wrap it into another function that will retry depending on the returned error. Probably not worth it right now since this is going to be back ported in all the production versions of Redis, and new code is always dangerous... :-)\n- It looks good to me now.  Thanks for the quick resolution!  Feel free to resolve this issue."}
{"project_id": "Redis", "bug_id": "25", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Redis-sentinel 3.2rc1 crashed after master was shutdown using \"poweroff\"\n[Symptom]:\nRedis-sentinel on one of the slaves crashed after master was shut down using the \"poweroff\" system command.\n\n```\nJan 26 15:52:06 redis-sentinel[652]: 652:X 26 Jan 15:52:06.315 # +sdown master redis-data-development   6379\nJan 26 15:52:06 redis-sentinel[652]: 652:X 26 Jan 15:52:06.315 # +sdown sentinel  :26379   26379 @ redis-data-development   6379\nJan 26 15:52:07 redis-sentinel[652]: 652:X 26 Jan 15:52:07.180 # +new-epoch 22\nJan 26 15:52:07 redis-sentinel[652]: 652:X 26 Jan 15:52:07.188 # +vote-for-leader   22\nJan 26 15:52:07 redis-sentinel[652]: 652:X 26 Jan 15:52:07.440 # +odown master redis-data-development   6379 #quorum 2/2\n... [Log Snipped] ...\nJan 26 15:52:08 systemd[1]: redis-sentinel.service: main process exited, code=killed, status=11/SEGV\nJan 26 15:52:08 systemd[1]: Unit redis-sentinel.service entered failed state.\n```\n\n[Context/Logs]:\n- Thanks, I was pretty sure there were left crashes on edge cases in Sentinel of Redis 3.2, connection sharing changed too many internals... I hope I can fix this before RC2 which is due for tomorrow.\n- Thank you for a quick reply. I just noticed that the bug persists on this server event after restarting redis-sentinel.\n- ... [Middle Discussions Snipped for Brevity] ...\n- Thanks @pako-pl, your help was really appreciated! RC2 will be released within the next 24h.\n- p.s. It will be just the last commit of the 3.2 branch tagged as \"RC2\" so if you want to use it, you can just grab it right now."}
{"project_id": "Redis", "bug_id": "26", "source_type": "github", "confidence": 0.85, "label": "Timing :: Resource Lifecycle (CWE-664)", "llm_input_text": "[Title]: Node of redis-cluster dies with certain sequences of commands\n[Symptom]:\nHi,\n\nWhile playing with redis-cluster today I noticed that certain sequences of commands can make a node of the cluster die. The OS is a Linux 32bit VM (full details are in the dump at the end of this ticket) and the cluster is composed of three nodes configured as follow:\n\n```\n./redis-trib.rb create  :6379  :6380  :6381\n```\n\nThis is the sequence of commands that always make the node fail (the key `foobar` is in the slot covered by node ` :6379`):\n\n```\nredis  :6379> SET foobar test\nOK\nredis  :6379> MGET foo foobar\n(error) ERR Multi keys request invalid in cluster\nredis  :6379> GETRANGE foobar 0 1\n... [Log Snipped] ...\nredis  :6379> GETRANGE foobar 0 1\nCould not connect to Redis at  :6379: Connection refused\n```\n\nThe thing I noticed is that the node starts acting strange only after issuing `MGET` with multiple keys, which returns a `-ERR` as one would expect, but only certain commands make the node fail after that one: for example it crashes with `GETRANGE` or `SETRANGE`, but `GET` or `EXISTS` seem to work normally returning the expected results. In the majority of cases the node crashed at the third `GETRANGE` request, but there were times when the node crashed instantly.\n\nThis is the dump generated by the failing node when issuing `GETRANGE` three times:\n\n```\n[12830] 29 Jul 10:17:04.321 #     Redis 2.9.7 crashed by signal: 11\n[12830] 29 Jul 10:17:04.321 #     Failed assertion:   ( :0)\n[12830] 29 Jul 10:17:04.321 # --- STACK TRACE\n./redis-server(logStackTrace+0x71)[ ]\n/lib/i386-linux-gnu/libc.so.6(+ )[ ]\n... [Log Snipped] ...\n[12830] 29 Jul 10:17:04.325 # (bfea2498) -> b684e218\n[12830] 29 Jul 10:17:04.325 #\n```\n\nAnd this is the dump generated when just the first `GETRANGE` made the node crash (note that the stack trace is different and the generated dump is incomplete):\n\n```\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\n[21541] 29 Jul 10:52:23.419 #     Redis 2.9.7 crashed by signal: 11\n[21541] 29 Jul 10:52:23.419 #     Failed assertion:   ( :0)\n[21\n...[Description Truncated]...\n\n[Context/Logs]:\n- I was able to reproduce this. Fixing today, thanks.\n- Fixed, thanks."}
{"project_id": "Redis", "bug_id": "27", "source_type": "github", "confidence": 0.7, "label": "Other", "llm_input_text": "[Title]: Redis crashed after a week of uptime. Ran memtest for a few minutes on vm.\n[Symptom]:\n[18952] 14 Dec 16:20:46.191 #     Redis 2.8.22 crashed by signal: 11\n[18952] 14 Dec 16:20:46.191 #     Failed assertion:   ( :0)\n[18952] 14 Dec 16:20:46.191 # --- STACK TRACE\nredis-server *:6379(logStackTrace+0x3e)[ ]\nredis-server *:6379(processCommand+0x1a9)[ ]\n/lib/x86_64-linux-gnu/libpthread.so.0(+ )[ ]\nredis-server *:6379(processCommand+0x1a9)[ ]\nredis-server *:6379(processInputBuffer+0x51)[ ]\nredis-server *:6379(readQueryFromClient+0xbd)[ ]\nredis-server *:6379(aeProcessEvents+0x230)[ ]\nredis-server *:6379(aeMain+0x2b)[ ]\nredis-server *:6379(main+0x31e)[ ]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xfd)[ ]\nredis-server *:6379[ ]\n[18952] 14 Dec 16:20:46.191 # --- INFO OUTPUT\n[18952] 14 Dec 16:20:46.191 # # Server\nredis_version:2.8.22\nredis_git_sha1:00000000\nredis_git_dirty:0\nredis_build_id: \nredis_mode:standalone\nos:Linux 3.2.0-4-amd64 x86_64\narch_bits:64\nmultiplexing_api:epoll\ngcc_version:4.7.2\nprocess_id:18952\nrun_id: \ntcp_port:6379\nuptime_in_seconds:1465093\nuptime_in_days:16\nhz:10\nlru_clock:7249656\nconfig_file:/etc/fk-3p-redis/redis-server.conf\n# Clients\n\nconnected_clients:78\nclient_longest_output_list:17815\nclient_biggest_input_buf:0\nblocked_clients:0\n# Memory\n\nused_memory:4999941976\nused_memory_human:4.66G\nused_memory_rss:3472392192\nused_memory_peak:5077248952\nused_memory_peak_human:4.73G\nused_memory_lua:36864\nmem_fragmentation_ratio:0.69\nmem_allocator:jemalloc-3.6.0\n# Persistence\n\nloading:0\nrdb_changes_since_last_save:3991\nrdb_bgsave_in_progress:0\nrdb_last_save_time:1450090023\nrdb_last_bgsave_status:ok\nrdb_last_bgsave_time_sec:2\nrdb_current_bgsave_time_sec:-1\naof_enabled:0\naof_rewrite_in_progress:0\naof_rewrite_scheduled:0\naof_last_rewrite_time_sec:-1\naof_current_rewrite_time_sec:-1\naof_last_bgrewrite_status:ok\naof_last_write_status:ok\n# Stats\n\ntotal_connections_received:1200\ntotal_commands_processed:1266751737\ninstantaneous_ops_per_sec:74\ntotal_net_input_bytes:219451461936\ntotal_net_output_bytes:39608808420918\ninstantaneous_input_kbps:11.58\ninstanta\n...[Description Truncated]...\n\n[Context/Logs]:\n- Hello, there are no known bugs that may lead to that AFAIK, so may be an HW failure or a new unknown Redis bug. There are no hints in the stack trace unfortunately. Please could you check if it happens again and post other crash reports? If they all happen at random locations it could be lack of stability of the hardware. Please also could you check with your VM provider if they are using error corrected memory or not?\n- Also could be useful to have the original redis server binary. You may send it to antirez at g-mail citing the issue number in the subject. Thanks.\n- ... [Middle Discussions Snipped for Brevity] ...\n- yeah, this is most likely fixed now (unless there's another bug we didn't spot there).\nI don't think there's any way to avoid this bug, but on the other hand, it seems VERY rare so i doubt you'll see it again.\non the other hand, you'll benefit a lot by upgrading to a more recent version due to other bug fixes.\n- +1 to Oran reasoning. Very rare, if you see it again in a short timeframe maybe is a different bug. However I'm releasing 2.8 and 3.0 new patchlevels in a matter of days, with this fix. I can't do it today because there are pending things in order to release 3.0.6.\n\nYou can either use the latest commit of the `2.8` branch if you want to be sure this bug is fixed in your environment, or also just apply commit e0b7388 in your current tree.\n\nOr wait a few days and install the new 2.8 or 3.0 releases."}
{"project_id": "Redis", "bug_id": "28", "source_type": "github", "confidence": 0.85, "label": "Algorithm :: Resource/Memory Leak (CWE-400)", "llm_input_text": "[Title]: Lua script multi-element LPUSH / BRPOPLPUSH replication bug\n[Symptom]:\nI noticed a replication bug while attempting to use Redis as a reliable queue with a Lua script pushing multiple elements onto the queue. It appears the wrong number of RPOP operations are sent to the slave instance, resulting in the queue on the slave growing unbounded, out of sync with master.\n\nI created an example repo to demonstrate this behavior:\n\n[URL]\n\nThis affects Redis 2.5.12 (and 2.5.11, likely early versions as well).\n\n[Context/Logs]:\n- Thank you for reporting, I'll fix it in the next days and report back.\n- @antirez any updates?\n- Hello, this issue is finally fixed in the unstable and 2.6 branch. An almost complete reimplementation of blocking operations was required in order to fix this issue, the details are documented in the commit message. Thanks for reporting! Closing."}
{"project_id": "Redis", "bug_id": "29", "source_type": "github", "confidence": 0.7, "label": "Other", "llm_input_text": "[Title]: Redis crashed after a week of uptime. Ran memtest for a few minutes on vm.\n[Symptom]:\n[18952] 14 Dec 16:20:46.191 #     Redis 2.8.22 crashed by signal: 11\n[18952] 14 Dec 16:20:46.191 #     Failed assertion:   ( :0)\n[18952] 14 Dec 16:20:46.191 # --- STACK TRACE\nredis-server *:6379(logStackTrace+0x3e)[ ]\nredis-server *:6379(processCommand+0x1a9)[ ]\n/lib/x86_64-linux-gnu/libpthread.so.0(+ )[ ]\nredis-server *:6379(processCommand+0x1a9)[ ]\nredis-server *:6379(processInputBuffer+0x51)[ ]\nredis-server *:6379(readQueryFromClient+0xbd)[ ]\nredis-server *:6379(aeProcessEvents+0x230)[ ]\nredis-server *:6379(aeMain+0x2b)[ ]\nredis-server *:6379(main+0x31e)[ ]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xfd)[ ]\nredis-server *:6379[ ]\n[18952] 14 Dec 16:20:46.191 # --- INFO OUTPUT\n[18952] 14 Dec 16:20:46.191 # # Server\nredis_version:2.8.22\nredis_git_sha1:00000000\nredis_git_dirty:0\nredis_build_id: \nredis_mode:standalone\nos:Linux 3.2.0-4-amd64 x86_64\narch_bits:64\nmultiplexing_api:epoll\ngcc_version:4.7.2\nprocess_id:18952\nrun_id: \ntcp_port:6379\nuptime_in_seconds:1465093\nuptime_in_days:16\nhz:10\nlru_clock:7249656\nconfig_file:/etc/fk-3p-redis/redis-server.conf\n# Clients\n\nconnected_clients:78\nclient_longest_output_list:17815\nclient_biggest_input_buf:0\nblocked_clients:0\n# Memory\n\nused_memory:4999941976\nused_memory_human:4.66G\nused_memory_rss:3472392192\nused_memory_peak:5077248952\nused_memory_peak_human:4.73G\nused_memory_lua:36864\nmem_fragmentation_ratio:0.69\nmem_allocator:jemalloc-3.6.0\n# Persistence\n\nloading:0\nrdb_changes_since_last_save:3991\nrdb_bgsave_in_progress:0\nrdb_last_save_time:1450090023\nrdb_last_bgsave_status:ok\nrdb_last_bgsave_time_sec:2\nrdb_current_bgsave_time_sec:-1\naof_enabled:0\naof_rewrite_in_progress:0\naof_rewrite_scheduled:0\naof_last_rewrite_time_sec:-1\naof_current_rewrite_time_sec:-1\naof_last_bgrewrite_status:ok\naof_last_write_status:ok\n# Stats\n\ntotal_connections_received:1200\ntotal_commands_processed:1266751737\ninstantaneous_ops_per_sec:74\ntotal_net_input_bytes:219451461936\ntotal_net_output_bytes:39608808420918\ninstantaneous_input_kbps:11.58\ninstanta\n...[Description Truncated]...\n\n[Context/Logs]:\n- Hello, there are no known bugs that may lead to that AFAIK, so may be an HW failure or a new unknown Redis bug. There are no hints in the stack trace unfortunately. Please could you check if it happens again and post other crash reports? If they all happen at random locations it could be lack of stability of the hardware. Please also could you check with your VM provider if they are using error corrected memory or not?\n- Also could be useful to have the original redis server binary. You may send it to antirez at g-mail citing the issue number in the subject. Thanks.\n- ... [Middle Discussions Snipped for Brevity] ...\n- yeah, this is most likely fixed now (unless there's another bug we didn't spot there).\nI don't think there's any way to avoid this bug, but on the other hand, it seems VERY rare so i doubt you'll see it again.\non the other hand, you'll benefit a lot by upgrading to a more recent version due to other bug fixes.\n- +1 to Oran reasoning. Very rare, if you see it again in a short timeframe maybe is a different bug. However I'm releasing 2.8 and 3.0 new patchlevels in a matter of days, with this fix. I can't do it today because there are pending things in order to release 3.0.6.\n\nYou can either use the latest commit of the `2.8` branch if you want to be sure this bug is fixed in your environment, or also just apply commit e0b7388 in your current tree.\n\nOr wait a few days and install the new 2.8 or 3.0 releases."}
{"project_id": "Redis", "bug_id": "30", "source_type": "github", "confidence": 0.85, "label": "Function :: Access Control (CWE-284)", "llm_input_text": "[Title]: Redis 3.2.3 crashed by signal: 11\n[Symptom]:\nWe have a big redis node in a cluster, and we're resharding it to other nodes. While doing that, we encountered many times the error reported below, which forced us to manually kill the instance using kill -9 and reload it.\r\n\r\nIn normal operation the node has been working for months without any problems. The only special thing about it is that there are some very big keys to migrate; for those usually we expected a timeout in the migration, but previously we didn't have this error which forces us to restart the node.\r\n\r\nresharding log:\r\nMoving slot 7929 from  :  to  : : .................$\r\nMoving slot 7930 from  :  to  : : .................$\r\nMoving slot 7931 from  :  to  : : .................$\r\nMoving slot 7932 from  :  to  : : .................$\r\n[ERR] Calling MIGRATE: Connection timed out\r\n\r\nredis log:\r\n\r\n```\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n29395:M 31 Jan 22:16:03.248 # Redis 3.2.3 crashed by signal: 11\r\n29395:M 31 Jan 22:16:03.248 # Crashed running the instuction at:  \r\n29395:M 31 Jan 22:16:03.248 # Accessing address: (nil)\r\n29395:M 31 Jan 22:16:03.248 # Failed assertion:   ( :0)\r\n... [Log Snipped] ...\n*** Preparing to test memory region 7ffec3a02000 (8192 bytes)\r\n*** Preparing to test memory region 7ffec3a06000 (4096 bytes)\n```\n\n[Context/Logs]:\n- Hello, are you still able to reproduce the problem in your environment? That would be very useful. Thanks!\n- Hi Salvatore\r\n\r\nWe stopped resharding the data because this happened quite a few times, but we didn't change anything since then so I'm pretty sure it would happen again if we tried. Did you publish anything new in the meantime? We could restart the sharding, but as it takes a few hours to reload this too big instance when it crashes, I'd rather not do it just to see if it will crash again...\r\n\r\nLet me know if you want any additional details.\n- ... [Middle Discussions Snipped for Brevity] ...\n- UPDATE: disassembling the `redis-server` executable it is quite clear that the problem is that the `port` parameter of the function is NULL. Should be easy to understand why, so I'm going to figure out when this happens.\n- Hello again @danmaz74 and @damaru00. I just tracked the bug cause and I'm preparing a fix. It looks like that regardless of the bug, that crashed the server, the migration is not going to work anyway because of a connection error happening while the big key is being migrated, but we can investigate this later as a second step after you upgrade the instance to a version that no longer crashes :-)"}
