[{"id":409109539,"node_id":"MDEyOkxhYmVsZWRFdmVudDQwOTEwOTUzOQ==","url":"https://api.github.com/repos/redis/redis/issues/events/409109539","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2015-09-14T20:36:55Z","label":{"name":"critical bug","color":"e10c02"},"performed_via_github_app":null},{"id":409109540,"node_id":"MDEyOkxhYmVsZWRFdmVudDQwOTEwOTU0MA==","url":"https://api.github.com/repos/redis/redis/issues/events/409109540","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"labeled","commit_id":null,"commit_url":null,"created_at":"2015-09-14T20:36:55Z","label":{"name":"geo","color":"bfe5bf"},"performed_via_github_app":null},{"url":"https://api.github.com/repos/redis/redis/issues/comments/140198892","html_url":"https://github.com/redis/redis/issues/2767#issuecomment-140198892","issue_url":"https://api.github.com/repos/redis/redis/issues/2767","id":140198892,"node_id":"MDEyOklzc3VlQ29tbWVudDE0MDE5ODg5Mg==","user":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-09-14T20:37:26Z","updated_at":"2015-09-14T20:37:50Z","body":"Thanks for reporting, actually you can use a single `GEOADD` command and yet the item will be reported twice. It is a bug with the GEORADIUS implementation and not with the underlying sorted set data structure. I'll fix this tomorrow hopefully.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/comments/140198892/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false}},{"url":"https://api.github.com/repos/redis/redis/issues/comments/140201008","html_url":"https://github.com/redis/redis/issues/2767#issuecomment-140201008","issue_url":"https://api.github.com/repos/redis/redis/issues/2767","id":140201008,"node_id":"MDEyOklzc3VlQ29tbWVudDE0MDIwMTAwOA==","user":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-09-14T20:47:08Z","updated_at":"2015-09-14T20:47:08Z","body":"In this specific case the problem is due to the fact that the neighbors squares calculated for north_west and south_west are the same, due probably to the huge radius used. It's a corner case which should be pretty easy to fix AFAIK.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/comments/140201008/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false}},{"id":409144926,"node_id":"MDExOkNsb3NlZEV2ZW50NDA5MTQ0OTI2","url":"https://api.github.com/repos/redis/redis/issues/events/409144926","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"closed","commit_id":"3c23b5ffd0d7dd01df79154c1701d4d3ded7bf66","commit_url":"https://api.github.com/repos/redis/redis/commits/3c23b5ffd0d7dd01df79154c1701d4d3ded7bf66","created_at":"2015-09-14T21:11:33Z","state_reason":null,"performed_via_github_app":null},{"url":"https://api.github.com/repos/redis/redis/issues/comments/140207141","html_url":"https://github.com/redis/redis/issues/2767#issuecomment-140207141","issue_url":"https://api.github.com/repos/redis/redis/issues/2767","id":140207141,"node_id":"MDEyOklzc3VlQ29tbWVudDE0MDIwNzE0MQ==","user":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-09-14T21:11:41Z","updated_at":"2015-09-14T21:11:41Z","body":"Fixed, thanks for reporting.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/comments/140207141/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false}},{"actor":{"login":"moria7757","id":76126820,"node_id":"MDQ6VXNlcjc2MTI2ODIw","avatar_url":"https://avatars.githubusercontent.com/u/76126820?v=4","gravatar_id":"","url":"https://api.github.com/users/moria7757","html_url":"https://github.com/moria7757","followers_url":"https://api.github.com/users/moria7757/followers","following_url":"https://api.github.com/users/moria7757/following{/other_user}","gists_url":"https://api.github.com/users/moria7757/gists{/gist_id}","starred_url":"https://api.github.com/users/moria7757/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moria7757/subscriptions","organizations_url":"https://api.github.com/users/moria7757/orgs","repos_url":"https://api.github.com/users/moria7757/repos","events_url":"https://api.github.com/users/moria7757/events{/privacy}","received_events_url":"https://api.github.com/users/moria7757/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-12-29T09:26:55Z","updated_at":"2020-12-29T09:26:55Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/8265","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/8265/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/8265/comments","events_url":"https://api.github.com/repos/redis/redis/issues/8265/events","html_url":"https://github.com/redis/redis/issues/8265","id":775792738,"node_id":"MDU6SXNzdWU3NzU3OTI3Mzg=","number":8265,"title":"*** [err]: Active defrag in tests/unit/memefficiency.tcl","user":{"login":"moria7757","id":76126820,"node_id":"MDQ6VXNlcjc2MTI2ODIw","avatar_url":"https://avatars.githubusercontent.com/u/76126820?v=4","gravatar_id":"","url":"https://api.github.com/users/moria7757","html_url":"https://github.com/moria7757","followers_url":"https://api.github.com/users/moria7757/followers","following_url":"https://api.github.com/users/moria7757/following{/other_user}","gists_url":"https://api.github.com/users/moria7757/gists{/gist_id}","starred_url":"https://api.github.com/users/moria7757/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moria7757/subscriptions","organizations_url":"https://api.github.com/users/moria7757/orgs","repos_url":"https://api.github.com/users/moria7757/repos","events_url":"https://api.github.com/users/moria7757/events{/privacy}","received_events_url":"https://api.github.com/users/moria7757/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":24,"created_at":"2020-12-29T09:26:53Z","updated_at":"2024-01-28T15:03:39Z","closed_at":"2021-01-08T08:03:21Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"Linux Version: CentOS Linux release 7.9.2009 (AltArch) - ppc64\r\nRedis Version: 5.0.9\r\nJemalloc Version: 5.2.1\r\ngcc Version: 4.8.5 20150623 (Red Hat 4.8.5-44)\r\nExecuted Command: make test & ./runtest --clients 1\r\n\r\nlscpu output:\r\n```\r\nArchitecture:          ppc64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Big Endian\r\nCPU(s):                32\r\nOn-line CPU(s) list:   0-31\r\nThread(s) per core:    4\r\nCore(s) per socket:    1\r\nSocket(s):             8\r\nNUMA node(s):          1\r\nModel:                 2.3 (pvr 003f 0203)\r\nModel name:            POWER7 (architected), altivec supported\r\nHypervisor vendor:     pHyp\r\nVirtualization type:   para\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nNUMA node0 CPU(s):     0-31\r\n```\r\nfree -m output:\r\n```\r\n              total        used        free      shared  buff/cache   available\r\nMem:           9802         937        2710          12        6154        8230\r\nSwap:          4095           0        4095\r\n```\r\n ./runtest --clients 1 output:\r\n```\r\nCleanup: may take some time... OK\r\nStarting test server at port 11111\r\n[ready]: 64621\r\n\u001B[1;37;49mTesting unit/printver\u001B[0m\r\nTesting Redis version 5.0.9 (00000000)\r\n[1/50 \u001B[0;33;49mdone\u001B[0m]: unit/printver (1 seconds)\r\n\u001B[1;37;49mTesting unit/dump\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: DUMP / RESTORE are able to serialize / unserialize a simple key\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set an arbitrary expire to the materialized key\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set an expire that overflows a 32 bit integer\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set an absolute expire\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set LRU\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set LFU\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE returns an error of the key already exists\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can overwrite an existing key with REPLACE\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can detect a syntax error for unrecongized options\r\n[\u001B[0;32;49mok\u001B[0m]: DUMP of non existing key returns nil\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE is caching connections\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE cached connections are released after some time\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE is able to migrate a key between two instances\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE is able to copy a key between two instances\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE will not overwrite existing keys, unless REPLACE is used\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE propagates TTL correctly\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE can correctly transfer large values\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE can correctly transfer hashes\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE timeout actually works\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE can migrate multiple keys at once\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys must have empty key arg\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys migrate just existing ones\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys: stress command rewriting\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys: delete just ack keys\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE AUTH: correct and wrong password cases\r\n[2/50 \u001B[0;33;49mdone\u001B[0m]: unit/dump (27 seconds)\r\n\u001B[1;37;49mTesting unit/auth\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: AUTH fails if there is no password configured server side\r\n[\u001B[0;32;49mok\u001B[0m]: AUTH fails when a wrong password is given\r\n[\u001B[0;32;49mok\u001B[0m]: Arbitrary command gives an error when AUTH is required\r\n[\u001B[0;32;49mok\u001B[0m]: AUTH succeeds when the right password is given\r\n[\u001B[0;32;49mok\u001B[0m]: Once AUTH succeeded we can actually send commands to the server\r\n[3/50 \u001B[0;33;49mdone\u001B[0m]: unit/auth (1 seconds)\r\n\u001B[1;37;49mTesting unit/protocol\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Handle an empty query\r\n[\u001B[0;32;49mok\u001B[0m]: Negative multibulk length\r\n[\u001B[0;32;49mok\u001B[0m]: Out of range multibulk length\r\n[\u001B[0;32;49mok\u001B[0m]: Wrong multibulk payload header\r\n[\u001B[0;32;49mok\u001B[0m]: Negative multibulk payload length\r\n[\u001B[0;32;49mok\u001B[0m]: Out of range multibulk payload length\r\n[\u001B[0;32;49mok\u001B[0m]: Non-number multibulk payload length\r\n[\u001B[0;32;49mok\u001B[0m]: Multi bulk request not followed by bulk arguments\r\n[\u001B[0;32;49mok\u001B[0m]: Generic wrong number of args\r\n[\u001B[0;32;49mok\u001B[0m]: Unbalanced number of quotes\r\n[\u001B[0;32;49mok\u001B[0m]: Protocol desync regression test #1\r\n[\u001B[0;32;49mok\u001B[0m]: Protocol desync regression test #2\r\n[\u001B[0;32;49mok\u001B[0m]: Protocol desync regression test #3\r\n[\u001B[0;32;49mok\u001B[0m]: Regression for a crash with blocking ops and pipelining\r\n[4/50 \u001B[0;33;49mdone\u001B[0m]: unit/protocol (0 seconds)\r\n\u001B[1;37;49mTesting unit/keyspace\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: DEL against a single item\r\n[\u001B[0;32;49mok\u001B[0m]: Vararg DEL\r\n[\u001B[0;32;49mok\u001B[0m]: KEYS with pattern\r\n[\u001B[0;32;49mok\u001B[0m]: KEYS to get all keys\r\n[\u001B[0;32;49mok\u001B[0m]: DBSIZE\r\n[\u001B[0;32;49mok\u001B[0m]: DEL all keys\r\n[\u001B[0;32;49mok\u001B[0m]: DEL against expired key\r\n[\u001B[0;32;49mok\u001B[0m]: EXISTS\r\n[\u001B[0;32;49mok\u001B[0m]: Zero length value in key. SET/GET/EXISTS\r\n[\u001B[0;32;49mok\u001B[0m]: Commands pipelining\r\n[\u001B[0;32;49mok\u001B[0m]: Non existing command\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME basic usage\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME source key should no longer exist\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME against already existing key\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX basic usage\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX against already existing key\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX against already existing key (2)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME against non existing source key\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME where source and dest key are the same (existing)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX where source and dest key are the same (existing)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME where source and dest key are the same (non existing)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME with volatile key, should move the TTL as well\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME with volatile key, should not inherit TTL of target key\r\n[\u001B[0;32;49mok\u001B[0m]: DEL all keys again (DB 0)\r\n[\u001B[0;32;49mok\u001B[0m]: DEL all keys again (DB 1)\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE basic usage\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE against key existing in the target DB\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE against non-integer DB (#1428)\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE can move key expire metadata as well\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE does not create an expire if it does not exist\r\n[\u001B[0;32;49mok\u001B[0m]: SET/GET keys in different DBs\r\n[\u001B[0;32;49mok\u001B[0m]: RANDOMKEY\r\n[\u001B[0;32;49mok\u001B[0m]: RANDOMKEY against empty DB\r\n[\u001B[0;32;49mok\u001B[0m]: RANDOMKEY regression 1\r\n[\u001B[0;32;49mok\u001B[0m]: KEYS * two times with long key, Github issue #1208\r\n[5/50 \u001B[0;33;49mdone\u001B[0m]: unit/keyspace (2 seconds)\r\n\u001B[1;37;49mTesting unit/scan\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN basic\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN COUNT\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN MATCH\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with encoding intset\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with encoding hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: HSCAN with encoding ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: HSCAN with encoding hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN with encoding ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN with encoding skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN guarantees check under write load\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with integer encoded object (issue #1345)\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with PATTERN\r\n[\u001B[0;32;49mok\u001B[0m]: HSCAN with PATTERN\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN with PATTERN\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN scores: regression test for issue #2175\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN regression test for issue #4906\r\n[6/50 \u001B[0;33;49mdone\u001B[0m]: unit/scan (8 seconds)\r\n\u001B[1;37;49mTesting unit/type/string\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SET and GET an item\r\n[\u001B[0;32;49mok\u001B[0m]: SET and GET an empty item\r\n[\u001B[0;32;49mok\u001B[0m]: Very big payload in GET/SET\r\n[\u001B[0;32;49mok\u001B[0m]: Very big payload random access\r\n[\u001B[0;32;49mok\u001B[0m]: SET 10000 numeric keys and access all them in reverse order\r\n[\u001B[0;32;49mok\u001B[0m]: DBSIZE should be 10000 now\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX target key missing\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX target key exists\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX against not-expired volatile key\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX against expired volatile key\r\n[\u001B[0;32;49mok\u001B[0m]: MGET\r\n[\u001B[0;32;49mok\u001B[0m]: MGET against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: MGET against non-string key\r\n[\u001B[0;32;49mok\u001B[0m]: GETSET (set new value)\r\n[\u001B[0;32;49mok\u001B[0m]: GETSET (replace old value)\r\n[\u001B[0;32;49mok\u001B[0m]: MSET base case\r\n[\u001B[0;32;49mok\u001B[0m]: MSET wrong number of args\r\n[\u001B[0;32;49mok\u001B[0m]: MSETNX with already existent key\r\n[\u001B[0;32;49mok\u001B[0m]: MSETNX with not existing keys\r\n[\u001B[0;32;49mok\u001B[0m]: STRLEN against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: STRLEN against integer-encoded value\r\n[\u001B[0;32;49mok\u001B[0m]: STRLEN against plain string\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against string-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against integer-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against key with wrong type\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT with out of range bit offset\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT with non-bit argument\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: GETBIT against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: GETBIT against string-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: GETBIT against integer-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against string-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against integer-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against key with wrong type\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE with out of range offset\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE against string value\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE against integer-encoded value\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET can detect syntax errors\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET NX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET XX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET EX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET PX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET using multiple options at once\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE with huge ranges, Github issue #1844\r\n[7/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/string (12 seconds)\r\n\u001B[1;37;49mTesting unit/type/incr\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: INCR against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: INCR against key created by incr itself\r\n[\u001B[0;32;49mok\u001B[0m]: INCR against key originally set with SET\r\n[\u001B[0;32;49mok\u001B[0m]: INCR over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBY over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against key with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against key with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against key with spaces (both)\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against a key holding a list\r\n[\u001B[0;32;49mok\u001B[0m]: DECRBY over 32bit value with over 32bit increment, negative res\r\n[\u001B[0;32;49mok\u001B[0m]: INCR uses shared objects in the 0-9999 range\r\n[\u001B[0;32;49mok\u001B[0m]: INCR can modify objects in-place\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT against key originally set with SET\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against key with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against key with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against key with spaces (both)\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against a key holding a list\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT does not allow NaN or Infinity\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT decrement\r\n[\u001B[0;32;49mok\u001B[0m]: string to double with null terminator\r\n[8/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/incr (0 seconds)\r\n\u001B[1;37;49mTesting unit/type/list\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - regular list\r\n[\u001B[0;32;49mok\u001B[0m]: R/LPOP against empty list\r\n[\u001B[0;32;49mok\u001B[0m]: Variadic RPUSH/LPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: DEL a list\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: single existing list - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: multiple existing lists - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: second list has an entry - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: single existing list - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: multiple existing lists - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: second list has an entry - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, LPUSH + DEL should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, LPUSH + DEL + SET should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP with same key multiple times should work (issue #801)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI/EXEC is isolated from the point of view of BLPOP\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP with variadic LPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with a client BLPOPing the target list\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with wrong source type\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with wrong destination type\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH maintains order of elements after failure\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with multiple blocked clients\r\n[\u001B[0;32;49mok\u001B[0m]: Linked BRPOPLPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: Circular BRPOPLPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: Self-referential BRPOPLPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH inside a transaction\r\n[\u001B[0;32;49mok\u001B[0m]: PUSH resulting from BRPOPLPUSH affect WATCH\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH does not affect WATCH while still blocked\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP when new key is moved into place\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP when result key is created by SORT..STORE\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with single empty list argument\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with negative timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with non-integer timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: second argument is not a list\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: arguments are empty\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with single empty list argument\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with negative timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with non-integer timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: second argument is not a list\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: arguments are empty\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP inside a transaction\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSHX, RPUSHX - generic\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSHX, RPUSHX - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LINSERT - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSHX, RPUSHX - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LINSERT - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LINSERT raise error on bad syntax\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX consistency test - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX random access - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX consistency test - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX random access - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LLEN against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: LLEN against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSH against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: RPUSH against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH base case - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with the same list as src and dst - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with linkedlist source and existing target linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with linkedlist source and existing target ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH base case - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with the same list as src and dst - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with ziplist source and existing target linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with ziplist source and existing target ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non list src key\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non list dst key\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non existing src key\r\n[\u001B[0;32;49mok\u001B[0m]: Basic LPOP/RPOP - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: Basic LPOP/RPOP - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LPOP/RPOP against non list value\r\n[\u001B[0;32;49mok\u001B[0m]: Mass RPOP/LPOP - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: Mass RPOP/LPOP - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE basics - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE inverted indexes - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range indexes including the full list - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range negative end index - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE inverted indexes - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range indexes including the full list - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range negative end index - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM basics - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM out of range negative end index - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM out of range negative end index - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET out of range index - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET out of range index - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LSET against non list value\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove all the occurrences - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove the first occurrence - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove non existing element - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count (2) - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM deleting objects that may be int encoded - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove all the occurrences - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove the first occurrence - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove non existing element - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count (2) - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM deleting objects that may be int encoded - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: Regression for bug 593 - chaining BRPOPLPUSH with other blocking cmds\r\n[9/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/list (13 seconds)\r\n\u001B[1;37;49mTesting unit/type/list-2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM stress testing - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM stress testing - ziplist\r\n[10/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/list-2 (17 seconds)\r\n\u001B[1;37;49mTesting unit/type/list-3\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Explicit regression for a list bug\r\n[\u001B[0;32;49mok\u001B[0m]: Regression for quicklist #3343 bug\r\n[\u001B[0;32;49mok\u001B[0m]: Stress tester for #3343-alike bugs\r\n[\u001B[0;32;49mok\u001B[0m]: ziplist implementation: value encoding and backlink\r\n[\u001B[0;32;49mok\u001B[0m]: ziplist implementation: encoding stress testing\r\n[11/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/list-3 (103 seconds)\r\n\u001B[1;37;49mTesting unit/type/set\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SADD, SCARD, SISMEMBER, SMEMBERS basics - regular set\r\n[\u001B[0;32;49mok\u001B[0m]: SADD, SCARD, SISMEMBER, SMEMBERS basics - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SADD against non set\r\n[\u001B[0;32;49mok\u001B[0m]: SADD a non-integer against an intset\r\n[\u001B[0;32;49mok\u001B[0m]: SADD an integer larger than 64 bits\r\n[\u001B[0;32;49mok\u001B[0m]: SADD overflows the maximum allowed integers in an intset\r\n[\u001B[0;32;49mok\u001B[0m]: Variadic SADD\r\n[\u001B[0;32;49mok\u001B[0m]: Set encoding after DEBUG RELOAD\r\n[\u001B[0;32;49mok\u001B[0m]: SREM basics - regular set\r\n[\u001B[0;32;49mok\u001B[0m]: SREM basics - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SREM with multiple arguments\r\n[\u001B[0;32;49mok\u001B[0m]: SREM variadic version with more args needed to destroy the key\r\n[\u001B[0;32;49mok\u001B[0m]: Generated sets must be encoded as hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets, after a DEBUG RELOAD - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SUNIONSTORE with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER against three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with non existing keys - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFFSTORE with three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: Generated sets must be encoded as intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets, after a DEBUG RELOAD - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SUNIONSTORE with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER against three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with non existing keys - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFFSTORE with three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with first set empty\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with same set two times\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER against non-set should throw error\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION against non-set should throw error\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER should handle non existing key as empty\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER with same integer elements but different encoding\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE against non existing keys should delete dstkey\r\n[\u001B[0;32;49mok\u001B[0m]: SUNIONSTORE against non existing keys should delete dstkey\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP basics - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>=1 - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP basics - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>=1 - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP using integers, testing Knuth's and Floyd's algorithm\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP using integers with Knuth's algorithm\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP new implementation: code path #1\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP new implementation: code path #2\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP new implementation: code path #3\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER with <count> against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER with <count> - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER with <count> - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE basics - from regular set to intset\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE basics - from intset to regular set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE non existing src set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE from regular set to non existing destination set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE from intset to non existing destination set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE wrong src key type\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE wrong dst key type\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE with identical source and destination\r\n[\u001B[0;32;49mok\u001B[0m]: intsets implementation stress testing\r\n[12/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/set (7 seconds)\r\n\u001B[1;37;49mTesting unit/type/zset\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Check encoding - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET basic ZADD and score update - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZADD - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD with options syntax error with incomplete pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX option without key - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX existing key - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX returns the number of elements actually added\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX updates existing elements score\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX and NX are not compatible\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX with non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX only add new elements without updating old ones\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works like ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works with a single score-elemenet pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD CH option changes return value to all changed elements\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY calls leading to NaN result in error\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version base case\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Return value is the number of actually added items\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version does not add nothing on single parsing err\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version will raise error on missing arg\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY does not work variadic even if shares ZADD implementation\r\n[\u001B[0;32;49mok\u001B[0m]: ZCARD basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM removes key after last element is removed\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version -- remove elements after key deletion\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREVRANGE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK/ZREVRANK basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK - after deletion - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - can create a new sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - increment and decrement - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY return value\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT and WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZLEXCOUNT advanced\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSLEX with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX with invalid lex range specifiers\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYRANK basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE against non-existing key doesn't set destination - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with empty set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with a regular set and weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MIN - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MAX - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with a regular set and weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MIN - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MAX - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with +inf/-inf scores - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with NaN weights ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with +inf/-inf scores - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with NaN weights ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: Basic ZPOP with a single key - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZPOP with count - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with a single existing sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with multiple existing sorted sets - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP second sorted set has members - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: Check encoding - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET basic ZADD and score update - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZADD - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD with options syntax error with incomplete pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX option without key - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX existing key - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX returns the number of elements actually added\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX updates existing elements score\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX and NX are not compatible\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX with non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX only add new elements without updating old ones\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works like ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works with a single score-elemenet pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD CH option changes return value to all changed elements\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY calls leading to NaN result in error\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version base case\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Return value is the number of actually added items\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version does not add nothing on single parsing err\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version will raise error on missing arg\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY does not work variadic even if shares ZADD implementation\r\n[\u001B[0;32;49mok\u001B[0m]: ZCARD basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM removes key after last element is removed\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version -- remove elements after key deletion\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREVRANGE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK/ZREVRANK basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK - after deletion - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - can create a new sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - increment and decrement - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY return value\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT and WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZLEXCOUNT advanced\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSLEX with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX with invalid lex range specifiers\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYRANK basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE against non-existing key doesn't set destination - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with empty set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with a regular set and weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MIN - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MAX - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with a regular set and weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MIN - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MAX - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with +inf/-inf scores - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with NaN weights skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with +inf/-inf scores - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with NaN weights skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: Basic ZPOP with a single key - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZPOP with count - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with a single existing sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with multiple existing sorted sets - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP second sorted set has members - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE regression with two sets, intset+hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE regression, should not create NaN in scores\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE #516 regression, mixed sets and ziplist zsets\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE result is sorted\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET commands don't accept the empty strings as valid score\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE after a DEBUG RELOAD - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET sorting stresser - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs skiplist implementation backlink consistency test - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs ZRANK augmented skip list stress testing - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with same key multiple times should work\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with variadic ZADD\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE after a DEBUG RELOAD - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET sorting stresser - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs skiplist implementation backlink consistency test - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs ZRANK augmented skip list stress testing - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with same key multiple times should work\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with variadic ZADD\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET skiplist order consistency when elements are moved\r\n[13/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/zset (13 seconds)\r\n\u001B[1;37;49mTesting unit/type/hash\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: HSET/HLEN - Small hash creation\r\n[\u001B[0;32;49mok\u001B[0m]: Is the small hash encoded with a ziplist?\r\n[\u001B[0;32;49mok\u001B[0m]: HSET/HLEN - Big hash creation\r\n[\u001B[0;32;49mok\u001B[0m]: Is the big hash encoded with an hash table?\r\n[\u001B[0;32;49mok\u001B[0m]: HGET against the small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGET against the big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGET against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: HSET in update and insert mode\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key missing - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key exists - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key missing - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key exists - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMSET wrong number of args\r\n[\u001B[0;32;49mok\u001B[0m]: HMSET - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMSET - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET against non existing key and fields\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET against wrong type\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HKEYS - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HKEYS - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HVALS - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HVALS - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGETALL - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGETALL - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HDEL and return value\r\n[\u001B[0;32;49mok\u001B[0m]: HDEL - more than a single value\r\n[\u001B[0;32;49mok\u001B[0m]: HDEL - hash becomes empty before deleting all specified fields\r\n[\u001B[0;32;49mok\u001B[0m]: HEXISTS\r\n[\u001B[0;32;49mok\u001B[0m]: Is a ziplist encoded Hash promoted on big payload?\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against non existing database key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against non existing hash key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against hash key created by hincrby itself\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against hash key originally set with HSET\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY fails against hash value with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY fails against hash value with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY can detect overflows\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against non existing database key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against non existing hash key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against hash key created by hincrby itself\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against hash key originally set with HSET\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT fails against hash value with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT fails against hash value with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN against the small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN against the big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN against non existing field\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN corner cases\r\n[\u001B[0;32;49mok\u001B[0m]: Hash ziplist regression test for large keys\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #1 - 10 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #2 - 10 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #1 - 512 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #2 - 512 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Stress test the hash ziplist -> hashtable encoding conversion\r\n[14/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/hash (5 seconds)\r\n\u001B[1;37;49mTesting unit/type/stream\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: XADD can add entries into a stream that XRANGE can fetch\r\n[\u001B[0;32;49mok\u001B[0m]: XADD IDs are incremental\r\n[\u001B[0;32;49mok\u001B[0m]: XADD IDs are incremental when ms is the same as well\r\n[\u001B[0;32;49mok\u001B[0m]: XADD IDs correctly report an error when overflowing\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with MAXLEN option\r\n[\u001B[0;32;49mok\u001B[0m]: XADD mass insertion and XLEN\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with ID 0-0\r\n[\u001B[0;32;49mok\u001B[0m]: XRANGE COUNT works as expected\r\n[\u001B[0;32;49mok\u001B[0m]: XREVRANGE COUNT works as expected\r\n[\u001B[0;32;49mok\u001B[0m]: XRANGE can be used to iterate the whole stream\r\n[\u001B[0;32;49mok\u001B[0m]: XREVRANGE returns the reverse of XRANGE\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD with non empty stream\r\n[\u001B[0;32;49mok\u001B[0m]: Non blocking XREAD with empty streams\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD with non empty second stream\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREAD waiting new data\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREAD waiting old data\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREAD will not reply with an empty array\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD: XADD + DEL should not awake client\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD: XADD + DEL + LPUSH should not awake client\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD with same stream name multiple times should work\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD + multiple XADD inside transaction\r\n[\u001B[0;32;49mok\u001B[0m]: XDEL basic test\r\n[\u001B[0;32;49mok\u001B[0m]: XDEL fuzz test\r\n[\u001B[0;32;49mok\u001B[0m]: XRANGE fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: XREVRANGE regression test for issue #5006\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD streamID edge (no-blocking)\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD streamID edge (blocking)\r\n[\u001B[0;32;49mok\u001B[0m]: XADD streamID edge\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with MAXLEN > xlen can propagate correctly\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with ~ MAXLEN can propagate correctly\r\n[\u001B[0;32;49mok\u001B[0m]: XTRIM with ~ MAXLEN can propagate correctly\r\n[\u001B[0;32;49mok\u001B[0m]: XADD can CREATE an empty stream\r\n[\u001B[0;32;49mok\u001B[0m]: XSETID can set a specific ID\r\n[\u001B[0;32;49mok\u001B[0m]: XSETID cannot SETID with smaller ID\r\n[\u001B[0;32;49mok\u001B[0m]: XSETID cannot SETID on non-existent key\r\n[\u001B[0;32;49mok\u001B[0m]: Empty stream can be rewrite into AOF correctly\r\n[\u001B[0;32;49mok\u001B[0m]: Stream can be rewrite into AOF correctly after XDEL lastid\r\n[15/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/stream (29 seconds)\r\n\u001B[1;37;49mTesting unit/type/stream-cgroups\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: XGROUP CREATE: creation and duplicate group name detection\r\n[\u001B[0;32;49mok\u001B[0m]: XGROUP CREATE: automatic stream creation fails without MKSTREAM\r\n[\u001B[0;32;49mok\u001B[0m]: XGROUP CREATE: automatic stream creation works with MKSTREAM\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP will return only new elements\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP can read the history of the elements we own\r\n[\u001B[0;32;49mok\u001B[0m]: XPENDING is able to return pending items\r\n[\u001B[0;32;49mok\u001B[0m]: XPENDING can return single consumer items\r\n[\u001B[0;32;49mok\u001B[0m]: XACK is able to remove items from the client/group PEL\r\n[\u001B[0;32;49mok\u001B[0m]: XACK can't remove the same item multiple times\r\n[\u001B[0;32;49mok\u001B[0m]: XACK is able to accept multiple arguments\r\n[\u001B[0;32;49mok\u001B[0m]: PEL NACK reassignment after XGROUP SETID event\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP will not report data on empty history. Bug #5577\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP history reporting of deleted entries. Bug #5570\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREADGROUP will not reply with an empty array\r\n[\u001B[0;32;49mok\u001B[0m]: XCLAIM can claim PEL items from another consumer\r\n[\u001B[0;32;49mok\u001B[0m]: XCLAIM without JUSTID increments delivery count\r\n[\u001B[0;32;49mok\u001B[0m]: Consumer group last ID propagation to slave (NOACK=0)\r\n[\u001B[0;32;49mok\u001B[0m]: Consumer group last ID propagation to slave (NOACK=1)\r\n[16/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/stream-cgroups (3 seconds)\r\n\u001B[1;37;49mTesting unit/sort\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Old Ziplist: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Old Ziplist: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Old Ziplist: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Old Linked list: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Old Linked list: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Old Linked list: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Old Big Linked list: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Old Big Linked list: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Old Big Linked list: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Intset: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Intset: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Intset: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Hash table: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Hash table: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Hash table: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Big Hash table: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Big Hash table: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Big Hash table: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET #\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET <const>\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET (key and hash) with sanity check\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY key STORE\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY hash field STORE\r\n[\u001B[0;32;49mok\u001B[0m]: SORT extracts STORE correctly\r\n[\u001B[0;32;49mok\u001B[0m]: SORT extracts multiple STORE correctly\r\n[\u001B[0;32;49mok\u001B[0m]: SORT DESC\r\n[\u001B[0;32;49mok\u001B[0m]: SORT ALPHA against integer encoded strings\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set BY nosort should retain ordering\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set BY nosort + LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set BY nosort works as expected from scripts\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set: +inf and -inf handling\r\n[\u001B[0;32;49mok\u001B[0m]: SORT regression for issue #19, sorting floats\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with STORE returns zero if result is empty (github issue 224)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with STORE does not create empty lists (github issue 224)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with STORE removes key if result is empty (github issue 227)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with BY <constant> and STORE should still order output\r\n[\u001B[0;32;49mok\u001B[0m]: SORT will complain with numerical sorting and bad doubles (1)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT will complain with numerical sorting and bad doubles (2)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY sub-sorts lexicographically if score is the same\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET with pattern ending with just -> does not get hash field\r\n[\u001B[0;32;49mok\u001B[0m]: SORT by nosort retains native order for lists\r\n[\u001B[0;32;49mok\u001B[0m]: SORT by nosort plus store retains native order for lists\r\n[\u001B[0;32;49mok\u001B[0m]: SORT by nosort with limit returns based on original list order\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list BY key, 100 times\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list BY hash field, 100 times\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list directly, 100 times\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list BY <const>, 100 times\r\n[17/50 \u001B[0;33;49mdone\u001B[0m]: unit/sort (9 seconds)\r\n\u001B[1;37;49mTesting unit/expire\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - set timeouts multiple times\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - It should be still possible to read 'x'\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - After 2.1 seconds the key should no longer be here\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - write on expire should work\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIREAT - Check for EXPIRE alike behavior\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Set + Expire combo operation. Check for TTL\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Check value\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Overwrite old key\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Wait for the key to expire\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Wrong time parameter\r\n[\u001B[0;32;49mok\u001B[0m]: PERSIST can undo an EXPIRE\r\n[\u001B[0;32;49mok\u001B[0m]: PERSIST returns 0 against non existing or non volatile keys\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE pricision is now the millisecond\r\n[\u001B[0;32;49mok\u001B[0m]: PEXPIRE/PSETEX/PEXPIREAT can set sub-second expires\r\n[\u001B[0;32;49mok\u001B[0m]: TTL returns time to live in seconds\r\n[\u001B[0;32;49mok\u001B[0m]: PTTL returns time to live in milliseconds\r\n[\u001B[0;32;49mok\u001B[0m]: TTL / PTTL return -1 if key has no expire\r\n[\u001B[0;32;49mok\u001B[0m]: TTL / PTTL return -2 if key does not exit\r\n[\u001B[0;32;49mok\u001B[0m]: Redis should actively expire keys incrementally\r\n[\u001B[0;32;49mok\u001B[0m]: Redis should lazy expire keys\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE should not resurrect keys (issue #1026)\r\n[\u001B[0;32;49mok\u001B[0m]: 5 keys in, 5 keys out\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE with empty string as TTL should report an error\r\n[\u001B[0;32;49mok\u001B[0m]: SET - use EX/PX option, TTL should not be reseted after loadaof\r\n[18/50 \u001B[0;33;49mdone\u001B[0m]: unit/expire (15 seconds)\r\n\u001B[1;37;49mTesting unit/other\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SAVE - make sure there are all the types as values\r\n[\u001B[0;32;49mok\u001B[0m]: FUZZ stresser with data model binary\r\n[\u001B[0;32;49mok\u001B[0m]: FUZZ stresser with data model alpha\r\n[\u001B[0;32;49mok\u001B[0m]: FUZZ stresser with data model compr\r\n[\u001B[0;32;49mok\u001B[0m]: BGSAVE\r\n[\u001B[0;32;49mok\u001B[0m]: SELECT an out of range DB\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRES after a reload (snapshot + append only file rewrite)\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRES after AOF reload (without rewrite)\r\n[\u001B[0;32;49mok\u001B[0m]: PIPELINING stresser (also a regression for the old epoll bug)\r\n[\u001B[0;32;49mok\u001B[0m]: APPEND basics\r\n[\u001B[0;32;49mok\u001B[0m]: APPEND basics, integer encoded values\r\n[\u001B[0;32;49mok\u001B[0m]: APPEND fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB\r\n[\u001B[0;32;49mok\u001B[0m]: Perform a final SAVE to leave a clean DB on disk\r\n[19/50 \u001B[0;33;49mdone\u001B[0m]: unit/other (9 seconds)\r\n\u001B[1;37;49mTesting unit/multi\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: MUTLI / EXEC basics\r\n[\u001B[0;32;49mok\u001B[0m]: DISCARD\r\n[\u001B[0;32;49mok\u001B[0m]: Nested MULTI are not allowed\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI where commands alter argc/argv\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH inside MULTI is not allowed\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fails if there are errors while queueing commands #1\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fails if there are errors while queueing commands #2\r\n[\u001B[0;32;49mok\u001B[0m]: If EXEC aborts, the client MULTI state is cleared\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC works on WATCHed key not modified\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fail on WATCHed key modified (1 key of 1 watched)\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fail on WATCHed key modified (1 key of 5 watched)\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fail on WATCHed key modified by SORT with STORE even if the result is empty\r\n[\u001B[0;32;49mok\u001B[0m]: After successful EXEC key is no longer watched\r\n[\u001B[0;32;49mok\u001B[0m]: After failed EXEC key is no longer watched\r\n[\u001B[0;32;49mok\u001B[0m]: It is possible to UNWATCH\r\n[\u001B[0;32;49mok\u001B[0m]: UNWATCH when there is nothing watched works as expected\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHALL is able to touch the watched keys\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHALL does not touch non affected keys\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB is able to touch the watched keys\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB does not touch non affected keys\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH is able to remember the DB a key belongs to\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH will consider touched keys target of EXPIRE\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH will not consider touched expired keys\r\n[\u001B[0;32;49mok\u001B[0m]: DISCARD should clear the WATCH dirty flag on the client\r\n[\u001B[0;32;49mok\u001B[0m]: DISCARD should UNWATCH all the keys\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (single write command)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (empty transaction)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (read-only commands)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (write command, no effect)\r\n[20/50 \u001B[0;33;49mdone\u001B[0m]: unit/multi (2 seconds)\r\n\u001B[1;37;49mTesting unit/quit\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: QUIT returns OK\r\n[\u001B[0;32;49mok\u001B[0m]: Pipelined commands after QUIT must not be executed\r\n[\u001B[0;32;49mok\u001B[0m]: Pipelined commands after QUIT that exceed read buffer size\r\n[21/50 \u001B[0;33;49mdone\u001B[0m]: unit/quit (0 seconds)\r\n\u001B[1;37;49mTesting unit/aofrw\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite during write load: RDB preamble=yes\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite during write load: RDB preamble=no\r\n[\u001B[0;32;49mok\u001B[0m]: Turning off AOF kills the background writing child if any\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of list with quicklist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of list with quicklist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with intset encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with hashtable encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with intset encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with hashtable encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with ziplist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with hashtable encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with ziplist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with hashtable encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with ziplist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with skiplist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with ziplist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with skiplist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: BGREWRITEAOF is delayed if BGSAVE is in progress\r\n[\u001B[0;32;49mok\u001B[0m]: BGREWRITEAOF is refused if already in progress\r\n[22/50 \u001B[0;33;49mdone\u001B[0m]: unit/aofrw (97 seconds)\r\n\u001B[1;37;49mTesting integration/block-repl\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication with blocking lists and sorted sets operations\r\n[23/50 \u001B[0;33;49mdone\u001B[0m]: integration/block-repl (27 seconds)\r\n\u001B[1;37;49mTesting integration/replication\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Slave enters handshake\r\n[\u001B[0;32;49mok\u001B[0m]: Slave is able to detect timeout during handshake\r\n[\u001B[0;32;49mok\u001B[0m]: Set instance A as slave of B\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH replication, when blocking against empty list\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH replication, list exists\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP followed by role change, issue #2473\r\n[\u001B[0;32;49mok\u001B[0m]: Second server should have role master at first\r\n[\u001B[0;32;49mok\u001B[0m]: SLAVEOF should start with link status \"down\"\r\n[\u001B[0;32;49mok\u001B[0m]: The role should immediately be changed to \"replica\"\r\n[\u001B[0;32;49mok\u001B[0m]: Sync should have transferred keys from master\r\n[\u001B[0;32;49mok\u001B[0m]: The link status should be up\r\n[\u001B[0;32;49mok\u001B[0m]: SET on the master should immediately propagate\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHALL should replicate\r\n[\u001B[0;32;49mok\u001B[0m]: ROLE in master reports master with a slave\r\n[\u001B[0;32;49mok\u001B[0m]: ROLE in slave reports slave in connected state\r\n[\u001B[0;32;49mok\u001B[0m]: Connect multiple replicas at the same time (issue #141), diskless=no\r\n[\u001B[0;32;49mok\u001B[0m]: Connect multiple replicas at the same time (issue #141), diskless=yes\r\n[\u001B[0;32;49mok\u001B[0m]: Master stream is correctly processed while the replica has a script in -BUSY state\r\n[24/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication (148 seconds)\r\n\u001B[1;37;49mTesting integration/replication-2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: If min-slaves-to-write is honored, write is accepted\r\n[\u001B[0;32;49mok\u001B[0m]: No write if min-slaves-to-write is < attached slaves\r\n[\u001B[0;32;49mok\u001B[0m]: If min-slaves-to-write is honored, write is accepted (again)\r\n[\u001B[0;32;49mok\u001B[0m]: No write if min-slaves-max-lag is > of the slave lag\r\n[\u001B[0;32;49mok\u001B[0m]: min-slaves-to-write is ignored by slaves\r\n[\u001B[0;32;49mok\u001B[0m]: MASTER and SLAVE dataset should be identical after complex ops\r\n[25/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-2 (16 seconds)\r\n\u001B[1;37;49mTesting integration/replication-3\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: MASTER and SLAVE consistency with expire\r\n[\u001B[0;32;49mok\u001B[0m]: Slave is able to evict keys created in writable slaves\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: MASTER and SLAVE consistency with EVALSHA replication\r\n[\u001B[0;32;49mok\u001B[0m]: SLAVE can reload \"lua\" AUX RDB fields of duplicated scripts\r\n[26/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-3 (32 seconds)\r\n\u001B[1;37;49mTesting integration/replication-4\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication with parallel clients writing in differnet DBs\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: With min-slaves-to-write (1,3): master should be writable\r\n[\u001B[0;32;49mok\u001B[0m]: With min-slaves-to-write (2,3): master should not be writable\r\n[\u001B[0;32;49mok\u001B[0m]: With min-slaves-to-write: master not writable with lagged slave\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: Replication: commands with many arguments (issue #1221)\r\n[\u001B[0;32;49mok\u001B[0m]: Replication of SPOP command -- alsoPropagate() API\r\n[27/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-4 (34 seconds)\r\n\u001B[1;37;49mTesting integration/replication-psync\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no reconnection, just sync (diskless: no, reconnect: 0)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok psync (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no backlog (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok after delay (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: backlog expired (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no reconnection, just sync (diskless: yes, reconnect: 0)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok psync (diskless: yes, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no backlog (diskless: yes, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok after delay (diskless: yes, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: backlog expired (diskless: yes, reconnect: 1)\r\n[28/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-psync (100 seconds)\r\n\u001B[1;37;49mTesting integration/aof\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Unfinished MULTI: Server should start if load-truncated is yes\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Server should start if load-truncated is yes\r\n[\u001B[0;32;49mok\u001B[0m]: Truncated AOF loaded: we expect foo to be equal to 5\r\n[\u001B[0;32;49mok\u001B[0m]: Append a new command after loading an incomplete AOF\r\n[\u001B[0;32;49mok\u001B[0m]: Short read + command: Server should start\r\n[\u001B[0;32;49mok\u001B[0m]: Truncated AOF loaded: we expect foo to be equal to 6 now\r\n[\u001B[0;32;49mok\u001B[0m]: Bad format: Server should have logged an error\r\n[\u001B[0;32;49mok\u001B[0m]: Unfinished MULTI: Server should have logged an error\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Server should have logged an error\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Utility should confirm the AOF is not valid\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Utility should be able to fix the AOF\r\n[\u001B[0;32;49mok\u001B[0m]: Fixed AOF: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: Fixed AOF: Keyspace should contain values that were parseable\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Set should have 1 member\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Set should have 1 member\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+EXPIRE: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+EXPIRE: List should be empty\r\n[\u001B[0;32;49mok\u001B[0m]: Redis should not try to convert DEL into EXPIREAT for EXPIRE -1\r\n[29/50 \u001B[0;33;49mdone\u001B[0m]: integration/aof (3 seconds)\r\n\u001B[1;37;49mTesting integration/rdb\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: RDB encoding loading test\r\n[\u001B[0;32;49mok\u001B[0m]: Server started empty with non-existing RDB file\r\n[\u001B[0;32;49mok\u001B[0m]: Server started empty with empty RDB file\r\n[\u001B[0;32;49mok\u001B[0m]: Test RDB stream encoding\r\n[\u001B[0;32;49mok\u001B[0m]: Server should not start if RDB is corrupted\r\n[30/50 \u001B[0;33;49mdone\u001B[0m]: integration/rdb (2 seconds)\r\n\u001B[1;37;49mTesting integration/convert-zipmap-hash-on-load\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: RDB load zipmap hash: converts to ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-entries is exceeded\r\n[\u001B[0;32;49mok\u001B[0m]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-value is exceeded\r\n[31/50 \u001B[0;33;49mdone\u001B[0m]: integration/convert-zipmap-hash-on-load (0 seconds)\r\n\u001B[1;37;49mTesting integration/logging\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Server is able to generate a stack trace on selected systems\r\n[32/50 \u001B[0;33;49mdone\u001B[0m]: integration/logging (1 seconds)\r\n\u001B[1;37;49mTesting integration/psync2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: --- CYCLE 1 ---\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #3 to replicate from #1\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #0 to replicate from #3\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #4 to replicate from #1\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #2 to replicate from #0\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after failover\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: generate load while killing replication links\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after load (x = 39955)\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: --- CYCLE 2 ---\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: [NEW LAYOUT] Set #2 as master\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #1 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #4 to replicate from #1\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #0 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #3 to replicate from #0\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after failover\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: generate load while killing replication links\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after load (x = 82245)\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: --- CYCLE 3 ---\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #2 to replicate from #0\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #3 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #1 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #4 to replicate from #3\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after failover\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: generate load while killing replication links\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after load (x = 128770)\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Bring the master back again for next test\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Partial resync after restart using RDB aux fields\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Replica RDB restart with EVALSHA in backlog issue #4483\r\n[33/50 \u001B[0;33;49mdone\u001B[0m]: integration/psync2 (28 seconds)\r\n\u001B[1;37;49mTesting integration/psync2-reg\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: setup\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: verify consistency\r\n[34/50 \u001B[0;33;49mdone\u001B[0m]: integration/psync2-reg (23 seconds)\r\n\u001B[1;37;49mTesting unit/pubsub\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Pub/Sub PING\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/SUBSCRIBE basics\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/SUBSCRIBE with two clients\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/SUBSCRIBE after UNSUBSCRIBE without arguments\r\n[\u001B[0;32;49mok\u001B[0m]: SUBSCRIBE to one channel more than once\r\n[\u001B[0;32;49mok\u001B[0m]: UNSUBSCRIBE from non-subscribed channels\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/PSUBSCRIBE basics\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/PSUBSCRIBE with two clients\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/PSUBSCRIBE after PUNSUBSCRIBE without arguments\r\n[\u001B[0;32;49mok\u001B[0m]: PUNSUBSCRIBE from non-subscribed channels\r\n[\u001B[0;32;49mok\u001B[0m]: NUMSUB returns numbers, not strings (#1561)\r\n[\u001B[0;32;49mok\u001B[0m]: Mix SUBSCRIBE and PSUBSCRIBE\r\n[\u001B[0;32;49mok\u001B[0m]: PUNSUBSCRIBE and UNSUBSCRIBE should always reply\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we receive keyspace notifications\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we receive keyevent notifications\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we can receive both kind of events\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we are able to mask events\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: general events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: list events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: set events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: zset events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: hash events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: expired events (triggered expire)\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: expired events (background expire)\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: evicted events\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: test CONFIG GET/SET of event flags\r\n[35/50 \u001B[0;33;49mdone\u001B[0m]: unit/pubsub (0 seconds)\r\n\u001B[1;37;49mTesting unit/slowlog\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - check that it starts with an empty log\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - only logs commands taking more time than specified\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - max entries is correctly handled\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - GET optional argument to limit output len works\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - RESET subcommand works\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - logged entry sanity check\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - commands with too many arguments are trimmed\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - too long arguments are trimmed\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - EXEC is not logged, just executed commands\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - can clean older entires\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - can be disabled\r\n[36/50 \u001B[0;33;49mdone\u001B[0m]: unit/slowlog (2 seconds)\r\n\u001B[1;37;49mTesting unit/scripting\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Does Lua interpreter replies to our requests?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua integer -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua string -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua true boolean -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua false boolean -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua status code reply -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua error reply -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua table -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Are the KEYS and ARGV arrays populated correctly?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - is Lua able to call Redis API?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Can we call a SHA1 if already defined?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Can we call a SHA1 in uppercase?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Do we get an error on invalid SHA1?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Do we get an error on non defined SHA1?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis integer -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis bulk -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis multi bulk -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis status reply -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis error reply -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis nil bulk reply -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Is the Lua client using the currently selected DB?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - SELECT inside Lua should not affect the caller\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Scripts can't run certain commands\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Scripts can't run certain commands\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - No arguments to redis.call/pcall is considered an error\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - JSON numeric decoding\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - JSON string decoding\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - cmsgpack can pack double?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - cmsgpack can pack negative int64?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - cmsgpack can pack and unpack circular references?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Numerical sanity check from bitop\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Verify minimal bitop functionality\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Able to parse trailing comments\r\n[\u001B[0;32;49mok\u001B[0m]: SCRIPTING FLUSH - is able to clear the scripts cache?\r\n[\u001B[0;32;49mok\u001B[0m]: SCRIPT EXISTS - can detect already defined scripts?\r\n[\u001B[0;32;49mok\u001B[0m]: SCRIPT LOAD - is able to register scripts in the scripting cache\r\n[\u001B[0;32;49mok\u001B[0m]: In the context of Lua the output of random commands gets ordered\r\n[\u001B[0;32;49mok\u001B[0m]: SORT is normally not alpha re-ordered for the scripting engine\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY <constant> output gets ordered for scripting\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY <constant> with GET gets ordered for scripting\r\n[\u001B[0;32;49mok\u001B[0m]: redis.sha1hex() implementation\r\n[\u001B[0;32;49mok\u001B[0m]: Globals protection reading an undeclared global variable\r\n[\u001B[0;32;49mok\u001B[0m]: Globals protection setting an undeclared global*\r\n[\u001B[0;32;49mok\u001B[0m]: Test an example script DECR_IF_GT\r\n[\u001B[0;32;49mok\u001B[0m]: Scripting engine resets PRNG at every script execution\r\n[\u001B[0;32;49mok\u001B[0m]: Scripting engine PRNG can be seeded correctly\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL does not leak in the Lua stack\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL processes writes from AOF in read-only slaves\r\n[\u001B[0;32;49mok\u001B[0m]: We can call scripts rewriting client->argv from Lua\r\n[\u001B[0;32;49mok\u001B[0m]: Call Redis command with many args from Lua (issue #1764)\r\n[\u001B[0;32;49mok\u001B[0m]: Number conversion precision test (issue #1118)\r\n[\u001B[0;32;49mok\u001B[0m]: String containing number precision test (regression of issue #1118)\r\n[\u001B[0;32;49mok\u001B[0m]: Verify negative arg count is error instead of crash (issue #1842)\r\n[\u001B[0;32;49mok\u001B[0m]: Correct handling of reused argv (issue #1939)\r\n[\u001B[0;32;49mok\u001B[0m]: Functions in the Redis namespace are able to report errors\r\n[\u001B[0;32;49mok\u001B[0m]: Timedout read-only scripts can be killed by SCRIPT KILL\r\n[\u001B[0;32;49mok\u001B[0m]: Timedout script link is still usable after Lua returns\r\n[\u001B[0;32;49mok\u001B[0m]: Timedout scripts that modified data can't be killed by SCRIPT KILL\r\n[\u001B[0;32;49mok\u001B[0m]: SHUTDOWN NOSAVE can kill a timedout script anyway\r\n[\u001B[0;32;49mok\u001B[0m]: Before the replica connects we issue two EVAL commands (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Connect a replica to the master instance (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Now use EVALSHA against the master, with both SHAs (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: If EVALSHA was replicated as EVAL, 'x' should be '4' (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Replication of script multiple pushes to list with BLPOP (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA replication when first call is readonly (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Lua scripts using SELECT are replicated correctly (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Before the replica connects we issue two EVAL commands (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Connect a replica to the master instance (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Now use EVALSHA against the master, with both SHAs (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: If EVALSHA was replicated as EVAL, 'x' should be '4' (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Replication of script multiple pushes to list with BLPOP (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA replication when first call is readonly (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Lua scripts using SELECT are replicated correctly (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Connect a replica to the master instance\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.replicate_commands() must be issued before any write\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.replicate_commands() must be issued before any write (2)\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.set_repl() must be issued after replicate_commands()\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.set_repl() don't accept invalid values\r\n[\u001B[0;32;49mok\u001B[0m]: Test selective replication of certain Redis commands from Lua\r\n[\u001B[0;32;49mok\u001B[0m]: PRNG is seeded randomly for command replication\r\n[\u001B[0;32;49mok\u001B[0m]: Using side effects is not a problem with command replication\r\n[37/50 \u001B[0;33;49mdone\u001B[0m]: unit/scripting (6 seconds)\r\n\u001B[1;37;49mTesting unit/maxmemory\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Without maxmemory small integers are shared\r\n[\u001B[0;32;49mok\u001B[0m]: With maxmemory and non-LRU policy integers are still shared\r\n[\u001B[0;32;49mok\u001B[0m]: With maxmemory and LRU policy integers are not shared\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy allkeys-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy allkeys-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy allkeys-lfu)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-lfu)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-ttl)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-ttl)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-lru should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-lfu should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-random should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-ttl should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: slave buffer are counted correctly\r\n[\u001B[0;32;49mok\u001B[0m]: replica buffer don't induce eviction\r\n[38/50 \u001B[0;33;49mdone\u001B[0m]: unit/maxmemory (43 seconds)\r\n\u001B[1;37;49mTesting unit/introspection\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT LIST\r\n[\u001B[0;32;49mok\u001B[0m]: MONITOR can log executed commands\r\n[\u001B[0;32;49mok\u001B[0m]: MONITOR can log commands issued by the scripting engine\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT GETNAME should return NIL if name is not assigned\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT LIST shows empty fields for unassigned names\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT SETNAME does not accept spaces\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT SETNAME can assign a name to this connection\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT SETNAME can change the name of an existing connection\r\n[\u001B[0;32;49mok\u001B[0m]: After CLIENT SETNAME, connection can still be closed\r\n[39/50 \u001B[0;33;49mdone\u001B[0m]: unit/introspection (0 seconds)\r\n\u001B[1;37;49mTesting unit/introspection-2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: TTL and TYPYE do not alter the last access time of a key\r\n[\u001B[0;32;49mok\u001B[0m]: TOUCH alters the last access time of a key\r\n[\u001B[0;32;49mok\u001B[0m]: TOUCH returns the number of existing keys specified\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for GEOADD\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for EXPIRE\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for BRPOP\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for MULTI\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for scripts\r\n[40/50 \u001B[0;33;49mdone\u001B[0m]: unit/introspection-2 (7 seconds)\r\n\u001B[1;37;49mTesting unit/limits\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Check if maxclients works refusing connections\r\n[41/50 \u001B[0;33;49mdone\u001B[0m]: unit/limits (1 seconds)\r\n\u001B[1;37;49mTesting unit/obuf-limits\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Client output buffer hard limit is enforced\r\n[\u001B[0;32;49mok\u001B[0m]: Client output buffer soft limit is not enforced if time is not overreached\r\n[\u001B[0;32;49mok\u001B[0m]: Client output buffer soft limit is enforced if time is overreached\r\n[42/50 \u001B[0;33;49mdone\u001B[0m]: unit/obuf-limits (168 seconds)\r\n\u001B[1;37;49mTesting unit/bitops\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT returns 0 against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT returns 0 with out of range indexes\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT returns 0 with negative indexes where start > end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #1\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #2\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #3\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #4\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #5\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT fuzzing without start/end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT fuzzing with start/end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT with start, end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT syntax error #1\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT regression test for github issue #582\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT misaligned prefix\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT misaligned prefix + full words + remainder\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP NOT (empty string)\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP NOT (known string)\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP where dest and target are the same key\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP AND|OR|XOR don't change the string with single input key\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP missing key is considered a stream of zero\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP shorter keys are zero-padded to the key with max length\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP and fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP or fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP xor fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP NOT fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP with integer encoded source objects\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP with non string source key\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP with empty string after non empty string (issue #529)\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 with empty key returns 0\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 with empty key returns -1\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 with string less than 1 word works\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 with string less than 1 word works\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 starting at unaligned address\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 starting at unaligned address\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 unaligned+full word+reminder\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 unaligned+full word+reminder\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 returns -1 if string is all 0 bits\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 works with intervals\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 works with intervals\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 changes behavior if end is given\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 fuzzy testing using SETBIT\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 fuzzy testing using SETBIT\r\n[43/50 \u001B[0;33;49mdone\u001B[0m]: unit/bitops (4 seconds)\r\n\u001B[1;37;49mTesting unit/bitfield\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD signed SET and GET basics\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD unsigned SET and GET basics\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD #<idx> form\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD basic INCRBY form\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD chaining of multiple commands\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD unsigned overflow wrap\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD unsigned overflow sat\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD signed overflow wrap\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD signed overflow sat\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD overflow detection fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD overflow wrap fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD regression for #3221\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD regression for #3564\r\n[44/50 \u001B[0;33;49mdone\u001B[0m]: unit/bitfield (1 seconds)\r\n\u001B[1;37;49mTesting unit/geo\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD create\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD update\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD invalid coordinates\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD multi add\r\n[\u001B[0;32;49mok\u001B[0m]: Check geoset values\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS simple (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS withdist (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS with COUNT\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS with COUNT but missing integer argument\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS with COUNT DESC\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS HUGE, issue #2767\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUSBYMEMBER simple (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUSBYMEMBER withdist (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEOHASH is able to return geohash strings\r\n[\u001B[0;32;49mok\u001B[0m]: GEOPOS simple\r\n[\u001B[0;32;49mok\u001B[0m]: GEOPOS missing element\r\n[\u001B[0;32;49mok\u001B[0m]: GEODIST simple & unit\r\n[\u001B[0;32;49mok\u001B[0m]: GEODIST missing elements\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS STORE option: syntax error\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STORE option: incompatible options\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STORE option: plain usage\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STOREDIST option: plain usage\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STOREDIST option: COUNT ASC and DESC\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD + GEORANGE randomized test\r\n[45/50 \u001B[0;33;49mdone\u001B[0m]: unit/geo (21 seconds)\r\n\u001B[1;37;49mTesting unit/memefficiency\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 32\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 64\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 128\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 1024\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 16384\r\n# Memory\r\nused_memory:104857512\r\nused_memory_human:100.00M\r\nused_memory_rss:167510016\r\nused_memory_rss_human:159.75M\r\nused_memory_peak:160476576\r\nused_memory_peak_human:153.04M\r\nused_memory_peak_perc:65.34%\r\nused_memory_overhead:25811926\r\nused_memory_startup:824224\r\nused_memory_dataset:79045586\r\nused_memory_dataset_perc:75.98%\r\nallocator_allocated:104998960\r\nallocator_active:133365760\r\nallocator_resident:166985728\r\ntotal_system_memory:10278404096\r\ntotal_system_memory_human:9.57G\r\nused_memory_lua:37888\r\nused_memory_lua_human:37.00K\r\nused_memory_scripts:0\r\nused_memory_scripts_human:0B\r\nnumber_of_cached_scripts:0\r\nmaxmemory:104857600\r\nmaxmemory_human:100.00M\r\nmaxmemory_policy:allkeys-lru\r\nallocator_frag_ratio:1.27\r\nallocator_frag_bytes:28366800\r\nallocator_rss_ratio:1.25\r\nallocator_rss_bytes:33619968\r\nrss_overhead_ratio:1.00\r\nrss_overhead_bytes:524288\r\nmem_fragmentation_ratio:1.60\r\nmem_fragmentation_bytes:62693528\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:0\r\nmem_clients_slaves:0\r\nmem_clients_normal:49694\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.1.0\r\nactive_defrag_running:67\r\nlazyfree_pending_objects:0\r\n\r\n___ Begin jemalloc statistics ___\r\nVersion: \"5.1.0-0-g0\"\r\nBuild-time option settings\r\n  config.cache_oblivious: true\r\n  config.debug: false\r\n  config.fill: true\r\n  config.lazy_lock: false\r\n  config.malloc_conf: \"\"\r\n  config.prof: false\r\n  config.prof_libgcc: false\r\n  config.prof_libunwind: false\r\n  config.stats: true\r\n  config.utrace: false\r\n  config.xmalloc: false\r\nRun-time option settings\r\n  opt.abort: false\r\n  opt.abort_conf: false\r\n  opt.retain: true\r\n  opt.dss: \"secondary\"\r\n  opt.narenas: 128\r\n  opt.percpu_arena: \"disabled\"\r\n  opt.metadata_thp: \"disabled\"\r\n  opt.background_thread: false (background_thread: false)\r\n  opt.dirty_decay_ms: 10000 (arenas.dirty_decay_ms: 10000)\r\n  opt.muzzy_decay_ms: 10000 (arenas.muzzy_decay_ms: 10000)\r\n  opt.junk: \"false\"\r\n  opt.zero: false\r\n  opt.tcache: true\r\n  opt.lg_tcache_max: 15\r\n  opt.thp: \"default\"\r\n  opt.stats_print: false\r\n  opt.stats_print_opts: \"\"\r\nArenas: 128\r\nQuantum size: 8\r\nPage size: 65536\r\nMaximum thread-cached size class: 229376\r\nNumber of bin size classes: 55\r\nNumber of thread-cache bin size classes: 55\r\nNumber of large size classes: 180\r\nAllocated: 105254960, active: 133693440, metadata: 5261600 (n_thp 0), resident: 166985728, mapped: 178520064, retained: 56360960\r\nBackground threads: 0, num_runs: 0, run_interval: 0 ns\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nbackground_thread                 380               0               0               1               0               0           0\r\nctl                               754               0               0               1               0               0           0\r\nprof                                0               0               0               0               0               0           0\r\narenas[0]:\r\nassigned threads: 1\r\nuptime: 22570024827\r\ndss allocation precedence: \"secondary\"\r\ndecaying:  time       npages       sweeps     madvises       purged\r\n   dirty: 10000          428           10           46          324\r\n   muzzy: 10000            0            0            0            0\r\n                            allocated     nmalloc     ndalloc   nrequests\r\nsmall:                       96538672     3799144     2132281     7311748\r\nlarge:                        8716288           2           0           2\r\ntotal:                      105254960     3799146     2132281     7311750\r\n                                     \r\nactive:                     133693440\r\nmapped:                     178520064\r\nretained:                    56360960\r\nbase:                         5204248\r\ninternal:                       57352\r\nmetadata_thp:                       0\r\ntcache_bytes:                  340088\r\nresident:                   166985728\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nlarge                             190               0               0               1               0               0           0\r\nextent_avail                     1242               0               0               3               0               0           0\r\nextents_dirty                    1586               0               0               3               0               0           0\r\nextents_muzzy                    1031               0               0               3               0               0           0\r\nextents_retained                 1917               0               0               3               0               0           0\r\ndecay_dirty                      3080               0               0               1               0               0           0\r\ndecay_muzzy                      3070               0               0               1               0               0           0\r\nbase                             1367               0               0               3               0               0           0\r\ntcache_list                       191               0               0               1               0               0           0\r\nbins:           size ind    allocated      nmalloc      ndalloc    nrequests      curregs     curslabs regs pgs   util       nfills     nflushes       nslabs     nreslabs      n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\n                   8   0         2208          319           43          445          276            1 8192   1  0.033            8            9            1            0             254               0               0              83               0               0           0\r\n                  16   1     13405920      1908683      1070813      3264459       837870          219 4096   1  0.934        16618         7219          345          293         4947917               0               0          786235               0               0           0\r\n                  24   2      9946560       948513       534073       948769       414440           74 8192   3  0.683         8158         3622           86           72         2471570               0               0          390949               0               0           0\r\n                  32   3          512          112           96      1904246           16            1 2048   1  0.007            3            7            1            0             201               0               0               1               0               0           0\r\n                  40   4          400          109           99           27           10            1 8192   5  0.001            3            7            1            0             201               0               0               1               0               0           0\r\n                  48   5         2832          162          103           57           59            1 4096   3  0.014            3            4            1            0             198               0               0               1               0               0           0\r\n                  56   6         1008          108           90       254614           18            1 8192   7  0.002            4            7            1            0             202               0               0               1               0               0           0\r\n                  64   7          192          100           97            6            3            1 1024   1  0.002            1            4            1            0             196               0               0               1               0               0           0\r\n                  80   8          240          100           97            4            3            1 4096   5  0.000            1            4            1            0             196               0               0               1               0               0           0\r\n                  96   9         9408          200          102          100           98            1 2048   3  0.047            3            4            1            0             198               0               0               1               0               0           0\r\n                 112  10          112          100           99            3            1            1 4096   7  0.000            1            4            1            0             196               0               0               1               0               0           0\r\n                 128  11            0          100          100            3            0            0  512   1      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 160  12     60006400       871006       495966       870857       375040          228 2048   5  0.803         7012         3517          342          230         2227528               0               0          341833               0               0           0\r\n                 192  13         1152          106          100            1            6            1 1024   3  0.005            2            4            2            0             199               0               0               1               0               0           0\r\n                 224  14            0          100          100            1            0            0 2048   7      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 256  15            0          100          100            4            0            0  256   1      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 320  16     12443520        68242        29356        68121        38886           47 1024   5  0.807          601          220           52           53          225985               0               0           31003               0               0           0\r\n                 384  17          384          100           99            1            1            1  512   3  0.001            1            4            1            0             196               0               0               1               0               0           0\r\n                 448  18            0          100          100            1            0            0 1024   7      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 512  19          512          100           99            4            1            1  128   1  0.007            1            4            1            0             196               0               0               1               0               0           0\r\n                 640  20            0          100          100            1            0            0  512   5      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 768  21            0            0            0            0            0            0  256   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                 896  22            0            0            0            0            0            0  512   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n                1024  23         3072           64           61            4            3            1   64   1  0.046            1            3            1            0             195               0               0               1               0               0           0\r\n                1280  24         7680          106          100            1            6            1  256   5  0.023            2            4            2            0             199               0               0               1               0               0           0\r\n                1536  25         9216          115          109            4            6            1  128   3  0.046            5            8            2            0             206               0               0               1               0               0           0\r\n                1792  26            0            0            0            0            0            0  256   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n                2048  27        14336           36           29            4            7            1   32   1  0.218            2            3            1            0             196               0               0               1               0               0           0\r\n                2560  28       256000          100            0            0          100            1  128   5  0.781            1            0            1            0             192               0               0               1               0               0           0\r\n                3072  29            0            0            0            0            0            0   64   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n                3584  30        21504          106          100            1            6            1  128   7  0.046            2            4            2            0             199               0               0               1               0               0           0\r\n                4096  31            0            0            0            0            0            0   16   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n                5120  32            0            0            0            0            0            0   64   5      1            0            0            0            0             190               0               0               1               0               0           0\r\n                6144  33            0            0            0            0            0            0   32   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                7168  34            0            0            0            0            0            0   64   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                8192  35            0            0            0            0            0            0    8   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n               10240  36            0            0            0            0            0            0   32   5      1            0            0            0            0             190               0               0               1               0               0           0\r\n               12288  37            0            0            0            0            0            0   16   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n               14336  38            0            0            0            0            0            0   32   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               16384  39            0           10           10            1            0            0    4   1      1            1            2            3            0             199               0               0               1               0               0           0\r\n               20480  40        61440           16           13            4            3            1   16   5  0.187            1            2            1            0             194               0               0               1               0               0           0\r\n               24576  41            0            0            0            0            0            0    8   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n               28672  42            0            0            0            0            0            0   16   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n               32768  43            0            0            0            0            0            0    2   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               40960  44        40960           10            9            2            1            1    8   5  0.125            1            2            2            0             196               0               0               1               0               0           0\r\n               49152  45            0            0            0            0            0            0    4   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               57344  46        57344            1            0            1            1            1    8   7  0.125            0            0            1            0             192               0               0               1               0               0           0\r\n               65536  47            0            0            0            0            0            0    1   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               81920  48        81920           10            9            1            1            1    4   5  0.250            1            2            3            0             198               0               0               1               0               0           0\r\n               98304  49            0            0            0            0            0            0    2   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n              114688  50            0            0            0            0            0            0    4   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n              131072  51            0            0            0            0            0            0    1   2      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n              163840  52       163840           10            9            1            1            1    2   5  0.500            1            2            5            0             202               0               0               1               0               0           0\r\n              196608  53            0            0            0            0            0            0    1   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n              229376  54            0            0            0            0            0            0    2   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\nlarge:          size ind    allocated      nmalloc      ndalloc    nrequests  curlextents\r\n                     ---\r\n              327680  56       327680            1            0            1            1\r\n                     ---\r\n             8388608  75      8388608            1            0            1            1\r\n                     ---\r\n--- End jemalloc statistics ---\r\n\r\n[\u001B[0;31;49merr\u001B[0m]: Active defrag in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\n# Memory\r\nused_memory:60252320\r\nused_memory_human:57.46M\r\nused_memory_rss:123863040\r\nused_memory_rss_human:118.12M\r\nused_memory_peak:160476576\r\nused_memory_peak_human:153.04M\r\nused_memory_peak_perc:37.55%\r\nused_memory_overhead:15085544\r\nused_memory_startup:824224\r\nused_memory_dataset:45166776\r\nused_memory_dataset_perc:76.00%\r\nallocator_allocated:60318880\r\nallocator_active:66453504\r\nallocator_resident:122028032\r\ntotal_system_memory:10278404096\r\ntotal_system_memory_human:9.57G\r\nused_memory_lua:37888\r\nused_memory_lua_human:37.00K\r\nused_memory_scripts:0\r\nused_memory_scripts_human:0B\r\nnumber_of_cached_scripts:0\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:allkeys-lru\r\nallocator_frag_ratio:1.10\r\nallocator_frag_bytes:6134624\r\nallocator_rss_ratio:1.84\r\nallocator_rss_bytes:55574528\r\nrss_overhead_ratio:1.02\r\nrss_overhead_bytes:1835008\r\nmem_fragmentation_ratio:2.06\r\nmem_fragmentation_bytes:63651744\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:0\r\nmem_clients_slaves:0\r\nmem_clients_normal:66616\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.1.0\r\nactive_defrag_running:65\r\nlazyfree_pending_objects:0\r\n\r\n___ Begin jemalloc statistics ___\r\nVersion: \"5.1.0-0-g0\"\r\nBuild-time option settings\r\n  config.cache_oblivious: true\r\n  config.debug: false\r\n  config.fill: true\r\n  config.lazy_lock: false\r\n  config.malloc_conf: \"\"\r\n  config.prof: false\r\n  config.prof_libgcc: false\r\n  config.prof_libunwind: false\r\n  config.stats: true\r\n  config.utrace: false\r\n  config.xmalloc: false\r\nRun-time option settings\r\n  opt.abort: false\r\n  opt.abort_conf: false\r\n  opt.retain: true\r\n  opt.dss: \"secondary\"\r\n  opt.narenas: 128\r\n  opt.percpu_arena: \"disabled\"\r\n  opt.metadata_thp: \"disabled\"\r\n  opt.background_thread: false (background_thread: false)\r\n  opt.dirty_decay_ms: 10000 (arenas.dirty_decay_ms: 10000)\r\n  opt.muzzy_decay_ms: 10000 (arenas.muzzy_decay_ms: 10000)\r\n  opt.junk: \"false\"\r\n  opt.zero: false\r\n  opt.tcache: true\r\n  opt.lg_tcache_max: 15\r\n  opt.thp: \"default\"\r\n  opt.stats_print: false\r\n  opt.stats_print_opts: \"\"\r\nArenas: 128\r\nQuantum size: 8\r\nPage size: 65536\r\nMaximum thread-cached size class: 229376\r\nNumber of bin size classes: 55\r\nNumber of thread-cache bin size classes: 55\r\nNumber of large size classes: 180\r\nAllocated: 60326560, active: 66453504, metadata: 5261600 (n_thp 0), resident: 122028032, mapped: 133562368, retained: 101318656\r\nBackground threads: 0, num_runs: 0, run_interval: 0 ns\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nbackground_thread                2213               0               0               1               0               0           0\r\nctl                              9784               0               0               1               0               0           0\r\nprof                                0               0               0               0               0               0           0\r\narenas[0]:\r\nassigned threads: 1\r\nuptime: 117400141402\r\ndss allocation precedence: \"secondary\"\r\ndecaying:  time       npages       sweeps     madvises       purged\r\n   dirty: 10000          768           32          194         1754\r\n   muzzy: 10000            0            0            0            0\r\n                            allocated     nmalloc     ndalloc   nrequests\r\nsmall:                       55804576     6588398     5486841    20565728\r\nlarge:                        4521984           7           5           7\r\ntotal:                       60326560     6588405     5486846    20565735\r\n                                     \r\nactive:                      66453504\r\nmapped:                     133562368\r\nretained:                   101318656\r\nbase:                         5204248\r\ninternal:                       57352\r\nmetadata_thp:                       0\r\ntcache_bytes:                   16880\r\nresident:                   122028032\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nlarge                            1106               0               0               1               0               0           0\r\nextent_avail                     3177               0               0               3               0               0           0\r\nextents_dirty                    4734               0               0               3               0               0           0\r\nextents_muzzy                    2147               0               0               3               0               0           0\r\nextents_retained                 3491               0               0               3               0               0           0\r\ndecay_dirty                      8000               0               0               1               0               0           0\r\ndecay_muzzy                      7968               0               0               1               0               0           0\r\nbase                             3199               0               0               3               0               0           0\r\ntcache_list                      1107               0               0               1               0               0           0\r\nbins:           size ind    allocated      nmalloc      ndalloc    nrequests      curregs     curslabs regs pgs   util       nfills     nflushes       nslabs     nreslabs      n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\n                   8   0      2082272       682452       422168       737512       260284           33 8192   1  0.962         5729         2899           63           35         5292332               0               0          342741               0               0           0\r\n                  16   1      4198176      2585949      2323563      7404066       262386           66 4096   1  0.970        21738        18490          441          390        10099741               0               0         1131829               0               0           0\r\n                  24   2      7502400      1681985      1369385      3943160       312600           42 8192   3  0.908        13940        10656          109          156         8756245               0               0          734355               0               0           0\r\n                  32   3        64896         2520          492      6441884         2028            1 2048   1  0.990          133          110            1            0           39521               0               0             153               0               0           0\r\n                  40   4       300080         9578         2076        59531         7502            1 8192   5  0.915          180           76            1            0          143711               0               0             155               0               0           0\r\n                  48   5         2448          200          149         2339           51            1 4096   3  0.012           29           33            1            0            1169               0               0               1               0               0           0\r\n                  56   6       105728         2607          719       350162         1888            1 8192   7  0.230          116          104            1            0           36743               0               0              79               0               0           0\r\n                  64   7          320          114          109         2039            5            1 1024   1  0.004            8           12            1            0            1146               0               0              39               0               0           0\r\n                  80   8        40560         1010          503         4518          507            1 4096   5  0.123           89           93            1            0           10865               0               0              41               0               0           0\r\n                  96   9       191424         2762          768         4218         1994            1 2048   3  0.973           98          100            1            0           37291               0               0             193               0               0           0\r\n                 112  10       252336         4742         2489         2262         2253            1 4096   7  0.550           99           98            1            0           44092               0               0             117               0               0           0\r\n                 128  11          384          126          123           17            3            1  512   1  0.005           10           16            2            0            1192               0               0              41               0               0           0\r\n                 160  12     40000320      1543928      1293926      1543761       250002          123 2048   5  0.992        12149        10159          588          359         7336648               0               0          687995               0               0           0\r\n                 192  13          192          115          114          168            1            1 1024   3  0.000            9           13            9            0            1145               0               0               1               0               0           0\r\n                 224  14            0          114          114            8            0            0 2048   7      1            6           11            6            0            1135               0               0               1               0               0           0\r\n                 256  15            0          116          116           15            0            0  256   1      1            8           13            8            0            1143               0               0               1               0               0           0\r\n                 320  16         5120        68246        68230        68128           16            1 1024   5  0.015          605          699           52           55          227430               0               0           31003               0               0           0\r\n                 384  17          384          116          115            9            1            1  512   3  0.001            8           13            1            0            1128               0               0               1               0               0           0\r\n                 448  18            0          113          113            8            0            0 1024   7      1            7           12            7            0            1139               0               0               1               0               0           0\r\n                 512  19          512          113          112           15            1            1  128   1  0.007            9           14            1            0            1130               0               0               1               0               0           0\r\n                 640  20            0          113          113            8            0            0  512   5      1            7           12            7            0            1139               0               0               1               0               0           0\r\n                 768  21            0          113          113            8            0            0  256   3      1            7           12            7            0            1139               0               0               1               0               0           0\r\n                 896  22            0          110          110            7            0            0  512   7      1            6           11            6            0            1135               0               0               1               0               0           0\r\n                1024  23         3072           81           78           15            3            1   64   1  0.046            9           14            1            0            1130               0               0               1               0               0           0\r\n                1280  24         3840          125          122          563            3            1  256   5  0.011           11           15            4            0            1177               0               0              77               0               0           0\r\n                1536  25         4608          125          122          189            3            1  128   3  0.023           15           17            3            0            1143               0               0               1               0               0           0\r\n                1792  26            0          109          109            6            0            0  256   7      1            5           10            5            0            1131               0               0               1               0               0           0\r\n                2048  27         8192           46           42          173            4            1   32   1  0.125           11           14            1            0            1132               0               0               1               0               0           0\r\n                2560  28        17920          121          114            7            7            1  128   5  0.054            7           10            3            0            1204               0               0              39               0               0           0\r\n                3072  29            0           68           68            3            0            0   64   3      1            2            6            2            0            1118               0               0               1               0               0           0\r\n                3584  30         3584          115          114          592            1            1  128   7  0.007            5            9            5            0            1129               0               0               1               0               0           0\r\n                4096  31            0           21           21            5            0            0   16   1      1            3            6            2            0            1119               0               0               1               0               0           0\r\n                5120  32            0           64           64            1            0            0   64   5      1            1            4            1            0            1113               0               0               1               0               0           0\r\n                6144  33            0           36           36            2            0            0   32   3      1            2            5            2            0            1117               0               0               1               0               0           0\r\n                7168  34            0           64           64            1            0            0   64   7      1            1            4            1            0            1113               0               0               1               0               0           0\r\n                8192  35            0           15           15            5            0            0    8   1      1            4            6            4            0            1124               0               0               1               0               0           0\r\n               10240  36            0           32           32            1            0            0   32   5      1            1            3            1            0            1112               0               0               1               0               0           0\r\n               12288  37            0           18           18            2            0            0   16   3      1            2            5            2            0            1117               0               0               1               0               0           0\r\n               14336  38            0            0            0            0            0            0   32   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n               16384  39            0           15           15            5            0            0    4   1      1            4            6            5            0            1126               0               0               1               0               0           0\r\n               20480  40        81920           22           18            8            4            1   16   5  0.250            3            5            1            0            1115               0               0               1               0               0           0\r\n               24576  41            0           10           10            1            0            0    8   3      1            1            2            2            0            1113               0               0               1               0               0           0\r\n               28672  42            0            0            0            0            0            0   16   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n               32768  43            0           11           11            4            0            0    2   1      1            2            5            6            0            1125               0               0               1               0               0           0\r\n               40960  44        40960           13           12          291            1            1    8   5  0.125            3            5            2            1            1117               0               0               1               0               0           0\r\n               49152  45            0            0            0            0            0            0    4   3      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n               57344  46        57344            1            0            1            1            1    8   7  0.125            0            0            1            0            1108               0               0               1               0               0           0\r\n               65536  47       196608           12            9            4            3            3    1   1      1            2            4           12            0            1190               0               0             115               0               0           0\r\n               81920  48        81920           10            9            1            1            1    4   5  0.250            1            2            3            0            1114               0               0               1               0               0           0\r\n               98304  49            0            0            0            0            0            0    2   3      1            0            0            0            0            1106               0               0               1               0               0           0\r\n              114688  50            0            0            0            0            0            0    4   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n              131072  51       393216           12            9            4            3            3    1   2      1            2            4           12            0            1190               0               0             115               0               0           0\r\n              163840  52       163840           10            9            1            1            1    2   5  0.500            1            2            5            0            1118               0               0               1               0               0           0\r\n              196608  53            0            0            0            0            0            0    1   3      1            0            0            0            0            1106               0               0               1               0               0           0\r\n              229376  54            0            0            0            0            0            0    2   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\nlarge:          size ind    allocated      nmalloc      ndalloc    nrequests  curlextents\r\n              262144  55            0            1            1            1            0\r\n              327680  56       327680            1            0            1            1\r\n                     ---\r\n              524288  59            0            1            1            1            0\r\n                     ---\r\n             1048576  63            0            1            1            1            0\r\n                     ---\r\n             2097152  67            0            1            1            1            0\r\n                     ---\r\n             4194304  71      4194304            1            0            1            1\r\n                     ---\r\n             8388608  75            0            1            1            1            0\r\n                     ---\r\n--- End jemalloc statistics ---\r\n\r\n[\u001B[0;31;49merr\u001B[0m]: Active defrag big keys in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\n[46/50 \u001B[0;33;49mdone\u001B[0m]: unit/memefficiency (122 seconds)\r\n\u001B[1;37;49mTesting unit/hyperloglog\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: HyperLogLog self test passes\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD without arguments creates an HLL value\r\n[\u001B[0;32;49mok\u001B[0m]: Approximated cardinality after creation is zero\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD returns 1 when at least 1 reg was modified\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD returns 0 when no reg was modified\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD works with empty string (regression)\r\n[\u001B[0;32;49mok\u001B[0m]: PFCOUNT returns approximated cardinality of set\r\n[\u001B[0;32;49mok\u001B[0m]: HyperLogLogs are promote from sparse to dense\r\n[\u001B[0;32;49mok\u001B[0m]: HyperLogLog sparse encoding stress test\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted sparse HyperLogLogs are detected: Additionl at tail\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted sparse HyperLogLogs are detected: Broken magic\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted sparse HyperLogLogs are detected: Invalid encoding\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted dense HyperLogLogs are detected: Wrong length\r\n[\u001B[0;32;49mok\u001B[0m]: Fuzzing dense/sparse encoding: Redis should always detect errors\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD, PFCOUNT, PFMERGE type checking works\r\n[\u001B[0;32;49mok\u001B[0m]: PFMERGE results on the cardinality of union of sets\r\n[\u001B[0;32;49mok\u001B[0m]: PFCOUNT multiple-keys merge returns cardinality of union #1\r\n[\u001B[0;32;49mok\u001B[0m]: PFCOUNT multiple-keys merge returns cardinality of union #2\r\n[\u001B[0;32;49mok\u001B[0m]: PFDEBUG GETREG returns the HyperLogLog raw registers\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD / PFCOUNT cache invalidation works\r\n[47/50 \u001B[0;33;49mdone\u001B[0m]: unit/hyperloglog (53 seconds)\r\n\u001B[1;37;49mTesting unit/lazyfree\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: UNLINK can reclaim memory in background\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB ASYNC can reclaim memory in background\r\n[48/50 \u001B[0;33;49mdone\u001B[0m]: unit/lazyfree (1 seconds)\r\n\u001B[1;37;49mTesting unit/wait\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Setup slave\r\n[\u001B[0;32;49mok\u001B[0m]: WAIT should acknowledge 1 additional copy of the data\r\n[\u001B[0;32;49mok\u001B[0m]: WAIT should not acknowledge 2 additional copies of the data\r\n[\u001B[0;32;49mok\u001B[0m]: WAIT should not acknowledge 1 additional copy if slave is blocked\r\n[49/50 \u001B[0;33;49mdone\u001B[0m]: unit/wait (7 seconds)\r\n\u001B[1;37;49mTesting unit/pendingquerybuf\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: pending querybuf: check size of pending_querybuf after set a big value\r\n[50/50 \u001B[0;33;49mdone\u001B[0m]: unit/pendingquerybuf (7 seconds)\r\n\r\n                   The End\r\n\r\nExecution time of different units:\r\n  1 seconds - unit/printver\r\n  27 seconds - unit/dump\r\n  1 seconds - unit/auth\r\n  0 seconds - unit/protocol\r\n  2 seconds - unit/keyspace\r\n  8 seconds - unit/scan\r\n  12 seconds - unit/type/string\r\n  0 seconds - unit/type/incr\r\n  13 seconds - unit/type/list\r\n  17 seconds - unit/type/list-2\r\n  103 seconds - unit/type/list-3\r\n  7 seconds - unit/type/set\r\n  13 seconds - unit/type/zset\r\n  5 seconds - unit/type/hash\r\n  29 seconds - unit/type/stream\r\n  3 seconds - unit/type/stream-cgroups\r\n  9 seconds - unit/sort\r\n  15 seconds - unit/expire\r\n  9 seconds - unit/other\r\n  2 seconds - unit/multi\r\n  0 seconds - unit/quit\r\n  97 seconds - unit/aofrw\r\n  27 seconds - integration/block-repl\r\n  148 seconds - integration/replication\r\n  16 seconds - integration/replication-2\r\n  32 seconds - integration/replication-3\r\n  34 seconds - integration/replication-4\r\n  100 seconds - integration/replication-psync\r\n  3 seconds - integration/aof\r\n  2 seconds - integration/rdb\r\n  0 seconds - integration/convert-zipmap-hash-on-load\r\n  1 seconds - integration/logging\r\n  28 seconds - integration/psync2\r\n  23 seconds - integration/psync2-reg\r\n  0 seconds - unit/pubsub\r\n  2 seconds - unit/slowlog\r\n  6 seconds - unit/scripting\r\n  43 seconds - unit/maxmemory\r\n  0 seconds - unit/introspection\r\n  7 seconds - unit/introspection-2\r\n  1 seconds - unit/limits\r\n  168 seconds - unit/obuf-limits\r\n  4 seconds - unit/bitops\r\n  1 seconds - unit/bitfield\r\n  21 seconds - unit/geo\r\n  122 seconds - unit/memefficiency\r\n  53 seconds - unit/hyperloglog\r\n  1 seconds - unit/lazyfree\r\n  7 seconds - unit/wait\r\n  7 seconds - unit/pendingquerybuf\r\n\r\n\u001B[1;31;49m!!! WARNING\u001B[0m The following tests failed:\r\n\r\n*** [\u001B[0;31;49merr\u001B[0m]: Active defrag in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\n*** [\u001B[0;31;49merr\u001B[0m]: Active defrag big keys in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\nCleanup: may take some time... OK\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/8265/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/8265/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"actor":{"login":"qq1052121189","id":23209206,"node_id":"MDQ6VXNlcjIzMjA5MjA2","avatar_url":"https://avatars.githubusercontent.com/u/23209206?v=4","gravatar_id":"","url":"https://api.github.com/users/qq1052121189","html_url":"https://github.com/qq1052121189","followers_url":"https://api.github.com/users/qq1052121189/followers","following_url":"https://api.github.com/users/qq1052121189/following{/other_user}","gists_url":"https://api.github.com/users/qq1052121189/gists{/gist_id}","starred_url":"https://api.github.com/users/qq1052121189/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qq1052121189/subscriptions","organizations_url":"https://api.github.com/users/qq1052121189/orgs","repos_url":"https://api.github.com/users/qq1052121189/repos","events_url":"https://api.github.com/users/qq1052121189/events{/privacy}","received_events_url":"https://api.github.com/users/qq1052121189/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-02-07T02:08:50Z","updated_at":"2021-02-07T02:08:50Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/8457","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/8457/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/8457/comments","events_url":"https://api.github.com/repos/redis/redis/issues/8457/events","html_url":"https://github.com/redis/redis/issues/8457","id":802835646,"node_id":"MDU6SXNzdWU4MDI4MzU2NDY=","number":8457,"title":"Centos7 redis-6.0.10 'make test' faiil: *** [err]: ZSCAN with encoding skiplist in tests/unit/scan.tcl","user":{"login":"qq1052121189","id":23209206,"node_id":"MDQ6VXNlcjIzMjA5MjA2","avatar_url":"https://avatars.githubusercontent.com/u/23209206?v=4","gravatar_id":"","url":"https://api.github.com/users/qq1052121189","html_url":"https://github.com/qq1052121189","followers_url":"https://api.github.com/users/qq1052121189/followers","following_url":"https://api.github.com/users/qq1052121189/following{/other_user}","gists_url":"https://api.github.com/users/qq1052121189/gists{/gist_id}","starred_url":"https://api.github.com/users/qq1052121189/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/qq1052121189/subscriptions","organizations_url":"https://api.github.com/users/qq1052121189/orgs","repos_url":"https://api.github.com/users/qq1052121189/repos","events_url":"https://api.github.com/users/qq1052121189/events{/privacy}","received_events_url":"https://api.github.com/users/qq1052121189/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2021-02-07T02:08:49Z","updated_at":"2021-02-09T06:19:59Z","closed_at":"2021-02-07T07:27:00Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"[ok]: SINTER against non-set should throw error\r\n[ok]: SUNION against non-set should throw error\r\n[ok]: SINTER should handle non existing key as empty\r\n[ok]: SINTER with same integer elements but different encoding\r\n[ok]: SINTERSTORE against non existing keys should delete dstkey\r\n[ok]: SUNIONSTORE against non existing keys should delete dstkey\r\n[ok]: SPOP basics - hashtable\r\n[ok]: SPOP with <count>=1 - hashtable\r\n[ok]: SRANDMEMBER - hashtable\r\n[ok]: SPOP basics - intset\r\n[ok]: SPOP with <count>=1 - intset\r\n[ok]: BZPOPMIN with zero timeout should block indefinitely\r\n[ok]: SRANDMEMBER - intset\r\n[ok]: SPOP with <count>\r\n[ok]: SPOP with <count>\r\n[ok]: SPOP using integers, testing Knuth's and Floyd's algorithm\r\n[ok]: SPOP using integers with Knuth's algorithm\r\n[ok]: SPOP new implementation: code path #1\r\n[ok]: ZSCORE - skiplist\r\n[ok]: SPOP new implementation: code path #2\r\n[ok]: SPOP new implementation: code path #3\r\n[ok]: SRANDMEMBER with <count> against non existing key\r\n[ok]: SRANDMEMBER with <count> - hashtable\r\n[ok]: SRANDMEMBER with <count> - intset\r\n[ok]: SMOVE basics - from regular set to intset\r\n[ok]: SMOVE basics - from intset to regular set\r\n[ok]: SMOVE non existing key\r\n[ok]: SMOVE non existing src set\r\n[ok]: SMOVE from regular set to non existing destination set\r\n[ok]: SMOVE from intset to non existing destination set\r\n[ok]: SMOVE wrong src key type\r\n[ok]: SMOVE wrong dst key type\r\n[ok]: SMOVE with identical source and destination\r\n[ok]: LTRIM stress testing - linkedlist\r\n[ok]: MULTI and script timeout\r\n[ok]: SCAN regression test for issue #4906\r\n[ok]: SET 10000 numeric keys and access all them in reverse order\r\n[ok]: DBSIZE should be 10000 now\r\n[ok]: SETNX target key missing\r\n[ok]: SETNX target key exists\r\n[ok]: SETNX against not-expired volatile key\r\n[ok]: BRPOPLPUSH timeout\r\n[ok]: BLPOP when new key is moved into place\r\n[ok]: BLPOP when result key is created by SORT..STORE\r\n[ok]: BLPOP: with single empty list argument\r\n[ok]: BLPOP: with negative timeout\r\n[ok]: BLPOP: with non-integer timeout\r\n[ok]: EXEC and script timeout\r\n[ok]: BGSAVE\r\n[ok]: SELECT an out of range DB\r\n[ok]: ZSCORE after a DEBUG RELOAD - skiplist\r\n[9/58 done]: unit/scan (5 seconds)\r\nTesting integration/block-repl\r\n[ok]: ZSET sorting stresser - skiplist\r\n[ok]: Big Hash table: SORT BY key\r\n[ok]: Big Hash table: SORT BY key with limit\r\n[ok]: MULTI-EXEC body and script timeout\r\n[ok]: Big Hash table: SORT BY hash field\r\n[ok]: SORT GET #\r\n[ok]: SORT GET <const>\r\n[ok]: SORT GET (key and hash) with sanity check\r\n[ok]: SORT BY key STORE\r\n[ok]: SORT BY hash field STORE\r\n[ok]: SORT extracts STORE correctly\r\n[ok]: SORT extracts multiple STORE correctly\r\n[ok]: SORT DESC\r\n[ok]: SORT ALPHA against integer encoded strings\r\n[ok]: SORT sorted set\r\n[ok]: SORT sorted set BY nosort should retain ordering\r\n[ok]: SORT sorted set BY nosort + LIMIT\r\n[ok]: SORT sorted set BY nosort works as expected from scripts\r\n[ok]: SORT sorted set: +inf and -inf handling\r\n[ok]: SORT regression for issue #19, sorting floats\r\n[ok]: SORT with STORE returns zero if result is empty (github issue 224)\r\n[ok]: SORT with STORE does not create empty lists (github issue 224)\r\n[ok]: SORT with STORE removes key if result is empty (github issue 227)\r\n[ok]: SORT with BY <constant> and STORE should still order output\r\n[ok]: SORT will complain with numerical sorting and bad doubles (1)\r\n[ok]: SORT will complain with numerical sorting and bad doubles (2)\r\n[ok]: SORT BY sub-sorts lexicographically if score is the same\r\n[ok]: SORT GET with pattern ending with just -> does not get hash field\r\n[ok]: SORT by nosort retains native order for lists\r\n[ok]: SORT by nosort plus store retains native order for lists\r\n[ok]: SORT by nosort with limit returns based on original list order\r\n[ok]: intsets implementation stress testing\r\n[ok]: SORT speed, 100 element list BY key, 100 times\r\n[ok]: SORT speed, 100 element list BY hash field, 100 times\r\n[ok]: SORT speed, 100 element list directly, 100 times\r\n[ok]: SORT speed, 100 element list BY <const>, 100 times\r\n[10/58 done]: unit/type/set (6 seconds)\r\nTesting integration/replication\r\n[11/58 done]: unit/sort (6 seconds)\r\nTesting integration/replication-2\r\n[ok]: EXPIRE precision is now the millisecond\r\n[ok]: BLPOP: with zero timeout should block indefinitely\r\n[ok]: BLPOP: second argument is not a list\r\n[ok]: just EXEC and script timeout\r\n[ok]: exec with write commands and state change\r\n[ok]: exec with read commands and stale replica state change\r\n[ok]: EXEC with only read commands should not be rejected when OOM\r\n[ok]: EXEC with at least one use-memory command should fail\r\n[ok]: Empty stream with no lastid can be rewrite into AOF correctly\r\n[ok]: EXPIRES after a reload (snapshot + append only file rewrite)\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: PEXPIRE/PSETEX/PEXPIREAT can set sub-second expires\r\n[ok]: TTL returns time to live in seconds\r\n[ok]: PTTL returns time to live in milliseconds\r\n[ok]: TTL / PTTL return -1 if key has no expire\r\n[ok]: TTL / PTTL return -2 if key does not exit\r\n[12/58 done]: unit/multi (6 seconds)\r\nTesting integration/replication-3\r\n[ok]: ZRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: ZSETs skiplist implementation backlink consistency test - skiplist\r\n[ok]: BLPOP: timeout\r\n[ok]: BLPOP: arguments are empty\r\n[ok]: BRPOP: with single empty list argument\r\n[ok]: BRPOP: with negative timeout\r\n[ok]: BRPOP: with non-integer timeout\r\n[ok]: Slave enters handshake\r\n[13/58 done]: unit/type/stream-cgroups (7 seconds)\r\nTesting integration/replication-4\r\n[ok]: ZSETs ZRANK augmented skip list stress testing - skiplist\r\n[ok]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[ok]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[ok]: BZPOPMIN with same key multiple times should work\r\n[ok]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[ok]: BZPOPMIN with variadic ZADD\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: If min-slaves-to-write is honored, write is accepted\r\n[ok]: No write if min-slaves-to-write is < attached slaves\r\n[ok]: If min-slaves-to-write is honored, write is accepted (again)\r\n[ok]: Test latency events logging\r\n[ok]: LATENCY HISTORY output is ok\r\n[ok]: LATENCY LATEST output is ok\r\n[ok]: LATENCY HISTORY / RESET with wrong event name is fine\r\n[ok]: LATENCY DOCTOR produces some output\r\n[ok]: LATENCY RESET is able to reset events\r\n[ok]: SETNX against expired volatile key\r\n[ok]: MGET\r\n[ok]: MGET against non existing key\r\n[ok]: MGET against non-string key\r\n[ok]: GETSET (set new value)\r\n[ok]: GETSET (replace old value)\r\n[ok]: MSET base case\r\n[ok]: MSET wrong number of args\r\n[ok]: MSETNX with already existent key\r\n[ok]: MSETNX with not existing keys\r\n[ok]: STRLEN against non-existing key\r\n[ok]: STRLEN against integer-encoded value\r\n[ok]: STRLEN against plain string\r\n[ok]: SETBIT against non-existing key\r\n[ok]: SETBIT against string-encoded key\r\n[ok]: SETBIT against integer-encoded key\r\n[ok]: SETBIT against key with wrong type\r\n[ok]: SETBIT with out of range bit offset\r\n[ok]: SETBIT with non-bit argument\r\n[ok]: Redis should actively expire keys incrementally\r\n[ok]: SETBIT fuzzing\r\n[ok]: GETBIT against non-existing key\r\n[ok]: GETBIT against string-encoded key\r\n[ok]: GETBIT against integer-encoded key\r\n[ok]: SETRANGE against non-existing key\r\n[ok]: SETRANGE against string-encoded key\r\n[ok]: SETRANGE against integer-encoded key\r\n[ok]: SETRANGE against key with wrong type\r\n[ok]: SETRANGE with out of range offset\r\n[ok]: GETRANGE against non-existing key\r\n[ok]: GETRANGE against string value\r\n[ok]: GETRANGE against integer-encoded value\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: BRPOP: with zero timeout should block indefinitely\r\n[ok]: BRPOP: second argument is not a list\r\n[ok]: BZPOPMIN with zero timeout should block indefinitely\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: Redis should lazy expire keys\r\n[ok]: GETRANGE fuzzing\r\n[ok]: Extended SET can detect syntax errors\r\n[ok]: Extended SET NX option\r\n[ok]: Extended SET XX option\r\n[ok]: Extended SET EX option\r\n[ok]: Extended SET PX option\r\n[ok]: Extended SET using multiple options at once\r\n[ok]: GETRANGE with huge ranges, Github issue #1844\r\n[ok]: STRALGO LCS string output with STRINGS option\r\n[ok]: STRALGO LCS len\r\n[ok]: LCS with KEYS option\r\n[ok]: LCS indexes\r\n[ok]: LCS indexes with match len\r\n[ok]: LCS indexes with match len and minimum match len\r\n[ok]: BRPOP: timeout\r\n[ok]: BRPOP: arguments are empty\r\n[ok]: BLPOP inside a transaction\r\n[ok]: LPUSHX, RPUSHX - generic\r\n[ok]: LPUSHX, RPUSHX - linkedlist\r\n[ok]: LINSERT - linkedlist\r\n[ok]: LPUSHX, RPUSHX - ziplist\r\n[ok]: LINSERT - ziplist\r\n[ok]: LINSERT raise error on bad syntax\r\n[ok]: LINDEX consistency test - quicklist\r\n[ok]: ZSET skiplist order consistency when elements are moved\r\n[ok]: LINDEX random access - quicklist\r\n[ok]: EXPIRE should not resurrect keys (issue #1026)\r\n[ok]: 5 keys in, 5 keys out\r\n[ok]: EXPIRE with empty string as TTL should report an error\r\n[ok]: EXPIRES after AOF reload (without rewrite)\r\n[14/58 done]: unit/type/string (10 seconds)\r\nTesting integration/replication-psync\r\n[15/58 done]: unit/type/zset (10 seconds)\r\nTesting integration/aof\r\n[ok]: Unfinished MULTI: Server should start if load-truncated is yes\r\n[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[ok]: LINDEX consistency test - quicklist\r\n[ok]: LTRIM stress testing - ziplist\r\n[ok]: LINDEX random access - quicklist\r\n[ok]: PIPELINING stresser (also a regression for the old epoll bug)\r\n[ok]: APPEND basics\r\n[ok]: APPEND basics, integer encoded values\r\n[16/58 done]: unit/type/list-2 (10 seconds)\r\nTesting integration/rdb\r\n[ok]: APPEND fuzzing\r\n[ok]: FLUSHDB\r\n[ok]: Perform a final SAVE to leave a clean DB on disk\r\n[ok]: RDB encoding loading test\r\n[ok]: Short read: Server should start if load-truncated is yes\r\n[ok]: Truncated AOF loaded: we expect foo to be equal to 5\r\n[ok]: Append a new command after loading an incomplete AOF\r\n[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[ok]: LLEN against non-list value error\r\n[ok]: LLEN against non existing key\r\n[ok]: LINDEX against non-list value error\r\n[ok]: LINDEX against non existing key\r\n[ok]: LPUSH against non-list value error\r\n[ok]: RPUSH against non-list value error\r\n[ok]: RPOPLPUSH base case - linkedlist\r\n[ok]: RPOPLPUSH with the same list as src and dst - linkedlist\r\n[ok]: RPOPLPUSH with linkedlist source and existing target linkedlist\r\n[ok]: RPOPLPUSH with linkedlist source and existing target ziplist\r\n[ok]: RPOPLPUSH base case - ziplist\r\n[ok]: RPOPLPUSH with the same list as src and dst - ziplist\r\n[ok]: RPOPLPUSH with ziplist source and existing target linkedlist\r\n[ok]: RPOPLPUSH with ziplist source and existing target ziplist\r\n[ok]: RPOPLPUSH against non existing key\r\n[ok]: RPOPLPUSH against non list src key\r\n[ok]: RPOPLPUSH against non list dst key\r\n[ok]: RPOPLPUSH against non existing src key\r\n[ok]: Basic LPOP/RPOP - linkedlist\r\n[ok]: Basic LPOP/RPOP - ziplist\r\n[ok]: LPOP/RPOP against non list value\r\n[ok]: Mass RPOP/LPOP - quicklist\r\n[ok]: Mass RPOP/LPOP - quicklist\r\n[ok]: LRANGE basics - linkedlist\r\n[ok]: LRANGE inverted indexes - linkedlist\r\n[ok]: LRANGE out of range indexes including the full list - linkedlist\r\n[ok]: LRANGE out of range negative end index - linkedlist\r\n[ok]: LRANGE basics - ziplist\r\n[ok]: LRANGE inverted indexes - ziplist\r\n[ok]: LRANGE out of range indexes including the full list - ziplist\r\n[ok]: LRANGE out of range negative end index - ziplist\r\n[ok]: LRANGE against non existing key\r\n[ok]: LTRIM basics - linkedlist\r\n[ok]: LTRIM out of range negative end index - linkedlist\r\n[ok]: LTRIM basics - ziplist\r\n[ok]: LTRIM out of range negative end index - ziplist\r\n[ok]: LSET - linkedlist\r\n[ok]: LSET out of range index - linkedlist\r\n[ok]: LSET - ziplist\r\n[ok]: LSET out of range index - ziplist\r\n[ok]: LSET against non existing key\r\n[ok]: LSET against non list value\r\n[ok]: LREM remove all the occurrences - linkedlist\r\n[ok]: LREM remove the first occurrence - linkedlist\r\n[ok]: LREM remove non existing element - linkedlist\r\n[ok]: LREM starting from tail with negative count - linkedlist\r\n[ok]: LREM starting from tail with negative count (2) - linkedlist\r\n[ok]: LREM deleting objects that may be int encoded - linkedlist\r\n[ok]: LREM remove all the occurrences - ziplist\r\n[ok]: LREM remove the first occurrence - ziplist\r\n[ok]: LREM remove non existing element - ziplist\r\n[ok]: LREM starting from tail with negative count - ziplist\r\n[ok]: LREM starting from tail with negative count (2) - ziplist\r\n[ok]: LREM deleting objects that may be int encoded - ziplist\r\n[ok]: LATENCY of expire events are correctly collected\r\n[ok]: LATENCY HELP should not have unexpected options\r\n[ok]: Server started empty with non-existing RDB file\r\n[ok]: Short read + command: Server should start\r\n[ok]: Truncated AOF loaded: we expect foo to be equal to 6 now\r\n[ok]: Don't rehash if redis has child proecess\r\n[17/58 done]: unit/other (10 seconds)\r\nTesting integration/convert-zipmap-hash-on-load\r\n[ok]: RDB load zipmap hash: converts to ziplist\r\n[ok]: Regression for bug 593 - chaining BRPOPLPUSH with other blocking cmds\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: no, disabled, reconnect: 0)\r\n[18/58 done]: unit/latency-monitor (8 seconds)\r\nTesting integration/logging\r\n[19/58 done]: unit/type/list (12 seconds)\r\nTesting integration/psync2\r\n[ok]: XRANGE fuzzing\r\n[ok]: XREVRANGE regression test for issue #5006\r\n[ok]: XREAD streamID edge (no-blocking)\r\n[ok]: XREAD streamID edge (blocking)\r\n[ok]: XADD streamID edge\r\n[ok]: Bad format: Server should have logged an error\r\n[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-entries is exceeded\r\n[ok]: Unfinished MULTI: Server should have logged an error\r\n[ok]: Server is able to generate a stack trace on selected systems\r\n[ok]: Short read: Server should have logged an error\r\n[ok]: Short read: Utility should confirm the AOF is not valid\r\n[ok]: Short read: Utility should be able to fix the AOF\r\n[ok]: Fixed AOF: Server should have been started\r\n[ok]: Fixed AOF: Keyspace should contain values that were parseable\r\n[ok]: PSYNC2: --- CYCLE 1 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[ok]: PSYNC2: Set #3 to replicate from #1\r\n[ok]: PSYNC2: Set #4 to replicate from #3\r\n[ok]: PSYNC2: Set #0 to replicate from #1\r\n[20/58 done]: integration/logging (1 seconds)\r\nTesting integration/psync2-reg\r\n[ok]: PSYNC2: Set #2 to replicate from #1\r\n[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-value is exceeded\r\n[ok]: Server started empty with empty RDB file\r\n[ok]: XADD with MAXLEN > xlen can propagate correctly\r\n[21/58 done]: integration/convert-zipmap-hash-on-load (2 seconds)\r\nTesting integration/psync2-pingoff\r\n[ok]: No write if min-slaves-max-lag is > of the slave lag\r\n[ok]: min-slaves-to-write is ignored by slaves\r\n[ok]: AOF+SPOP: Server should have been started\r\n[ok]: AOF+SPOP: Set should have 1 member\r\n[ok]: XADD with ~ MAXLEN can propagate correctly\r\n[ok]: SET - use EX/PX option, TTL should not be reseted after loadaof\r\n[ok]: SET command will remove expire\r\n[ok]: SET - use KEEPTTL option, TTL should not be removed\r\n[ok]: Test RDB stream encoding\r\n[ok]: AOF+SPOP: Server should have been started\r\n[ok]: AOF+SPOP: Set should have 1 member\r\n[ok]: Test replication with parallel clients writing in different DBs\r\n[ok]: XTRIM with ~ MAXLEN can propagate correctly\r\n[ok]: PSYNC2 #3899 regression: setup\r\n[ok]: Server should not start if RDB is corrupted\r\n[ok]: AOF+EXPIRE: Server should have been started\r\n[ok]: AOF+EXPIRE: List should be empty\r\n[ok]: XADD can CREATE an empty stream\r\n[ok]: XSETID can set a specific ID\r\n[ok]: XSETID cannot SETID with smaller ID\r\n[ok]: XSETID cannot SETID on non-existent key\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: Test FLUSHALL aborts bgsave\r\n[ok]: Redis should not try to convert DEL into EXPIREAT for EXPIRE -1\r\n[ok]: bgsave resets the change counter\r\n[ok]: PSYNC2 pingoff: setup\r\n[ok]: PSYNC2 pingoff: write and wait replication\r\n[ok]: SET - use KEEPTTL option, TTL should not be removed after loadaof\r\n[ok]: MIGRATE cached connections are released after some time\r\n[22/58 done]: unit/expire (16 seconds)\r\nTesting integration/redis-cli\r\n[ok]: Interactive CLI: INFO response should be printed raw\r\n[ok]: Interactive CLI: Status reply\r\n[ok]: Interactive CLI: Integer reply\r\n[ok]: Interactive CLI: Bulk reply\r\n[ok]: MIGRATE is able to migrate a key between two instances\r\n[ok]: Interactive CLI: Multi-bulk reply\r\n[ok]: Interactive CLI: Parsing quotes\r\n[ok]: Non-interactive TTY CLI: Status reply\r\n[ok]: Non-interactive TTY CLI: Integer reply\r\n[ok]: Non-interactive TTY CLI: Bulk reply\r\n[ok]: Non-interactive TTY CLI: Multi-bulk reply\r\n[ok]: Non-interactive TTY CLI: Read last argument from pipe\r\n[ok]: Non-interactive TTY CLI: Read last argument from file\r\n[ok]: Non-interactive non-TTY CLI: Status reply\r\n[ok]: Non-interactive non-TTY CLI: Integer reply\r\n[ok]: Non-interactive non-TTY CLI: Bulk reply\r\n[ok]: Non-interactive non-TTY CLI: Multi-bulk reply\r\n[ok]: Non-interactive non-TTY CLI: Read last argument from pipe\r\n[ok]: Empty stream can be rewrite into AOF correctly\r\n[ok]: Non-interactive non-TTY CLI: Read last argument from file\r\n[ok]: MASTER and SLAVE consistency with expire\r\n[ok]: MIGRATE is able to copy a key between two instances\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: With min-slaves-to-write (1,3): master should be writable\r\n[ok]: With min-slaves-to-write (2,3): master should not be writable\r\nWaiting for process 16173 to exit...\r\n[ok]: Stream can be rewrite into AOF correctly after XDEL lastid\r\n[ok]: Slave is able to detect timeout during handshake\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: MIGRATE will not overwrite existing keys, unless REPLACE is used\r\n[ok]: MIGRATE propagates TTL correctly\r\n[ok]: XGROUP HELP should not have unexpected options\r\n[23/58 done]: unit/type/stream (18 seconds)\r\nTesting unit/pubsub\r\n[ok]: Pub/Sub PING\r\n[ok]: PUBLISH/SUBSCRIBE basics\r\n[ok]: PUBLISH/SUBSCRIBE with two clients\r\n[ok]: PUBLISH/SUBSCRIBE after UNSUBSCRIBE without arguments\r\n[ok]: SUBSCRIBE to one channel more than once\r\n[ok]: UNSUBSCRIBE from non-subscribed channels\r\n[ok]: PUBLISH/PSUBSCRIBE basics\r\n[ok]: PUBLISH/PSUBSCRIBE with two clients\r\n[ok]: PUBLISH/PSUBSCRIBE after PUNSUBSCRIBE without arguments\r\n[ok]: PUNSUBSCRIBE from non-subscribed channels\r\n[ok]: NUMSUB returns numbers, not strings (#1561)\r\n[ok]: Mix SUBSCRIBE and PSUBSCRIBE\r\n[ok]: PUNSUBSCRIBE and UNSUBSCRIBE should always reply\r\n[ok]: Keyspace notifications: we receive keyspace notifications\r\n[ok]: Keyspace notifications: we receive keyevent notifications\r\n[ok]: Keyspace notifications: we can receive both kind of events\r\n[ok]: Keyspace notifications: we are able to mask events\r\n[ok]: Keyspace notifications: general events test\r\n[ok]: Keyspace notifications: list events test\r\n[ok]: Keyspace notifications: set events test\r\n[ok]: Keyspace notifications: zset events test\r\n[ok]: Keyspace notifications: hash events test\r\n[ok]: Keyspace notifications: expired events (triggered expire)\r\n[ok]: Keyspace notifications: expired events (background expire)\r\n[ok]: Keyspace notifications: evicted events\r\n[ok]: Keyspace notifications: test CONFIG GET/SET of event flags\r\n[24/58 done]: unit/pubsub (1 seconds)\r\nTesting unit/slowlog\r\n[ok]: SLOWLOG - check that it starts with an empty log\r\n[ok]: Set instance A as slave of B\r\n[ok]: SLOWLOG - only logs commands taking more time than specified\r\n[ok]: SLOWLOG - max entries is correctly handled\r\n[ok]: SLOWLOG - GET optional argument to limit output len works\r\n[ok]: SLOWLOG - RESET subcommand works\r\n[ok]: MASTER and SLAVE dataset should be identical after complex ops\r\n[ok]: SLOWLOG - logged entry sanity check\r\n[ok]: SLOWLOG - commands with too many arguments are trimmed\r\n[ok]: SLOWLOG - too long arguments are trimmed\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: SLOWLOG - EXEC is not logged, just executed commands\r\n[25/58 done]: integration/replication-2 (14 seconds)\r\nTesting unit/scripting\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 55798)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 2 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[ok]: PSYNC2: Set #0 to replicate from #1\r\n[ok]: PSYNC2: Set #2 to replicate from #0\r\n[ok]: PSYNC2: Set #4 to replicate from #0\r\n[ok]: PSYNC2: Set #3 to replicate from #2\r\n[ok]: EVAL - Does Lua interpreter replies to our requests?\r\n[ok]: EVAL - Lua integer -> Redis protocol type conversion\r\n[ok]: EVAL - Lua string -> Redis protocol type conversion\r\n[ok]: EVAL - Lua true boolean -> Redis protocol type conversion\r\n[ok]: EVAL - Lua false boolean -> Redis protocol type conversion\r\n[ok]: EVAL - Lua status code reply -> Redis protocol type conversion\r\n[ok]: EVAL - Lua error reply -> Redis protocol type conversion\r\n[ok]: EVAL - Lua table -> Redis protocol type conversion\r\n[ok]: EVAL - Are the KEYS and ARGV arrays populated correctly?\r\n[ok]: EVAL - is Lua able to call Redis API?\r\n[ok]: EVALSHA - Can we call a SHA1 if already defined?\r\n[ok]: EVALSHA - Can we call a SHA1 in uppercase?\r\n[ok]: EVALSHA - Do we get an error on invalid SHA1?\r\n[ok]: EVALSHA - Do we get an error on non defined SHA1?\r\n[ok]: EVAL - Redis integer -> Lua type conversion\r\n[ok]: EVAL - Redis bulk -> Lua type conversion\r\n[ok]: EVAL - Redis multi bulk -> Lua type conversion\r\n[ok]: EVAL - Redis status reply -> Lua type conversion\r\n[ok]: EVAL - Redis error reply -> Lua type conversion\r\n[ok]: EVAL - Redis nil bulk reply -> Lua type conversion\r\n[ok]: EVAL - Is the Lua client using the currently selected DB?\r\n[ok]: EVAL - SELECT inside Lua should not affect the caller\r\n[ok]: EVAL - Scripts can't run certain commands\r\n[ok]: EVAL - Scripts can't run XREAD and XREADGROUP with BLOCK option\r\n[ok]: EVAL - Scripts can't run certain commands\r\n[ok]: EVAL - No arguments to redis.call/pcall is considered an error\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - JSON numeric decoding\r\n[ok]: EVAL - JSON string decoding\r\n[ok]: EVAL - cmsgpack can pack double?\r\n[ok]: EVAL - cmsgpack can pack negative int64?\r\n[ok]: EVAL - cmsgpack can pack and unpack circular references?\r\n[ok]: EVAL - Numerical sanity check from bitop\r\n[ok]: EVAL - Verify minimal bitop functionality\r\n[ok]: EVAL - Able to parse trailing comments\r\n[ok]: SCRIPTING FLUSH - is able to clear the scripts cache?\r\n[ok]: SCRIPT EXISTS - can detect already defined scripts?\r\n[ok]: SCRIPT LOAD - is able to register scripts in the scripting cache\r\n[ok]: In the context of Lua the output of random commands gets ordered\r\n[ok]: SORT is normally not alpha re-ordered for the scripting engine\r\n[ok]: SORT BY <constant> output gets ordered for scripting\r\n[ok]: SORT BY <constant> with GET gets ordered for scripting\r\n[ok]: redis.sha1hex() implementation\r\n[ok]: Globals protection reading an undeclared global variable\r\n[ok]: Globals protection setting an undeclared global*\r\n[ok]: Test an example script DECR_IF_GT\r\n[ok]: Scripting engine resets PRNG at every script execution\r\n[ok]: Scripting engine PRNG can be seeded correctly\r\n[ok]: SLOWLOG - can clean older entires\r\n[ok]: EVAL does not leak in the Lua stack\r\n[ok]: Dumping an RDB\r\n[ok]: INCRBYFLOAT replication, should not remove expire\r\n[ok]: BRPOPLPUSH replication, when blocking against empty list\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: SLOWLOG - can be disabled\r\n[ok]: client freed during loading\r\n[26/58 done]: integration/rdb (10 seconds)\r\nTesting unit/maxmemory\r\n[ok]: With min-slaves-to-write: master not writable with lagged slave\r\n[ok]: PSYNC2 pingoff: pause replica and promote it\r\n[ok]: Without maxmemory small integers are shared\r\n[ok]: With maxmemory and non-LRU policy integers are still shared\r\n[ok]: With maxmemory and LRU policy integers are not shared\r\n[27/58 done]: unit/slowlog (1 seconds)\r\nTesting unit/introspection\r\n[ok]: EVAL processes writes from AOF in read-only slaves\r\n[ok]: CLIENT LIST\r\n[ok]: MONITOR can log executed commands\r\n[ok]: MONITOR can log commands issued by the scripting engine\r\n[ok]: CLIENT GETNAME should return NIL if name is not assigned\r\n[ok]: CLIENT LIST shows empty fields for unassigned names\r\n[ok]: CLIENT SETNAME does not accept spaces\r\n[ok]: CLIENT SETNAME can assign a name to this connection\r\n[ok]: CLIENT SETNAME can change the name of an existing connection\r\n[ok]: After CLIENT SETNAME, connection can still be closed\r\n[ok]: CONFIG sanity\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-random)\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: CONFIG REWRITE sanity\r\n[ok]: BRPOPLPUSH replication, list exists\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-lru)\r\n[28/58 done]: unit/introspection (1 seconds)\r\nTesting unit/introspection-2\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-lfu)\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-lru)\r\n[ok]: Connecting as a replica\r\n[ok]: Test replication partial resync: ok psync (diskless: no, disabled, reconnect: 1)\r\n[ok]: Slave is able to evict keys created in writable slaves\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-lfu)\r\n[ok]: BLPOP followed by role change, issue #2473\r\n[ok]: Make the old master a replica of the new one and check conditions\r\n[ok]: EVAL timeout from AOF\r\n[ok]: We can call scripts rewriting client->argv from Lua\r\n[ok]: Call Redis command with many args from Lua (issue #1764)\r\n[ok]: Number conversion precision test (issue #1118)\r\n[ok]: String containing number precision test (regression of issue #1118)\r\n[ok]: Verify negative arg count is error instead of crash (issue #1842)\r\n[ok]: Correct handling of reused argv (issue #1939)\r\n[ok]: Functions in the Redis namespace are able to report errors\r\n[ok]: Script with RESP3 map\r\n[ok]: Piping raw protocol\r\n[ok]: Second server should have role master at first\r\n[ok]: SLAVEOF should start with link status \"down\"\r\n[ok]: The role should immediately be changed to \"replica\"\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-random)\r\n[ok]: MIGRATE can correctly transfer large values\r\n[29/58 done]: integration/redis-cli (7 seconds)\r\nTesting unit/limits\r\n[ok]: MIGRATE can correctly transfer hashes\r\n[ok]: Sync should have transferred keys from master\r\n[ok]: The link status should be up\r\n[ok]: SET on the master should immediately propagate\r\n[ok]: FLUSHALL should replicate\r\n[ok]: ROLE in master reports master with a slave\r\n[ok]: ROLE in slave reports slave in connected state\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-ttl)\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: Timedout read-only scripts can be killed by SCRIPT KILL\r\n[ok]: AOF fsync always barrier issue\r\n[ok]: Timedout script link is still usable after Lua returns\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-random)\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[30/58 done]: integration/aof (14 seconds)\r\nTesting unit/obuf-limits\r\n[ok]: Timedout scripts that modified data can't be killed by SCRIPT KILL\r\n[ok]: SHUTDOWN NOSAVE can kill a timedout script anyway\r\n[ok]: TTL, TYPE and EXISTS do not alter the last access time of a key\r\n[ok]: Check if maxclients works refusing connections\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-lru)\r\n[ok]: Before the replica connects we issue two EVAL commands (scripts replication)\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: MIGRATE timeout actually works\r\n[31/58 done]: unit/limits (2 seconds)\r\nTesting unit/bitops\r\n[ok]: MIGRATE can migrate multiple keys at once\r\n[ok]: MIGRATE with multiple keys must have empty key arg\r\n[ok]: BITCOUNT returns 0 against non existing key\r\n[ok]: BITCOUNT returns 0 with out of range indexes\r\n[ok]: BITCOUNT returns 0 with negative indexes where start > end\r\n[ok]: BITCOUNT against test vector #1\r\n[ok]: BITCOUNT against test vector #2\r\n[ok]: BITCOUNT against test vector #3\r\n[ok]: BITCOUNT against test vector #4\r\n[ok]: BITCOUNT against test vector #5\r\n[ok]: BITCOUNT fuzzing without start/end\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-lru)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: MIGRATE with multiple keys migrate just existing ones\r\n[ok]: Connect a replica to the master instance (scripts replication)\r\n[ok]: Now use EVALSHA against the master, with both SHAs (scripts replication)\r\n[ok]: If EVALSHA was replicated as EVAL, 'x' should be '4' (scripts replication)\r\n[ok]: Replication of script multiple pushes to list with BLPOP (scripts replication)\r\n[ok]: EVALSHA replication when first call is readonly (scripts replication)\r\n[ok]: Lua scripts using SELECT are replicated correctly (scripts replication)\r\n[ok]: BITCOUNT fuzzing with start/end\r\n[ok]: BITCOUNT with start, end\r\n[ok]: BITCOUNT syntax error #1\r\n[ok]: BITCOUNT regression test for github issue #582\r\n[ok]: BITCOUNT misaligned prefix\r\n[ok]: BITCOUNT misaligned prefix + full words + remainder\r\n[ok]: BITOP NOT (empty string)\r\n[ok]: BITOP NOT (known string)\r\n[ok]: BITOP where dest and target are the same key\r\n[ok]: BITOP AND|OR|XOR don't change the string with single input key\r\n[ok]: BITOP missing key is considered a stream of zero\r\n[ok]: BITOP shorter keys are zero-padded to the key with max length\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: MIGRATE with multiple keys: stress command rewriting\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-random)\r\n[ok]: Before the replica connects we issue two EVAL commands (commands replication)\r\n[ok]: BITOP and fuzzing\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-ttl)\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 112624)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 3 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #2 as master\r\n[ok]: PSYNC2: Set #0 to replicate from #2\r\n[ok]: PSYNC2: Set #1 to replicate from #2\r\n[ok]: PSYNC2: Set #4 to replicate from #0\r\n[ok]: PSYNC2: Set #3 to replicate from #2\r\n[ok]: MIGRATE with multiple keys: delete just ack keys\r\n[ok]: MIGRATE AUTH: correct and wrong password cases\r\n[ok]: maxmemory - policy volatile-lru should only remove volatile keys.\r\n[ok]: Connect a replica to the master instance (commands replication)\r\n[ok]: Now use EVALSHA against the master, with both SHAs (commands replication)\r\n[ok]: If EVALSHA was replicated as EVAL, 'x' should be '4' (commands replication)\r\n[ok]: Replication of script multiple pushes to list with BLPOP (commands replication)\r\n[ok]: EVALSHA replication when first call is readonly (commands replication)\r\n[ok]: Lua scripts using SELECT are replicated correctly (commands replication)\r\n[ok]: BITOP or fuzzing\r\n[32/58 done]: unit/dump (27 seconds)\r\nTesting unit/bitfield\r\n[ok]: TOUCH alters the last access time of a key\r\n[ok]: TOUCH returns the number of existing keys specified\r\n[ok]: command stats for GEOADD\r\n[ok]: command stats for EXPIRE\r\n[ok]: command stats for BRPOP\r\n[ok]: command stats for MULTI\r\n[ok]: command stats for scripts\r\n[ok]: BITFIELD signed SET and GET basics\r\n[ok]: BITFIELD unsigned SET and GET basics\r\n[ok]: BITFIELD #<idx> form\r\n[ok]: BITFIELD basic INCRBY form\r\n[ok]: BITFIELD chaining of multiple commands\r\n[ok]: BITFIELD unsigned overflow wrap\r\n[ok]: BITFIELD unsigned overflow sat\r\n[ok]: BITFIELD signed overflow wrap\r\n[ok]: BITFIELD signed overflow sat\r\n[ok]: maxmemory - policy volatile-lfu should only remove volatile keys.\r\n[ok]: BITFIELD overflow detection fuzzing\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[33/58 done]: unit/introspection-2 (7 seconds)\r\nTesting unit/geo\r\n[ok]: GEOADD create\r\n[ok]: GEOADD update\r\n[ok]: GEOADD invalid coordinates\r\n[ok]: GEOADD multi add\r\n[ok]: Check geoset values\r\n[ok]: GEORADIUS simple (sorted)\r\n[ok]: GEORADIUS withdist (sorted)\r\n[ok]: GEORADIUS with COUNT\r\n[ok]: GEORADIUS with COUNT but missing integer argument\r\n[ok]: GEORADIUS with COUNT DESC\r\n[ok]: GEORADIUS HUGE, issue #2767\r\n[ok]: GEORADIUSBYMEMBER simple (sorted)\r\n[ok]: GEORADIUSBYMEMBER withdist (sorted)\r\n[ok]: GEOHASH is able to return geohash strings\r\n[ok]: GEOPOS simple\r\n[ok]: GEOPOS missing element\r\n[ok]: GEODIST simple & unit\r\n[ok]: GEODIST missing elements\r\n[ok]: GEORADIUS STORE option: syntax error\r\n[ok]: GEORANGE STORE option: incompatible options\r\n[ok]: GEORANGE STORE option: plain usage\r\n[ok]: GEORANGE STOREDIST option: plain usage\r\n[ok]: GEORANGE STOREDIST option: COUNT ASC and DESC\r\n[ok]: BITFIELD overflow wrap fuzzing\r\n[ok]: BITFIELD regression for #3221\r\n[ok]: BITFIELD regression for #3564\r\n[ok]: maxmemory - policy volatile-random should only remove volatile keys.\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: BITOP xor fuzzing\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: maxmemory - policy volatile-ttl should only remove volatile keys.\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: Connect a replica to the master instance\r\n[ok]: Redis.replicate_commands() must be issued before any write\r\n[ok]: Redis.replicate_commands() must be issued before any write (2)\r\n[ok]: Redis.set_repl() must be issued after replicate_commands()\r\n[ok]: Redis.set_repl() don't accept invalid values\r\n[ok]: Test selective replication of certain Redis commands from Lua\r\n[ok]: PRNG is seeded randomly for command replication\r\n[ok]: Using side effects is not a problem with command replication\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: BITFIELD: setup slave\r\n[ok]: BITFIELD: write on master, read on slave\r\n[ok]: BITFIELD_RO fails when write option is used\r\n[ok]: Replication: commands with many arguments (issue #1221)\r\n[ok]: Test replication with blocking lists and sorted sets operations\r\n[34/58 done]: unit/scripting (11 seconds)\r\nTesting unit/memefficiency\r\n[ok]: BITOP NOT fuzzing\r\n[ok]: BITOP with integer encoded source objects\r\n[ok]: BITOP with non string source key\r\n[ok]: BITOP with empty string after non empty string (issue #529)\r\n[ok]: BITPOS bit=0 with empty key returns 0\r\n[ok]: BITPOS bit=1 with empty key returns -1\r\n[ok]: BITPOS bit=0 with string less than 1 word works\r\n[ok]: BITPOS bit=1 with string less than 1 word works\r\n[ok]: BITPOS bit=0 starting at unaligned address\r\n[ok]: BITPOS bit=1 starting at unaligned address\r\n[ok]: BITPOS bit=0 unaligned+full word+reminder\r\n[ok]: BITPOS bit=1 unaligned+full word+reminder\r\n[ok]: BITPOS bit=1 returns -1 if string is all 0 bits\r\n[ok]: BITPOS bit=0 works with intervals\r\n[ok]: BITPOS bit=1 works with intervals\r\n[ok]: BITPOS bit=0 changes behavior if end is given\r\n[35/58 done]: unit/bitfield (5 seconds)\r\nTesting unit/hyperloglog\r\n[ok]: BITPOS bit=1 fuzzy testing using SETBIT\r\n[ok]: BITPOS bit=0 fuzzy testing using SETBIT\r\n[ok]: Replication of SPOP command -- alsoPropagate() API\r\n[36/58 done]: integration/block-repl (27 seconds)\r\nTesting unit/lazyfree\r\n[ok]: test various edge cases of repl topology changes with missing pings at the end\r\n[ok]: HyperLogLog self test passes\r\n[ok]: PFADD without arguments creates an HLL value\r\n[ok]: Approximated cardinality after creation is zero\r\n[ok]: PFADD returns 1 when at least 1 reg was modified\r\n[ok]: PFADD returns 0 when no reg was modified\r\n[ok]: PFADD works with empty string (regression)\r\n[ok]: PFCOUNT returns approximated cardinality of set\r\n[37/58 done]: unit/bitops (8 seconds)\r\nTesting unit/wait\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 144832)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 4 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #4 as master\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #2 to replicate from #4\r\n[ok]: PSYNC2: Set #1 to replicate from #4\r\n[ok]: PSYNC2: Set #0 to replicate from #3\r\n[ok]: Memory efficiency with values in range 32\r\n[ok]: UNLINK can reclaim memory in background\r\n[ok]: FLUSHDB ASYNC can reclaim memory in background\r\n[ok]: Memory efficiency with values in range 64\r\n[ok]: HyperLogLogs are promote from sparse to dense\r\n[38/58 done]: integration/replication-4 (26 seconds)\r\nTesting unit/pendingquerybuf\r\n[39/58 done]: unit/lazyfree (1 seconds)\r\nTesting unit/tls\r\n[ok]: Memory efficiency with values in range 128\r\n[ok]: Test replication partial resync: no backlog (diskless: no, disabled, reconnect: 1)\r\n[40/58 done]: unit/tls (1 seconds)\r\nTesting unit/tracking\r\n[ok]: HyperLogLog sparse encoding stress test\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Additional at tail\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Broken magic\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Invalid encoding\r\n[ok]: Corrupted dense HyperLogLogs are detected: Wrong length\r\n[ok]: Setup slave\r\n[ok]: WAIT should acknowledge 1 additional copy of the data\r\n[ok]: Memory efficiency with values in range 1024\r\n[ok]: Clients are able to enable tracking and redirect it\r\n[ok]: The other connection is able to get invalidations\r\n[ok]: The client is now able to disable tracking\r\n[ok]: Clients can enable the BCAST mode with the empty prefix\r\n[ok]: The connection gets invalidation messages about all the keys\r\n[ok]: Clients can enable the BCAST mode with prefixes\r\n[ok]: Adding prefixes to BCAST mode works\r\n[ok]: Tracking NOLOOP mode in standard mode works\r\n[ok]: Tracking NOLOOP mode in BCAST mode works\r\n[ok]: PSYNC2 #3899 regression: verify consistency\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[41/58 done]: integration/psync2-reg (22 seconds)\r\nTesting unit/oom-score-adj\r\n[ok]: CONFIG SET oom-score-adj works as expected\r\n[ok]: WAIT should not acknowledge 2 additional copies of the data\r\n[ok]: Tracking gets notification of expired keys\r\n[ok]: Tracking gets notification on tracking table key eviction\r\n[42/58 done]: unit/tracking (2 seconds)\r\nTesting unit/shutdown\r\n[ok]: Memory efficiency with values in range 16384\r\n[ok]: Temp rdb will be deleted if we use bg_unlink when shutdown\r\n[ok]: Temp rdb will be deleted in signal handle\r\n[43/58 done]: unit/shutdown (0 seconds)\r\n[44/58 done]: unit/memefficiency (5 seconds)\r\n[45/58 done]: unit/oom-score-adj (1 seconds)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: pending querybuf: check size of pending_querybuf after set a big value\r\n[46/58 done]: unit/pendingquerybuf (5 seconds)\r\n[ok]: WAIT should not acknowledge 1 additional copy if slave is blocked\r\n[ok]: Chained replicas disconnect when replica re-connect with the same master\r\n[ok]: MASTER and SLAVE consistency with EVALSHA replication\r\n[47/58 done]: unit/wait (7 seconds)\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 193602)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 5 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #4 as master\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #2 to replicate from #3\r\n[ok]: PSYNC2: Set #1 to replicate from #4\r\n[ok]: PSYNC2: Set #0 to replicate from #2\r\n[48/58 done]: integration/psync2-pingoff (27 seconds)\r\n[ok]: AOF rewrite during write load: RDB preamble=yes\r\n[ok]: slave buffer are counted correctly\r\n[ok]: SLAVE can reload \"lua\" AUX RDB fields of duplicated scripts\r\n[49/58 done]: integration/replication-3 (36 seconds)\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: GEOADD + GEORANGE randomized test\r\n[50/58 done]: unit/geo (18 seconds)\r\n[ok]: Test replication partial resync: ok after delay (diskless: no, disabled, reconnect: 1)\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 244773)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 6 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #3 as master\r\n[ok]: PSYNC2: Set #1 to replicate from #3\r\n[ok]: PSYNC2: Set #4 to replicate from #1\r\n[ok]: PSYNC2: Set #0 to replicate from #3\r\n[ok]: PSYNC2: Set #2 to replicate from #0\r\n[ok]: replica buffer don't induce eviction\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: client tracking don't cause eviction feedback loop\r\n[51/58 done]: unit/maxmemory (33 seconds)\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 315943)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=no, replica diskless=disabled\r\n[ok]: PSYNC2: Bring the master back again for next test\r\nWaiting for process 19663 to exit...\r\n[ok]: PSYNC2: Partial resync after restart using RDB aux fields\r\nWaiting for process 19607 to exit...\r\n[ok]: PSYNC2: Replica RDB restart with EVALSHA in backlog issue #4483\r\n[ok]: Client output buffer hard limit is enforced\r\nWaiting for process 19567 to exit...\r\n[52/58 done]: integration/psync2 (48 seconds)\r\n[ok]: Test replication partial resync: backlog expired (diskless: no, disabled, reconnect: 1)\r\nWaiting for process 19527 to exit...\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: no, swapdb, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: ok psync (diskless: no, swapdb, reconnect: 1)\r\n[ok]: Client output buffer soft limit is not enforced if time is not overreached\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Fuzzing dense/sparse encoding: Redis should always detect errors\r\n[ok]: PFADD, PFCOUNT, PFMERGE type checking works\r\n[ok]: PFMERGE results on the cardinality of union of sets\r\n[ok]: Stress tester for #3343-alike bugs\r\n[ok]: PFCOUNT multiple-keys merge returns cardinality of union #1\r\n[ok]: PFCOUNT multiple-keys merge returns cardinality of union #2\r\n[ok]: PFDEBUG GETREG returns the HyperLogLog raw registers\r\n[ok]: PFADD / PFCOUNT cache invalidation works\r\n[53/58 done]: unit/hyperloglog (49 seconds)\r\n[ok]: Test replication partial resync: no backlog (diskless: no, swapdb, reconnect: 1)\r\n[ok]: Client output buffer soft limit is enforced if time is overreached\r\n[ok]: No response for single command if client output buffer hard limit is enforced\r\n[ok]: ziplist implementation: value encoding and backlink\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: No response for multi commands in pipeline if client output buffer limit is enforced\r\n[ok]: Execute transactions completely even if client output buffer limit is enforced\r\n[54/58 done]: unit/obuf-limits (63 seconds)\r\n[ok]: ziplist implementation: encoding stress testing\r\n[55/58 done]: unit/type/list-3 (91 seconds)\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=no, replica diskless=swapdb\r\nWaiting for process 25891 to exit...\r\nWaiting for process 25845 to exit...\r\n[ok]: Test replication partial resync: ok after delay (diskless: no, swapdb, reconnect: 1)\r\nWaiting for process 25805 to exit...\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\nWaiting for process 25763 to exit...\r\n[ok]: Test replication partial resync: backlog expired (diskless: no, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: yes, disabled, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: AOF rewrite during write load: RDB preamble=no\r\nWaiting for process 11187 to exit...\r\nWaiting for process 11187 to exit...\r\nWaiting for process 11187 to exit...\r\nWaiting for process 11187 to exit...\r\nWaiting for process 11187 to exit...\r\n[ok]: Test replication partial resync: ok psync (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Turning off AOF kills the background writing child if any\r\n[ok]: AOF rewrite of list with quicklist encoding, string data\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: AOF rewrite of list with quicklist encoding, int data\r\n[ok]: AOF rewrite of set with intset encoding, string data\r\n[ok]: AOF rewrite of set with hashtable encoding, string data\r\n[ok]: AOF rewrite of set with intset encoding, int data\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=yes, replica diskless=disabled\r\nWaiting for process 28545 to exit...\r\n[ok]: AOF rewrite of set with hashtable encoding, int data\r\n[ok]: AOF rewrite of hash with ziplist encoding, string data\r\nWaiting for process 28525 to exit...\r\n[ok]: AOF rewrite of hash with hashtable encoding, string data\r\nWaiting for process 28525 to exit...\r\n[ok]: AOF rewrite of hash with ziplist encoding, int data\r\nWaiting for process 28505 to exit...\r\n[ok]: Test replication partial resync: no backlog (diskless: yes, disabled, reconnect: 1)\r\n[ok]: AOF rewrite of hash with hashtable encoding, int data\r\nWaiting for process 28485 to exit...\r\n[ok]: AOF rewrite of zset with ziplist encoding, string data\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: AOF rewrite of zset with skiplist encoding, string data\r\n[ok]: AOF rewrite of zset with ziplist encoding, int data\r\n[ok]: AOF rewrite of zset with skiplist encoding, int data\r\n[ok]: BGREWRITEAOF is delayed if BGSAVE is in progress\r\n[ok]: BGREWRITEAOF is refused if already in progress\r\n[56/58 done]: unit/aofrw (149 seconds)\r\n[ok]: Test replication partial resync: ok after delay (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: backlog expired (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=yes, replica diskless=swapdb\r\nWaiting for process 32298 to exit...\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: yes, swapdb, reconnect: 0)\r\nWaiting for process 32278 to exit...\r\nWaiting for process 32258 to exit...\r\nWaiting for process 32238 to exit...\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: ok psync (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no backlog (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Master stream is correctly processed while the replica has a script in -BUSY state\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: slave fails full sync and diskless load swapdb recovers it\r\nWaiting for process 2984 to exit...\r\n[ok]: Test replication partial resync: ok after delay (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: diskless loading short read\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: diskless no replicas drop during rdb pipe\r\n[ok]: Test replication partial resync: backlog expired (diskless: yes, swapdb, reconnect: 1)\r\nWaiting for process 5423 to exit...\r\n[57/58 done]: integration/replication-psync (232 seconds)\r\n[ok]: diskless slow replicas drop during rdb pipe\r\n[ok]: diskless fast replicas drop during rdb pipe\r\n[ok]: diskless all replicas drop during rdb pipe\r\nWaiting for process 5403 to exit...\r\nWaiting for process 5403 to exit...\r\nWaiting for process 5403 to exit...\r\n[ok]: replicaof right after disconnection\r\n[58/58 done]: integration/replication (259 seconds)\r\nTesting solo test\r\n[ok]: Active defrag\r\n[ok]: Active defrag big keys\r\n[ok]: Active defrag big list\r\n[ok]: Active defrag edge case\r\n[58/58 done]: defrag (72 seconds)\r\n\r\n                   The End\r\n\r\nExecution time of different units:\r\n  0 seconds - unit/printver\r\n  0 seconds - unit/type/incr\r\n  1 seconds - unit/auth\r\n  1 seconds - unit/protocol\r\n  1 seconds - unit/keyspace\r\n  1 seconds - unit/quit\r\n  3 seconds - unit/type/hash\r\n  1 seconds - unit/acl\r\n  5 seconds - unit/scan\r\n  6 seconds - unit/type/set\r\n  6 seconds - unit/sort\r\n  6 seconds - unit/multi\r\n  7 seconds - unit/type/stream-cgroups\r\n  10 seconds - unit/type/string\r\n  10 seconds - unit/type/zset\r\n  10 seconds - unit/type/list-2\r\n  10 seconds - unit/other\r\n  8 seconds - unit/latency-monitor\r\n  12 seconds - unit/type/list\r\n  1 seconds - integration/logging\r\n  2 seconds - integration/convert-zipmap-hash-on-load\r\n  16 seconds - unit/expire\r\n  18 seconds - unit/type/stream\r\n  1 seconds - unit/pubsub\r\n  14 seconds - integration/replication-2\r\n  10 seconds - integration/rdb\r\n  1 seconds - unit/slowlog\r\n  1 seconds - unit/introspection\r\n  7 seconds - integration/redis-cli\r\n  14 seconds - integration/aof\r\n  2 seconds - unit/limits\r\n  27 seconds - unit/dump\r\n  7 seconds - unit/introspection-2\r\n  11 seconds - unit/scripting\r\n  5 seconds - unit/bitfield\r\n  27 seconds - integration/block-repl\r\n  8 seconds - unit/bitops\r\n  26 seconds - integration/replication-4\r\n  1 seconds - unit/lazyfree\r\n  1 seconds - unit/tls\r\n  22 seconds - integration/psync2-reg\r\n  2 seconds - unit/tracking\r\n  0 seconds - unit/shutdown\r\n  5 seconds - unit/memefficiency\r\n  1 seconds - unit/oom-score-adj\r\n  5 seconds - unit/pendingquerybuf\r\n  7 seconds - unit/wait\r\n  27 seconds - integration/psync2-pingoff\r\n  36 seconds - integration/replication-3\r\n  18 seconds - unit/geo\r\n  33 seconds - unit/maxmemory\r\n  48 seconds - integration/psync2\r\n  49 seconds - unit/hyperloglog\r\n  63 seconds - unit/obuf-limits\r\n  91 seconds - unit/type/list-3\r\n  149 seconds - unit/aofrw\r\n  232 seconds - integration/replication-psync\r\n  259 seconds - integration/replication\r\n  72 seconds - defrag\r\n\r\n!!! WARNING The following tests failed:\r\n\r\n*** [err]: ZSCAN with encoding skiplist in tests/unit/scan.tcl\r\nExpected key:0 eq \"key:nan\" (context: type eval line 31 cmd {assert {$k eq \"key:$v\"}} proc ::test)\r\nCleanup: may take some time... OK\r\nmake[1]: *** [test] Error 1\r\nmake[1]: Leaving directory `/usr/local/tools/redis/redis-6.0.10/src'\r\nmake: *** [test] Error 2\r\n","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/8457/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/8457/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"actor":{"login":"stefanschindler","id":786048,"node_id":"MDQ6VXNlcjc4NjA0OA==","avatar_url":"https://avatars.githubusercontent.com/u/786048?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanschindler","html_url":"https://github.com/stefanschindler","followers_url":"https://api.github.com/users/stefanschindler/followers","following_url":"https://api.github.com/users/stefanschindler/following{/other_user}","gists_url":"https://api.github.com/users/stefanschindler/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanschindler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanschindler/subscriptions","organizations_url":"https://api.github.com/users/stefanschindler/orgs","repos_url":"https://api.github.com/users/stefanschindler/repos","events_url":"https://api.github.com/users/stefanschindler/events{/privacy}","received_events_url":"https://api.github.com/users/stefanschindler/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-20T12:26:00Z","updated_at":"2021-04-20T12:26:00Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/8828","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/8828/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/8828/comments","events_url":"https://api.github.com/repos/redis/redis/issues/8828/events","html_url":"https://github.com/redis/redis/issues/8828","id":862763567,"node_id":"MDU6SXNzdWU4NjI3NjM1Njc=","number":8828,"title":"[BUG] `make test` fails on Ubuntu 18.04 (tests/unit/networking.tcl)","user":{"login":"stefanschindler","id":786048,"node_id":"MDQ6VXNlcjc4NjA0OA==","avatar_url":"https://avatars.githubusercontent.com/u/786048?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanschindler","html_url":"https://github.com/stefanschindler","followers_url":"https://api.github.com/users/stefanschindler/followers","following_url":"https://api.github.com/users/stefanschindler/following{/other_user}","gists_url":"https://api.github.com/users/stefanschindler/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanschindler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanschindler/subscriptions","organizations_url":"https://api.github.com/users/stefanschindler/orgs","repos_url":"https://api.github.com/users/stefanschindler/repos","events_url":"https://api.github.com/users/stefanschindler/events{/privacy}","received_events_url":"https://api.github.com/users/stefanschindler/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":13,"created_at":"2021-04-20T12:25:59Z","updated_at":"2021-04-27T15:09:49Z","closed_at":"2021-04-27T15:09:49Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"**Describe the bug**\r\n\r\n`make test` fails on Ubuntu 18.04 with error:\r\n\r\n```\r\n*** [err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\n```\r\n\r\nI tried to track down the issue and running just the failed test, but the output didn't help me either.\r\n\r\n**To reproduce**\r\n\r\n```\r\nwget http://download.redis.io/redis-stable.tar.gz\r\ntar xvzf redis-stable.tar.gz\r\ncd redis-stable\r\nmake test\r\n\r\n```\r\n\r\n**Expected behavior**\r\n\r\n`make test` does not fail\r\n\r\n**Additional information**\r\n\r\nUsing Ubuntu 18.04. I have some servers where it works, but one server always fails. All servers are set up similarly.\r\n\r\n<details>\r\n<summary>Whole Log Output:</summary>\r\n\r\n```\r\nCleanup: may take some time... OK\r\nStarting test server at port 21079\r\n[ready]: 6295\r\nTesting unit/printver\r\n[ready]: 6294\r\nTesting unit/dump\r\n[ready]: 6297\r\nTesting unit/auth\r\n[ready]: 6296\r\nTesting unit/protocol\r\n[ready]: 6298\r\nTesting unit/keyspace\r\n[ready]: 6299\r\nTesting unit/scan\r\n[ready]: 6301\r\nTesting unit/info\r\n[ready]: 6300\r\nTesting unit/type/string\r\n[ready]: 6302\r\nTesting unit/type/incr\r\n[ready]: 6303\r\nTesting unit/type/list\r\n[ready]: 6305\r\nTesting unit/type/list-2\r\n[ready]: 6307\r\nTesting unit/type/list-3\r\n[ready]: 6304\r\nTesting unit/type/set\r\n[ready]: 6309\r\nTesting unit/type/zset\r\n[ready]: 6306\r\nTesting unit/type/hash\r\n[ready]: 6308\r\nTesting unit/type/stream\r\n[ok]: AUTH fails if there is no password configured server side\r\n[ok]: Explicit regression for a list bug\r\n[ok]: LPOS basic usage\r\n[ok]: LPOS RANK (positive and negative rank) option\r\n[ok]: LPOS COUNT option\r\n[ok]: LPOS COUNT + RANK option\r\n[ok]: LPOS non existing key\r\n[ok]: LPOS no match\r\n[ok]: LPOS MAXLEN\r\n[ok]: LPOS when RANK is greater than matches\r\n[ok]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - ziplist\r\n[ok]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - regular list\r\n[ok]: R/LPOP against empty list\r\n[ok]: R/LPOP with the optional count argument\r\n[ok]: Variadic RPUSH/LPUSH\r\n[ok]: DEL a list\r\n[ok]: BLPOP, BRPOP: single existing list - linkedlist\r\n[ok]: BLPOP, BRPOP: multiple existing lists - linkedlist\r\n[ok]: BLPOP, BRPOP: second list has an entry - linkedlist\r\n[ok]: BRPOPLPUSH - linkedlist\r\n[ok]: BLMOVE left left - linkedlist\r\n[ok]: BLMOVE left right - linkedlist\r\n[ok]: BLMOVE right left - linkedlist\r\n[ok]: BLMOVE right right - linkedlist\r\n[ok]: BLPOP, BRPOP: single existing list - ziplist\r\n[ok]: BLPOP, BRPOP: multiple existing lists - ziplist\r\n[ok]: BLPOP, BRPOP: second list has an entry - ziplist\r\n[ok]: BRPOPLPUSH - ziplist\r\n[ok]: BLMOVE left left - ziplist\r\n[ok]: BLMOVE left right - ziplist\r\n[ok]: BLMOVE right left - ziplist\r\n[ok]: BLMOVE right right - ziplist\r\n[ok]: BLPOP, LPUSH + DEL should not awake blocked client\r\n[ok]: DUMP / RESTORE are able to serialize / unserialize a simple key\r\n[ok]: RESTORE can set an arbitrary expire to the materialized key\r\n[ok]: RESTORE can set an expire that overflows a 32 bit integer\r\n[ok]: RESTORE can set an absolute expire\r\n[ok]: RESTORE with ABSTTL in the past\r\n[ok]: RESTORE can set LRU\r\n[ok]: RESTORE can set LFU\r\n[ok]: RESTORE returns an error of the key already exists\r\n[ok]: RESTORE can overwrite an existing key with REPLACE\r\n[ok]: RESTORE can detect a syntax error for unrecongized options\r\n[ok]: DUMP of non existing key returns nil\r\n[ok]: Regression for quicklist #3343 bug\r\n[ok]: HSET/HLEN - Small hash creation\r\n[ok]: DEL against a single item\r\n[ok]: Check encoding - ziplist\r\n[ok]: Vararg DEL\r\n[ok]: Is the small hash encoded with a ziplist?\r\n[ok]: ZSET basic ZADD and score update - ziplist\r\n[ok]: KEYS with pattern\r\n[ok]: KEYS to get all keys\r\n[ok]: ZSET element can't be set to NaN with ZADD - ziplist\r\n[ok]: DBSIZE\r\n[ok]: ZSET element can't be set to NaN with ZINCRBY - ziplist\r\n[ok]: ZADD with options syntax error with incomplete pair - ziplist\r\n[ok]: ZADD XX option without key - ziplist\r\n[ok]: DEL all keys\r\n[ok]: ZADD XX existing key - ziplist\r\n[ok]: ZADD XX returns the number of elements actually added - ziplist\r\n[ok]: ZADD XX updates existing elements score - ziplist\r\n[ok]: ZADD GT updates existing elements when new scores are greater - ziplist\r\n[ok]: SET and GET an item\r\n[ok]: ZADD LT updates existing elements when new scores are lower - ziplist\r\n[ok]: SET and GET an empty item\r\n[ok]: ZADD GT XX updates existing elements when new scores are greater and skips new elements - ziplist\r\n[ok]: ZADD LT XX updates existing elements when new scores are lower and skips new elements - ziplist\r\n[ok]: ZADD XX and NX are not compatible - ziplist\r\nTesting Redis version 6.2.2 (00000000)\r\n[ok]: ZADD NX with non existing key - ziplist\r\n[ok]: ZADD NX only add new elements without updating old ones - ziplist\r\n[ok]: ZADD GT and NX are not compatible - ziplist\r\n[ok]: ZADD LT and NX are not compatible - ziplist\r\n[ok]: ZADD LT and GT are not compatible - ziplist\r\n[ok]: HRANDFIELD - ziplist\r\n[ok]: ZADD INCR LT/GT replies with nill if score not updated - ziplist\r\n[ok]: ZADD INCR LT/GT with inf - ziplist\r\n[ok]: ZADD INCR works like ZINCRBY - ziplist\r\n[ok]: ZADD INCR works with a single score-elemenet pair - ziplist\r\n[ok]: ZADD CH option changes return value to all changed elements - ziplist\r\n[ok]: ZINCRBY calls leading to NaN result in error - ziplist\r\n[ok]: ZADD - Variadic version base case - $encoding\r\n[ok]: ZADD - Return value is the number of actually added items - $encoding\r\n[ok]: ZADD - Variadic version does not add nothing on single parsing err - $encoding\r\n[ok]: SADD, SCARD, SISMEMBER, SMISMEMBER, SMEMBERS basics - regular set\r\n[ok]: ZADD - Variadic version will raise error on missing arg - $encoding\r\n[ok]: AUTH fails when a wrong password is given\r\n[ok]: ZINCRBY does not work variadic even if shares ZADD implementation - $encoding\r\n[ok]: ZCARD basics - ziplist\r\n[ok]: INCR against non existing key\r\n[ok]: Arbitrary command gives an error when AUTH is required\r\n[ok]: AUTH succeeds when the right password is given\r\n[ok]: INCR against key created by incr itself\r\n[ok]: Once AUTH succeeded we can actually send commands to the server\r\n[ok]: ZREM removes key after last element is removed - ziplist\r\n[ok]: INCR against key originally set with SET\r\n[ok]: INCR over 32bit value\r\n[ok]: ZREM variadic version - ziplist\r\n[ok]: ZREM variadic version -- remove elements after key deletion - ziplist\r\n[ok]: INCRBY over 32bit value with over 32bit increment\r\n[ok]: INCR fails against key with spaces (left)\r\n[ok]: SCAN basic\r\n[ok]: INCR fails against key with spaces (right)\r\n[ok]: INCR fails against key with spaces (both)\r\n[ok]: ZRANGE basics - ziplist\r\n[ok]: HRANDFIELD - hashtable\r\n[ok]: INCR fails against a key holding a list\r\n[ok]: DECRBY over 32bit value with over 32bit increment, negative res\r\n[ok]: SADD, SCARD, SISMEMBER, SMISMEMBER, SMEMBERS basics - intset\r\n[ok]: HRANDFIELD with RESP3\r\n[ok]: SMISMEMBER against non set\r\n[ok]: INCR uses shared objects in the 0-9999 range\r\n[ok]: ZREVRANGE basics - ziplist\r\n[ok]: HRANDFIELD count of 0 is handled correctly\r\n[ok]: SMISMEMBER non existing key\r\n[ok]: INCR can modify objects in-place\r\n[ok]: HRANDFIELD with <count> against non existing key\r\n[ok]: ZRANK/ZREVRANK basics - ziplist\r\n[ok]: ZRANK - after deletion - ziplist\r\n[ok]: INCRBYFLOAT against non existing key\r\n[ok]: ZINCRBY - can create a new sorted set - ziplist\r\n[ok]: INCRBYFLOAT against key originally set with SET\r\n[ok]: INCRBYFLOAT over 32bit value\r\n[ok]: SMISMEMBER requires one or more members\r\n[ok]: ZINCRBY - increment and decrement - ziplist\r\n[ok]: INCRBYFLOAT over 32bit value with over 32bit increment\r\n[ok]: SADD against non set\r\n[ok]: ZINCRBY return value - ziplist\r\n[ok]: INCRBYFLOAT fails against key with spaces (left)\r\n[ok]: INCRBYFLOAT fails against key with spaces (right)\r\n[ok]: INCRBYFLOAT fails against key with spaces (both)\r\n[ok]: INCRBYFLOAT fails against a key holding a list\r\n[ok]: SADD a non-integer against an intset\r\n[ok]: INCRBYFLOAT does not allow NaN or Infinity\r\n[ok]: SADD an integer larger than 64 bits\r\n[ok]: INCRBYFLOAT decrement\r\n[ok]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics - ziplist\r\n[ok]: string to double with null terminator\r\n[ok]: ZRANGEBYSCORE with WITHSCORES - ziplist\r\n[ok]: No negative zero\r\n[ok]: ZRANGEBYSCORE with LIMIT - ziplist\r\n[ok]: ZRANGEBYSCORE with LIMIT and WITHSCORES - ziplist\r\n[ok]: ZRANGEBYSCORE with non-value min or max - ziplist\r\n[ok]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics - ziplist\r\n[ok]: BLPOP, LPUSH + DEL + SET should not awake blocked client\r\n[ok]: ZLEXCOUNT advanced - ziplist\r\n[ok]: BLPOP with same key multiple times should work (issue #801)\r\n[ok]: ZRANGEBYSLEX with LIMIT - ziplist\r\n[ok]: MULTI/EXEC is isolated from the point of view of BLPOP\r\n[ok]: ZRANGEBYLEX with invalid lex range specifiers - ziplist\r\n[ok]: errorstats: failed call authentication error\r\n[ok]: BLPOP with variadic LPUSH\r\n[ok]: BRPOPLPUSH with zero timeout should block indefinitely\r\n[ok]: errorstats: failed call within MULTI/EXEC\r\n[ok]: BLMOVE left left with zero timeout should block indefinitely\r\n[ok]: BLMOVE left right with zero timeout should block indefinitely\r\n[ok]: errorstats: failed call within LUA\r\n[ok]: BLMOVE right left with zero timeout should block indefinitely\r\n[ok]: BLMOVE right right with zero timeout should block indefinitely\r\n[ok]: errorstats: failed call NOSCRIPT error\r\n[ok]: ZREMRANGEBYSCORE basics - ziplist\r\n[ok]: ZREMRANGEBYSCORE with non-value min or max - ziplist\r\n[ok]: BLMOVE (left, left) with a client BLPOPing the target list\r\n[ok]: errorstats: failed call NOGROUP error\r\n[ok]: BLMOVE (left, right) with a client BLPOPing the target list\r\n[ok]: BLMOVE (right, left) with a client BLPOPing the target list\r\n[ok]: XADD can add entries into a stream that XRANGE can fetch\r\n[ok]: ZREMRANGEBYRANK basics - ziplist\r\n[ok]: XADD IDs are incremental\r\n[ok]: ZUNIONSTORE against non-existing key doesn't set destination - ziplist\r\n[ok]: BLMOVE (right, right) with a client BLPOPing the target list\r\n[ok]: XADD IDs are incremental when ms is the same as well\r\n[ok]: ZUNION/ZINTER/ZDIFF against non-existing key - ziplist\r\n[ok]: errorstats: rejected call unknown command\r\n[ok]: XADD IDs correctly report an error when overflowing\r\n[ok]: BRPOPLPUSH with wrong source type\r\n[ok]: ZUNIONSTORE with empty set - ziplist\r\n[ok]: ZUNION/ZINTER/ZDIFF with empty set - ziplist\r\n[ok]: ZUNIONSTORE basics - ziplist\r\n[ok]: BRPOPLPUSH with wrong destination type\r\n[ok]: errorstats: rejected call within MULTI/EXEC\r\n[ok]: BRPOPLPUSH maintains order of elements after failure\r\n[ok]: ZUNION/ZINTER/ZDIFF with integer members - ziplist\r\n[ok]: ZUNIONSTORE with weights - ziplist\r\n[ok]: SCAN COUNT\r\n[ok]: ZUNION with weights - ziplist\r\n[ok]: errorstats: rejected call due to wrong arity\r\n[ok]: Handle an empty query\r\n[ok]: BRPOPLPUSH with multiple blocked clients\r\n[ok]: ZUNIONSTORE with a regular set and weights - ziplist\r\n[ok]: ZUNIONSTORE with AGGREGATE MIN - ziplist\r\n[ok]: ZUNION/ZINTER with AGGREGATE MIN - ziplist\r\n[ok]: ZUNIONSTORE with AGGREGATE MAX - ziplist\r\n[ok]: errorstats: rejected call by OOM error\r\n[ok]: ZUNION/ZINTER with AGGREGATE MAX - ziplist\r\n[ok]: ZINTERSTORE basics - ziplist\r\n[ok]: ZINTER basics - ziplist\r\n[ok]: Linked LMOVEs\r\n[ok]: ZINTER RESP3 - ziplist\r\n[ok]: ZINTERSTORE with weights - ziplist\r\n[ok]: ZINTER with weights - ziplist\r\n[ok]: errorstats: rejected call by authorization error\r\n[ok]: ZINTERSTORE with a regular set and weights - ziplist\r\n[ok]: ZINTERSTORE with AGGREGATE MIN - ziplist\r\n[ok]: ZINTERSTORE with AGGREGATE MAX - ziplist\r\n[ok]: ZUNIONSTORE with +inf/-inf scores - ziplist\r\n[ok]: ZUNIONSTORE with NaN weights - ziplist\r\n[ok]: ZINTERSTORE with +inf/-inf scores - ziplist\r\n[ok]: ZINTERSTORE with NaN weights - ziplist\r\n[ok]: ZDIFFSTORE basics - ziplist\r\n[ok]: ZDIFF basics - ziplist\r\n[ok]: ZDIFFSTORE with a regular set - ziplist\r\n[ok]: ZDIFF subtracting set from itself - ziplist\r\n[ok]: ZDIFF algorithm 1 - ziplist\r\n[ok]: ZDIFF algorithm 2 - ziplist\r\n[ok]: Circular BRPOPLPUSH\r\n[ok]: Self-referential BRPOPLPUSH\r\n[ok]: SCAN MATCH\r\n[ok]: BRPOPLPUSH inside a transaction\r\n[ok]: PUSH resulting from BRPOPLPUSH affect WATCH\r\n[ok]: BRPOPLPUSH does not affect WATCH while still blocked\r\n[ok]: SADD overflows the maximum allowed integers in an intset\r\n[ok]: Variadic SADD\r\n[ok]: SCAN TYPE\r\n[ok]: SSCAN with encoding intset\r\n[ok]: Negative multibulk length\r\n[ok]: Out of range multibulk length\r\n[ok]: Wrong multibulk payload header\r\n[ok]: Negative multibulk payload length\r\n[ok]: Out of range multibulk payload length\r\n[ok]: Non-number multibulk payload length\r\n[ok]: Multi bulk request not followed by bulk arguments\r\n[ok]: Generic wrong number of args\r\n[ok]: Unbalanced number of quotes\r\n[ok]: Very big payload in GET/SET\r\n[ok]: SSCAN with encoding hashtable\r\n[ok]: HSCAN with encoding ziplist\r\n[ok]: XADD with MAXLEN option\r\n[1/64 done]: unit/printver (1 seconds)\r\nTesting unit/type/stream-cgroups\r\n[2/64 done]: unit/type/incr (1 seconds)\r\nTesting unit/sort\r\n[ok]: Set encoding after DEBUG RELOAD\r\n[ok]: Protocol desync regression test #1\r\n[ok]: SREM basics - regular set\r\n[ok]: SREM basics - intset\r\n[ok]: SREM with multiple arguments\r\n[ok]: SREM variadic version with more args needed to destroy the key\r\n[ok]: AUTH fails when binary password is wrong\r\n[ok]: AUTH succeeds when binary password is correct\r\n[ok]: HRANDFIELD with <count> - hashtable\r\n[ok]: XADD with MAXLEN option and the '=' argument\r\n[ok]: XGROUP CREATE: creation and duplicate group name detection\r\n[ok]: XGROUP CREATE: automatic stream creation fails without MKSTREAM\r\n[ok]: XGROUP CREATE: automatic stream creation works with MKSTREAM\r\n[ok]: MIGRATE is caching connections\r\n[ok]: XREADGROUP will return only new elements\r\n[ok]: XREADGROUP can read the history of the elements we own\r\n[ok]: XPENDING is able to return pending items\r\n[ok]: XPENDING can return single consumer items\r\n[ok]: XPENDING only group\r\n[ok]: Generated sets must be encoded as hashtable\r\n[ok]: SINTER with two sets - hashtable\r\n[ok]: SINTERSTORE with two sets - hashtable\r\n[ok]: XPENDING with IDLE\r\n[ok]: XPENDING with exclusive range intervals works as expected\r\n[ok]: XACK is able to remove items from the consumer/group PEL\r\n[ok]: XACK can't remove the same item multiple times\r\n[ok]: XACK is able to accept multiple arguments\r\n[ok]: XACK should fail if got at least one invalid ID\r\n[ok]: PEL NACK reassignment after XGROUP SETID event\r\n[ok]: XREADGROUP will not report data on empty history. Bug #5577\r\n[ok]: SINTERSTORE with two sets, after a DEBUG RELOAD - hashtable\r\n[ok]: XREADGROUP history reporting of deleted entries. Bug #5570\r\n[ok]: Protocol desync regression test #2\r\n[ok]: HSCAN with encoding hashtable\r\n[ok]: SUNION with two sets - hashtable\r\n[ok]: ZSCAN with encoding ziplist\r\n[ok]: SUNIONSTORE with two sets - hashtable\r\n[ok]: SINTER against three sets - hashtable\r\n[ok]: SINTERSTORE with three sets - hashtable\r\n[ok]: SUNION with non existing keys - hashtable\r\n[ok]: SDIFF with two sets - hashtable\r\n[ok]: SDIFF with three sets - hashtable\r\n[ok]: SDIFFSTORE with three sets - hashtable\r\n[ok]: Old Ziplist: SORT BY key\r\n[ok]: Old Ziplist: SORT BY key with limit\r\n[ok]: Unsafe command names are sanitized in INFO output\r\n[ok]: Old Ziplist: SORT BY hash field\r\n[ok]: XADD with MAXLEN option and the '~' argument\r\n[ok]: XADD with NOMKSTREAM option\r\n[ok]: HRANDFIELD with <count> - ziplist\r\n[ok]: Blocking XREADGROUP will not reply with an empty array\r\n[ok]: XGROUP DESTROY should unblock XREADGROUP with -NOGROUP\r\n[ok]: RENAME can unblock XREADGROUP with data\r\n[ok]: Protocol desync regression test #3\r\n[ok]: RENAME can unblock XREADGROUP with -NOGROUP\r\n[ok]: Generated sets must be encoded as intset\r\n[ok]: SINTER with two sets - intset\r\n[ok]: SINTERSTORE with two sets - intset\r\n[ok]: SINTERSTORE with two sets, after a DEBUG RELOAD - intset\r\n[ok]: SUNION with two sets - intset\r\n[ok]: SUNIONSTORE with two sets - intset\r\n[ok]: SINTER against three sets - intset\r\n[ok]: SINTERSTORE with three sets - intset\r\n[ok]: SUNION with non existing keys - intset\r\n[ok]: SDIFF with two sets - intset\r\n[ok]: SDIFF with three sets - intset\r\n[ok]: SDIFFSTORE with three sets - intset\r\n[ok]: SDIFF with first set empty\r\n[ok]: SDIFF with same set two times\r\n[ok]: ZSCAN with encoding skiplist\r\n[ok]: SCAN guarantees check under write load\r\n[ok]: SSCAN with integer encoded object (issue #1345)\r\n[ok]: SSCAN with PATTERN\r\n[ok]: HSCAN with PATTERN\r\n[ok]: ZSCAN with PATTERN\r\n[ok]: XADD with MINID option\r\n[ok]: XTRIM with MINID option\r\n[ok]: HSET/HLEN - Big hash creation\r\n[ok]: Is the big hash encoded with an hash table?\r\n[ok]: HGET against the small hash\r\n[ok]: Regression for a crash with blocking ops and pipelining\r\n[ok]: ZSCAN scores: regression test for issue #2175\r\n[ok]: HGET against the big hash\r\n[ok]: HGET against non existing key\r\n[ok]: HSET in update and insert mode\r\n[ok]: HSETNX target key missing - small hash\r\n[ok]: HSETNX target key exists - small hash\r\n[ok]: HSETNX target key missing - big hash\r\n[ok]: HSETNX target key exists - big hash\r\n[ok]: HMSET wrong number of args\r\n[ok]: HMSET - small hash\r\n[3/64 done]: unit/info (1 seconds)\r\nTesting unit/expire\r\n[ok]: Old Linked list: SORT BY key\r\n[ok]: Old Linked list: SORT BY key with limit\r\n[ok]: HMSET - big hash\r\n[ok]: HMGET against non existing key and fields\r\n[ok]: HMGET against wrong type\r\n[ok]: HMGET - small hash\r\n[ok]: Old Linked list: SORT BY hash field\r\n[4/64 done]: unit/protocol (1 seconds)\r\nTesting unit/other\r\n[ok]: EXPIRE - set timeouts multiple times\r\n[ok]: EXPIRE - It should be still possible to read 'x'\r\n[ok]: HMGET - big hash\r\n[ok]: HKEYS - small hash\r\n[ok]: HKEYS - big hash\r\n[ok]: HVALS - small hash\r\n[ok]: HVALS - big hash\r\n[ok]: HGETALL - small hash\r\n[ok]: HGETALL - big hash\r\n[ok]: HDEL and return value\r\n[ok]: HDEL - more than a single value\r\n[ok]: HDEL - hash becomes empty before deleting all specified fields\r\n[ok]: HEXISTS\r\n[ok]: Is a ziplist encoded Hash promoted on big payload?\r\n[ok]: HINCRBY against non existing database key\r\n[ok]: HINCRBY against non existing hash key\r\n[ok]: HINCRBY against hash key created by hincrby itself\r\n[ok]: HINCRBY against hash key originally set with HSET\r\n[ok]: HINCRBY over 32bit value\r\n[ok]: HINCRBY over 32bit value with over 32bit increment\r\n[ok]: HINCRBY fails against hash value with spaces (left)\r\n[ok]: HINCRBY fails against hash value with spaces (right)\r\n[ok]: HINCRBY can detect overflows\r\n[ok]: HINCRBYFLOAT against non existing database key\r\n[ok]: HINCRBYFLOAT against non existing hash key\r\n[ok]: HINCRBYFLOAT against hash key created by hincrby itself\r\n[ok]: HINCRBYFLOAT against hash key originally set with HSET\r\n[ok]: HINCRBYFLOAT over 32bit value\r\n[ok]: HINCRBYFLOAT over 32bit value with over 32bit increment\r\n[ok]: HINCRBYFLOAT fails against hash value with spaces (left)\r\n[ok]: HINCRBYFLOAT fails against hash value with spaces (right)\r\n[ok]: HINCRBYFLOAT fails against hash value that contains a null-terminator in the middle\r\n[ok]: HSTRLEN against the small hash\r\n[ok]: HSTRLEN against the big hash\r\n[ok]: HSTRLEN against non existing field\r\n[ok]: HSTRLEN corner cases\r\n[ok]: Hash ziplist regression test for large keys\r\n[ok]: SAVE - make sure there are all the types as values\r\n[ok]: Hash fuzzing #1 - 10 fields\r\n[ok]: Hash fuzzing #2 - 10 fields\r\n[ok]: XCLAIM can claim PEL items from another consumer\r\n[ok]: FUZZ stresser with data model binary\r\n[ok]: BRPOPLPUSH timeout\r\n[ok]: BLPOP when new key is moved into place\r\n[ok]: BLPOP when result key is created by SORT..STORE\r\n[ok]: BLPOP: with single empty list argument\r\n[ok]: BLPOP: with negative timeout\r\n[ok]: DEL against expired key\r\n[ok]: EXISTS\r\n[ok]: Zero length value in key. SET/GET/EXISTS\r\n[ok]: Commands pipelining\r\n[ok]: Non existing command\r\n[ok]: RENAME basic usage\r\n[ok]: RENAME source key should no longer exist\r\n[ok]: RENAME against already existing key\r\n[ok]: RENAMENX basic usage\r\n[ok]: RENAMENX against already existing key\r\n[ok]: RENAMENX against already existing key (2)\r\n[ok]: RENAME against non existing source key\r\n[ok]: RENAME where source and dest key are the same (existing)\r\n[ok]: RENAMENX where source and dest key are the same (existing)\r\n[ok]: RENAME where source and dest key are the same (non existing)\r\n[ok]: RENAME with volatile key, should move the TTL as well\r\n[ok]: RENAME with volatile key, should not inherit TTL of target key\r\n[ok]: DEL all keys again (DB 0)\r\n[ok]: DEL all keys again (DB 1)\r\n[ok]: COPY basic usage for string\r\n[ok]: COPY for string does not replace an existing key without REPLACE option\r\n[ok]: COPY for string can replace an existing key with REPLACE option\r\n[ok]: COPY for string ensures that copied data is independent of copying data\r\n[ok]: COPY for string does not copy data to no-integer DB\r\n[ok]: COPY can copy key expire metadata as well\r\n[ok]: COPY does not create an expire if it does not exist\r\n[ok]: COPY basic usage for list\r\n[ok]: COPY basic usage for intset set\r\n[ok]: COPY basic usage for hashtable set\r\n[ok]: COPY basic usage for ziplist sorted set\r\n[ok]: COPY basic usage for skiplist sorted set\r\n[ok]: COPY basic usage for ziplist hash\r\n[ok]: COPY basic usage for hashtable hash\r\n[ok]: COPY basic usage for stream\r\n[ok]: COPY basic usage for stream-cgroups\r\n[ok]: MOVE basic usage\r\n[ok]: MOVE against key existing in the target DB\r\n[ok]: MOVE against non-integer DB (#1428)\r\n[ok]: MOVE can move key expire metadata as well\r\n[ok]: MOVE does not create an expire if it does not exist\r\n[ok]: SET/GET keys in different DBs\r\n[ok]: RANDOMKEY\r\n[ok]: RANDOMKEY against empty DB\r\n[ok]: RANDOMKEY regression 1\r\n[ok]: KEYS * two times with long key, Github issue #1208\r\n[ok]: XCLAIM without JUSTID increments delivery count\r\n[5/64 done]: unit/keyspace (2 seconds)\r\nTesting unit/multi\r\n[ok]: MASTERAUTH test with binary password\r\n[ok]: MUTLI / EXEC basics\r\n[ok]: DISCARD\r\n[ok]: Nested MULTI are not allowed\r\n[ok]: MULTI where commands alter argc/argv\r\n[ok]: WATCH inside MULTI is not allowed\r\n[ok]: EXEC fails if there are errors while queueing commands #1\r\n[ok]: EXEC fails if there are errors while queueing commands #2\r\n[ok]: If EXEC aborts, the client MULTI state is cleared\r\n[ok]: EXEC works on WATCHed key not modified\r\n[ok]: EXEC fail on WATCHed key modified (1 key of 1 watched)\r\n[ok]: EXEC fail on WATCHed key modified (1 key of 5 watched)\r\n[ok]: EXEC fail on WATCHed key modified by SORT with STORE even if the result is empty\r\n[ok]: After successful EXEC key is no longer watched\r\n[ok]: After failed EXEC key is no longer watched\r\n[ok]: It is possible to UNWATCH\r\n[ok]: UNWATCH when there is nothing watched works as expected\r\n[ok]: FLUSHALL is able to touch the watched keys\r\n[ok]: FLUSHALL does not touch non affected keys\r\n[ok]: FLUSHDB is able to touch the watched keys\r\n[ok]: FLUSHDB does not touch non affected keys\r\n[ok]: SWAPDB is able to touch the watched keys that exist\r\n[ok]: SWAPDB is able to touch the watched keys that do not exist\r\n[ok]: WATCH is able to remember the DB a key belongs to\r\n[ok]: WATCH will consider touched keys target of EXPIRE\r\n[ok]: BLPOP: with non-integer timeout\r\n[ok]: XCLAIM same consumer\r\n[6/64 done]: unit/auth (2 seconds)\r\nTesting unit/quit\r\n[ok]: QUIT returns OK\r\n[ok]: Pipelined commands after QUIT must not be executed\r\n[ok]: Pipelined commands after QUIT that exceed read buffer size\r\n[ok]: FUZZ stresser with data model alpha\r\n[7/64 done]: unit/quit (0 seconds)\r\nTesting unit/aofrw\r\n[ok]: Hash fuzzing #1 - 512 fields\r\n[ok]: XAUTOCLAIM can claim PEL items from another consumer\r\n[ok]: FUZZ stresser with data model compr\r\n[ok]: XAUTOCLAIM as an iterator\r\n[ok]: XAUTOCLAIM COUNT must be > 0\r\n[ok]: XINFO FULL output\r\n[ok]: XGROUP CREATECONSUMER: create consumer if does not exist\r\n[ok]: XGROUP CREATECONSUMER: group must exist\r\n[ok]: BLPOP: with zero timeout should block indefinitely\r\n[ok]: BLPOP: second argument is not a list\r\n[ok]: XREADGROUP with NOACK creates consumer\r\n[ok]: WATCH will consider touched expired keys\r\n[ok]: DISCARD should clear the WATCH dirty flag on the client\r\n[ok]: DISCARD should UNWATCH all the keys\r\n[ok]: XADD mass insertion and XLEN\r\n[ok]: XADD with ID 0-0\r\n[ok]: XRANGE COUNT works as expected\r\n[ok]: XREVRANGE COUNT works as expected\r\n[ok]: Very big payload random access\r\n[ok]: EXPIRE - After 2.1 seconds the key should no longer be here\r\n[ok]: EXPIRE - write on expire should work\r\n[ok]: EXPIREAT - Check for EXPIRE alike behavior\r\n[ok]: SETEX - Set + Expire combo operation. Check for TTL\r\n[ok]: SETEX - Check value\r\n[ok]: SETEX - Overwrite old key\r\n[ok]: MULTI / EXEC is propagated correctly (single write command)\r\n[ok]: Old Big Linked list: SORT BY key\r\n[ok]: Old Big Linked list: SORT BY key with limit\r\n[ok]: MULTI / EXEC is propagated correctly (empty transaction)\r\n[ok]: MULTI / EXEC is propagated correctly (read-only commands)\r\n[ok]: MULTI / EXEC is propagated correctly (write command, no effect)\r\n[ok]: DISCARD should not fail during OOM\r\n[ok]: Old Big Linked list: SORT BY hash field\r\n[ok]: Intset: SORT BY key\r\n[ok]: Intset: SORT BY key with limit\r\n[ok]: Intset: SORT BY hash field\r\n[ok]: Hash fuzzing #2 - 512 fields\r\n[ok]: XRANGE can be used to iterate the whole stream\r\n[ok]: BGSAVE\r\n[ok]: SELECT an out of range DB\r\n[ok]: Hash table: SORT BY key\r\n[ok]: Hash table: SORT BY key with limit\r\n[ok]: Hash table: SORT BY hash field\r\n[ok]: MULTI and script timeout\r\n[ok]: SDIFF fuzzing\r\n[ok]: SINTER against non-set should throw error\r\n[ok]: SUNION against non-set should throw error\r\n[ok]: SINTER should handle non existing key as empty\r\n[ok]: SINTER with same integer elements but different encoding\r\n[ok]: SINTERSTORE against non existing keys should delete dstkey\r\n[ok]: SUNIONSTORE against non existing keys should delete dstkey\r\n[ok]: SPOP basics - hashtable\r\n[ok]: SPOP with <count>=1 - hashtable\r\n[ok]: SRANDMEMBER - hashtable\r\n[ok]: SPOP basics - intset\r\n[ok]: SPOP with <count>=1 - intset\r\n[ok]: SRANDMEMBER - intset\r\n[ok]: SPOP with <count>\r\n[ok]: SPOP with <count>\r\n[ok]: SPOP using integers, testing Knuth's and Floyd's algorithm\r\n[ok]: SPOP using integers with Knuth's algorithm\r\n[ok]: SPOP new implementation: code path #1\r\n[ok]: SPOP new implementation: code path #2\r\n[ok]: SPOP new implementation: code path #3\r\n[ok]: SRANDMEMBER with <count> against non existing key\r\n[ok]: SRANDMEMBER with <count> - hashtable\r\n[ok]: SRANDMEMBER with <count> - intset\r\n[ok]: SRANDMEMBER histogram distribution - hashtable\r\n[ok]: ZDIFF fuzzing - ziplist\r\n[ok]: Basic ZPOP with a single key - ziplist\r\n[ok]: ZPOP with count - ziplist\r\n[ok]: BZPOP with a single existing sorted set - ziplist\r\n[ok]: BZPOP with multiple existing sorted sets - ziplist\r\n[ok]: BZPOP second sorted set has members - ziplist\r\n[ok]: Check encoding - skiplist\r\n[ok]: ZSET basic ZADD and score update - skiplist\r\n[ok]: ZSET element can't be set to NaN with ZADD - skiplist\r\n[ok]: ZSET element can't be set to NaN with ZINCRBY - skiplist\r\n[ok]: ZADD with options syntax error with incomplete pair - skiplist\r\n[ok]: ZADD XX option without key - skiplist\r\n[ok]: ZADD XX existing key - skiplist\r\n[ok]: ZADD XX returns the number of elements actually added - skiplist\r\n[ok]: ZADD XX updates existing elements score - skiplist\r\n[ok]: ZADD GT updates existing elements when new scores are greater - skiplist\r\n[ok]: ZADD LT updates existing elements when new scores are lower - skiplist\r\n[ok]: BLPOP: timeout\r\n[ok]: ZADD GT XX updates existing elements when new scores are greater and skips new elements - skiplist\r\n[ok]: ZADD LT XX updates existing elements when new scores are lower and skips new elements - skiplist\r\n[ok]: ZADD XX and NX are not compatible - skiplist\r\n[ok]: ZADD NX with non existing key - skiplist\r\n[ok]: ZADD NX only add new elements without updating old ones - skiplist\r\n[ok]: ZADD GT and NX are not compatible - skiplist\r\n[ok]: BLPOP: arguments are empty\r\n[ok]: ZADD LT and NX are not compatible - skiplist\r\n[ok]: ZADD LT and GT are not compatible - skiplist\r\n[ok]: ZADD INCR LT/GT replies with nill if score not updated - skiplist\r\n[ok]: BRPOP: with single empty list argument\r\n[ok]: BRPOP: with negative timeout\r\n[ok]: ZADD INCR LT/GT with inf - skiplist\r\n[ok]: ZADD INCR works like ZINCRBY - skiplist\r\n[ok]: BRPOP: with non-integer timeout\r\n[ok]: ZADD INCR works with a single score-elemenet pair - skiplist\r\n[ok]: ZADD CH option changes return value to all changed elements - skiplist\r\n[ok]: ZINCRBY calls leading to NaN result in error - skiplist\r\n[ok]: ZADD - Variadic version base case - $encoding\r\n[ok]: ZADD - Return value is the number of actually added items - $encoding\r\n[ok]: ZADD - Variadic version does not add nothing on single parsing err - $encoding\r\n[ok]: ZADD - Variadic version will raise error on missing arg - $encoding\r\n[ok]: ZINCRBY does not work variadic even if shares ZADD implementation - $encoding\r\n[ok]: ZCARD basics - skiplist\r\n[ok]: ZREM removes key after last element is removed - skiplist\r\n[ok]: ZREM variadic version - skiplist\r\n[ok]: ZREM variadic version -- remove elements after key deletion - skiplist\r\n[ok]: ZRANGE basics - skiplist\r\n[ok]: ZREVRANGE basics - skiplist\r\n[ok]: ZRANK/ZREVRANK basics - skiplist\r\n[ok]: ZRANK - after deletion - skiplist\r\n[ok]: ZINCRBY - can create a new sorted set - skiplist\r\n[ok]: ZINCRBY - increment and decrement - skiplist\r\n[ok]: ZINCRBY return value - skiplist\r\n[ok]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics - skiplist\r\n[ok]: ZRANGEBYSCORE with WITHSCORES - skiplist\r\n[ok]: ZRANGEBYSCORE with LIMIT - skiplist\r\n[ok]: ZRANGEBYSCORE with LIMIT and WITHSCORES - skiplist\r\n[ok]: ZRANGEBYSCORE with non-value min or max - skiplist\r\n[ok]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics - skiplist\r\n[ok]: ZLEXCOUNT advanced - skiplist\r\n[ok]: ZRANGEBYSLEX with LIMIT - skiplist\r\n[ok]: ZRANGEBYLEX with invalid lex range specifiers - skiplist\r\n[ok]: ZREMRANGEBYSCORE basics - skiplist\r\n[ok]: ZREMRANGEBYSCORE with non-value min or max - skiplist\r\n[ok]: ZREMRANGEBYRANK basics - skiplist\r\n[ok]: ZUNIONSTORE against non-existing key doesn't set destination - skiplist\r\n[ok]: ZUNION/ZINTER/ZDIFF against non-existing key - skiplist\r\n[ok]: ZUNIONSTORE with empty set - skiplist\r\n[ok]: ZUNION/ZINTER/ZDIFF with empty set - skiplist\r\n[ok]: ZUNIONSTORE basics - skiplist\r\n[ok]: ZUNION/ZINTER/ZDIFF with integer members - skiplist\r\n[ok]: ZUNIONSTORE with weights - skiplist\r\n[ok]: ZUNION with weights - skiplist\r\n[ok]: ZUNIONSTORE with a regular set and weights - skiplist\r\n[ok]: ZUNIONSTORE with AGGREGATE MIN - skiplist\r\n[ok]: ZUNION/ZINTER with AGGREGATE MIN - skiplist\r\n[ok]: SRANDMEMBER histogram distribution - intset\r\n[ok]: ZUNIONSTORE with AGGREGATE MAX - skiplist\r\n[ok]: Consumer without PEL is present in AOF after AOFRW\r\n[ok]: ZUNION/ZINTER with AGGREGATE MAX - skiplist\r\n[ok]: ZINTERSTORE basics - skiplist\r\n[ok]: ZINTER basics - skiplist\r\n[ok]: SMOVE basics - from regular set to intset\r\n[ok]: ZINTER RESP3 - skiplist\r\n[ok]: ZINTERSTORE with weights - skiplist\r\n[ok]: SMOVE basics - from intset to regular set\r\n[ok]: ZINTER with weights - skiplist\r\n[ok]: ZINTERSTORE with a regular set and weights - skiplist\r\n[ok]: SMOVE non existing key\r\n[ok]: ZINTERSTORE with AGGREGATE MIN - skiplist\r\n[ok]: ZINTERSTORE with AGGREGATE MAX - skiplist\r\n[ok]: SMOVE non existing src set\r\n[ok]: SMOVE from regular set to non existing destination set\r\n[ok]: ZUNIONSTORE with +inf/-inf scores - skiplist\r\n[ok]: ZUNIONSTORE with NaN weights - skiplist\r\n[ok]: SMOVE from intset to non existing destination set\r\n[ok]: SMOVE wrong src key type\r\n[ok]: SMOVE wrong dst key type\r\n[ok]: SMOVE with identical source and destination\r\n[ok]: ZINTERSTORE with +inf/-inf scores - skiplist\r\n[ok]: ZINTERSTORE with NaN weights - skiplist\r\n[ok]: ZDIFFSTORE basics - skiplist\r\n[ok]: ZDIFF basics - skiplist\r\n[ok]: ZDIFFSTORE with a regular set - skiplist\r\n[ok]: ZDIFF subtracting set from itself - skiplist\r\n[ok]: ZDIFF algorithm 1 - skiplist\r\n[ok]: ZDIFF algorithm 2 - skiplist\r\n[ok]: Check consistency of different data types after a reload\r\n[ok]: SETEX - Wait for the key to expire\r\n[ok]: SETEX - Wrong time parameter\r\n[ok]: PERSIST can undo an EXPIRE\r\n[ok]: PERSIST returns 0 against non existing or non volatile keys\r\n[ok]: EXEC and script timeout\r\n[ok]: Consumer group last ID propagation to slave (NOACK=0)\r\n[ok]: Consumer group last ID propagation to slave (NOACK=1)\r\n[ok]: SET 10000 numeric keys and access all them in reverse order\r\n[ok]: DBSIZE should be 10000 now\r\n[ok]: SETNX target key missing\r\n[ok]: SETNX target key exists\r\n[ok]: SETNX against not-expired volatile key\r\n[ok]: MULTI-EXEC body and script timeout\r\n[ok]: BRPOP: with zero timeout should block indefinitely\r\n[ok]: BRPOP: second argument is not a list\r\n[ok]: just EXEC and script timeout\r\n[ok]: exec with write commands and state change\r\n[ok]: exec with read commands and stale replica state change\r\n[ok]: EXEC with only read commands should not be rejected when OOM\r\n[ok]: EXEC with at least one use-memory command should fail\r\n[ok]: Blocking commands ignores the timeout\r\n[ok]: MULTI propagation of PUBLISH\r\n[ok]: Same dataset digest if saving/reloading as AOF?\r\n[ok]: Stress test the hash ziplist -> hashtable encoding conversion\r\n[ok]: Test HINCRBYFLOAT for correct float representation (issue #2846)\r\n[ok]: XREVRANGE returns the reverse of XRANGE\r\n[ok]: XRANGE exclusive ranges\r\n[ok]: XREAD with non empty stream\r\n[ok]: Non blocking XREAD with empty streams\r\n[ok]: XREAD with non empty second stream\r\n[ok]: Blocking XREAD waiting new data\r\n[ok]: Blocking XREAD waiting old data\r\n[ok]: MULTI propagation of SCRIPT LOAD\r\n[ok]: Hash ziplist of various encodings\r\n[ok]: Hash ziplist of various encodings - sanitize dump\r\n[ok]: Blocking XREAD will not reply with an empty array\r\n[ok]: XREAD: XADD + DEL should not awake client\r\n[ok]: XREAD: XADD + DEL + LPUSH should not awake client\r\n[ok]: XREAD with same stream name multiple times should work\r\n[ok]: XREAD + multiple XADD inside transaction\r\n[ok]: XDEL basic test\r\n[ok]: MULTI propagation of SCRIPT LOAD\r\n[8/64 done]: unit/type/hash (5 seconds)\r\nTesting unit/acl\r\n[ok]: MULTI propagation of XREADGROUP\r\n[ok]: Connections start with the default user\r\n[ok]: It is possible to create new users\r\n[ok]: New users start disabled\r\n[ok]: Enabling the user allows the login\r\n[ok]: Only the set of correct passwords work\r\n[ok]: It is possible to remove passwords from the set of valid ones\r\n[ok]: Test password hashes can be added\r\n[ok]: Test password hashes validate input\r\n[ok]: ACL GETUSER returns the password hash instead of the actual password\r\n[ok]: Test hashed passwords removal\r\n[ok]: By default users are not able to access any command\r\n[ok]: By default users are not able to access any key\r\n[ok]: It's possible to allow the access of a subset of keys\r\n[ok]: By default users are able to publish to any channel\r\n[ok]: By default users are able to subscribe to any channel\r\n[ok]: By default users are able to subscribe to any pattern\r\n[ok]: It's possible to allow publishing to a subset of channels\r\n[ok]: Validate subset of channels is prefixed with resetchannels flag\r\n[ok]: In transaction queue publish/subscribe/psubscribe to unauthorized channel will fail\r\n[ok]: It's possible to allow subscribing to a subset of channels\r\n[ok]: It's possible to allow subscribing to a subset of channel patterns\r\n[ok]: Subscribers are killed when revoked of channel permission\r\n[ok]: Subscribers are killed when revoked of pattern permission\r\n[ok]: Subscribers are pardoned if literal permissions are retained and/or gaining allchannels\r\n[ok]: Users can be configured to authenticate with any password\r\n[ok]: ACLs can exclude single commands\r\n[ok]: ACLs can include or exclude whole classes of commands\r\n[ok]: ACLs can include single subcommands\r\n[ok]: intsets implementation stress testing\r\n[ok]: ACLs set can include subcommands, if already full command exists\r\n[ok]: ACL GETUSER is able to translate back command permissions\r\n[ok]: ACL GETUSER provides reasonable results\r\n[ok]: ACL #5998 regression: memory leaks adding / removing subcommands\r\n[ok]: ACL LOG shows failed command executions at toplevel\r\n[ok]: ACL LOG is able to test similar events\r\n[ok]: ACL LOG is able to log keys access violations and key name\r\n[ok]: ACL LOG is able to log channel access violations and channel name\r\n[ok]: ACL LOG RESET is able to flush the entries in the log\r\n[ok]: ACL LOG can distinguish the transaction context (1)\r\n[ok]: ACL LOG can distinguish the transaction context (2)\r\n[ok]: ACL can log errors in the context of Lua scripting\r\n[ok]: ACL LOG can accept a numerical argument to show less entries\r\n[ok]: ACL LOG can log failed auth attempts\r\n[ok]: ACL LOG entries are limited to a maximum amount\r\n[ok]: When default user is off, new connections are not authenticated\r\n[ok]: When default user has no command permission, hello command still works for other users\r\n[ok]: ACL HELP should not have unexpected options\r\n[ok]: Delete a user that the client doesn't use\r\n[ok]: Delete a user that the client is using\r\n[9/64 done]: unit/multi (4 seconds)\r\nTesting unit/latency-monitor\r\n[10/64 done]: unit/type/set (6 seconds)\r\nTesting integration/block-repl\r\n[ok]: Empty stream with no lastid can be rewrite into AOF correctly\r\n[ok]: default: load from include file, can access any channels\r\n[ok]: default: with config acl-pubsub-default allchannels after reset, can access any channels\r\n[ok]: default: with config acl-pubsub-default resetchannels after reset, can not access any channels\r\n[ok]: Alice: can execute all command\r\n[ok]: Bob: just execute @set and acl command\r\n[ok]: ACL load and save\r\n[ok]: ACL load and save with restricted channels\r\n[11/64 done]: unit/type/stream-cgroups (5 seconds)\r\nTesting integration/replication\r\n[ok]: Big Hash table: SORT BY key\r\n[ok]: Big Hash table: SORT BY key with limit\r\n[ok]: Default user has access to all channels irrespective of flag\r\n[ok]: Update acl-pubsub-default, existing users shouldn't get affected\r\n[ok]: Single channel is valid\r\n[ok]: Single channel is not valid with allchannels\r\n[ok]: Slave enters handshake\r\n[ok]: BRPOP: timeout\r\n[ok]: BRPOP: arguments are empty\r\n[ok]: BLPOP inside a transaction\r\n[ok]: LPUSHX, RPUSHX - generic\r\n[ok]: LPUSHX, RPUSHX - linkedlist\r\n[ok]: LINSERT - linkedlist\r\n[ok]: LPUSHX, RPUSHX - ziplist\r\n[ok]: LINSERT - ziplist\r\n[ok]: LINSERT raise error on bad syntax\r\n[ok]: LINDEX consistency test - quicklist\r\n[ok]: LINDEX random access - quicklist\r\n[ok]: EXPIRES after a reload (snapshot + append only file rewrite)\r\n[ok]: Big Hash table: SORT BY hash field\r\n[ok]: SORT GET #\r\n[ok]: SORT GET <const>\r\n[ok]: SORT GET (key and hash) with sanity check\r\n[ok]: SORT BY key STORE\r\n[ok]: SORT BY hash field STORE\r\n[ok]: SORT extracts STORE correctly\r\n[ok]: SORT extracts multiple STORE correctly\r\n[ok]: SORT DESC\r\n[ok]: SORT ALPHA against integer encoded strings\r\n[ok]: SORT sorted set\r\n[ok]: EXPIRE precision is now the millisecond\r\n[ok]: SORT sorted set BY nosort should retain ordering\r\n[ok]: SORT sorted set BY nosort + LIMIT\r\n[ok]: SORT sorted set BY nosort works as expected from scripts\r\n[ok]: SORT sorted set: +inf and -inf handling\r\n[ok]: Only default user has access to all channels irrespective of flag\r\n[ok]: SORT regression for issue #19, sorting floats\r\n[ok]: SORT with STORE returns zero if result is empty (github issue 224)\r\n[ok]: SORT with STORE does not create empty lists (github issue 224)\r\n[ok]: SORT with STORE removes key if result is empty (github issue 227)\r\n[ok]: SORT with BY <constant> and STORE should still order output\r\n[ok]: SORT will complain with numerical sorting and bad doubles (1)\r\n[ok]: SORT will complain with numerical sorting and bad doubles (2)\r\n[ok]: SORT BY sub-sorts lexicographically if score is the same\r\n[ok]: SORT GET with pattern ending with just -> does not get hash field\r\n[ok]: SORT by nosort retains native order for lists\r\n[ok]: SORT by nosort plus store retains native order for lists\r\n[ok]: SORT by nosort with limit returns based on original list order\r\n[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[ok]: SORT speed, 100 element list BY key, 100 times\r\n[ok]: SORT speed, 100 element list BY hash field, 100 times\r\n[ok]: SORT speed, 100 element list directly, 100 times\r\n[ok]: SORT speed, 100 element list BY <const>, 100 times\r\n[ok]: LTRIM stress testing - linkedlist\r\n[ok]: LINDEX consistency test - quicklist\r\n[12/64 done]: unit/sort (5 seconds)\r\nTesting integration/replication-2\r\n[ok]: LINDEX random access - quicklist\r\n[ok]: default: load from config file, can access any channels\r\n[ok]: XDEL fuzz test\r\n[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[ok]: LLEN against non-list value error\r\n[ok]: LLEN against non existing key\r\n[ok]: LINDEX against non-list value error\r\n[ok]: LINDEX against non existing key\r\n[ok]: LPUSH against non-list value error\r\n[ok]: RPUSH against non-list value error\r\n[ok]: RPOPLPUSH base case - linkedlist\r\n[ok]: LMOVE left left base case - linkedlist\r\n[ok]: LMOVE left right base case - linkedlist\r\n[ok]: LMOVE right left base case - linkedlist\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: If min-slaves-to-write is honored, write is accepted\r\n[ok]: LMOVE right right base case - linkedlist\r\n[ok]: No write if min-slaves-to-write is < attached slaves\r\n[ok]: If min-slaves-to-write is honored, write is accepted (again)\r\n[ok]: RPOPLPUSH with the same list as src and dst - linkedlist\r\n[ok]: LMOVE left left with the same list as src and dst - linkedlist\r\n[ok]: LMOVE left right with the same list as src and dst - linkedlist\r\n[ok]: LMOVE right left with the same list as src and dst - linkedlist\r\n[ok]: LMOVE right right with the same list as src and dst - linkedlist\r\n[ok]: RPOPLPUSH with linkedlist source and existing target linkedlist\r\n[13/64 done]: unit/acl (2 seconds)\r\nTesting integration/replication-3\r\n[ok]: LMOVE left left with linkedlist source and existing target linkedlist\r\n[ok]: LMOVE left right with linkedlist source and existing target linkedlist\r\n[ok]: LMOVE right left with linkedlist source and existing target linkedlist\r\n[ok]: LMOVE right right with linkedlist source and existing target linkedlist\r\n[ok]: RPOPLPUSH with linkedlist source and existing target ziplist\r\n[ok]: LMOVE left left with linkedlist source and existing target ziplist\r\n[ok]: LMOVE left right with linkedlist source and existing target ziplist\r\n[ok]: LMOVE right left with linkedlist source and existing target ziplist\r\n[ok]: LMOVE right right with linkedlist source and existing target ziplist\r\n[ok]: RPOPLPUSH base case - ziplist\r\n[ok]: LMOVE left left base case - ziplist\r\n[ok]: LMOVE left right base case - ziplist\r\n[ok]: LMOVE right left base case - ziplist\r\n[ok]: LMOVE right right base case - ziplist\r\n[ok]: RPOPLPUSH with the same list as src and dst - ziplist\r\n[ok]: LMOVE left left with the same list as src and dst - ziplist\r\n[ok]: LMOVE left right with the same list as src and dst - ziplist\r\n[ok]: LMOVE right left with the same list as src and dst - ziplist\r\n[ok]: LMOVE right right with the same list as src and dst - ziplist\r\n[ok]: RPOPLPUSH with ziplist source and existing target linkedlist\r\n[ok]: LMOVE left left with ziplist source and existing target linkedlist\r\n[ok]: LMOVE left right with ziplist source and existing target linkedlist\r\n[ok]: LMOVE right left with ziplist source and existing target linkedlist\r\n[ok]: LMOVE right right with ziplist source and existing target linkedlist\r\n[ok]: RPOPLPUSH with ziplist source and existing target ziplist\r\n[ok]: LMOVE left left with ziplist source and existing target ziplist\r\n[ok]: LMOVE left right with ziplist source and existing target ziplist\r\n[ok]: LMOVE right left with ziplist source and existing target ziplist\r\n[ok]: LMOVE right right with ziplist source and existing target ziplist\r\n[ok]: RPOPLPUSH against non existing key\r\n[ok]: RPOPLPUSH against non list src key\r\n[ok]: RPOPLPUSH against non list dst key\r\n[ok]: RPOPLPUSH against non existing src key\r\n[ok]: Basic LPOP/RPOP - linkedlist\r\n[ok]: Basic LPOP/RPOP - ziplist\r\n[ok]: LPOP/RPOP against non list value\r\n[ok]: Mass RPOP/LPOP - quicklist\r\n[ok]: Mass RPOP/LPOP - quicklist\r\n[ok]: LRANGE basics - linkedlist\r\n[ok]: LRANGE inverted indexes - linkedlist\r\n[ok]: LRANGE out of range indexes including the full list - linkedlist\r\n[ok]: LRANGE out of range negative end index - linkedlist\r\n[ok]: LRANGE basics - ziplist\r\n[ok]: LRANGE inverted indexes - ziplist\r\n[ok]: LRANGE out of range indexes including the full list - ziplist\r\n[ok]: LRANGE out of range negative end index - ziplist\r\n[ok]: LRANGE against non existing key\r\n[ok]: LRANGE with start > end yields an empty array for backward compatibility\r\n[ok]: LTRIM basics - linkedlist\r\n[ok]: LTRIM out of range negative end index - linkedlist\r\n[ok]: LTRIM basics - ziplist\r\n[ok]: LTRIM out of range negative end index - ziplist\r\n[ok]: LSET - linkedlist\r\n[ok]: LSET out of range index - linkedlist\r\n[ok]: LSET - ziplist\r\n[ok]: LSET out of range index - ziplist\r\n[ok]: LSET against non existing key\r\n[ok]: LSET against non list value\r\n[ok]: LREM remove all the occurrences - linkedlist\r\n[ok]: LREM remove the first occurrence - linkedlist\r\n[ok]: LREM remove non existing element - linkedlist\r\n[ok]: LREM starting from tail with negative count - linkedlist\r\n[ok]: LREM starting from tail with negative count (2) - linkedlist\r\n[ok]: LREM deleting objects that may be int encoded - linkedlist\r\n[ok]: LREM remove all the occurrences - ziplist\r\n[ok]: LREM remove the first occurrence - ziplist\r\n[ok]: LREM remove non existing element - ziplist\r\n[ok]: LREM starting from tail with negative count - ziplist\r\n[ok]: LREM starting from tail with negative count (2) - ziplist\r\n[ok]: LREM deleting objects that may be int encoded - ziplist\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: SETNX against expired volatile key\r\n[ok]: GETEX EX option\r\n[ok]: GETEX PX option\r\n[ok]: GETEX EXAT option\r\n[ok]: GETEX PXAT option\r\n[ok]: GETEX PERSIST option\r\n[ok]: GETEX no option\r\n[ok]: GETEX syntax errors\r\n[ok]: GETEX no arguments\r\n[ok]: GETDEL command\r\n[ok]: GETDEL propagate as DEL command to replica\r\n[ok]: GETEX without argument does not propagate to replica\r\n[ok]: MGET\r\n[ok]: MGET against non existing key\r\n[ok]: MGET against non-string key\r\n[ok]: GETSET (set new value)\r\n[ok]: GETSET (replace old value)\r\n[ok]: MSET base case\r\n[ok]: MSET wrong number of args\r\n[ok]: MSETNX with already existent key\r\n[ok]: MSETNX with not existing keys\r\n[ok]: STRLEN against non-existing key\r\n[ok]: STRLEN against integer-encoded value\r\n[ok]: STRLEN against plain string\r\n[ok]: SETBIT against non-existing key\r\n[ok]: SETBIT against string-encoded key\r\n[ok]: SETBIT against integer-encoded key\r\n[ok]: SETBIT against key with wrong type\r\n[ok]: SETBIT with out of range bit offset\r\n[ok]: SETBIT with non-bit argument\r\n[ok]: PEXPIRE/PSETEX/PEXPIREAT can set sub-second expires\r\n[ok]: TTL returns time to live in seconds\r\n[ok]: PTTL returns time to live in milliseconds\r\n[ok]: TTL / PTTL return -1 if key has no expire\r\n[ok]: TTL / PTTL return -2 if key does not exit\r\n[ok]: ZDIFF fuzzing - skiplist\r\n[ok]: Basic ZPOP with a single key - skiplist\r\n[ok]: ZPOP with count - skiplist\r\n[ok]: BZPOP with a single existing sorted set - skiplist\r\n[ok]: BZPOP with multiple existing sorted sets - skiplist\r\n[ok]: BZPOP second sorted set has members - skiplist\r\n[ok]: ZINTERSTORE regression with two sets, intset+hashtable\r\n[ok]: ZUNIONSTORE regression, should not create NaN in scores\r\n[ok]: ZINTERSTORE #516 regression, mixed sets and ziplist zsets\r\n[ok]: SETBIT fuzzing\r\n[ok]: GETBIT against non-existing key\r\n[ok]: GETBIT against string-encoded key\r\n[ok]: GETBIT against integer-encoded key\r\n[ok]: SETRANGE against non-existing key\r\n[ok]: SETRANGE against string-encoded key\r\n[ok]: SETRANGE against integer-encoded key\r\n[ok]: SETRANGE against key with wrong type\r\n[ok]: SETRANGE with out of range offset\r\n[ok]: GETRANGE against non-existing key\r\n[ok]: GETRANGE against string value\r\n[ok]: GETRANGE against integer-encoded value\r\n[ok]: ZUNIONSTORE result is sorted\r\n[ok]: ZUNIONSTORE/ZINTERSTORE/ZDIFFSTORE error if using WITHSCORES \r\n[ok]: ZMSCORE retrieve\r\n[ok]: ZMSCORE retrieve from empty set\r\n[ok]: ZMSCORE retrieve with missing member\r\n[ok]: ZMSCORE retrieve single member\r\n[ok]: ZMSCORE retrieve requires one or more members\r\n[ok]: ZSET commands don't accept the empty strings as valid score\r\n[ok]: ZSCORE - ziplist\r\n[ok]: ZMSCORE - ziplist\r\n[ok]: ZSCORE after a DEBUG RELOAD - ziplist\r\n[ok]: ZSET sorting stresser - ziplist\r\n[ok]: Regression for bug 593 - chaining BRPOPLPUSH with other blocking cmds\r\n[ok]: client unblock tests\r\n[ok]: List ziplist of various encodings\r\n[ok]: List ziplist of various encodings - sanitize dump\r\n[ok]: SCAN regression test for issue #4906\r\n[14/64 done]: unit/type/list (8 seconds)\r\nTesting integration/replication-4\r\n[15/64 done]: unit/scan (8 seconds)\r\nTesting integration/replication-psync\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: no, disabled, reconnect: 0)\r\n[ok]: GETRANGE fuzzing\r\n[ok]: Extended SET can detect syntax errors\r\n[ok]: Extended SET NX option\r\n[ok]: Extended SET XX option\r\n[ok]: Extended SET GET option\r\n[ok]: Extended SET GET option with no previous value\r\n[ok]: Extended SET GET with NX option should result in syntax err\r\n[ok]: Extended SET GET with incorrect type should result in wrong type error\r\n[ok]: Extended SET EX option\r\n[ok]: Extended SET PX option\r\n[ok]: Extended SET EXAT option\r\n[ok]: Extended SET PXAT option\r\n[ok]: Extended SET using multiple options at once\r\n[ok]: GETRANGE with huge ranges, Github issue #1844\r\n[ok]: STRALGO LCS string output with STRINGS option\r\n[ok]: STRALGO LCS len\r\n[ok]: LCS with KEYS option\r\n[ok]: LCS indexes\r\n[ok]: LCS indexes with match len\r\n[ok]: LCS indexes with match len and minimum match len\r\n[ok]: Redis should actively expire keys incrementally\r\n[16/64 done]: unit/type/string (8 seconds)\r\nTesting integration/aof\r\n[ok]: Unfinished MULTI: Server should start if load-truncated is yes\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Short read: Server should start if load-truncated is yes\r\n[ok]: Truncated AOF loaded: we expect foo to be equal to 5\r\n[ok]: Append a new command after loading an incomplete AOF\r\n[ok]: Short read + command: Server should start\r\n[ok]: Truncated AOF loaded: we expect foo to be equal to 6 now\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: Test latency events logging\r\n[ok]: LATENCY HISTORY output is ok\r\n[ok]: LATENCY LATEST output is ok\r\n[ok]: LATENCY HISTORY / RESET with wrong event name is fine\r\n[ok]: LATENCY DOCTOR produces some output\r\n[ok]: LATENCY RESET is able to reset events\r\n[ok]: Bad format: Server should have logged an error\r\n[ok]: EXPIRES after AOF reload (without rewrite)\r\n[ok]: Unfinished MULTI: Server should have logged an error\r\n[ok]: Short read: Server should have logged an error\r\n[ok]: Short read: Utility should confirm the AOF is not valid\r\n[ok]: Short read: Utility should be able to fix the AOF\r\n[ok]: Fixed AOF: Server should have been started\r\n[ok]: Fixed AOF: Keyspace should contain values that were parseable\r\n[ok]: No write if min-slaves-max-lag is > of the slave lag\r\n[ok]: Redis should lazy expire keys\r\n[ok]: min-slaves-to-write is ignored by slaves\r\n[ok]: Detect write load to master\r\n[ok]: AOF+SPOP: Server should have been started\r\n[ok]: AOF+SPOP: Set should have 1 member\r\n[ok]: AOF+SPOP: Server should have been started\r\n[ok]: AOF+SPOP: Set should have 1 member\r\n[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[ok]: ZRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[ok]: AOF+EXPIRE: Server should have been started\r\n[ok]: AOF+EXPIRE: List should be empty\r\n[ok]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[ok]: ZSETs skiplist implementation backlink consistency test - ziplist\r\n[ok]: Redis should not try to convert DEL into EXPIREAT for EXPIRE -1\r\n[ok]: EXPIRE should not resurrect keys (issue #1026)\r\n[ok]: 5 keys in, 5 keys out\r\n[ok]: EXPIRE with empty string as TTL should report an error\r\n[ok]: SET with EX with big integer should report an error\r\n[ok]: SET with EX with smallest integer should report an error\r\n[ok]: GETEX with big integer should report an error\r\n[ok]: GETEX with smallest integer should report an error\r\n[ok]: EXPIRE with big integer overflows when converted to milliseconds\r\n[ok]: PEXPIRE with big integer overflow when basetime is added\r\n[ok]: EXPIRE with big negative integer\r\n[ok]: PEXPIREAT with big integer works\r\n[ok]: PEXPIREAT with big negative integer works\r\n[ok]: PIPELINING stresser (also a regression for the old epoll bug)\r\n[ok]: APPEND basics\r\n[ok]: APPEND basics, integer encoded values\r\n[ok]: APPEND fuzzing\r\n[ok]: FLUSHDB\r\n[ok]: Perform a final SAVE to leave a clean DB on disk\r\n[ok]: RESET clears client state\r\n[ok]: RESET clears MONITOR state\r\n[ok]: RESET clears and discards MULTI state\r\n[ok]: RESET clears Pub/Sub state\r\n[ok]: RESET clears authenticated state\r\n[ok]: ZSETs ZRANK augmented skip list stress testing - ziplist\r\n[ok]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[ok]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[ok]: BZPOPMIN with same key multiple times should work\r\n[ok]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[ok]: BZPOPMIN with variadic ZADD\r\n[ok]: Don't rehash if redis has child proecess\r\n[ok]: Process title set as expected\r\n[17/64 done]: unit/other (11 seconds)\r\nTesting integration/rdb\r\n[ok]: RDB encoding loading test\r\n[ok]: LTRIM stress testing - ziplist\r\n[ok]: BZPOPMIN with zero timeout should block indefinitely\r\n[ok]: ZSCORE - skiplist\r\n[ok]: ZMSCORE - skiplist\r\n[ok]: ZSCORE after a DEBUG RELOAD - skiplist\r\n[18/64 done]: unit/type/list-2 (12 seconds)\r\nTesting integration/corrupt-dump\r\n[ok]: ZSET sorting stresser - skiplist\r\n[ok]: Server started empty with non-existing RDB file\r\n[ok]: corrupt payload: #7445 - with sanitize\r\n[ok]: EXPIRE and SET/GETEX EX/PX/EXAT/PXAT option, TTL should not be reset after loadaof\r\n[ok]: Server started empty with empty RDB file\r\n[ok]: corrupt payload: #7445 - without sanitize - 1\r\n[ok]: EXPIRE relative and absolute propagation to replicas\r\n[ok]: SET command will remove expire\r\n[ok]: SET - use KEEPTTL option, TTL should not be removed\r\n[ok]: corrupt payload: #7445 - without sanitize - 2\r\n[ok]: Test RDB stream encoding\r\n[ok]: Test RDB stream encoding - sanitize dump\r\n[ok]: corrupt payload: hash with valid zip list header, invalid entry len\r\n[ok]: Server should not start if RDB is corrupted\r\n[ok]: corrupt payload: invalid zlbytes header\r\n[ok]: corrupt payload: valid zipped hash header, dup records\r\n[ok]: Test FLUSHALL aborts bgsave\r\n[ok]: bgsave resets the change counter\r\n[ok]: corrupt payload: quicklist big ziplist prev len\r\n[ok]: corrupt payload: quicklist small ziplist prev len\r\n[ok]: corrupt payload: quicklist ziplist wrong count\r\n[ok]: corrupt payload: #3080 - quicklist\r\n[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: corrupt payload: #3080 - ziplist\r\n[ok]: corrupt payload: load corrupted rdb with no CRC - #3505\r\n[ok]: ZRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: corrupt payload: listpack invalid size header\r\n[ok]: corrupt payload: listpack too long entry len\r\n[ok]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: ZSETs skiplist implementation backlink consistency test - skiplist\r\n[ok]: corrupt payload: listpack very long entry len\r\n[ok]: corrupt payload: listpack too long entry prev len\r\n[ok]: SET - use KEEPTTL option, TTL should not be removed after loadaof\r\n[ok]: GETEX use of PERSIST option should remove TTL\r\n[ok]: corrupt payload: hash ziplist with duplicate records\r\n[ok]: MASTER and SLAVE consistency with expire\r\n[ok]: corrupt payload: hash ziplist uneven record count\r\n[ok]: ZSETs ZRANK augmented skip list stress testing - skiplist\r\n[ok]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[ok]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[ok]: BZPOPMIN with same key multiple times should work\r\n[ok]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[ok]: BZPOPMIN with variadic ZADD\r\n[ok]: corrupt payload: hash dupliacte records\r\n[ok]: Test replication with parallel clients writing in different DBs\r\n[ok]: corrupt payload: fuzzer findings - NPD in streamIteratorGetID\r\n[ok]: LATENCY of expire events are correctly collected\r\n[ok]: LATENCY HELP should not have unexpected options\r\n[ok]: corrupt payload: fuzzer findings - listpack NPD on invalid stream\r\n[ok]: corrupt payload: fuzzer findings - NPD in quicklistIndex\r\n[ok]: corrupt payload: fuzzer findings - invalid read in ziplistFind\r\n[19/64 done]: unit/latency-monitor (9 seconds)\r\nTesting integration/corrupt-dump-fuzzer\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: With min-slaves-to-write (1,3): master should be writable\r\n[ok]: With min-slaves-to-write (2,3): master should not be writable\r\n[ok]: corrupt payload: fuzzer findings - invalid ziplist encoding\r\n[ok]: MIGRATE cached connections are released after some time\r\n[ok]: corrupt payload: fuzzer findings - hash crash\r\n[ok]: MIGRATE is able to migrate a key between two instances\r\n[ok]: corrupt payload: fuzzer findings - uneven entry count in hash\r\n[ok]: Slave is able to detect timeout during handshake\r\n[ok]: BZPOPMIN with zero timeout should block indefinitely\r\n[ok]: MASTER and SLAVE dataset should be identical after complex ops\r\n[ok]: AOF fsync always barrier issue\r\n[ok]: MIGRATE is able to copy a key between two instances\r\n[ok]: corrupt payload: fuzzer findings - invalid read in lzf_decompress\r\n[ok]: client freed during loading\r\n[ok]: GETEX should not append to AOF\r\n[20/64 done]: integration/replication-2 (10 seconds)\r\nTesting integration/convert-zipmap-hash-on-load\r\n[ok]: RDB load zipmap hash: converts to ziplist\r\n[ok]: MIGRATE will not overwrite existing keys, unless REPLACE is used\r\n[ok]: corrupt payload: fuzzer findings - leak in rdbloading due to dup entry in set\r\n[21/64 done]: integration/aof (8 seconds)\r\nTesting integration/logging\r\n[ok]: corrupt payload: fuzzer findings - empty intset div by zero\r\n[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-entries is exceeded\r\n[ok]: Set instance A as slave of B\r\n[ok]: corrupt payload: fuzzer findings - valgrind ziplist - crash report prints freed memory\r\n[ok]: Test replication partial resync: ok psync (diskless: no, disabled, reconnect: 1)\r\n[ok]: MIGRATE propagates TTL correctly\r\n[ok]: corrupt payload: fuzzer findings - valgrind ziplist prevlen reaches outside the ziplist\r\n[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-value is exceeded\r\n[ok]: ZSET skiplist order consistency when elements are moved\r\n[ok]: ZRANGESTORE basic\r\n[ok]: ZRANGESTORE RESP3\r\n[ok]: ZRANGESTORE range\r\n[ok]: ZRANGESTORE BYLEX\r\n[ok]: ZRANGESTORE BYSCORE\r\n[ok]: ZRANGESTORE BYSCORE LIMIT\r\n[ok]: ZRANGESTORE BYSCORE REV LIMIT\r\n[ok]: ZRANGE BYSCORE REV LIMIT\r\n[ok]: ZRANGESTORE - empty range\r\n[ok]: ZRANGESTORE BYLEX - empty range\r\n[ok]: ZRANGESTORE BYSCORE - empty range\r\n[ok]: ZRANGE BYLEX\r\n[ok]: ZRANGESTORE invalid syntax\r\n[ok]: ZRANGE invalid syntax\r\n[ok]: Server is able to generate a stack trace on selected systems\r\n[ok]: ZRANDMEMBER - ziplist\r\n[ok]: ZRANDMEMBER - skiplist\r\n[ok]: ZRANDMEMBER with RESP3\r\n[ok]: ZRANDMEMBER count of 0 is handled correctly\r\n[ok]: ZRANDMEMBER with <count> against non existing key\r\n[22/64 done]: integration/convert-zipmap-hash-on-load (1 seconds)\r\nTesting integration/psync2\r\n[ok]: GETEX use of PERSIST option should remove TTL after loadaof\r\n[ok]: corrupt payload: fuzzer findings - valgrind - bad rdbLoadDoubleValue\r\n[ok]: corrupt payload: fuzzer findings - valgrind ziplist prev too big\r\n[ok]: GETEX propagate as to replica as PERSIST, DEL, or nothing\r\n[ok]: ZRANDMEMBER with <count> - skiplist\r\n[ok]: ZRANDMEMBER with <count> - ziplist\r\n[23/64 done]: unit/expire (16 seconds)\r\nTesting integration/psync2-reg\r\n[24/64 done]: unit/type/zset (17 seconds)\r\nTesting integration/psync2-pingoff\r\n[ok]: Crash report generated on SIGABRT\r\n[ok]: AOF rewrite during write load: RDB preamble=yes\r\n[ok]: corrupt payload: fuzzer findings - lzf decompression fails, avoid valgrind invalid read\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: PSYNC2: --- CYCLE 1 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[ok]: PSYNC2: Set #4 to replicate from #1\r\n[ok]: PSYNC2: Set #0 to replicate from #1\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #2 to replicate from #4\r\n[ok]: corrupt payload: fuzzer findings - stream bad lp_count\r\n[25/64 done]: integration/logging (1 seconds)\r\nTesting integration/failover\r\n[ok]: INCRBYFLOAT replication, should not remove expire\r\n[ok]: GETSET replication\r\n[ok]: BRPOPLPUSH replication, when blocking against empty list\r\n[ok]: corrupt payload: fuzzer findings - stream bad lp_count - unsanitized\r\n[ok]: failover command fails without connected replica\r\n[ok]: corrupt payload: fuzzer findings - stream integrity check issue\r\n[ok]: setup replication for following tests\r\n[ok]: failover command fails with invalid host\r\n[ok]: failover command fails with invalid port\r\n[ok]: failover command fails with just force and timeout\r\n[ok]: failover command fails when sent to a replica\r\n[ok]: failover command fails with force without timeout\r\n[ok]: corrupt payload: fuzzer findings - infinite loop\r\n[ok]: corrupt payload: fuzzer findings - hash convert asserts on RESTORE with shallow sanitization\r\n[ok]: PSYNC2 pingoff: setup\r\n[ok]: PSYNC2 pingoff: write and wait replication\r\n[ok]: PSYNC2 #3899 regression: setup\r\n[ok]: corrupt payload: OOM in rdbGenericLoadStringObject\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: BRPOPLPUSH replication, list exists\r\n[ok]: BLMOVE (left, left) replication, when blocking against empty list\r\n[ok]: With min-slaves-to-write: master not writable with lagged slave\r\n[ok]: corrupt payload: fuzzer findings - OOM in dictExpand\r\n[ok]: corrupt payload: fuzzer findings - invalid tail offset after removal\r\n[ok]: failover command to specific replica works\r\n[ok]: corrupt payload: fuzzer findings - negative reply length\r\n[ok]: corrupt payload: fuzzer findings - valgrind negative malloc\r\n[ok]: Test child sending info\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: BLMOVE (left, left) replication, list exists\r\n[ok]: BLMOVE (left, right) replication, when blocking against empty list\r\n[26/64 done]: integration/rdb (7 seconds)\r\nTesting integration/redis-cli\r\n[ok]: corrupt payload: fuzzer findings - valgrind invalid read\r\n[ok]: Interactive CLI: INFO response should be printed raw\r\n[ok]: Interactive CLI: Status reply\r\n[ok]: failover command to any replica works\r\n[ok]: Interactive CLI: Integer reply\r\n[ok]: Interactive CLI: Bulk reply\r\n[ok]: Interactive CLI: Multi-bulk reply\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: corrupt payload: fuzzer findings - HRANDFIELD on bad ziplist\r\n[ok]: Interactive CLI: Parsing quotes\r\n[ok]: Non-interactive TTY CLI: Status reply\r\n[ok]: Non-interactive TTY CLI: Integer reply\r\n[ok]: Non-interactive TTY CLI: Bulk reply\r\n[ok]: corrupt payload: fuzzer findings - stream with no records\r\n[ok]: Non-interactive TTY CLI: Multi-bulk reply\r\n[27/64 done]: integration/corrupt-dump (8 seconds)\r\nTesting integration/redis-benchmark\r\n[ok]: Non-interactive TTY CLI: Read last argument from pipe\r\n[ok]: Non-interactive TTY CLI: Read last argument from file\r\n[ok]: Non-interactive non-TTY CLI: Status reply\r\n[ok]: Non-interactive non-TTY CLI: Integer reply\r\n[ok]: failover to a replica with force works\r\n[ok]: Non-interactive non-TTY CLI: Bulk reply\r\n[ok]: Non-interactive non-TTY CLI: Multi-bulk reply\r\n[ok]: Non-interactive non-TTY CLI: Quoted input arguments\r\n[ok]: Non-interactive non-TTY CLI: No accidental unquoting of input arguments\r\n[ok]: Non-interactive non-TTY CLI: Invalid quoted input arguments\r\n[ok]: benchmark: set,get\r\n[ok]: Non-interactive non-TTY CLI: Read last argument from pipe\r\n[ok]: Non-interactive non-TTY CLI: Read last argument from file\r\n[ok]: benchmark: full test suite\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: BLMOVE (left, right) replication, list exists\r\n[ok]: BLMOVE (right, left) replication, when blocking against empty list\r\n[ok]: failover with timeout aborts if replica never catches up\r\n[ok]: failovers can be aborted\r\n[ok]: Slave is able to evict keys created in writable slaves\r\n[ok]: benchmark: multi-thread set,get\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: benchmark: pipelined full set,get\r\n[ok]: benchmark: arbitrary command\r\n[ok]: BLMOVE (right, left) replication, list exists\r\n[ok]: BLMOVE (right, right) replication, when blocking against empty list\r\n[ok]: benchmark: keyspace length\r\n[ok]: failover aborts if target rejects sync request\r\n[28/64 done]: integration/redis-benchmark (2 seconds)\r\nTesting unit/pubsub\r\n[ok]: Pub/Sub PING\r\n[ok]: PUBLISH/SUBSCRIBE basics\r\n[ok]: PUBLISH/SUBSCRIBE with two clients\r\n[ok]: PUBLISH/SUBSCRIBE after UNSUBSCRIBE without arguments\r\n[ok]: SUBSCRIBE to one channel more than once\r\n[ok]: UNSUBSCRIBE from non-subscribed channels\r\n[ok]: PUBLISH/PSUBSCRIBE basics\r\n[ok]: PUBLISH/PSUBSCRIBE with two clients\r\n[ok]: PUBLISH/PSUBSCRIBE after PUNSUBSCRIBE without arguments\r\n[ok]: PUNSUBSCRIBE from non-subscribed channels\r\n[ok]: NUMSUB returns numbers, not strings (#1561)\r\n[ok]: Mix SUBSCRIBE and PSUBSCRIBE\r\n[ok]: PUNSUBSCRIBE and UNSUBSCRIBE should always reply\r\n[ok]: Keyspace notifications: we receive keyspace notifications\r\n[ok]: Keyspace notifications: we receive keyevent notifications\r\n[ok]: Keyspace notifications: we can receive both kind of events\r\n[ok]: Keyspace notifications: we are able to mask events\r\n[ok]: Keyspace notifications: general events test\r\n[ok]: Keyspace notifications: list events test\r\n[ok]: Keyspace notifications: set events test\r\n[ok]: Keyspace notifications: zset events test\r\n[ok]: Keyspace notifications: hash events test\r\n[ok]: XRANGE fuzzing\r\n[ok]: XREVRANGE regression test for issue #5006\r\n[ok]: XREAD streamID edge (no-blocking)\r\n[ok]: XREAD streamID edge (blocking)\r\n[ok]: XADD streamID edge\r\n[ok]: XTRIM with MAXLEN option basic test\r\n[ok]: XADD with LIMIT consecutive calls\r\n[ok]: XTRIM with ~ is limited\r\n[ok]: XTRIM without ~ is not limited\r\n[ok]: XTRIM without ~ and with LIMIT\r\n[ok]: Keyspace notifications: expired events (triggered expire)\r\n[ok]: Keyspace notifications: expired events (background expire)\r\n[ok]: Keyspace notifications: evicted events\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: Keyspace notifications: test CONFIG GET/SET of event flags\r\n[29/64 done]: integration/failover (5 seconds)\r\nTesting unit/slowlog\r\n[ok]: SLOWLOG - check that it starts with an empty log\r\n[30/64 done]: unit/pubsub (0 seconds)\r\nTesting unit/scripting\r\n[ok]: EVAL - Does Lua interpreter replies to our requests?\r\n[ok]: EVAL - Lua integer -> Redis protocol type conversion\r\n[ok]: EVAL - Lua string -> Redis protocol type conversion\r\n[ok]: EVAL - Lua true boolean -> Redis protocol type conversion\r\n[ok]: EVAL - Lua false boolean -> Redis protocol type conversion\r\n[ok]: EVAL - Lua status code reply -> Redis protocol type conversion\r\n[ok]: EVAL - Lua error reply -> Redis protocol type conversion\r\n[ok]: EVAL - Lua table -> Redis protocol type conversion\r\n[ok]: XADD with MAXLEN > xlen can propagate correctly\r\n[ok]: EVAL - Are the KEYS and ARGV arrays populated correctly?\r\n[ok]: EVAL - is Lua able to call Redis API?\r\n[ok]: EVALSHA - Can we call a SHA1 if already defined?\r\n[ok]: EVALSHA - Can we call a SHA1 in uppercase?\r\n[ok]: EVALSHA - Do we get an error on invalid SHA1?\r\n[ok]: EVALSHA - Do we get an error on non defined SHA1?\r\n[ok]: EVAL - Redis integer -> Lua type conversion\r\n[ok]: EVAL - Redis bulk -> Lua type conversion\r\n[ok]: EVAL - Redis multi bulk -> Lua type conversion\r\n[ok]: EVAL - Redis status reply -> Lua type conversion\r\n[ok]: EVAL - Redis error reply -> Lua type conversion\r\n[ok]: EVAL - Redis nil bulk reply -> Lua type conversion\r\n[ok]: EVAL - Is the Lua client using the currently selected DB?\r\n[ok]: EVAL - SELECT inside Lua should not affect the caller\r\n[ok]: EVAL - Scripts can't run blpop command\r\n[ok]: EVAL - Scripts can't run brpop command\r\n[ok]: EVAL - Scripts can't run brpoplpush command\r\n[ok]: EVAL - Scripts can't run blmove command\r\n[ok]: EVAL - Scripts can't run bzpopmin command\r\n[ok]: EVAL - Scripts can't run bzpopmax command\r\n[ok]: EVAL - Scripts can't run XREAD and XREADGROUP with BLOCK option\r\n[ok]: EVAL - Scripts can't run certain commands\r\n[ok]: EVAL - No arguments to redis.call/pcall is considered an error\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - JSON numeric decoding\r\n[ok]: EVAL - JSON string decoding\r\n[ok]: EVAL - cmsgpack can pack double?\r\n[ok]: EVAL - cmsgpack can pack negative int64?\r\n[ok]: EVAL - cmsgpack can pack and unpack circular references?\r\n[ok]: EVAL - Numerical sanity check from bitop\r\n[ok]: EVAL - Verify minimal bitop functionality\r\n[ok]: EVAL - Able to parse trailing comments\r\n[ok]: SCRIPTING FLUSH - is able to clear the scripts cache?\r\n[ok]: SCRIPTING FLUSH ASYNC\r\n[ok]: SCRIPT EXISTS - can detect already defined scripts?\r\n[ok]: SCRIPT LOAD - is able to register scripts in the scripting cache\r\n[ok]: In the context of Lua the output of random commands gets ordered\r\n[ok]: SORT is normally not alpha re-ordered for the scripting engine\r\n[ok]: SORT BY <constant> output gets ordered for scripting\r\n[ok]: SORT BY <constant> with GET gets ordered for scripting\r\n[ok]: redis.sha1hex() implementation\r\n[ok]: Globals protection reading an undeclared global variable\r\n[ok]: Globals protection setting an undeclared global*\r\n[ok]: Test an example script DECR_IF_GT\r\n[ok]: Scripting engine resets PRNG at every script execution\r\n[ok]: Scripting engine PRNG can be seeded correctly\r\n[ok]: SLOWLOG - only logs commands taking more time than specified\r\n[ok]: SLOWLOG - max entries is correctly handled\r\n[ok]: SLOWLOG - GET optional argument to limit output len works\r\n[ok]: SLOWLOG - RESET subcommand works\r\n[ok]: BLMOVE (right, right) replication, list exists\r\n[ok]: BLPOP followed by role change, issue #2473\r\n[ok]: SLOWLOG - logged entry sanity check\r\n[ok]: SLOWLOG - Certain commands are omitted that contain sensitive information\r\n[ok]: SLOWLOG - Rewritten commands are logged as their original command\r\n[ok]: SLOWLOG - commands with too many arguments are trimmed\r\n[ok]: SLOWLOG - too long arguments are trimmed\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: XADD with MINID > lastid can propagate correctly\r\n[ok]: SLOWLOG - EXEC is not logged, just executed commands\r\n[ok]: SLOWLOG - can clean older entries\r\n[ok]: PSYNC2 pingoff: pause replica and promote it\r\n[ok]: XADD with ~ MAXLEN can propagate correctly\r\n[ok]: EVAL does not leak in the Lua stack\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 29410)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 2 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[ok]: PSYNC2: Set #4 to replicate from #1\r\n[ok]: PSYNC2: Set #2 to replicate from #1\r\n[ok]: PSYNC2: Set #3 to replicate from #1\r\n[ok]: PSYNC2: Set #0 to replicate from #4\r\n[ok]: EVAL processes writes from AOF in read-only slaves\r\n[ok]: Second server should have role master at first\r\n[ok]: SLAVEOF should start with link status \"down\"\r\n[ok]: The role should immediately be changed to \"replica\"\r\n[ok]: MIGRATE can correctly transfer large values\r\n[ok]: SLOWLOG - can be disabled\r\n[ok]: Dumping an RDB\r\n[ok]: XADD with ~ MAXLEN and LIMIT can propagate correctly\r\n[ok]: Sync should have transferred keys from master\r\n[ok]: The link status should be up\r\n[ok]: SET on the master should immediately propagate\r\n[ok]: FLUSHALL should replicate\r\n[ok]: ROLE in master reports master with a slave\r\n[ok]: ROLE in slave reports slave in connected state\r\n[ok]: Scan mode\r\n[31/64 done]: unit/slowlog (2 seconds)\r\nTesting unit/maxmemory\r\n[ok]: MIGRATE can correctly transfer hashes\r\n[ok]: Without maxmemory small integers are shared\r\n[ok]: With maxmemory and non-LRU policy integers are still shared\r\n[ok]: With maxmemory and LRU policy integers are not shared\r\n[ok]: XADD with ~ MINID can propagate correctly\r\n[ok]: XADD with ~ MINID and LIMIT can propagate correctly\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-random)\r\n[ok]: Make the old master a replica of the new one and check conditions\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: XTRIM with ~ MAXLEN can propagate correctly\r\n[ok]: MIGRATE timeout actually works\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-lru)\r\n[ok]: Connecting as a replica\r\n[ok]: XADD can CREATE an empty stream\r\n[ok]: XSETID can set a specific ID\r\n[ok]: XSETID cannot SETID with smaller ID\r\n[ok]: XSETID cannot SETID on non-existent key\r\n[ok]: Fuzzer corrupt restore payloads - sanitize_dump: no\r\n[ok]: MIGRATE can migrate multiple keys at once\r\n[ok]: MIGRATE with multiple keys must have empty key arg\r\n[ok]: MIGRATE with multiple keys migrate just existing ones\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-lfu)\r\n[ok]: MIGRATE with multiple keys: stress command rewriting\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-lru)\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: MIGRATE with multiple keys: delete just ack keys\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: MIGRATE AUTH: correct and wrong password cases\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-lfu)\r\n[32/64 done]: unit/dump (26 seconds)\r\nTesting unit/introspection\r\n[ok]: CLIENT LIST\r\n[ok]: CLIENT LIST with IDs\r\n[ok]: CLIENT INFO\r\n[ok]: MONITOR can log executed commands\r\n[ok]: MONITOR can log commands issued by the scripting engine\r\n[ok]: CLIENT GETNAME should return NIL if name is not assigned\r\n[ok]: CLIENT LIST shows empty fields for unassigned names\r\n[ok]: CLIENT SETNAME does not accept spaces\r\n[ok]: CLIENT SETNAME can assign a name to this connection\r\n[ok]: CLIENT SETNAME can change the name of an existing connection\r\n[ok]: After CLIENT SETNAME, connection can still be closed\r\n[ok]: Empty stream can be rewrite into AOF correctly\r\n[ok]: Test replication partial resync: no backlog (diskless: no, disabled, reconnect: 1)\r\n[ok]: CONFIG save params special case handled properly\r\n[ok]: CONFIG sanity\r\n[ok]: Piping raw protocol\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-random)\r\n[ok]: CONFIG REWRITE sanity\r\n[33/64 done]: integration/redis-cli (8 seconds)\r\nTesting unit/introspection-2\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-ttl)\r\n[ok]: Stream can be rewrite into AOF correctly after XDEL lastid\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: XGROUP HELP should not have unexpected options\r\n[ok]: test various edge cases of repl topology changes with missing pings at the end\r\n[34/64 done]: unit/type/stream (28 seconds)\r\nTesting unit/limits\r\n[ok]: CONFIG REWRITE handles save properly\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-random)\r\n[35/64 done]: unit/introspection (2 seconds)\r\nTesting unit/obuf-limits\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-lru)\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: Check if maxclients works refusing connections\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-lru)\r\n[36/64 done]: unit/limits (1 seconds)\r\nTesting unit/bitops\r\n[ok]: EVAL timeout from AOF\r\n[ok]: We can call scripts rewriting client->argv from Lua\r\n[ok]: Call Redis command with many args from Lua (issue #1764)\r\n[ok]: Number conversion precision test (issue #1118)\r\n[ok]: String containing number precision test (regression of issue #1118)\r\n[ok]: Verify negative arg count is error instead of crash (issue #1842)\r\n[ok]: Correct handling of reused argv (issue #1939)\r\n[ok]: Functions in the Redis namespace are able to report errors\r\n[ok]: Script with RESP3 map\r\n[ok]: BITCOUNT returns 0 against non existing key\r\n[ok]: BITCOUNT returns 0 with out of range indexes\r\n[ok]: BITCOUNT returns 0 with negative indexes where start > end\r\n[ok]: BITCOUNT against test vector #1\r\n[ok]: BITCOUNT against test vector #2\r\n[ok]: BITCOUNT against test vector #3\r\n[ok]: BITCOUNT against test vector #4\r\n[ok]: BITCOUNT against test vector #5\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-random)\r\n[ok]: BITCOUNT fuzzing without start/end\r\n[ok]: Timedout read-only scripts can be killed by SCRIPT KILL\r\n[ok]: Timedout read-only scripts can be killed by SCRIPT KILL even when use pcall\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-ttl)\r\n[ok]: TTL, TYPE and EXISTS do not alter the last access time of a key\r\n[ok]: Timedout script does not cause a false dead client\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: BITCOUNT fuzzing with start/end\r\n[ok]: BITCOUNT with start, end\r\n[ok]: BITCOUNT syntax error #1\r\n[ok]: BITCOUNT regression test for github issue #582\r\n[ok]: BITCOUNT misaligned prefix\r\n[ok]: BITCOUNT misaligned prefix + full words + remainder\r\n[ok]: BITOP NOT (empty string)\r\n[ok]: BITOP NOT (known string)\r\n[ok]: BITOP where dest and target are the same key\r\n[ok]: BITOP AND|OR|XOR don't change the string with single input key\r\n[ok]: BITOP missing key is considered a stream of zero\r\n[ok]: BITOP shorter keys are zero-padded to the key with max length\r\n[ok]: maxmemory - policy volatile-lru should only remove volatile keys.\r\n[ok]: Timedout script link is still usable after Lua returns\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 57900)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 3 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[ok]: PSYNC2: Set #3 to replicate from #0\r\n[ok]: PSYNC2: Set #4 to replicate from #3\r\n[ok]: PSYNC2: Set #1 to replicate from #0\r\n[ok]: PSYNC2: Set #2 to replicate from #1\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Timedout scripts that modified data can't be killed by SCRIPT KILL\r\n[ok]: SHUTDOWN NOSAVE can kill a timedout script anyway\r\n[ok]: maxmemory - policy volatile-lfu should only remove volatile keys.\r\n[ok]: Before the replica connects we issue two EVAL commands (scripts replication)\r\n[ok]: BITOP and fuzzing\r\n[ok]: maxmemory - policy volatile-random should only remove volatile keys.\r\n[ok]: Connect a replica to the master instance (scripts replication)\r\n[ok]: Now use EVALSHA against the master, with both SHAs (scripts replication)\r\n[ok]: If EVALSHA was replicated as EVAL, 'x' should be '4' (scripts replication)\r\n[ok]: Replication of script multiple pushes to list with BLPOP (scripts replication)\r\n[ok]: EVALSHA replication when first call is readonly (scripts replication)\r\n[ok]: Lua scripts using SELECT are replicated correctly (scripts replication)\r\n[ok]: maxmemory - policy volatile-ttl should only remove volatile keys.\r\n[ok]: BITOP or fuzzing\r\n[ok]: Before the replica connects we issue two EVAL commands (commands replication)\r\n[ok]: Connect a replica to the master instance (commands replication)\r\n[ok]: Now use EVALSHA against the master, with both SHAs (commands replication)\r\n[ok]: If EVALSHA was replicated as EVAL, 'x' should be '4' (commands replication)\r\n[ok]: Replication of script multiple pushes to list with BLPOP (commands replication)\r\n[ok]: EVALSHA replication when first call is readonly (commands replication)\r\n[ok]: Lua scripts using SELECT are replicated correctly (commands replication)\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: Chained replicas disconnect when replica re-connect with the same master\r\n[ok]: BITOP xor fuzzing\r\n[ok]: BITOP NOT fuzzing\r\n[ok]: BITOP with integer encoded source objects\r\n[ok]: BITOP with non string source key\r\n[ok]: BITOP with empty string after non empty string (issue #529)\r\n[ok]: BITPOS bit=0 with empty key returns 0\r\n[ok]: BITPOS bit=1 with empty key returns -1\r\n[ok]: BITPOS bit=0 with string less than 1 word works\r\n[ok]: BITPOS bit=1 with string less than 1 word works\r\n[ok]: BITPOS bit=0 starting at unaligned address\r\n[ok]: BITPOS bit=1 starting at unaligned address\r\n[ok]: BITPOS bit=0 unaligned+full word+reminder\r\n[ok]: BITPOS bit=1 unaligned+full word+reminder\r\n[ok]: BITPOS bit=1 returns -1 if string is all 0 bits\r\n[ok]: BITPOS bit=0 works with intervals\r\n[ok]: BITPOS bit=1 works with intervals\r\n[ok]: BITPOS bit=0 changes behavior if end is given\r\n[ok]: Test replication with blocking lists and sorted sets operations\r\n[ok]: BITPOS bit=1 fuzzy testing using SETBIT\r\n[37/64 done]: integration/psync2-pingoff (15 seconds)\r\nTesting unit/bitfield\r\n[ok]: Connect a replica to the master instance\r\n[ok]: Redis.replicate_commands() must be issued before any write\r\n[ok]: Redis.replicate_commands() must be issued before any write (2)\r\n[ok]: Redis.set_repl() must be issued after replicate_commands()\r\n[ok]: Redis.set_repl() don't accept invalid values\r\n[ok]: Test selective replication of certain Redis commands from Lua\r\n[ok]: PRNG is seeded randomly for command replication\r\n[ok]: Using side effects is not a problem with command replication\r\n[ok]: BITFIELD signed SET and GET basics\r\n[ok]: BITFIELD unsigned SET and GET basics\r\n[ok]: BITFIELD #<idx> form\r\n[ok]: BITFIELD basic INCRBY form\r\n[ok]: BITFIELD chaining of multiple commands\r\n[ok]: BITFIELD unsigned overflow wrap\r\n[ok]: BITFIELD unsigned overflow sat\r\n[ok]: BITFIELD signed overflow wrap\r\n[ok]: BITFIELD signed overflow sat\r\n[ok]: BITPOS bit=0 fuzzy testing using SETBIT\r\n[38/64 done]: integration/block-repl (26 seconds)\r\nTesting unit/geo\r\n[39/64 done]: unit/bitops (4 seconds)\r\nTesting unit/memefficiency\r\n[ok]: GEOADD create\r\n[ok]: GEOADD update\r\n[ok]: GEOADD update with CH option\r\n[ok]: GEOADD update with NX option\r\n[ok]: GEOADD update with XX option\r\n[ok]: GEOADD update with CH NX option\r\n[ok]: GEOADD update with CH XX option\r\n[ok]: GEOADD update with XX NX option will return syntax error\r\n[ok]: GEOADD update with invalid option\r\n[ok]: GEOADD invalid coordinates\r\n[ok]: GEOADD multi add\r\n[ok]: Check geoset values\r\n[ok]: GEORADIUS simple (sorted)\r\n[ok]: GEOSEARCH simple (sorted)\r\n[ok]: GEOSEARCH FROMLONLAT and FROMMEMBER cannot exist at the same time\r\n[ok]: GEOSEARCH FROMLONLAT and FROMMEMBER one must exist\r\n[ok]: GEOSEARCH BYRADIUS and BYBOX cannot exist at the same time\r\n[ok]: GEOSEARCH BYRADIUS and BYBOX one must exist\r\n[ok]: GEOSEARCH with STOREDIST option\r\n[ok]: GEORADIUS withdist (sorted)\r\n[ok]: GEOSEARCH withdist (sorted)\r\n[ok]: GEORADIUS with COUNT\r\n[ok]: GEORADIUS with ANY not sorted by default\r\n[ok]: GEORADIUS with ANY sorted by ASC\r\n[ok]: GEORADIUS with ANY but no COUNT\r\n[ok]: GEORADIUS with COUNT but missing integer argument\r\n[ok]: GEORADIUS with COUNT DESC\r\n[ok]: GEORADIUS HUGE, issue #2767\r\n[ok]: GEORADIUSBYMEMBER simple (sorted)\r\n[ok]: GEOSEARCH FROMMEMBER simple (sorted)\r\n[ok]: GEOSEARCH vs GEORADIUS\r\n[ok]: GEOSEARCH non square, long and narrow\r\n[ok]: GEOSEARCH corner point test\r\n[ok]: GEORADIUSBYMEMBER withdist (sorted)\r\n[ok]: GEOHASH is able to return geohash strings\r\n[ok]: GEOPOS simple\r\n[ok]: GEOPOS missing element\r\n[ok]: GEODIST simple & unit\r\n[ok]: GEODIST missing elements\r\n[ok]: GEORADIUS STORE option: syntax error\r\n[ok]: GEOSEARCHSTORE STORE option: syntax error\r\n[ok]: GEORANGE STORE option: incompatible options\r\n[ok]: GEORANGE STORE option: plain usage\r\n[ok]: GEOSEARCHSTORE STORE option: plain usage\r\n[ok]: GEORANGE STOREDIST option: plain usage\r\n[ok]: GEOSEARCHSTORE STOREDIST option: plain usage\r\n[ok]: GEORANGE STOREDIST option: COUNT ASC and DESC\r\n[ok]: GEOSEARCH the box spans -180 or 180\r\n[ok]: BITFIELD overflow detection fuzzing\r\n[ok]: TOUCH alters the last access time of a key\r\n[ok]: TOUCH returns the number of existing keys specified\r\n[ok]: command stats for GEOADD\r\n[ok]: command stats for EXPIRE\r\n[ok]: command stats for BRPOP\r\n[ok]: command stats for MULTI\r\n[ok]: command stats for scripts\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[40/64 done]: unit/scripting (11 seconds)\r\nTesting unit/hyperloglog\r\n[41/64 done]: unit/introspection-2 (6 seconds)\r\nTesting unit/lazyfree\r\n[ok]: BITFIELD overflow wrap fuzzing\r\n[ok]: BITFIELD regression for #3221\r\n[ok]: BITFIELD regression for #3564\r\n[ok]: Memory efficiency with values in range 32\r\n[ok]: BITFIELD: setup slave\r\n[ok]: BITFIELD: write on master, read on slave\r\n[ok]: BITFIELD_RO fails when write option is used\r\n[ok]: UNLINK can reclaim memory in background\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[42/64 done]: unit/bitfield (2 seconds)\r\nTesting unit/wait\r\n[ok]: FLUSHDB ASYNC can reclaim memory in background\r\n[ok]: Memory efficiency with values in range 64\r\n[43/64 done]: unit/lazyfree (2 seconds)\r\nTesting unit/pendingquerybuf\r\n[ok]: Setup slave\r\n[ok]: WAIT should acknowledge 1 additional copy of the data\r\n[ok]: Fuzzer corrupt restore payloads - sanitize_dump: yes\r\n[44/64 done]: integration/corrupt-dump-fuzzer (20 seconds)\r\nTesting unit/tls\r\n[ok]: Memory efficiency with values in range 128\r\n[ok]: HyperLogLog self test passes\r\n[ok]: PFADD without arguments creates an HLL value\r\n[ok]: Approximated cardinality after creation is zero\r\n[ok]: PFADD returns 1 when at least 1 reg was modified\r\n[ok]: PFADD returns 0 when no reg was modified\r\n[ok]: PFADD works with empty string (regression)\r\n[ok]: PFCOUNT returns approximated cardinality of set\r\n[45/64 done]: unit/tls (0 seconds)\r\nTesting unit/tracking\r\n[ok]: Clients are able to enable tracking and redirect it\r\n[ok]: The other connection is able to get invalidations\r\n[ok]: The client is now able to disable tracking\r\n[ok]: Clients can enable the BCAST mode with the empty prefix\r\n[ok]: The connection gets invalidation messages about all the keys\r\n[ok]: Clients can enable the BCAST mode with prefixes\r\n[ok]: Adding prefixes to BCAST mode works\r\n[ok]: Tracking NOLOOP mode in standard mode works\r\n[ok]: Tracking NOLOOP mode in BCAST mode works\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 91881)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 4 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #4 as master\r\n[ok]: PSYNC2: Set #2 to replicate from #4\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #1 to replicate from #3\r\n[ok]: PSYNC2: Set #0 to replicate from #4\r\n[ok]: Memory efficiency with values in range 1024\r\n[ok]: HyperLogLogs are promote from sparse to dense\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: WAIT should not acknowledge 2 additional copies of the data\r\n[ok]: Tracking gets notification of expired keys\r\n[ok]: HELLO 3 reply is correct\r\n[ok]: HELLO without protover\r\n[ok]: RESP3 based basic invalidation\r\n[ok]: RESP3 tracking redirection\r\n[ok]: Invalidations of previous keys can be redirected after switching to RESP3\r\n[ok]: Invalidations of new keys can be redirected after switching to RESP3\r\n[ok]: RESP3 Client gets tracking-redir-broken push message after cached key changed when rediretion client is terminated\r\n[ok]: Different clients can redirect to the same connection\r\n[ok]: Different clients using different protocols can track the same key\r\n[ok]: No invalidation message when using OPTIN option\r\n[ok]: Invalidation message sent when using OPTIN option with CLIENT CACHING yes\r\n[ok]: Invalidation message sent when using OPTOUT option\r\n[ok]: No invalidation message when using OPTOUT option with CLIENT CACHING no\r\n[ok]: Able to redirect to a RESP3 client\r\n[ok]: After switching from normal tracking to BCAST mode, no invalidation message is produced for pre-BCAST keys\r\n[ok]: BCAST with prefix collisions throw errors\r\n[ok]: Tracking gets notification on tracking table key eviction\r\n[ok]: Invalidation message received for flushall\r\n[ok]: Invalidation message received for flushdb\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: HyperLogLog sparse encoding stress test\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Additional at tail\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Broken magic\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Invalid encoding\r\n[ok]: Corrupted dense HyperLogLogs are detected: Wrong length\r\n[ok]: Server is able to evacuate enough keys when num of keys surpasses limit by more than defined initial effort\r\n[ok]: Tracking info is correct\r\n[ok]: CLIENT GETREDIR provides correct client id\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking off\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking on\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking on with options\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking optin\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking optout\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking bcast mode\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking redir broken\r\n[ok]: Memory efficiency with values in range 16384\r\n[46/64 done]: unit/tracking (1 seconds)\r\nTesting unit/oom-score-adj\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: CONFIG SET oom-score-adj works as expected\r\n[47/64 done]: unit/memefficiency (4 seconds)\r\nTesting unit/shutdown\r\n[ok]: WAIT should not acknowledge 1 additional copy if slave is blocked\r\n[ok]: Temp rdb will be deleted if we use bg_unlink when shutdown\r\n[ok]: Temp rdb will be deleted in signal handle\r\n[48/64 done]: unit/shutdown (0 seconds)\r\nTesting unit/networking\r\n[ok]: MASTER and SLAVE consistency with EVALSHA replication\r\n[ok]: CONFIG SET port number\r\n[ok]: Test replication partial resync: ok after delay (diskless: no, disabled, reconnect: 1)\r\n[err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\n[49/64 done]: unit/networking (1 seconds)\r\n[50/64 done]: unit/oom-score-adj (2 seconds)\r\n[ok]: WAIT implicitly blocks on client pause since ACKs aren't sent\r\n[ok]: PSYNC2 #3899 regression: verify consistency\r\n[51/64 done]: unit/wait (4 seconds)\r\n[ok]: Slave should be able to synchronize with the master\r\n[52/64 done]: integration/psync2-reg (22 seconds)\r\n[ok]: Detect write load to master\r\n[ok]: pending querybuf: check size of pending_querybuf after set a big value\r\n[ok]: SLAVE can reload \"lua\" AUX RDB fields of duplicated scripts\r\n[53/64 done]: unit/pendingquerybuf (6 seconds)\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 125895)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 5 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[ok]: PSYNC2: Set #2 to replicate from #0\r\n[ok]: PSYNC2: Set #4 to replicate from #2\r\n[ok]: PSYNC2: Set #3 to replicate from #2\r\n[ok]: PSYNC2: Set #1 to replicate from #3\r\n[54/64 done]: integration/replication-3 (34 seconds)\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Client output buffer hard limit is enforced\r\n[ok]: Replication: commands with many arguments (issue #1221)\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 190238)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 6 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #4 as master\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #1 to replicate from #4\r\n[ok]: PSYNC2: Set #2 to replicate from #3\r\n[ok]: PSYNC2: Set #0 to replicate from #2\r\n[ok]: Replication of SPOP command -- alsoPropagate() API\r\n[55/64 done]: integration/replication-4 (40 seconds)\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Test replication partial resync: backlog expired (diskless: no, disabled, reconnect: 1)\r\n[ok]: Client output buffer soft limit is not enforced if time is not overreached\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: no, swapdb, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: slave buffer are counted correctly\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 257556)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 7 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[ok]: PSYNC2: Set #1 to replicate from #0\r\n[ok]: PSYNC2: Set #2 to replicate from #1\r\n[ok]: PSYNC2: Set #3 to replicate from #2\r\n[ok]: PSYNC2: Set #4 to replicate from #0\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Client output buffer soft limit is enforced if time is overreached\r\n[ok]: No response for single command if client output buffer hard limit is enforced\r\n[ok]: No response for multi commands in pipeline if client output buffer limit is enforced\r\n[ok]: Execute transactions completely even if client output buffer limit is enforced\r\n[56/64 done]: unit/obuf-limits (27 seconds)\r\n[ok]: AOF rewrite during write load: RDB preamble=no\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=no, replica diskless=disabled\r\n[ok]: Turning off AOF kills the background writing child if any\r\n[ok]: replica buffer don't induce eviction\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 310403)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: Test replication partial resync: ok psync (diskless: no, swapdb, reconnect: 1)\r\n[ok]: AOF rewrite of list with quicklist encoding, string data\r\n[ok]: GEOSEARCH fuzzy test - byradius\r\n[ok]: Don't rehash if used memory exceeds maxmemory after rehash\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: PSYNC2: Bring the master back again for next test\r\n[ok]: PSYNC2: Partial resync after restart using RDB aux fields\r\n[ok]: AOF rewrite of list with quicklist encoding, int data\r\n[ok]: Detect write load to master\r\n[ok]: client tracking don't cause eviction feedback loop\r\n[57/64 done]: unit/maxmemory (36 seconds)\r\n[ok]: PSYNC2: Replica RDB restart with EVALSHA in backlog issue #4483\r\n[ok]: AOF rewrite of set with intset encoding, string data\r\n[58/64 done]: integration/psync2 (44 seconds)\r\n[ok]: AOF rewrite of set with hashtable encoding, string data\r\n[ok]: AOF rewrite of set with intset encoding, int data\r\n[ok]: AOF rewrite of set with hashtable encoding, int data\r\n[ok]: AOF rewrite of hash with ziplist encoding, string data\r\n[ok]: AOF rewrite of hash with hashtable encoding, string data\r\n[ok]: AOF rewrite of hash with ziplist encoding, int data\r\n[ok]: AOF rewrite of hash with hashtable encoding, int data\r\n[ok]: Test replication partial resync: no backlog (diskless: no, swapdb, reconnect: 1)\r\n[ok]: AOF rewrite of zset with ziplist encoding, string data\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: AOF rewrite of zset with skiplist encoding, string data\r\n[ok]: AOF rewrite of zset with ziplist encoding, int data\r\n[ok]: AOF rewrite of zset with skiplist encoding, int data\r\n[ok]: BGREWRITEAOF is delayed if BGSAVE is in progress\r\n[ok]: BGREWRITEAOF is refused if already in progress\r\n[59/64 done]: unit/aofrw (71 seconds)\r\n[ok]: GEOSEARCH fuzzy test - bybox\r\n[ok]: GEOSEARCH box edges fuzzy test\r\n[60/64 done]: north (43 seconds)\r\n[ok]: Fuzzing dense/sparse encoding: Redis should always detect errors\r\n[ok]: PFADD, PFCOUNT, PFMERGE type checking works\r\n[ok]: PFMERGE results on the cardinality of union of sets\r\n[ok]: Test replication partial resync: ok after delay (diskless: no, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Stress tester for #3343-alike bugs\r\n[ok]: PFCOUNT multiple-keys merge returns cardinality of union #1\r\n[ok]: PFCOUNT multiple-keys merge returns cardinality of union #2\r\n[ok]: PFDEBUG GETREG returns the HyperLogLog raw registers\r\n[ok]: PFADD / PFCOUNT cache invalidation works\r\n[61/64 done]: unit/hyperloglog (53 seconds)\r\n[ok]: Test replication partial resync: backlog expired (diskless: no, swapdb, reconnect: 1)\r\n[ok]: ziplist implementation: value encoding and backlink\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: yes, disabled, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=no, replica diskless=swapdb\r\n[ok]: ziplist implementation: encoding stress testing\r\n[62/64 done]: unit/type/list-3 (98 seconds)\r\n[ok]: Test replication partial resync: ok psync (diskless: yes, disabled, reconnect: 1)\r\nWaiting for process 11961 to exit...\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no backlog (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: ok after delay (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: backlog expired (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: yes, swapdb, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=yes, replica diskless=disabled\r\n[ok]: Test replication partial resync: ok psync (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no backlog (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: ok after delay (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: backlog expired (diskless: yes, swapdb, reconnect: 1)\r\n[63/64 done]: integration/replication-psync (172 seconds)\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=yes, replica diskless=swapdb\r\n[ok]: Master stream is correctly processed while the replica has a script in -BUSY state\r\n[ok]: slave fails full sync and diskless load swapdb recovers it\r\n[ok]: diskless loading short read\r\n[ok]: diskless no replicas drop during rdb pipe\r\n[ok]: diskless slow replicas drop during rdb pipe\r\n[ok]: diskless fast replicas drop during rdb pipe\r\n[ok]: diskless all replicas drop during rdb pipe\r\n[ok]: diskless timeout replicas drop during rdb pipe\r\n[ok]: diskless replication child being killed is collected\r\n[ok]: replicaof right after disconnection\r\n[ok]: Kill rdb child process if its dumping RDB is not useful\r\n[64/64 done]: integration/replication (257 seconds)\r\nTesting solo test\r\n[ok]: Active defrag\r\n[ok]: Active defrag big keys\r\n[ok]: Active defrag big list\r\n[ok]: Active defrag edge case\r\n[64/64 done]: defrag (98 seconds)\r\n\r\n                   The End\r\n\r\nExecution time of different units:\r\n  1 seconds - unit/printver\r\n  1 seconds - unit/type/incr\r\n  1 seconds - unit/info\r\n  1 seconds - unit/protocol\r\n  2 seconds - unit/keyspace\r\n  2 seconds - unit/auth\r\n  0 seconds - unit/quit\r\n  5 seconds - unit/type/hash\r\n  4 seconds - unit/multi\r\n  6 seconds - unit/type/set\r\n  5 seconds - unit/type/stream-cgroups\r\n  5 seconds - unit/sort\r\n  2 seconds - unit/acl\r\n  8 seconds - unit/type/list\r\n  8 seconds - unit/scan\r\n  8 seconds - unit/type/string\r\n  11 seconds - unit/other\r\n  12 seconds - unit/type/list-2\r\n  9 seconds - unit/latency-monitor\r\n  10 seconds - integration/replication-2\r\n  8 seconds - integration/aof\r\n  1 seconds - integration/convert-zipmap-hash-on-load\r\n  16 seconds - unit/expire\r\n  17 seconds - unit/type/zset\r\n  1 seconds - integration/logging\r\n  7 seconds - integration/rdb\r\n  8 seconds - integration/corrupt-dump\r\n  2 seconds - integration/redis-benchmark\r\n  5 seconds - integration/failover\r\n  0 seconds - unit/pubsub\r\n  2 seconds - unit/slowlog\r\n  26 seconds - unit/dump\r\n  8 seconds - integration/redis-cli\r\n  28 seconds - unit/type/stream\r\n  2 seconds - unit/introspection\r\n  1 seconds - unit/limits\r\n  15 seconds - integration/psync2-pingoff\r\n  26 seconds - integration/block-repl\r\n  4 seconds - unit/bitops\r\n  11 seconds - unit/scripting\r\n  6 seconds - unit/introspection-2\r\n  2 seconds - unit/bitfield\r\n  2 seconds - unit/lazyfree\r\n  20 seconds - integration/corrupt-dump-fuzzer\r\n  0 seconds - unit/tls\r\n  1 seconds - unit/tracking\r\n  4 seconds - unit/memefficiency\r\n  0 seconds - unit/shutdown\r\n  1 seconds - unit/networking\r\n  2 seconds - unit/oom-score-adj\r\n  4 seconds - unit/wait\r\n  22 seconds - integration/psync2-reg\r\n  6 seconds - unit/pendingquerybuf\r\n  34 seconds - integration/replication-3\r\n  40 seconds - integration/replication-4\r\n  27 seconds - unit/obuf-limits\r\n  36 seconds - unit/maxmemory\r\n  44 seconds - integration/psync2\r\n  71 seconds - unit/aofrw\r\n  43 seconds - north\r\n  53 seconds - unit/hyperloglog\r\n  98 seconds - unit/type/list-3\r\n  172 seconds - integration/replication-psync\r\n  257 seconds - integration/replication\r\n  98 seconds - defrag\r\n\r\n!!! WARNING The following tests failed:\r\n\r\n*** [err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\nCleanup: may take some time... OK\r\nMakefile:387: recipe for target 'test' failed\r\nmake[1]: *** [test] Error 1\r\nmake[1]: Leaving directory '/tmp/redis-stable/src'\r\nMakefile:6: recipe for target 'test' failed\r\nmake: *** [test] Error 2\r\n\r\n```\r\n</details>\r\n\r\n<details>\r\n<summary>Output of `./runtest --single unit/networking`</summary>\r\n\r\n```\r\nCleanup: may take some time... OK\r\nStarting test server at port 21079\r\n[ready]: 16821\r\nTesting unit/networking\r\n[ready]: 16822\r\n[ready]: 16823\r\n[ready]: 16824\r\n[ready]: 16825\r\n[ready]: 16826\r\n[ready]: 16827\r\n[ready]: 16828\r\n[ready]: 16830\r\n[ready]: 16829\r\n[ready]: 16831\r\n[ready]: 16832\r\n[ready]: 16833\r\n[ready]: 16834\r\n[ready]: 16835\r\n[ready]: 16836\r\n[ok]: CONFIG SET port number\r\n[err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\n[1/1 done]: unit/networking (1 seconds)\r\n\r\n                   The End\r\n\r\nExecution time of different units:\r\n  1 seconds - unit/networking\r\n\r\n!!! WARNING The following tests failed:\r\n\r\n*** [err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\nCleanup: may take some time... OK\r\n\r\n```\r\n</details>","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/8828/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/8828/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"id":16613613697,"node_id":"REFE_lADOAAJhcs4GV9DqzwAAAAPeP6CB","url":"https://api.github.com/repos/redis/redis/issues/events/16613613697","actor":{"login":"thohng","id":9668549,"node_id":"MDQ6VXNlcjk2Njg1NDk=","avatar_url":"https://avatars.githubusercontent.com/u/9668549?v=4","gravatar_id":"","url":"https://api.github.com/users/thohng","html_url":"https://github.com/thohng","followers_url":"https://api.github.com/users/thohng/followers","following_url":"https://api.github.com/users/thohng/following{/other_user}","gists_url":"https://api.github.com/users/thohng/gists{/gist_id}","starred_url":"https://api.github.com/users/thohng/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/thohng/subscriptions","organizations_url":"https://api.github.com/users/thohng/orgs","repos_url":"https://api.github.com/users/thohng/repos","events_url":"https://api.github.com/users/thohng/events{/privacy}","received_events_url":"https://api.github.com/users/thohng/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"3c23b5ffd0d7dd01df79154c1701d4d3ded7bf66","commit_url":"https://api.github.com/repos/teslahub/redis/commits/3c23b5ffd0d7dd01df79154c1701d4d3ded7bf66","created_at":"2025-03-06T09:02:58Z","performed_via_github_app":null}]