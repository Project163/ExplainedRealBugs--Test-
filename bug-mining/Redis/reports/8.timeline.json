[{"id":16041371,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDE2MDQxMzcx","url":"https://api.github.com/repos/redis/redis/issues/events/16041371","actor":{"login":"atanivist","id":1767603,"node_id":"MDQ6VXNlcjE3Njc2MDM=","avatar_url":"https://avatars.githubusercontent.com/u/1767603?v=4","gravatar_id":"","url":"https://api.github.com/users/atanivist","html_url":"https://github.com/atanivist","followers_url":"https://api.github.com/users/atanivist/followers","following_url":"https://api.github.com/users/atanivist/following{/other_user}","gists_url":"https://api.github.com/users/atanivist/gists{/gist_id}","starred_url":"https://api.github.com/users/atanivist/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/atanivist/subscriptions","organizations_url":"https://api.github.com/users/atanivist/orgs","repos_url":"https://api.github.com/users/atanivist/repos","events_url":"https://api.github.com/users/atanivist/events{/privacy}","received_events_url":"https://api.github.com/users/atanivist/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2012-05-23T00:10:06Z","performed_via_github_app":null},{"actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2012-05-23T08:37:37Z","updated_at":"2012-05-23T08:37:37Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/519","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/519/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/519/comments","events_url":"https://api.github.com/repos/redis/redis/issues/519/events","html_url":"https://github.com/redis/redis/issues/519","id":4707123,"node_id":"MDU6SXNzdWU0NzA3MTIz","number":519,"title":"ZINTERSTORE mixing sets and sorted sets may produce wrong results.","user":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":155760,"node_id":"MDU6TGFiZWwxNTU3NjA=","url":"https://api.github.com/repos/redis/redis/labels/critical%20bug","name":"critical bug","color":"e10c02","default":false,"description":null}],"state":"closed","locked":false,"assignee":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"assignees":[{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false}],"milestone":{"url":"https://api.github.com/repos/redis/redis/milestones/1","html_url":"https://github.com/redis/redis/milestone/1","labels_url":"https://api.github.com/repos/redis/redis/milestones/1/labels","id":38963,"node_id":"MDk6TWlsZXN0b25lMzg5NjM=","number":1,"title":"Redis 2.6","description":"Redis 2.6, first version of Redis with scripting support.","creator":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"open_issues":0,"closed_issues":75,"state":"closed","created_at":"2011-09-20T12:59:46Z","updated_at":"2014-12-11T14:54:39Z","due_on":null,"closed_at":"2012-10-05T09:21:16Z"},"comments":1,"created_at":"2012-05-23T08:35:57Z","updated_at":"2012-05-23T09:53:45Z","closed_at":"2012-05-23T09:53:45Z","author_association":"CONTRIBUTOR","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"**Joel Stevenson reports:**\n\nI have two sets and a single sorted set and I'm trying to use zinterstore to get the scored intersection of all three.  The operation is failing with my production data but succeeding if I substitute a test sorted set it works in some cases but not all and I'm stumped about why.\n\nTo setup the test, add three entries to set \"one\", four entries to set \"two\" - including a signle entry that exists in set \"one\", and four entries in the sorted set - including that same single entry from set \"one\"\n\nsadd one 100 101 102 103 \nsadd two 100 200 201 202\nzadd three 1 500 1 501 1 502 1 503 1 100\n\nNow if you run\n\nzinterstore to_here 3 one two three WEIGHTS 0 0 1\n\nNothing is found to intersect.\n\nCreate a new sort set \"four\":\n\nzadd four 1 600 1 100 \n\nzinterstore to_here 3 one two four WEIGHTS 0 0 1\n\nThere is an intersection on the entry 100!\n\nMy production data isn't so simple but I'm seeing the same result, some intersections appear to work, at least in part, but others fail completely.  I'm sure I must be doing something wrong but I can't see what it is.  Can anyone help me out?\n\nThis happens on redis versions 2.4.13 and the latest 2.6 RC.\n\n**Josiah Carlson adds:**\n\nTesting against Redis 2.4.1, 2.4.7, 2.4.10 your intersection works for me.\nTesting against Redis 2.4.13 however, fails.\n\nThis looks like a bug to me.\n","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/519/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/519/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"id":16061360,"node_id":"MDEzOkFzc2lnbmVkRXZlbnQxNjA2MTM2MA==","url":"https://api.github.com/repos/redis/redis/issues/events/16061360","actor":{"login":"ghost","id":10137,"node_id":"MDQ6VXNlcjEwMTM3","avatar_url":"https://avatars.githubusercontent.com/u/10137?v=4","gravatar_id":"","url":"https://api.github.com/users/ghost","html_url":"https://github.com/ghost","followers_url":"https://api.github.com/users/ghost/followers","following_url":"https://api.github.com/users/ghost/following{/other_user}","gists_url":"https://api.github.com/users/ghost/gists{/gist_id}","starred_url":"https://api.github.com/users/ghost/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ghost/subscriptions","organizations_url":"https://api.github.com/users/ghost/orgs","repos_url":"https://api.github.com/users/ghost/repos","events_url":"https://api.github.com/users/ghost/events{/privacy}","received_events_url":"https://api.github.com/users/ghost/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"assigned","commit_id":null,"commit_url":null,"created_at":"2012-05-23T08:37:56Z","assignee":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"performed_via_github_app":null},{"id":16061361,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDE2MDYxMzYx","url":"https://api.github.com/repos/redis/redis/issues/events/16061361","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2012-05-23T08:37:56Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/redis/redis/issues/comments/5867759","html_url":"https://github.com/redis/redis/issues/516#issuecomment-5867759","issue_url":"https://api.github.com/repos/redis/redis/issues/516","id":5867759,"node_id":"MDEyOklzc3VlQ29tbWVudDU4Njc3NTk=","user":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2012-05-23T08:38:13Z","updated_at":"2012-05-23T08:38:13Z","body":"Thanks, investigating right now.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/comments/5867759/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false}},{"id":16064733,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDE2MDY0NzMz","url":"https://api.github.com/repos/redis/redis/issues/events/16064733","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"b0a20939562ede36e6e66c75a60abf423bee15ab","commit_url":"https://api.github.com/repos/redis/redis/commits/b0a20939562ede36e6e66c75a60abf423bee15ab","created_at":"2012-05-23T09:34:10Z","performed_via_github_app":null},{"id":16064739,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDE2MDY0NzM5","url":"https://api.github.com/repos/redis/redis/issues/events/16064739","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"4dada1b5bce3da69899eb14364142819002cf029","commit_url":"https://api.github.com/repos/redis/redis/commits/4dada1b5bce3da69899eb14364142819002cf029","created_at":"2012-05-23T09:34:14Z","performed_via_github_app":null},{"id":16064740,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDE2MDY0NzQw","url":"https://api.github.com/repos/redis/redis/issues/events/16064740","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"348ee1a40a4d8105dfaf6fa2ab2dffc15a47d86d","commit_url":"https://api.github.com/repos/redis/redis/commits/348ee1a40a4d8105dfaf6fa2ab2dffc15a47d86d","created_at":"2012-05-23T09:34:16Z","performed_via_github_app":null},{"url":"https://api.github.com/repos/redis/redis/issues/comments/5869022","html_url":"https://github.com/redis/redis/issues/516#issuecomment-5869022","issue_url":"https://api.github.com/repos/redis/redis/issues/516","id":5869022,"node_id":"MDEyOklzc3VlQ29tbWVudDU4NjkwMjI=","user":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2012-05-23T09:54:03Z","updated_at":"2012-05-23T09:54:03Z","body":"Fixed in 2.4.14, already available for download. Thanks.\n","author_association":"CONTRIBUTOR","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/comments/5869022/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"performed_via_github_app":null,"event":"commented","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false}},{"id":16952381,"node_id":"MDExOkNsb3NlZEV2ZW50MTY5NTIzODE=","url":"https://api.github.com/repos/redis/redis/issues/events/16952381","actor":{"login":"antirez","id":65632,"node_id":"MDQ6VXNlcjY1NjMy","avatar_url":"https://avatars.githubusercontent.com/u/65632?v=4","gravatar_id":"","url":"https://api.github.com/users/antirez","html_url":"https://github.com/antirez","followers_url":"https://api.github.com/users/antirez/followers","following_url":"https://api.github.com/users/antirez/following{/other_user}","gists_url":"https://api.github.com/users/antirez/gists{/gist_id}","starred_url":"https://api.github.com/users/antirez/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/antirez/subscriptions","organizations_url":"https://api.github.com/users/antirez/orgs","repos_url":"https://api.github.com/users/antirez/repos","events_url":"https://api.github.com/users/antirez/events{/privacy}","received_events_url":"https://api.github.com/users/antirez/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"closed","commit_id":null,"commit_url":null,"created_at":"2012-06-05T06:51:59Z","state_reason":null,"performed_via_github_app":null},{"id":21695023,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDIxNjk1MDIz","url":"https://api.github.com/repos/redis/redis/issues/events/21695023","actor":{"login":"tsee","id":87995,"node_id":"MDQ6VXNlcjg3OTk1","avatar_url":"https://avatars.githubusercontent.com/u/87995?v=4","gravatar_id":"","url":"https://api.github.com/users/tsee","html_url":"https://github.com/tsee","followers_url":"https://api.github.com/users/tsee/followers","following_url":"https://api.github.com/users/tsee/following{/other_user}","gists_url":"https://api.github.com/users/tsee/gists{/gist_id}","starred_url":"https://api.github.com/users/tsee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tsee/subscriptions","organizations_url":"https://api.github.com/users/tsee/orgs","repos_url":"https://api.github.com/users/tsee/repos","events_url":"https://api.github.com/users/tsee/events{/privacy}","received_events_url":"https://api.github.com/users/tsee/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"74ed594e545d1c34920399b7bd46a99aba7d2b8f","commit_url":"https://api.github.com/repos/tsee/redis/commits/74ed594e545d1c34920399b7bd46a99aba7d2b8f","created_at":"2012-07-31T18:12:40Z","performed_via_github_app":null},{"id":21695025,"node_id":"MDE1OlN1YnNjcmliZWRFdmVudDIxNjk1MDI1","url":"https://api.github.com/repos/redis/redis/issues/events/21695025","actor":{"login":"tsee","id":87995,"node_id":"MDQ6VXNlcjg3OTk1","avatar_url":"https://avatars.githubusercontent.com/u/87995?v=4","gravatar_id":"","url":"https://api.github.com/users/tsee","html_url":"https://github.com/tsee","followers_url":"https://api.github.com/users/tsee/followers","following_url":"https://api.github.com/users/tsee/following{/other_user}","gists_url":"https://api.github.com/users/tsee/gists{/gist_id}","starred_url":"https://api.github.com/users/tsee/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/tsee/subscriptions","organizations_url":"https://api.github.com/users/tsee/orgs","repos_url":"https://api.github.com/users/tsee/repos","events_url":"https://api.github.com/users/tsee/events{/privacy}","received_events_url":"https://api.github.com/users/tsee/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"subscribed","commit_id":null,"commit_url":null,"created_at":"2012-07-31T18:12:40Z","performed_via_github_app":null},{"id":158917624,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDE1ODkxNzYyNA==","url":"https://api.github.com/repos/redis/redis/issues/events/158917624","actor":{"login":"Hailei","id":1724869,"node_id":"MDQ6VXNlcjE3MjQ4Njk=","avatar_url":"https://avatars.githubusercontent.com/u/1724869?v=4","gravatar_id":"","url":"https://api.github.com/users/Hailei","html_url":"https://github.com/Hailei","followers_url":"https://api.github.com/users/Hailei/followers","following_url":"https://api.github.com/users/Hailei/following{/other_user}","gists_url":"https://api.github.com/users/Hailei/gists{/gist_id}","starred_url":"https://api.github.com/users/Hailei/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Hailei/subscriptions","organizations_url":"https://api.github.com/users/Hailei/orgs","repos_url":"https://api.github.com/users/Hailei/repos","events_url":"https://api.github.com/users/Hailei/events{/privacy}","received_events_url":"https://api.github.com/users/Hailei/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"dca7ab1bbdb62997378a81ca4bf0b76152dd6511","commit_url":"https://api.github.com/repos/Hailei/redis/commits/dca7ab1bbdb62997378a81ca4bf0b76152dd6511","created_at":"2014-08-29T11:01:28Z","performed_via_github_app":null},{"actor":{"login":"Dudeguy409","id":8725918,"node_id":"MDQ6VXNlcjg3MjU5MTg=","avatar_url":"https://avatars.githubusercontent.com/u/8725918?v=4","gravatar_id":"","url":"https://api.github.com/users/Dudeguy409","html_url":"https://github.com/Dudeguy409","followers_url":"https://api.github.com/users/Dudeguy409/followers","following_url":"https://api.github.com/users/Dudeguy409/following{/other_user}","gists_url":"https://api.github.com/users/Dudeguy409/gists{/gist_id}","starred_url":"https://api.github.com/users/Dudeguy409/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Dudeguy409/subscriptions","organizations_url":"https://api.github.com/users/Dudeguy409/orgs","repos_url":"https://api.github.com/users/Dudeguy409/repos","events_url":"https://api.github.com/users/Dudeguy409/events{/privacy}","received_events_url":"https://api.github.com/users/Dudeguy409/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2015-10-21T18:43:44Z","updated_at":"2015-10-21T18:43:44Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/2818","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/2818/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/2818/comments","events_url":"https://api.github.com/repos/redis/redis/issues/2818/events","html_url":"https://github.com/redis/redis/issues/2818","id":112653626,"node_id":"MDU6SXNzdWUxMTI2NTM2MjY=","number":2818,"title":"Make Test Eror","user":{"login":"Dudeguy409","id":8725918,"node_id":"MDQ6VXNlcjg3MjU5MTg=","avatar_url":"https://avatars.githubusercontent.com/u/8725918?v=4","gravatar_id":"","url":"https://api.github.com/users/Dudeguy409","html_url":"https://github.com/Dudeguy409","followers_url":"https://api.github.com/users/Dudeguy409/followers","following_url":"https://api.github.com/users/Dudeguy409/following{/other_user}","gists_url":"https://api.github.com/users/Dudeguy409/gists{/gist_id}","starred_url":"https://api.github.com/users/Dudeguy409/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/Dudeguy409/subscriptions","organizations_url":"https://api.github.com/users/Dudeguy409/orgs","repos_url":"https://api.github.com/users/Dudeguy409/repos","events_url":"https://api.github.com/users/Dudeguy409/events{/privacy}","received_events_url":"https://api.github.com/users/Dudeguy409/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":155763,"node_id":"MDU6TGFiZWwxNTU3NjM=","url":"https://api.github.com/repos/redis/redis/labels/WAITING-OP-REPLY","name":"WAITING-OP-REPLY","color":"02d7e1","default":false,"description":""},{"id":4550344,"node_id":"MDU6TGFiZWw0NTUwMzQ0","url":"https://api.github.com/repos/redis/redis/labels/testing","name":"testing","color":"5319e7","default":false,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":11,"created_at":"2015-10-21T18:43:43Z","updated_at":"2017-07-07T15:46:22Z","closed_at":"2017-07-07T15:46:22Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"andrew@andrew-VirtualBox:~/redis-stable$ make test\ncd src && make test\nmake[1]: Entering directory `/home/andrew/redis-stable/src'\nCleanup: may take some time... OK\nStarting test server at port 11111\n\nTesting unit/printver\n\nTesting unit/dump\n\nTesting unit/auth\n\nTesting unit/protocol\n\nTesting unit/basic\n\nTesting unit/scan\n\nTesting unit/type/list\n\nTesting unit/type/list-2\n\nTesting unit/type/list-3\n\nTesting unit/type/set\n\nTesting unit/type/zset\n\nTesting unit/type/hash\n\nTesting unit/sort\n\nTesting unit/expire\n\nTesting unit/other\n\nTesting unit/multi\n[ok](DBSIZE): AUTH fails if there is no password configured server side\nTesting Redis version 3.0.5 (00000000)\n[ok](DBSIZE): DEL all keys to start with a clean DB\n[ok](DBSIZE): SET and GET an item\n[ok](DBSIZE): DUMP / RESTORE are able to serialize / unserialize a simple key\n[ok](DBSIZE): RESTORE can set an arbitrary expire to the materialized key\n[ok](DBSIZE): RESTORE can set an expire that overflows a 32 bit integer\n[ok](DBSIZE): RESTORE returns an error of the key already exists\n[ok](DBSIZE): SET and GET an empty item\n[ok](DBSIZE): DEL against a single item\n[ok](DBSIZE): Vararg DEL\n[ok](DBSIZE): RESTORE can overwrite an existing key with REPLACE\n[ok](DBSIZE): Explicit regression for a list bug\n[ok](DBSIZE): SCAN basic\n[ok](DBSIZE): LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - ziplist\n[ok](DBSIZE): MUTLI / EXEC basics\n[ok](DBSIZE): SAVE - make sure there are all the types as values\n[ok](DBSIZE): EXPIRE - set timeouts multiple times\n[ok](DBSIZE): Ziplist: SORT BY key\n[ok](DBSIZE): HSET/HLEN - Small hash creation\n[ok](DBSIZE): Check encoding - ziplist\n[ok](DBSIZE): SADD, SCARD, SISMEMBER, SMEMBERS basics - regular set\n[ok](DBSIZE): KEYS with pattern\n[ok](DBSIZE): RESTORE can detect a syntax error for unrecongized options\n[ok](DBSIZE): LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - regular list\n\n[ok](DBSIZE): EXPIRE - It should be still possible to read 'x'\n[ok](DBSIZE): Ziplist: SORT BY key with limit\n[ok](DBSIZE): Is the small hash encoded with a ziplist?\n[ok](DBSIZE): ZSET basic ZADD and score update - ziplist\n[ok](DBSIZE): SADD, SCARD, SISMEMBER, SMEMBERS basics - intset\n[ok](DBSIZE): KEYS to get all keys\n[ok](DBSIZE): DUMP of non existing key returns nil\n[ok](DBSIZE): R/LPOP against empty list\n\n[ok](DBSIZE): Nested MULTI are not allowed\n[ok](DBSIZE): Ziplist: SORT BY hash field\n[ok](DBSIZE): ZSET element can't be set to NaN with ZADD - ziplist\n[ok](DBSIZE): SADD against non set\n[ok](DBSIZE): Variadic RPUSH/LPUSH\n[ok](DBSIZE): DEL all keys\n[ok](DBSIZE): MULTI where commands alter argc/argv\n[ok](DBSIZE): ZSET element can't be set to NaN with ZINCRBY\n[ok](DBSIZE): SADD a non-integer against an intset\n[ok](DBSIZE): DEL a list - ziplist\n[ok](DBSIZE): WATCH inside MULTI is not allowed\n[ok](DBSIZE): ZADD with options syntax error with incomplete pair\n[ok](DBSIZE): SADD an integer larger than 64 bits\n[ok](DBSIZE): EXEC fails if there are errors while queueing commands #1\n[ok](DBSIZE): DEL a list - regular list\n[ok](DBSIZE): ZADD XX option without key - ziplist\n[ok](DBSIZE): EXEC fails if there are errors while queueing commands #2\n[ok](DBSIZE): BLPOP, BRPOP: single existing list - linkedlist\n[ok](DBSIZE): ZADD XX existing key - ziplist\n[ok](DBSIZE): If EXEC aborts, the client MULTI state is cleared\n[ok](DBSIZE): BLPOP, BRPOP: multiple existing lists - linkedlist\n[ok](DBSIZE): ZADD XX returns the number of elements actually added\n[ok](DBSIZE): EXEC works on WATCHed key not modified\n[ok](DBSIZE): BLPOP, BRPOP: second list has an entry - linkedlist\n[ok](DBSIZE): ZADD XX updates existing elements score\n[ok](DBSIZE): EXEC fail on WATCHed key modified (1 key of 1 watched)\n[ok](DBSIZE): BRPOPLPUSH - linkedlist\n[ok](DBSIZE): ZADD XX and NX are not compatible\n[ok](DBSIZE): EXEC fail on WATCHed key modified (1 key of 5 watched)\n[ok](DBSIZE): BLPOP, BRPOP: single existing list - ziplist\n[ok](DBSIZE): EXEC fail on WATCHed key modified by SORT with STORE even if the result is empty\n[ok](DBSIZE): ZADD NX with non exisitng key\n[ok](DBSIZE): BLPOP, BRPOP: multiple existing lists - ziplist\n[ok](DBSIZE): After successful EXEC key is no longer watched\n[ok](DBSIZE): ZADD NX only add new elements without updating old ones\n[ok](DBSIZE): After failed EXEC key is no longer watched\n[ok](DBSIZE): BLPOP, BRPOP: second list has an entry - ziplist\n[ok](DBSIZE): ZADD INCR works like ZINCRBY\n[ok](DBSIZE): It is possible to UNWATCH\n[ok](DBSIZE): BRPOPLPUSH - ziplist\n[ok](DBSIZE): ZADD INCR works with a single score-elemenet pair\n[ok](DBSIZE): UNWATCH when there is nothing watched works as expected\n[ok](DBSIZE): BLPOP, LPUSH + DEL should not awake blocked client\n[ok](DBSIZE): ZADD CH option changes return value to all changed elements\n[ok](DBSIZE): BLPOP, LPUSH + DEL + SET should not awake blocked client\n[ok](DBSIZE): ZINCRBY calls leading to NaN result in error\n[ok](DBSIZE): BLPOP with same key multiple times should work (issue #801)\n[ok](DBSIZE): ZADD - Variadic version base case\n[ok](DBSIZE): MULTI/EXEC is isolated from the point of view of BLPOP\n[ok](DBSIZE): FLUSHALL is able to touch the watched keys\n[ok](DBSIZE): ZADD - Return value is the number of actually added items\n[ok](DBSIZE): BLPOP with variadic LPUSH\n[ok](DBSIZE): ZADD - Variadic version does not add nothing on single parsing err\n[ok](DBSIZE): ZADD - Variadic version will raise error on missing arg\n[ok](DBSIZE): ZINCRBY does not work variadic even if shares ZADD implementation\n[ok](DBSIZE): EXPIRE - After 2.1 seconds the key should no longer be here\n[ok](DBSIZE): Handle an empty query\n[ok](DBSIZE): ZCARD basics - ziplist\n[ok](DBSIZE): EXPIRE - write on expire should work\n[ok](DBSIZE): ZREM removes key after last element is removed\n[ok](DBSIZE): EXPIREAT - Check for EXPIRE alike behavior\n[ok](DBSIZE): ZREM variadic version\n[ok](DBSIZE): SETEX - Set + Expire combo operation. Check for TTL\n[ok](DBSIZE): ZREM variadic version -- remove elements after key deletion\n[ok](DBSIZE): SETEX - Check value\n[ok](DBSIZE): ZRANGE basics - ziplist\n[ok](DBSIZE): SETEX - Overwrite old key\n[ok](DBSIZE): ZREVRANGE basics - ziplist\n[ok](DBSIZE): ZRANK/ZREVRANK basics - ziplist\n[ok](DBSIZE): ZRANK - after deletion - ziplist\n[ok](DBSIZE): ZINCRBY - can create a new sorted set - ziplist\n[ok](DBSIZE): ZINCRBY - increment and decrement - ziplist\n[ok](DBSIZE): ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics\n[ok](DBSIZE): ZRANGEBYSCORE with WITHSCORES\n[ok](DBSIZE): ZRANGEBYSCORE with LIMIT\n[ok](DBSIZE): ZRANGEBYSCORE with LIMIT and WITHSCORES\n[ok](DBSIZE): ZRANGEBYSCORE with non-value min or max\n[ok](DBSIZE): ZRANGEBYLEX/ZREVRANGEBYLEX/ZCOUNT basics\n[ok](DBSIZE): Negative multibulk length\n[ok](DBSIZE): ZRANGEBYSLEX with LIMIT\n[ok](DBSIZE): Out of range multibulk length\n[ok](DBSIZE): ZRANGEBYLEX with invalid lex range specifiers\n[ok](DBSIZE): Wrong multibulk payload header\n[ok](DBSIZE): Negative multibulk payload length\n[ok](DBSIZE): Out of range multibulk payload length\n[ok](DBSIZE): Non-number multibulk payload length\n[ok](DBSIZE): Multi bulk request not followed by bulk arguments\n[ok](DBSIZE): Generic wrong number of args\n[ok](DBSIZE): SCAN COUNT\n[ok](DBSIZE): Unbalanced number of quotes\n[ok](DBSIZE): BRPOPLPUSH with zero timeout should block indefinitely\n[ok](DBSIZE): ZREMRANGEBYSCORE basics\n[ok](DBSIZE): ZREMRANGEBYSCORE with non-value min or max\n[ok](DBSIZE): FLUSHALL does not touch non affected keys\n[ok](DBSIZE): SADD overflows the maximum allowed integers in an intset\n[ok](DBSIZE): FLUSHDB is able to touch the watched keys\n[ok](DBSIZE): Variadic SADD\n[ok](DBSIZE): FLUSHDB does not touch non affected keys\n[ok](DBSIZE): WATCH is able to remember the DB a key belongs to\n[ok](DBSIZE): WATCH will consider touched keys target of EXPIRE\n[ok](DBSIZE): ZREMRANGEBYRANK basics\n[ok](DBSIZE): ZUNIONSTORE against non-existing key doesn't set destination - ziplist\n[ok](DBSIZE): ZUNIONSTORE with empty set - ziplist\n[ok](DBSIZE): SETEX - Wait for the key to expire\n[ok](DBSIZE): SETEX - Wrong time parameter\n[ok](DBSIZE): PERSIST can undo an EXPIRE\n[ok](DBSIZE): PERSIST returns 0 against non existing or non volatile keys\n[ok](DBSIZE): SCAN MATCH\n[ok](DBSIZE): ZUNIONSTORE basics - ziplist\n[ok](DBSIZE): ZUNIONSTORE with weights - ziplist\n[ok](DBSIZE): SSCAN with encoding intset\n[ok](DBSIZE): ZUNIONSTORE with a regular set and weights - ziplist\n[ok](DBSIZE): ZUNIONSTORE with AGGREGATE MIN - ziplist\n[ok](DBSIZE): ZUNIONSTORE with AGGREGATE MAX - ziplist\n[ok](DBSIZE): ZINTERSTORE basics - ziplist\n[ok](DBSIZE): ZINTERSTORE with weights - ziplist\n[ok](DBSIZE): BRPOPLPUSH with a client BLPOPing the target list\n[ok](DBSIZE): BRPOPLPUSH with wrong source type\n[ok](DBSIZE): ZINTERSTORE with a regular set and weights - ziplist\n[ok](DBSIZE): ZINTERSTORE with AGGREGATE MIN - ziplist\n[ok](DBSIZE): ZINTERSTORE with AGGREGATE MAX - ziplist\n[ok](DBSIZE): SSCAN with encoding hashtable\n[ok](DBSIZE): ZUNIONSTORE with +inf/-inf scores - ziplist\n[ok](DBSIZE): ZUNIONSTORE with NaN weights ziplist\n[ok](DBSIZE): HSCAN with encoding ziplist\n[ok](DBSIZE): ZINTERSTORE with +inf/-inf scores - ziplist\n[ok](DBSIZE): ZINTERSTORE with NaN weights ziplist\n[ok](DBSIZE): Check encoding - skiplist\n[ok](DBSIZE): ZSET basic ZADD and score update - skiplist\n[ok](DBSIZE): ZSET element can't be set to NaN with ZADD - skiplist\n[ok](DBSIZE): ZSET element can't be set to NaN with ZINCRBY\n[ok](DBSIZE): ZADD with options syntax error with incomplete pair\n[ok](DBSIZE): ZADD XX option without key - skiplist\n[ok](DBSIZE): WATCH will not consider touched expired keys\n[ok](DBSIZE): DISCARD should clear the WATCH dirty flag on the client\n[ok](DBSIZE): DISCARD should UNWATCH all the keys\n[ok](DBSIZE): ZADD XX existing key - skiplist\n[ok](DBSIZE): ZADD XX returns the number of elements actually added\n[ok](DBSIZE): ZADD XX updates existing elements score\n[ok](DBSIZE): ZADD XX and NX are not compatible\n[ok](DBSIZE): ZADD NX with non exisitng key\n[ok](DBSIZE): ZADD NX only add new elements without updating old ones\n[ok](DBSIZE): BRPOPLPUSH with wrong destination type\n[ok](DBSIZE): BRPOPLPUSH maintains order of elements after failure\n\nTesting unit/quit\n[ok](DBSIZE): ZADD INCR works like ZINCRBY\n[ok](DBSIZE): ZADD INCR works with a single score-elemenet pair\n[ok](DBSIZE): BRPOPLPUSH with multiple blocked clients\n[ok](DBSIZE): ZADD CH option changes return value to all changed elements\n[ok](DBSIZE): ZINCRBY calls leading to NaN result in error\n[ok](DBSIZE): ZADD - Variadic version base case\n[ok](DBSIZE): ZADD - Return value is the number of actually added items\n[ok](DBSIZE): ZADD - Variadic version does not add nothing on single parsing err\n[ok](DBSIZE): ZADD - Variadic version will raise error on missing arg\n[ok](DBSIZE): ZINCRBY does not work variadic even if shares ZADD implementation\n[ok](DBSIZE): ZCARD basics - skiplist\n[ok](DBSIZE): ZREM removes key after last element is removed\n[ok](DBSIZE): Linked BRPOPLPUSH\n[ok](DBSIZE): ZREM variadic version\n[ok](DBSIZE): ZREM variadic version -- remove elements after key deletion\n[ok](DBSIZE): ZRANGE basics - skiplist\n[ok](DBSIZE): EXPIRE pricision is now the millisecond\n[ok](DBSIZE): Circular BRPOPLPUSH\n[ok](DBSIZE): ZREVRANGE basics - skiplist\n[ok](DBSIZE): ZRANK/ZREVRANK basics - skiplist\n[ok](DBSIZE): Self-referential BRPOPLPUSH\n[ok](DBSIZE): ZRANK - after deletion - skiplist\n[ok](DBSIZE): BRPOPLPUSH inside a transaction\n[ok](DBSIZE): ZINCRBY - can create a new sorted set - skiplist\n[ok](DBSIZE): ZINCRBY - increment and decrement - skiplist\n[ok](DBSIZE): PUSH resulting from BRPOPLPUSH affect WATCH\n[ok](DBSIZE): ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics\n[ok](DBSIZE): BRPOPLPUSH does not affect WATCH while still blocked\n[ok](DBSIZE): ZRANGEBYSCORE with WITHSCORES\n[ok](DBSIZE): ZRANGEBYSCORE with LIMIT\n[ok](DBSIZE): ZRANGEBYSCORE with LIMIT and WITHSCORES\n[ok](DBSIZE): ZRANGEBYSCORE with non-value min or max\n[ok](DBSIZE): ZRANGEBYLEX/ZREVRANGEBYLEX/ZCOUNT basics\n[ok](DBSIZE): ZRANGEBYSLEX with LIMIT\n[ok](DBSIZE): ZRANGEBYLEX with invalid lex range specifiers\n[ok](DBSIZE): AUTH fails when a wrong password is given\n[ok](DBSIZE): Arbitrary command gives an error when AUTH is required\n[ok](DBSIZE): AUTH succeeds when the right password is given\n[ok](DBSIZE): Once AUTH succeeded we can actually send commands to the server\n[ok](DBSIZE): ZREMRANGEBYSCORE basics\n[ok](DBSIZE): ZREMRANGEBYSCORE with non-value min or max\n[ok](DBSIZE): PEXPIRE/PSETEX/PEXPIREAT can set sub-second expires\n[ok](DBSIZE): TTL returns tiem to live in seconds\n[ok](DBSIZE): PTTL returns time to live in milliseconds\n[ok](DBSIZE): TTL / PTTL return -1 if key has no expire\n[ok](DBSIZE): TTL / PTTL return -2 if key does not exit\n[ok](DBSIZE): HSCAN with encoding hashtable\n[ok](DBSIZE): ZREMRANGEBYRANK basics\n[ok](DBSIZE): ZUNIONSTORE against non-existing key doesn't set destination - skiplist\n[ok](DBSIZE): ZUNIONSTORE with empty set - skiplist\n[ok](DBSIZE): ZUNIONSTORE basics - skiplist\n[ok](DBSIZE): MIGRATE is caching connections\n[ok](DBSIZE): ZUNIONSTORE with weights - skiplist\n[ok](DBSIZE): ZUNIONSTORE with a regular set and weights - skiplist\n[ok](DBSIZE): ZSCAN with encoding ziplist\n[ok](DBSIZE): ZUNIONSTORE with AGGREGATE MIN - skiplist\n[ok](DBSIZE): ZUNIONSTORE with AGGREGATE MAX - skiplist\n[ok](DBSIZE): ZINTERSTORE basics - skiplist\n[ok](DBSIZE): ZINTERSTORE with weights - skiplist\n[ok](DBSIZE): Redis should actively expire keys incrementally\n[ok](DBSIZE): BRPOPLPUSH timeout\n[ok](DBSIZE): QUIT returns OK\n[ok](DBSIZE): ZINTERSTORE with a regular set and weights - skiplist\n[ok](DBSIZE): BLPOP when new key is moved into place\n[ok](DBSIZE): Pipelined commands after QUIT must not be executed\n[ok](DBSIZE): ZINTERSTORE with AGGREGATE MIN - skiplist\n[ok](DBSIZE): BLPOP when result key is created by SORT..STORE\n[ok](DBSIZE): Pipelined commands after QUIT that exceed read buffer size\n[ok](DBSIZE): ZINTERSTORE with AGGREGATE MAX - skiplist\n[ok](DBSIZE): BLPOP: with single empty list argument\n[ok](DBSIZE): ZUNIONSTORE with +inf/-inf scores - skiplist\n[ok](DBSIZE): BLPOP: with negative timeout\n[ok](DBSIZE): ZUNIONSTORE with NaN weights skiplist\n[ok](DBSIZE): BLPOP: with non-integer timeout\n[ok](DBSIZE): ZINTERSTORE with +inf/-inf scores - skiplist\n[ok](DBSIZE): ZINTERSTORE with NaN weights skiplist\n[ok](DBSIZE): ZINTERSTORE regression with two sets, intset+hashtable\n[ok](DBSIZE): ZUNIONSTORE regression, should not create NaN in scores\n[ok](DBSIZE): ZINTERSTORE #516 regression, mixed sets and ziplist zsets\n[ok](DBSIZE): Redis should lazy expire keys\n[ok](DBSIZE): BLPOP: with zero timeout should block indefinitely\n[ok](DBSIZE): BLPOP: second argument is not a list\n[ok](DBSIZE): ZSCAN with encoding skiplist\n\nLogged warnings (pid 6120):\n[ok](DBSIZE): HSET/HLEN - Big hash creation\n\nTesting unit/aofrw\n[ok](DBSIZE): Is the big hash encoded with an hash table?\n[ok](DBSIZE): HGET against the small hash\n(none)\n[ok](DBSIZE): EXPIRE should not resurrect keys (issue #1026)\n[ok](DBSIZE): 5 keys in, 5 keys out\n\n[exception]: Executing test client: attach_to_replication_stream error. Received '' as count..\nattach_to_replication_stream error. Received '' as count.\n    while executing\n\"error \"attach_to_replication_stream error. Received '$count' as count.\"\"\n    (procedure \"attach_to_replication_stream\" line 11)\n    invoked from within\n\"attach_to_replication_stream\"\n    (\"uplevel\" body line 2)\n    invoked from within\n\"uplevel 1 $code\"\n    (procedure \"test\" line 29)\n    invoked from within\n\"test {MULTI / EXEC is propagated correctly (single write command)} {\n        set repl [attach_to_replication_stream]\n        r multi\n        r set foo...\"\n    (\"uplevel\" body line 256)\n    invoked from within\n\"uplevel 1 $code \"\n    (procedure \"start_server\" line 3)\n    invoked from within\n\"start_server {tags {\"multi\"}} {\n    test {MUTLI / EXEC basics} {\n        r del mylist\n        r rpush mylist a\n        r rpush mylist b\n        r rpus...\"\n    (file \"tests/unit/multi.tcl\" line 1)\n    invoked from within\n\"source $path\"\n    (procedure \"execute_tests\" line 4)\n    invoked from within\n\"execute_tests $data\"\n    (procedure \"test_client_main\" line 10)\n    invoked from within\n\"test_client_main $::test_server_port \"\nKilling still running Redis server 6036\nKilling still running Redis server 6039\nKilling still running Redis server 6042\nKilling still running Redis server 6045\nKilling still running Redis server 6047\nKilling still running Redis server 6052\nKilling still running Redis server 6046\nKilling still running Redis server 6054\nKilling still running Redis server 6055\nKilling still running Redis server 6060\nKilling still running Redis server 6067\nKilling still running Redis server 6077\nKilling still running Redis server 6090\nKilling still running Redis server 6277\nmake[1]: **\\* [test] Error 1\nmake[1]: Leaving directory `/home/andrew/redis-stable/src'\nmake: **\\* [test] Error 2\n","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/2818/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/2818/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"id":770172911,"node_id":"MDE1OlJlZmVyZW5jZWRFdmVudDc3MDE3MjkxMQ==","url":"https://api.github.com/repos/redis/redis/issues/events/770172911","actor":{"login":"JackieXie168","id":8347113,"node_id":"MDQ6VXNlcjgzNDcxMTM=","avatar_url":"https://avatars.githubusercontent.com/u/8347113?v=4","gravatar_id":"","url":"https://api.github.com/users/JackieXie168","html_url":"https://github.com/JackieXie168","followers_url":"https://api.github.com/users/JackieXie168/followers","following_url":"https://api.github.com/users/JackieXie168/following{/other_user}","gists_url":"https://api.github.com/users/JackieXie168/gists{/gist_id}","starred_url":"https://api.github.com/users/JackieXie168/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/JackieXie168/subscriptions","organizations_url":"https://api.github.com/users/JackieXie168/orgs","repos_url":"https://api.github.com/users/JackieXie168/repos","events_url":"https://api.github.com/users/JackieXie168/events{/privacy}","received_events_url":"https://api.github.com/users/JackieXie168/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"361a3d2424cb7a879a22f0a8a3488c1b261975c1","commit_url":"https://api.github.com/repos/JackieXie168/redis/commits/361a3d2424cb7a879a22f0a8a3488c1b261975c1","created_at":"2016-08-29T02:51:04Z","performed_via_github_app":null},{"actor":{"login":"pinnymz","id":505458,"node_id":"MDQ6VXNlcjUwNTQ1OA==","avatar_url":"https://avatars.githubusercontent.com/u/505458?v=4","gravatar_id":"","url":"https://api.github.com/users/pinnymz","html_url":"https://github.com/pinnymz","followers_url":"https://api.github.com/users/pinnymz/followers","following_url":"https://api.github.com/users/pinnymz/following{/other_user}","gists_url":"https://api.github.com/users/pinnymz/gists{/gist_id}","starred_url":"https://api.github.com/users/pinnymz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pinnymz/subscriptions","organizations_url":"https://api.github.com/users/pinnymz/orgs","repos_url":"https://api.github.com/users/pinnymz/repos","events_url":"https://api.github.com/users/pinnymz/events{/privacy}","received_events_url":"https://api.github.com/users/pinnymz/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-03-30T03:39:49Z","updated_at":"2020-03-30T03:39:49Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/sds/mock_redis/issues/182","repository_url":"https://api.github.com/repos/sds/mock_redis","labels_url":"https://api.github.com/repos/sds/mock_redis/issues/182/labels{/name}","comments_url":"https://api.github.com/repos/sds/mock_redis/issues/182/comments","events_url":"https://api.github.com/repos/sds/mock_redis/issues/182/events","html_url":"https://github.com/sds/mock_redis/pull/182","id":589969915,"node_id":"MDExOlB1bGxSZXF1ZXN0Mzk1Mzg2MjU0","number":182,"title":"support for unsorted sets within zinterstore/zunionstore","user":{"login":"pinnymz","id":505458,"node_id":"MDQ6VXNlcjUwNTQ1OA==","avatar_url":"https://avatars.githubusercontent.com/u/505458?v=4","gravatar_id":"","url":"https://api.github.com/users/pinnymz","html_url":"https://github.com/pinnymz","followers_url":"https://api.github.com/users/pinnymz/followers","following_url":"https://api.github.com/users/pinnymz/following{/other_user}","gists_url":"https://api.github.com/users/pinnymz/gists{/gist_id}","starred_url":"https://api.github.com/users/pinnymz/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/pinnymz/subscriptions","organizations_url":"https://api.github.com/users/pinnymz/orgs","repos_url":"https://api.github.com/users/pinnymz/repos","events_url":"https://api.github.com/users/pinnymz/events{/privacy}","received_events_url":"https://api.github.com/users/pinnymz/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[{"id":86105961,"node_id":"MDU6TGFiZWw4NjEwNTk2MQ==","url":"https://api.github.com/repos/sds/mock_redis/labels/enhancement","name":"enhancement","color":"bfe5bf","default":true,"description":null}],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2020-03-30T03:39:48Z","updated_at":"2020-04-06T00:53:38Z","closed_at":"2020-04-06T00:53:37Z","author_association":"CONTRIBUTOR","active_lock_reason":null,"draft":false,"repository":{"id":2014670,"node_id":"MDEwOlJlcG9zaXRvcnkyMDE0Njcw","name":"mock_redis","full_name":"sds/mock_redis","private":false,"owner":{"login":"sds","id":677877,"node_id":"MDQ6VXNlcjY3Nzg3Nw==","avatar_url":"https://avatars.githubusercontent.com/u/677877?v=4","gravatar_id":"","url":"https://api.github.com/users/sds","html_url":"https://github.com/sds","followers_url":"https://api.github.com/users/sds/followers","following_url":"https://api.github.com/users/sds/following{/other_user}","gists_url":"https://api.github.com/users/sds/gists{/gist_id}","starred_url":"https://api.github.com/users/sds/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sds/subscriptions","organizations_url":"https://api.github.com/users/sds/orgs","repos_url":"https://api.github.com/users/sds/repos","events_url":"https://api.github.com/users/sds/events{/privacy}","received_events_url":"https://api.github.com/users/sds/received_events","type":"User","user_view_type":"public","site_admin":false},"html_url":"https://github.com/sds/mock_redis","description":"Mock Redis gem for Ruby","fork":false,"url":"https://api.github.com/repos/sds/mock_redis","forks_url":"https://api.github.com/repos/sds/mock_redis/forks","keys_url":"https://api.github.com/repos/sds/mock_redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/sds/mock_redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/sds/mock_redis/teams","hooks_url":"https://api.github.com/repos/sds/mock_redis/hooks","issue_events_url":"https://api.github.com/repos/sds/mock_redis/issues/events{/number}","events_url":"https://api.github.com/repos/sds/mock_redis/events","assignees_url":"https://api.github.com/repos/sds/mock_redis/assignees{/user}","branches_url":"https://api.github.com/repos/sds/mock_redis/branches{/branch}","tags_url":"https://api.github.com/repos/sds/mock_redis/tags","blobs_url":"https://api.github.com/repos/sds/mock_redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/sds/mock_redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/sds/mock_redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/sds/mock_redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/sds/mock_redis/statuses/{sha}","languages_url":"https://api.github.com/repos/sds/mock_redis/languages","stargazers_url":"https://api.github.com/repos/sds/mock_redis/stargazers","contributors_url":"https://api.github.com/repos/sds/mock_redis/contributors","subscribers_url":"https://api.github.com/repos/sds/mock_redis/subscribers","subscription_url":"https://api.github.com/repos/sds/mock_redis/subscription","commits_url":"https://api.github.com/repos/sds/mock_redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/sds/mock_redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/sds/mock_redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/sds/mock_redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/sds/mock_redis/contents/{+path}","compare_url":"https://api.github.com/repos/sds/mock_redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/sds/mock_redis/merges","archive_url":"https://api.github.com/repos/sds/mock_redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/sds/mock_redis/downloads","issues_url":"https://api.github.com/repos/sds/mock_redis/issues{/number}","pulls_url":"https://api.github.com/repos/sds/mock_redis/pulls{/number}","milestones_url":"https://api.github.com/repos/sds/mock_redis/milestones{/number}","notifications_url":"https://api.github.com/repos/sds/mock_redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/sds/mock_redis/labels{/name}","releases_url":"https://api.github.com/repos/sds/mock_redis/releases{/id}","deployments_url":"https://api.github.com/repos/sds/mock_redis/deployments","created_at":"2011-07-07T21:10:29Z","updated_at":"2025-11-24T08:20:36Z","pushed_at":"2025-11-24T08:20:33Z","git_url":"git://github.com/sds/mock_redis.git","ssh_url":"git@github.com:sds/mock_redis.git","clone_url":"https://github.com/sds/mock_redis.git","svn_url":"https://github.com/sds/mock_redis","homepage":"","size":1081,"stargazers_count":505,"watchers_count":505,"language":"Ruby","has_issues":true,"has_projects":false,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":false,"forks_count":158,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":6,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":[],"visibility":"public","forks":158,"open_issues":6,"watchers":505,"default_branch":"main","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"pull_request":{"url":"https://api.github.com/repos/sds/mock_redis/pulls/182","html_url":"https://github.com/sds/mock_redis/pull/182","diff_url":"https://github.com/sds/mock_redis/pull/182.diff","patch_url":"https://github.com/sds/mock_redis/pull/182.patch","merged_at":"2020-04-06T00:53:37Z"},"body":"Per [Redis Labs documentation](https://redislabs.com/ebook/part-1-getting-started/chapter-1-getting-to-know-redis/1-3-hello-redis/1-3-3-grouping-articles/), zinterstore and zunionstore should support passing unsorted sets to these commands with an implicit score of 1.0 applied to all values within the set.\r\n\r\n> Redis has a command called ZINTERSTORE, which, when provided with SETs and ZSETs, will find those entries that are in all of the SETs and ZSETs, combining their scores in a few different ways (items in SETs are considered to have scores equal to 1).\r\n\r\nCuriously, the ZINTERSTORE and ZUNIONSTORE command documentation [make no mention of this](https://github.com/antirez/redis-io/issues/172).  However, as referenced above this is officially supported, and patches [ensuring this behavior](https://github.com/antirez/redis/issues/516) have been merged accordingly.\r\n\r\nThis patch adds this functionality to the `.zinterstore` and `.zunionstore` methods so it will behave as Redis itself would.","reactions":{"url":"https://api.github.com/repos/sds/mock_redis/issues/182/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/sds/mock_redis/issues/182/timeline","performed_via_github_app":null,"state_reason":null}},"event":"cross-referenced"},{"actor":{"login":"verbus","id":148915,"node_id":"MDQ6VXNlcjE0ODkxNQ==","avatar_url":"https://avatars.githubusercontent.com/u/148915?v=4","gravatar_id":"","url":"https://api.github.com/users/verbus","html_url":"https://github.com/verbus","followers_url":"https://api.github.com/users/verbus/followers","following_url":"https://api.github.com/users/verbus/following{/other_user}","gists_url":"https://api.github.com/users/verbus/gists{/gist_id}","starred_url":"https://api.github.com/users/verbus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/verbus/subscriptions","organizations_url":"https://api.github.com/users/verbus/orgs","repos_url":"https://api.github.com/users/verbus/repos","events_url":"https://api.github.com/users/verbus/events{/privacy}","received_events_url":"https://api.github.com/users/verbus/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-05-01T16:58:52Z","updated_at":"2020-05-01T16:58:52Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/7169","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/7169/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/7169/comments","events_url":"https://api.github.com/repos/redis/redis/issues/7169/events","html_url":"https://github.com/redis/redis/issues/7169","id":610799917,"node_id":"MDU6SXNzdWU2MTA3OTk5MTc=","number":7169,"title":"Redis 6.0 Test Fails @ PSYNC2 #3899 regression: kill first replica","user":{"login":"verbus","id":148915,"node_id":"MDQ6VXNlcjE0ODkxNQ==","avatar_url":"https://avatars.githubusercontent.com/u/148915?v=4","gravatar_id":"","url":"https://api.github.com/users/verbus","html_url":"https://github.com/verbus","followers_url":"https://api.github.com/users/verbus/followers","following_url":"https://api.github.com/users/verbus/following{/other_user}","gists_url":"https://api.github.com/users/verbus/gists{/gist_id}","starred_url":"https://api.github.com/users/verbus/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/verbus/subscriptions","organizations_url":"https://api.github.com/users/verbus/orgs","repos_url":"https://api.github.com/users/verbus/repos","events_url":"https://api.github.com/users/verbus/events{/privacy}","received_events_url":"https://api.github.com/users/verbus/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":28,"created_at":"2020-05-01T15:10:26Z","updated_at":"2020-05-02T11:44:40Z","closed_at":null,"author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"[ok]: PSYNC2 #3899 regression: kill first replica\r\n\r\nLogged warnings (pid 3128):\r\n=== REDIS BUG REPORT START: Cut & paste starting from here ===\r\n3128:M 01 May 2020 15:03:32.527 # Redis 6.0.0 crashed by signal: 11\r\n3128:M 01 May 2020 15:03:32.527 # Crashed running the instruction at: 0x7f62cd883c01\r\n3128:M 01 May 2020 15:03:32.527 # Accessing address: 0x558df8000000\r\n3128:M 01 May 2020 15:03:32.527 # Failed assertion: <no assertion failed> (<no file>:0)\r\n\r\n------ STACK TRACE ------\r\nEIP:\r\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x2b1)[0x7f62cd883c01]\r\n\r\nBacktrace:\r\nsrc/redis-server 127.0.0.1:21307(logStackTrace+0x5a)[0x558df7cc336a]\r\nsrc/redis-server 127.0.0.1:21307(sigsegvHandler+0xb1)[0x558df7cc3b21]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x12890)[0x7f62cdbef890]\r\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x2b1)[0x7f62cd883c01]\r\nsrc/redis-server 127.0.0.1:21307(listDelNode+0x37)[0x558df7c73dc7]\r\nsrc/redis-server 127.0.0.1:21307(writeToClient+0x24a)[0x558df7c8b8da]\r\nsrc/redis-server 127.0.0.1:21307(handleClientsWithPendingWrites+0x82)[0x558df7c8ba02]\r\nsrc/redis-server 127.0.0.1:21307(handleClientsWithPendingWritesUsingThreads+0x265)[0x558df7c913f5]\r\nsrc/redis-server 127.0.0.1:21307(beforeSleep+0xad)[0x558df7c7a76d]\r\nsrc/redis-server 127.0.0.1:21307(aeMain+0x1e)[0x558df7c770ee]\r\nsrc/redis-server 127.0.0.1:21307(main+0x52d)[0x558df7c737bd]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xe7)[0x7f62cd80db97]\r\nsrc/redis-server 127.0.0.1:21307(_start+0x2a)[0x558df7c73a1a]\r\n\r\n------ INFO OUTPUT ------\r\n# Server\r\nredis_version:6.0.0\r\nredis_git_sha1:00000000\r\nredis_git_dirty:0\r\nredis_build_id:fd911d122c1dea24\r\nredis_mode:standalone\r\nos:Linux 4.15.0-99-generic x86_64\r\narch_bits:64\r\nmultiplexing_api:epoll\r\natomicvar_api:atomic-builtin\r\ngcc_version:7.5.0\r\nprocess_id:3128\r\nrun_id:d41e59cb418c0b9291d39f6c09fc86687aec5116\r\ntcp_port:21307\r\nuptime_in_seconds:0\r\nuptime_in_days:0\r\nhz:10\r\nconfigured_hz:10\r\nlru_clock:11287108\r\nexecutable:/home/verbus/redis-6.0.0/src/redis-server\r\nconfig_file:/home/verbus/redis-6.0.0/./tests/tmp/redis.conf.1671.31\r\n\r\n# Clients\r\nconnected_clients:1\r\nclient_recent_max_input_buffer:4\r\nclient_recent_max_output_buffer:0\r\nblocked_clients:0\r\ntracking_clients:0\r\nclients_in_timeout_table:0\r\n\r\n# Memory\r\nused_memory:945280\r\nused_memory_human:923.12K\r\nused_memory_rss:4993024\r\nused_memory_rss_human:4.76M\r\nused_memory_peak:945280\r\nused_memory_peak_human:923.12K\r\nused_memory_peak_perc:105.78%\r\nused_memory_overhead:894012\r\nused_memory_startup:876096\r\nused_memory_dataset:51268\r\nused_memory_dataset_perc:74.10%\r\nallocator_allocated:893624\r\nallocator_active:4955136\r\nallocator_resident:4955136\r\ntotal_system_memory:8363720704\r\ntotal_system_memory_human:7.79G\r\nused_memory_lua:44032\r\nused_memory_lua_human:43.00K\r\nused_memory_scripts:928\r\nused_memory_scripts_human:928B\r\nnumber_of_cached_scripts:8\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:noeviction\r\nallocator_frag_ratio:5.54\r\nallocator_frag_bytes:4061512\r\nallocator_rss_ratio:1.00\r\nallocator_rss_bytes:0\r\nrss_overhead_ratio:1.01\r\nrss_overhead_bytes:37888\r\nmem_fragmentation_ratio:5.59\r\nmem_fragmentation_bytes:4099400\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:0\r\nmem_clients_slaves:0\r\nmem_clients_normal:16988\r\nmem_aof_buffer:0\r\nmem_allocator:libc\r\nactive_defrag_running:0\r\nlazyfree_pending_objects:0\r\n\r\n# Persistence\r\nloading:0\r\nrdb_changes_since_last_save:0\r\nrdb_bgsave_in_progress:0\r\nrdb_last_save_time:1588345412\r\nrdb_last_bgsave_status:ok\r\nrdb_last_bgsave_time_sec:-1\r\nrdb_current_bgsave_time_sec:-1\r\nrdb_last_cow_size:0\r\naof_enabled:0\r\naof_rewrite_in_progress:0\r\naof_rewrite_scheduled:0\r\naof_last_rewrite_time_sec:-1\r\naof_current_rewrite_time_sec:-1\r\naof_last_bgrewrite_status:ok\r\naof_last_write_status:ok\r\naof_last_cow_size:0\r\nmodule_fork_in_progress:0\r\nmodule_fork_last_cow_size:0\r\n\r\n# Stats\r\ntotal_connections_received:2\r\ntotal_commands_processed:10\r\ninstantaneous_ops_per_sec:0\r\ntotal_net_input_bytes:399\r\ntotal_net_output_bytes:82\r\ninstantaneous_input_kbps:0.00\r\ninstantaneous_output_kbps:0.00\r\nrejected_connections:0\r\nsync_full:0\r\nsync_partial_ok:0\r\nsync_partial_err:0\r\nexpired_keys:0\r\nexpired_stale_perc:0.00\r\nexpired_time_cap_reached_count:0\r\nexpire_cycle_cpu_milliseconds:0\r\nevicted_keys:0\r\nkeyspace_hits:0\r\nkeyspace_misses:0\r\npubsub_channels:0\r\npubsub_patterns:0\r\nlatest_fork_usec:0\r\nmigrate_cached_sockets:0\r\nslave_expires_tracked_keys:0\r\nactive_defrag_hits:0\r\nactive_defrag_misses:0\r\nactive_defrag_key_hits:0\r\nactive_defrag_key_misses:0\r\ntracking_total_keys:0\r\ntracking_total_items:0\r\nunexpected_error_replies:0\r\n\r\n# Replication\r\nrole:master\r\nconnected_slaves:0\r\nmaster_replid:6ded99b3fb22d028b6bdacdd54017dfe1fbcfdd6\r\nmaster_replid2:0000000000000000000000000000000000000000\r\nmaster_repl_offset:0\r\nmaster_repl_meaningful_offset:0\r\nsecond_repl_offset:-1\r\nrepl_backlog_active:0\r\nrepl_backlog_size:1048576\r\nrepl_backlog_first_byte_offset:0\r\nrepl_backlog_histlen:0\r\n\r\n# CPU\r\nused_cpu_sys:0.000000\r\nused_cpu_user:0.008132\r\nused_cpu_sys_children:0.000000\r\nused_cpu_user_children:0.000000\r\n\r\n# Modules\r\n\r\n# Commandstats\r\ncmdstat_eval:calls=8,usec=347,usec_per_call=43.38\r\ncmdstat_select:calls=1,usec=2,usec_per_call=2.00\r\ncmdstat_ping:calls=1,usec=1,usec_per_call=1.00\r\n\r\n# Cluster\r\ncluster_enabled:0\r\n\r\n# Keyspace\r\n\r\n------ CLIENT LIST OUTPUT ------\r\nid=5 addr=127.0.0.1:45731 fd=8 name= age=0 idle=0 flags=N db=9 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=1 omem=40 events=r cmd=eval user=default\r\n\r\n------ REGISTERS ------\r\n3128:M 01 May 2020 15:03:32.528 # \r\nRAX:0000558df8000000 RBX:00007f62cdbd7c40\r\nRCX:0000000000000a00 RDX:0000000000000a08\r\nRDI:0000558df91ff640 RSI:0000000000000a0d\r\nRBP:ffffffffffffff28 RSP:00007fff20955be0\r\nR8 :0000000000000000 R9 :0000bcbc649d006d\r\nR10:0000000000000000 R11:0000000000000000\r\nR12:0000558df91ff640 R13:0000558df91ff630\r\nR14:000000000000000c R15:000000000000000c\r\nRIP:00007f62cd883c01 EFL:0000000000010206\r\nCSGSFS:002b000000000033\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955bef) -> 0000558df9203980\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955bee) -> 0000000000000002\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955bed) -> 0000558df7c73dc7\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955bec) -> 000000000000000c\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955beb) -> 000000000000000c\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955bea) -> 0000558df91ff640\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be9) -> 0000558df9203bd8\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be8) -> 0000558df91ff530\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be7) -> 0000558df91fda60\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be6) -> 00007fff20955c60\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be5) -> 2324522307c77e00\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be4) -> 000000005eac3a44\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be3) -> 2324522307c77e00\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be2) -> 0000000000000000\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be1) -> 0000558df7c7dab2\r\n3128:M 01 May 2020 15:03:32.528 # (00007fff20955be0) -> 0005a4977c182563\r\n\r\n------ MODULES INFO OUTPUT ------\r\n\r\n------ FAST MEMORY TEST ------\r\n3128:M 01 May 2020 15:03:32.529 # Bio thread for job type #0 terminated\r\n3128:M 01 May 2020 15:03:32.529 # Bio thread for job type #1 terminated\r\n3128:M 01 May 2020 15:03:32.529 # Bio thread for job type #2 terminated\r\n*** Preparing to test memory region 558df7f8c000 (118784 bytes)\r\n*** Preparing to test memory region 558df9151000 (929792 bytes)\r\n*** Preparing to test memory region 7f62cb2ac000 (8388608 bytes)\r\n*** Preparing to test memory region 7f62cbaad000 (8388608 bytes)\r\n*** Preparing to test memory region 7f62cc2ae000 (8716288 bytes)\r\n*** Preparing to test memory region 7f62cd1a1000 (4096 bytes)\r\n*** Preparing to test memory region 7f62cdbd9000 (16384 bytes)\r\n*** Preparing to test memory region 7f62cddf8000 (16384 bytes)\r\n*** Preparing to test memory region 7f62ce07f000 (4096 bytes)\r\n*** Preparing to test memory region 7f62ce819000 (32768 bytes)\r\n*** Preparing to test memory region 7f62ce84b000 (4096 bytes)\r\n.O.O.O.O.O.O.O.O.O.O.O\r\nFast memory test PASSED, however your memory can still be broken. Please run a memory test for several hours if possible.\r\n\r\n------ DUMPING CODE AROUND EIP ------\r\nSymbol: cfree (base: 0x7f62cd883950)\r\nModule: /lib/x86_64-linux-gnu/libc.so.6 (base 0x7f62cd7ec000)\r\n$ xxd -r -p /tmp/dump.hex /tmp/dump.bin\r\n$ objdump --adjust-vma=0x7f62cd883950 -D -b binary -m i386:x86-64 /tmp/dump.bin\r\n------\r\n3128:M 01 May 2020 15:03:33.168 # dump of function (hexdump of 817 bytes):\r\n41574156415541544989fc55534883ec3864488b042528000000488944242831c0488b0570353500488b004885c00f859c0200004885ff0f8413010000488b77f84c8d6ff040f6c6020f8529010000488b2dd23335006448837d00000f84d604000040f6c604488d1d834235000f85350200004989f64983e6f84c89f048f7d84c39e80f823704000041f6c50f0f852d0400004983fe1f0f863304000040f6c6080f852904000064488b55004885d27426498d46ef48c1e804483b05c03835007315480fbe3c02483b3dc23835004889f90f82090400004c3b35125f35000f87fc0100004b8d543500488b42084883f8100f86890400004883e0f8483b83880800000f83780400008b05ce5e350085c00f8547060000c7430801000000488d35848e350041c1ee04418d4efe8b36488d04cb488b501085f60f85110500004939d50f8461050000498914244c89681090488b4424286448330425280000000f85940900004883c4385b5d415c415d415e415fc30f1f4400008b3de6373500488b05635e350085ff0f85c3000000483b35ac3735000f86b60000004881fe000000020f87a90000004939c50f83900000004883e6f8488d0436488935813735004889056a37350090498b7424f840f6c6020f85310c0000488b05c3323500488d0d45c11100488d1d05d2110041b90f0b0000488b10488d0585c31100803a00480f45c84883ec085350488d0509151200504c8d0591d11100488d35ea0b120031ff31c0e85962feff488b05323235004883c420488b38e8566cfeffe8318bfaff904c3b2d995d35000f8363ffffff0f1f004883e6f84939c57367498b4424f04c89ef4829c74801c6488b059a3235004889fa4809f2488b40184883e8014885d00f85eb020000f0ff0dcc3635004889f048f7d8f0480105ce363500e8c13e0800e9acfeffff0f1f40004c89e84825000000fc488b18e9bafdffff0f1f80000000004c3b2d195d35007390e982feffff6690488b742468ffd0e974feffff0f1f400083e6020f8577020000488d05b88c3500bd010000008b0085c00f859c040000488b43604f8d7c35004939c50f84c1040000f64304020f84ea010000498b4708a8010f84010200004889c14883e1f84883f8\r\nFunction at 0x7f62cd86a7e0 is fflush\r\nFunction at 0x7f62cd82c6c0 is abort\r\nFunction at 0x7f62cd907ab0 is __munmap\r\nFunction at 0x7f62cd886147 is __libc_calloc\r\n\r\n=== REDIS BUG REPORT END. Make sure to include from START to END. ===\r\n\r\n       Please report the crash by opening an issue on github:\r\n\r\n           http://github.com/antirez/redis/issues\r\n\r\n  Suspect RAM error? Use redis-server --test-memory to verify it.\r\n","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/7169/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/7169/timeline","performed_via_github_app":null,"state_reason":null}},"event":"cross-referenced"},{"actor":{"login":"moria7757","id":76126820,"node_id":"MDQ6VXNlcjc2MTI2ODIw","avatar_url":"https://avatars.githubusercontent.com/u/76126820?v=4","gravatar_id":"","url":"https://api.github.com/users/moria7757","html_url":"https://github.com/moria7757","followers_url":"https://api.github.com/users/moria7757/followers","following_url":"https://api.github.com/users/moria7757/following{/other_user}","gists_url":"https://api.github.com/users/moria7757/gists{/gist_id}","starred_url":"https://api.github.com/users/moria7757/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moria7757/subscriptions","organizations_url":"https://api.github.com/users/moria7757/orgs","repos_url":"https://api.github.com/users/moria7757/repos","events_url":"https://api.github.com/users/moria7757/events{/privacy}","received_events_url":"https://api.github.com/users/moria7757/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2020-12-29T09:26:55Z","updated_at":"2020-12-29T09:26:55Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/8265","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/8265/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/8265/comments","events_url":"https://api.github.com/repos/redis/redis/issues/8265/events","html_url":"https://github.com/redis/redis/issues/8265","id":775792738,"node_id":"MDU6SXNzdWU3NzU3OTI3Mzg=","number":8265,"title":"*** [err]: Active defrag in tests/unit/memefficiency.tcl","user":{"login":"moria7757","id":76126820,"node_id":"MDQ6VXNlcjc2MTI2ODIw","avatar_url":"https://avatars.githubusercontent.com/u/76126820?v=4","gravatar_id":"","url":"https://api.github.com/users/moria7757","html_url":"https://github.com/moria7757","followers_url":"https://api.github.com/users/moria7757/followers","following_url":"https://api.github.com/users/moria7757/following{/other_user}","gists_url":"https://api.github.com/users/moria7757/gists{/gist_id}","starred_url":"https://api.github.com/users/moria7757/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/moria7757/subscriptions","organizations_url":"https://api.github.com/users/moria7757/orgs","repos_url":"https://api.github.com/users/moria7757/repos","events_url":"https://api.github.com/users/moria7757/events{/privacy}","received_events_url":"https://api.github.com/users/moria7757/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":24,"created_at":"2020-12-29T09:26:53Z","updated_at":"2024-01-28T15:03:39Z","closed_at":"2021-01-08T08:03:21Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"Linux Version: CentOS Linux release 7.9.2009 (AltArch) - ppc64\r\nRedis Version: 5.0.9\r\nJemalloc Version: 5.2.1\r\ngcc Version: 4.8.5 20150623 (Red Hat 4.8.5-44)\r\nExecuted Command: make test & ./runtest --clients 1\r\n\r\nlscpu output:\r\n```\r\nArchitecture:          ppc64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Big Endian\r\nCPU(s):                32\r\nOn-line CPU(s) list:   0-31\r\nThread(s) per core:    4\r\nCore(s) per socket:    1\r\nSocket(s):             8\r\nNUMA node(s):          1\r\nModel:                 2.3 (pvr 003f 0203)\r\nModel name:            POWER7 (architected), altivec supported\r\nHypervisor vendor:     pHyp\r\nVirtualization type:   para\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nNUMA node0 CPU(s):     0-31\r\n```\r\nfree -m output:\r\n```\r\n              total        used        free      shared  buff/cache   available\r\nMem:           9802         937        2710          12        6154        8230\r\nSwap:          4095           0        4095\r\n```\r\n ./runtest --clients 1 output:\r\n```\r\nCleanup: may take some time... OK\r\nStarting test server at port 11111\r\n[ready]: 64621\r\n\u001B[1;37;49mTesting unit/printver\u001B[0m\r\nTesting Redis version 5.0.9 (00000000)\r\n[1/50 \u001B[0;33;49mdone\u001B[0m]: unit/printver (1 seconds)\r\n\u001B[1;37;49mTesting unit/dump\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: DUMP / RESTORE are able to serialize / unserialize a simple key\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set an arbitrary expire to the materialized key\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set an expire that overflows a 32 bit integer\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set an absolute expire\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set LRU\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can set LFU\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE returns an error of the key already exists\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can overwrite an existing key with REPLACE\r\n[\u001B[0;32;49mok\u001B[0m]: RESTORE can detect a syntax error for unrecongized options\r\n[\u001B[0;32;49mok\u001B[0m]: DUMP of non existing key returns nil\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE is caching connections\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE cached connections are released after some time\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE is able to migrate a key between two instances\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE is able to copy a key between two instances\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE will not overwrite existing keys, unless REPLACE is used\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE propagates TTL correctly\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE can correctly transfer large values\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE can correctly transfer hashes\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE timeout actually works\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE can migrate multiple keys at once\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys must have empty key arg\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys migrate just existing ones\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys: stress command rewriting\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE with multiple keys: delete just ack keys\r\n[\u001B[0;32;49mok\u001B[0m]: MIGRATE AUTH: correct and wrong password cases\r\n[2/50 \u001B[0;33;49mdone\u001B[0m]: unit/dump (27 seconds)\r\n\u001B[1;37;49mTesting unit/auth\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: AUTH fails if there is no password configured server side\r\n[\u001B[0;32;49mok\u001B[0m]: AUTH fails when a wrong password is given\r\n[\u001B[0;32;49mok\u001B[0m]: Arbitrary command gives an error when AUTH is required\r\n[\u001B[0;32;49mok\u001B[0m]: AUTH succeeds when the right password is given\r\n[\u001B[0;32;49mok\u001B[0m]: Once AUTH succeeded we can actually send commands to the server\r\n[3/50 \u001B[0;33;49mdone\u001B[0m]: unit/auth (1 seconds)\r\n\u001B[1;37;49mTesting unit/protocol\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Handle an empty query\r\n[\u001B[0;32;49mok\u001B[0m]: Negative multibulk length\r\n[\u001B[0;32;49mok\u001B[0m]: Out of range multibulk length\r\n[\u001B[0;32;49mok\u001B[0m]: Wrong multibulk payload header\r\n[\u001B[0;32;49mok\u001B[0m]: Negative multibulk payload length\r\n[\u001B[0;32;49mok\u001B[0m]: Out of range multibulk payload length\r\n[\u001B[0;32;49mok\u001B[0m]: Non-number multibulk payload length\r\n[\u001B[0;32;49mok\u001B[0m]: Multi bulk request not followed by bulk arguments\r\n[\u001B[0;32;49mok\u001B[0m]: Generic wrong number of args\r\n[\u001B[0;32;49mok\u001B[0m]: Unbalanced number of quotes\r\n[\u001B[0;32;49mok\u001B[0m]: Protocol desync regression test #1\r\n[\u001B[0;32;49mok\u001B[0m]: Protocol desync regression test #2\r\n[\u001B[0;32;49mok\u001B[0m]: Protocol desync regression test #3\r\n[\u001B[0;32;49mok\u001B[0m]: Regression for a crash with blocking ops and pipelining\r\n[4/50 \u001B[0;33;49mdone\u001B[0m]: unit/protocol (0 seconds)\r\n\u001B[1;37;49mTesting unit/keyspace\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: DEL against a single item\r\n[\u001B[0;32;49mok\u001B[0m]: Vararg DEL\r\n[\u001B[0;32;49mok\u001B[0m]: KEYS with pattern\r\n[\u001B[0;32;49mok\u001B[0m]: KEYS to get all keys\r\n[\u001B[0;32;49mok\u001B[0m]: DBSIZE\r\n[\u001B[0;32;49mok\u001B[0m]: DEL all keys\r\n[\u001B[0;32;49mok\u001B[0m]: DEL against expired key\r\n[\u001B[0;32;49mok\u001B[0m]: EXISTS\r\n[\u001B[0;32;49mok\u001B[0m]: Zero length value in key. SET/GET/EXISTS\r\n[\u001B[0;32;49mok\u001B[0m]: Commands pipelining\r\n[\u001B[0;32;49mok\u001B[0m]: Non existing command\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME basic usage\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME source key should no longer exist\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME against already existing key\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX basic usage\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX against already existing key\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX against already existing key (2)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME against non existing source key\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME where source and dest key are the same (existing)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAMENX where source and dest key are the same (existing)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME where source and dest key are the same (non existing)\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME with volatile key, should move the TTL as well\r\n[\u001B[0;32;49mok\u001B[0m]: RENAME with volatile key, should not inherit TTL of target key\r\n[\u001B[0;32;49mok\u001B[0m]: DEL all keys again (DB 0)\r\n[\u001B[0;32;49mok\u001B[0m]: DEL all keys again (DB 1)\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE basic usage\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE against key existing in the target DB\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE against non-integer DB (#1428)\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE can move key expire metadata as well\r\n[\u001B[0;32;49mok\u001B[0m]: MOVE does not create an expire if it does not exist\r\n[\u001B[0;32;49mok\u001B[0m]: SET/GET keys in different DBs\r\n[\u001B[0;32;49mok\u001B[0m]: RANDOMKEY\r\n[\u001B[0;32;49mok\u001B[0m]: RANDOMKEY against empty DB\r\n[\u001B[0;32;49mok\u001B[0m]: RANDOMKEY regression 1\r\n[\u001B[0;32;49mok\u001B[0m]: KEYS * two times with long key, Github issue #1208\r\n[5/50 \u001B[0;33;49mdone\u001B[0m]: unit/keyspace (2 seconds)\r\n\u001B[1;37;49mTesting unit/scan\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN basic\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN COUNT\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN MATCH\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with encoding intset\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with encoding hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: HSCAN with encoding ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: HSCAN with encoding hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN with encoding ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN with encoding skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN guarantees check under write load\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with integer encoded object (issue #1345)\r\n[\u001B[0;32;49mok\u001B[0m]: SSCAN with PATTERN\r\n[\u001B[0;32;49mok\u001B[0m]: HSCAN with PATTERN\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN with PATTERN\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCAN scores: regression test for issue #2175\r\n[\u001B[0;32;49mok\u001B[0m]: SCAN regression test for issue #4906\r\n[6/50 \u001B[0;33;49mdone\u001B[0m]: unit/scan (8 seconds)\r\n\u001B[1;37;49mTesting unit/type/string\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SET and GET an item\r\n[\u001B[0;32;49mok\u001B[0m]: SET and GET an empty item\r\n[\u001B[0;32;49mok\u001B[0m]: Very big payload in GET/SET\r\n[\u001B[0;32;49mok\u001B[0m]: Very big payload random access\r\n[\u001B[0;32;49mok\u001B[0m]: SET 10000 numeric keys and access all them in reverse order\r\n[\u001B[0;32;49mok\u001B[0m]: DBSIZE should be 10000 now\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX target key missing\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX target key exists\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX against not-expired volatile key\r\n[\u001B[0;32;49mok\u001B[0m]: SETNX against expired volatile key\r\n[\u001B[0;32;49mok\u001B[0m]: MGET\r\n[\u001B[0;32;49mok\u001B[0m]: MGET against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: MGET against non-string key\r\n[\u001B[0;32;49mok\u001B[0m]: GETSET (set new value)\r\n[\u001B[0;32;49mok\u001B[0m]: GETSET (replace old value)\r\n[\u001B[0;32;49mok\u001B[0m]: MSET base case\r\n[\u001B[0;32;49mok\u001B[0m]: MSET wrong number of args\r\n[\u001B[0;32;49mok\u001B[0m]: MSETNX with already existent key\r\n[\u001B[0;32;49mok\u001B[0m]: MSETNX with not existing keys\r\n[\u001B[0;32;49mok\u001B[0m]: STRLEN against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: STRLEN against integer-encoded value\r\n[\u001B[0;32;49mok\u001B[0m]: STRLEN against plain string\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against string-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against integer-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT against key with wrong type\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT with out of range bit offset\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT with non-bit argument\r\n[\u001B[0;32;49mok\u001B[0m]: SETBIT fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: GETBIT against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: GETBIT against string-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: GETBIT against integer-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against string-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against integer-encoded key\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE against key with wrong type\r\n[\u001B[0;32;49mok\u001B[0m]: SETRANGE with out of range offset\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE against non-existing key\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE against string value\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE against integer-encoded value\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET can detect syntax errors\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET NX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET XX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET EX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET PX option\r\n[\u001B[0;32;49mok\u001B[0m]: Extended SET using multiple options at once\r\n[\u001B[0;32;49mok\u001B[0m]: GETRANGE with huge ranges, Github issue #1844\r\n[7/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/string (12 seconds)\r\n\u001B[1;37;49mTesting unit/type/incr\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: INCR against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: INCR against key created by incr itself\r\n[\u001B[0;32;49mok\u001B[0m]: INCR against key originally set with SET\r\n[\u001B[0;32;49mok\u001B[0m]: INCR over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBY over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against key with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against key with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against key with spaces (both)\r\n[\u001B[0;32;49mok\u001B[0m]: INCR fails against a key holding a list\r\n[\u001B[0;32;49mok\u001B[0m]: DECRBY over 32bit value with over 32bit increment, negative res\r\n[\u001B[0;32;49mok\u001B[0m]: INCR uses shared objects in the 0-9999 range\r\n[\u001B[0;32;49mok\u001B[0m]: INCR can modify objects in-place\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT against key originally set with SET\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against key with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against key with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against key with spaces (both)\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT fails against a key holding a list\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT does not allow NaN or Infinity\r\n[\u001B[0;32;49mok\u001B[0m]: INCRBYFLOAT decrement\r\n[\u001B[0;32;49mok\u001B[0m]: string to double with null terminator\r\n[8/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/incr (0 seconds)\r\n\u001B[1;37;49mTesting unit/type/list\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - regular list\r\n[\u001B[0;32;49mok\u001B[0m]: R/LPOP against empty list\r\n[\u001B[0;32;49mok\u001B[0m]: Variadic RPUSH/LPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: DEL a list\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: single existing list - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: multiple existing lists - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: second list has an entry - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: single existing list - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: multiple existing lists - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, BRPOP: second list has an entry - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, LPUSH + DEL should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP, LPUSH + DEL + SET should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP with same key multiple times should work (issue #801)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI/EXEC is isolated from the point of view of BLPOP\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP with variadic LPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with a client BLPOPing the target list\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with wrong source type\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with wrong destination type\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH maintains order of elements after failure\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH with multiple blocked clients\r\n[\u001B[0;32;49mok\u001B[0m]: Linked BRPOPLPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: Circular BRPOPLPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: Self-referential BRPOPLPUSH\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH inside a transaction\r\n[\u001B[0;32;49mok\u001B[0m]: PUSH resulting from BRPOPLPUSH affect WATCH\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH does not affect WATCH while still blocked\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP when new key is moved into place\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP when result key is created by SORT..STORE\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with single empty list argument\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with negative timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with non-integer timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: second argument is not a list\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP: arguments are empty\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with single empty list argument\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with negative timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with non-integer timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: second argument is not a list\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: timeout\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOP: arguments are empty\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP inside a transaction\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSHX, RPUSHX - generic\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSHX, RPUSHX - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LINSERT - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSHX, RPUSHX - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LINSERT - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LINSERT raise error on bad syntax\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX consistency test - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX random access - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX consistency test - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX random access - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LLEN against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: LLEN against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: LINDEX against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LPUSH against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: RPUSH against non-list value error\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH base case - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with the same list as src and dst - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with linkedlist source and existing target linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with linkedlist source and existing target ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH base case - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with the same list as src and dst - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with ziplist source and existing target linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH with ziplist source and existing target ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non list src key\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non list dst key\r\n[\u001B[0;32;49mok\u001B[0m]: RPOPLPUSH against non existing src key\r\n[\u001B[0;32;49mok\u001B[0m]: Basic LPOP/RPOP - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: Basic LPOP/RPOP - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LPOP/RPOP against non list value\r\n[\u001B[0;32;49mok\u001B[0m]: Mass RPOP/LPOP - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: Mass RPOP/LPOP - quicklist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE basics - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE inverted indexes - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range indexes including the full list - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range negative end index - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE inverted indexes - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range indexes including the full list - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE out of range negative end index - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LRANGE against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM basics - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM out of range negative end index - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM out of range negative end index - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET out of range index - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET out of range index - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LSET against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: LSET against non list value\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove all the occurrences - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove the first occurrence - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove non existing element - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count (2) - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM deleting objects that may be int encoded - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove all the occurrences - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove the first occurrence - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM remove non existing element - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM starting from tail with negative count (2) - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: LREM deleting objects that may be int encoded - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: Regression for bug 593 - chaining BRPOPLPUSH with other blocking cmds\r\n[9/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/list (13 seconds)\r\n\u001B[1;37;49mTesting unit/type/list-2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM stress testing - linkedlist\r\n[\u001B[0;32;49mok\u001B[0m]: LTRIM stress testing - ziplist\r\n[10/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/list-2 (17 seconds)\r\n\u001B[1;37;49mTesting unit/type/list-3\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Explicit regression for a list bug\r\n[\u001B[0;32;49mok\u001B[0m]: Regression for quicklist #3343 bug\r\n[\u001B[0;32;49mok\u001B[0m]: Stress tester for #3343-alike bugs\r\n[\u001B[0;32;49mok\u001B[0m]: ziplist implementation: value encoding and backlink\r\n[\u001B[0;32;49mok\u001B[0m]: ziplist implementation: encoding stress testing\r\n[11/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/list-3 (103 seconds)\r\n\u001B[1;37;49mTesting unit/type/set\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SADD, SCARD, SISMEMBER, SMEMBERS basics - regular set\r\n[\u001B[0;32;49mok\u001B[0m]: SADD, SCARD, SISMEMBER, SMEMBERS basics - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SADD against non set\r\n[\u001B[0;32;49mok\u001B[0m]: SADD a non-integer against an intset\r\n[\u001B[0;32;49mok\u001B[0m]: SADD an integer larger than 64 bits\r\n[\u001B[0;32;49mok\u001B[0m]: SADD overflows the maximum allowed integers in an intset\r\n[\u001B[0;32;49mok\u001B[0m]: Variadic SADD\r\n[\u001B[0;32;49mok\u001B[0m]: Set encoding after DEBUG RELOAD\r\n[\u001B[0;32;49mok\u001B[0m]: SREM basics - regular set\r\n[\u001B[0;32;49mok\u001B[0m]: SREM basics - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SREM with multiple arguments\r\n[\u001B[0;32;49mok\u001B[0m]: SREM variadic version with more args needed to destroy the key\r\n[\u001B[0;32;49mok\u001B[0m]: Generated sets must be encoded as hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets, after a DEBUG RELOAD - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SUNIONSTORE with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER against three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with non existing keys - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with two sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFFSTORE with three sets - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: Generated sets must be encoded as intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with two sets, after a DEBUG RELOAD - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SUNIONSTORE with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER against three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE with three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION with non existing keys - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with two sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFFSTORE with three sets - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with first set empty\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF with same set two times\r\n[\u001B[0;32;49mok\u001B[0m]: SDIFF fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER against non-set should throw error\r\n[\u001B[0;32;49mok\u001B[0m]: SUNION against non-set should throw error\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER should handle non existing key as empty\r\n[\u001B[0;32;49mok\u001B[0m]: SINTER with same integer elements but different encoding\r\n[\u001B[0;32;49mok\u001B[0m]: SINTERSTORE against non existing keys should delete dstkey\r\n[\u001B[0;32;49mok\u001B[0m]: SUNIONSTORE against non existing keys should delete dstkey\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP basics - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>=1 - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP basics - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>=1 - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP with <count>\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP using integers, testing Knuth's and Floyd's algorithm\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP using integers with Knuth's algorithm\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP new implementation: code path #1\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP new implementation: code path #2\r\n[\u001B[0;32;49mok\u001B[0m]: SPOP new implementation: code path #3\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER with <count> against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER with <count> - hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: SRANDMEMBER with <count> - intset\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE basics - from regular set to intset\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE basics - from intset to regular set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE non existing src set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE from regular set to non existing destination set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE from intset to non existing destination set\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE wrong src key type\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE wrong dst key type\r\n[\u001B[0;32;49mok\u001B[0m]: SMOVE with identical source and destination\r\n[\u001B[0;32;49mok\u001B[0m]: intsets implementation stress testing\r\n[12/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/set (7 seconds)\r\n\u001B[1;37;49mTesting unit/type/zset\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Check encoding - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET basic ZADD and score update - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZADD - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD with options syntax error with incomplete pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX option without key - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX existing key - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX returns the number of elements actually added\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX updates existing elements score\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX and NX are not compatible\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX with non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX only add new elements without updating old ones\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works like ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works with a single score-elemenet pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD CH option changes return value to all changed elements\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY calls leading to NaN result in error\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version base case\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Return value is the number of actually added items\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version does not add nothing on single parsing err\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version will raise error on missing arg\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY does not work variadic even if shares ZADD implementation\r\n[\u001B[0;32;49mok\u001B[0m]: ZCARD basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM removes key after last element is removed\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version -- remove elements after key deletion\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREVRANGE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK/ZREVRANK basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK - after deletion - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - can create a new sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - increment and decrement - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY return value\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT and WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZLEXCOUNT advanced\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSLEX with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX with invalid lex range specifiers\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYRANK basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE against non-existing key doesn't set destination - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with empty set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with a regular set and weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MIN - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MAX - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE basics - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with a regular set and weights - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MIN - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MAX - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with +inf/-inf scores - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with NaN weights ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with +inf/-inf scores - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with NaN weights ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: Basic ZPOP with a single key - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZPOP with count - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with a single existing sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with multiple existing sorted sets - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP second sorted set has members - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: Check encoding - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET basic ZADD and score update - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZADD - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET element can't be set to NaN with ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD with options syntax error with incomplete pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX option without key - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX existing key - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX returns the number of elements actually added\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX updates existing elements score\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD XX and NX are not compatible\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX with non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD NX only add new elements without updating old ones\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works like ZINCRBY\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD INCR works with a single score-elemenet pair\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD CH option changes return value to all changed elements\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY calls leading to NaN result in error\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version base case\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Return value is the number of actually added items\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version does not add nothing on single parsing err\r\n[\u001B[0;32;49mok\u001B[0m]: ZADD - Variadic version will raise error on missing arg\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY does not work variadic even if shares ZADD implementation\r\n[\u001B[0;32;49mok\u001B[0m]: ZCARD basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM removes key after last element is removed\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version\r\n[\u001B[0;32;49mok\u001B[0m]: ZREM variadic version -- remove elements after key deletion\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREVRANGE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK/ZREVRANK basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANK - after deletion - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - can create a new sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY - increment and decrement - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINCRBY return value\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with LIMIT and WITHSCORES\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZLEXCOUNT advanced\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSLEX with LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX with invalid lex range specifiers\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYSCORE with non-value min or max\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYRANK basics\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE against non-existing key doesn't set destination - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with empty set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with a regular set and weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MIN - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with AGGREGATE MAX - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE basics - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with a regular set and weights - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MIN - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with AGGREGATE MAX - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with +inf/-inf scores - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE with NaN weights skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with +inf/-inf scores - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE with NaN weights skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: Basic ZPOP with a single key - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZPOP with count - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with a single existing sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP with multiple existing sorted sets - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOP second sorted set has members - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE regression with two sets, intset+hashtable\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE regression, should not create NaN in scores\r\n[\u001B[0;32;49mok\u001B[0m]: ZINTERSTORE #516 regression, mixed sets and ziplist zsets\r\n[\u001B[0;32;49mok\u001B[0m]: ZUNIONSTORE result is sorted\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET commands don't accept the empty strings as valid score\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE after a DEBUG RELOAD - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET sorting stresser - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs skiplist implementation backlink consistency test - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs ZRANK augmented skip list stress testing - ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with same key multiple times should work\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with variadic ZADD\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSCORE after a DEBUG RELOAD - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET sorting stresser - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYSCORE fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs skiplist implementation backlink consistency test - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: ZSETs ZRANK augmented skip list stress testing - skiplist\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with same key multiple times should work\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with variadic ZADD\r\n[\u001B[0;32;49mok\u001B[0m]: BZPOPMIN with zero timeout should block indefinitely\r\n[\u001B[0;32;49mok\u001B[0m]: ZSET skiplist order consistency when elements are moved\r\n[13/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/zset (13 seconds)\r\n\u001B[1;37;49mTesting unit/type/hash\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: HSET/HLEN - Small hash creation\r\n[\u001B[0;32;49mok\u001B[0m]: Is the small hash encoded with a ziplist?\r\n[\u001B[0;32;49mok\u001B[0m]: HSET/HLEN - Big hash creation\r\n[\u001B[0;32;49mok\u001B[0m]: Is the big hash encoded with an hash table?\r\n[\u001B[0;32;49mok\u001B[0m]: HGET against the small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGET against the big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGET against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: HSET in update and insert mode\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key missing - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key exists - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key missing - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSETNX target key exists - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMSET wrong number of args\r\n[\u001B[0;32;49mok\u001B[0m]: HMSET - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMSET - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET against non existing key and fields\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET against wrong type\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HMGET - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HKEYS - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HKEYS - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HVALS - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HVALS - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGETALL - small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HGETALL - big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HDEL and return value\r\n[\u001B[0;32;49mok\u001B[0m]: HDEL - more than a single value\r\n[\u001B[0;32;49mok\u001B[0m]: HDEL - hash becomes empty before deleting all specified fields\r\n[\u001B[0;32;49mok\u001B[0m]: HEXISTS\r\n[\u001B[0;32;49mok\u001B[0m]: Is a ziplist encoded Hash promoted on big payload?\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against non existing database key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against non existing hash key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against hash key created by hincrby itself\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY against hash key originally set with HSET\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY fails against hash value with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY fails against hash value with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBY can detect overflows\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against non existing database key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against non existing hash key\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against hash key created by hincrby itself\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT against hash key originally set with HSET\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT over 32bit value\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT over 32bit value with over 32bit increment\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT fails against hash value with spaces (left)\r\n[\u001B[0;32;49mok\u001B[0m]: HINCRBYFLOAT fails against hash value with spaces (right)\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN against the small hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN against the big hash\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN against non existing field\r\n[\u001B[0;32;49mok\u001B[0m]: HSTRLEN corner cases\r\n[\u001B[0;32;49mok\u001B[0m]: Hash ziplist regression test for large keys\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #1 - 10 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #2 - 10 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #1 - 512 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Hash fuzzing #2 - 512 fields\r\n[\u001B[0;32;49mok\u001B[0m]: Stress test the hash ziplist -> hashtable encoding conversion\r\n[14/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/hash (5 seconds)\r\n\u001B[1;37;49mTesting unit/type/stream\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: XADD can add entries into a stream that XRANGE can fetch\r\n[\u001B[0;32;49mok\u001B[0m]: XADD IDs are incremental\r\n[\u001B[0;32;49mok\u001B[0m]: XADD IDs are incremental when ms is the same as well\r\n[\u001B[0;32;49mok\u001B[0m]: XADD IDs correctly report an error when overflowing\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with MAXLEN option\r\n[\u001B[0;32;49mok\u001B[0m]: XADD mass insertion and XLEN\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with ID 0-0\r\n[\u001B[0;32;49mok\u001B[0m]: XRANGE COUNT works as expected\r\n[\u001B[0;32;49mok\u001B[0m]: XREVRANGE COUNT works as expected\r\n[\u001B[0;32;49mok\u001B[0m]: XRANGE can be used to iterate the whole stream\r\n[\u001B[0;32;49mok\u001B[0m]: XREVRANGE returns the reverse of XRANGE\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD with non empty stream\r\n[\u001B[0;32;49mok\u001B[0m]: Non blocking XREAD with empty streams\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD with non empty second stream\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREAD waiting new data\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREAD waiting old data\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREAD will not reply with an empty array\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD: XADD + DEL should not awake client\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD: XADD + DEL + LPUSH should not awake client\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD with same stream name multiple times should work\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD + multiple XADD inside transaction\r\n[\u001B[0;32;49mok\u001B[0m]: XDEL basic test\r\n[\u001B[0;32;49mok\u001B[0m]: XDEL fuzz test\r\n[\u001B[0;32;49mok\u001B[0m]: XRANGE fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: XREVRANGE regression test for issue #5006\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD streamID edge (no-blocking)\r\n[\u001B[0;32;49mok\u001B[0m]: XREAD streamID edge (blocking)\r\n[\u001B[0;32;49mok\u001B[0m]: XADD streamID edge\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with MAXLEN > xlen can propagate correctly\r\n[\u001B[0;32;49mok\u001B[0m]: XADD with ~ MAXLEN can propagate correctly\r\n[\u001B[0;32;49mok\u001B[0m]: XTRIM with ~ MAXLEN can propagate correctly\r\n[\u001B[0;32;49mok\u001B[0m]: XADD can CREATE an empty stream\r\n[\u001B[0;32;49mok\u001B[0m]: XSETID can set a specific ID\r\n[\u001B[0;32;49mok\u001B[0m]: XSETID cannot SETID with smaller ID\r\n[\u001B[0;32;49mok\u001B[0m]: XSETID cannot SETID on non-existent key\r\n[\u001B[0;32;49mok\u001B[0m]: Empty stream can be rewrite into AOF correctly\r\n[\u001B[0;32;49mok\u001B[0m]: Stream can be rewrite into AOF correctly after XDEL lastid\r\n[15/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/stream (29 seconds)\r\n\u001B[1;37;49mTesting unit/type/stream-cgroups\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: XGROUP CREATE: creation and duplicate group name detection\r\n[\u001B[0;32;49mok\u001B[0m]: XGROUP CREATE: automatic stream creation fails without MKSTREAM\r\n[\u001B[0;32;49mok\u001B[0m]: XGROUP CREATE: automatic stream creation works with MKSTREAM\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP will return only new elements\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP can read the history of the elements we own\r\n[\u001B[0;32;49mok\u001B[0m]: XPENDING is able to return pending items\r\n[\u001B[0;32;49mok\u001B[0m]: XPENDING can return single consumer items\r\n[\u001B[0;32;49mok\u001B[0m]: XACK is able to remove items from the client/group PEL\r\n[\u001B[0;32;49mok\u001B[0m]: XACK can't remove the same item multiple times\r\n[\u001B[0;32;49mok\u001B[0m]: XACK is able to accept multiple arguments\r\n[\u001B[0;32;49mok\u001B[0m]: PEL NACK reassignment after XGROUP SETID event\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP will not report data on empty history. Bug #5577\r\n[\u001B[0;32;49mok\u001B[0m]: XREADGROUP history reporting of deleted entries. Bug #5570\r\n[\u001B[0;32;49mok\u001B[0m]: Blocking XREADGROUP will not reply with an empty array\r\n[\u001B[0;32;49mok\u001B[0m]: XCLAIM can claim PEL items from another consumer\r\n[\u001B[0;32;49mok\u001B[0m]: XCLAIM without JUSTID increments delivery count\r\n[\u001B[0;32;49mok\u001B[0m]: Consumer group last ID propagation to slave (NOACK=0)\r\n[\u001B[0;32;49mok\u001B[0m]: Consumer group last ID propagation to slave (NOACK=1)\r\n[16/50 \u001B[0;33;49mdone\u001B[0m]: unit/type/stream-cgroups (3 seconds)\r\n\u001B[1;37;49mTesting unit/sort\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Old Ziplist: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Old Ziplist: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Old Ziplist: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Old Linked list: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Old Linked list: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Old Linked list: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Old Big Linked list: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Old Big Linked list: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Old Big Linked list: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Intset: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Intset: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Intset: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Hash table: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Hash table: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Hash table: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: Big Hash table: SORT BY key\r\n[\u001B[0;32;49mok\u001B[0m]: Big Hash table: SORT BY key with limit\r\n[\u001B[0;32;49mok\u001B[0m]: Big Hash table: SORT BY hash field\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET #\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET <const>\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET (key and hash) with sanity check\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY key STORE\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY hash field STORE\r\n[\u001B[0;32;49mok\u001B[0m]: SORT extracts STORE correctly\r\n[\u001B[0;32;49mok\u001B[0m]: SORT extracts multiple STORE correctly\r\n[\u001B[0;32;49mok\u001B[0m]: SORT DESC\r\n[\u001B[0;32;49mok\u001B[0m]: SORT ALPHA against integer encoded strings\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set BY nosort should retain ordering\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set BY nosort + LIMIT\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set BY nosort works as expected from scripts\r\n[\u001B[0;32;49mok\u001B[0m]: SORT sorted set: +inf and -inf handling\r\n[\u001B[0;32;49mok\u001B[0m]: SORT regression for issue #19, sorting floats\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with STORE returns zero if result is empty (github issue 224)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with STORE does not create empty lists (github issue 224)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with STORE removes key if result is empty (github issue 227)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT with BY <constant> and STORE should still order output\r\n[\u001B[0;32;49mok\u001B[0m]: SORT will complain with numerical sorting and bad doubles (1)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT will complain with numerical sorting and bad doubles (2)\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY sub-sorts lexicographically if score is the same\r\n[\u001B[0;32;49mok\u001B[0m]: SORT GET with pattern ending with just -> does not get hash field\r\n[\u001B[0;32;49mok\u001B[0m]: SORT by nosort retains native order for lists\r\n[\u001B[0;32;49mok\u001B[0m]: SORT by nosort plus store retains native order for lists\r\n[\u001B[0;32;49mok\u001B[0m]: SORT by nosort with limit returns based on original list order\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list BY key, 100 times\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list BY hash field, 100 times\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list directly, 100 times\r\n[\u001B[0;32;49mok\u001B[0m]: SORT speed, 100 element list BY <const>, 100 times\r\n[17/50 \u001B[0;33;49mdone\u001B[0m]: unit/sort (9 seconds)\r\n\u001B[1;37;49mTesting unit/expire\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - set timeouts multiple times\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - It should be still possible to read 'x'\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - After 2.1 seconds the key should no longer be here\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE - write on expire should work\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIREAT - Check for EXPIRE alike behavior\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Set + Expire combo operation. Check for TTL\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Check value\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Overwrite old key\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Wait for the key to expire\r\n[\u001B[0;32;49mok\u001B[0m]: SETEX - Wrong time parameter\r\n[\u001B[0;32;49mok\u001B[0m]: PERSIST can undo an EXPIRE\r\n[\u001B[0;32;49mok\u001B[0m]: PERSIST returns 0 against non existing or non volatile keys\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE pricision is now the millisecond\r\n[\u001B[0;32;49mok\u001B[0m]: PEXPIRE/PSETEX/PEXPIREAT can set sub-second expires\r\n[\u001B[0;32;49mok\u001B[0m]: TTL returns time to live in seconds\r\n[\u001B[0;32;49mok\u001B[0m]: PTTL returns time to live in milliseconds\r\n[\u001B[0;32;49mok\u001B[0m]: TTL / PTTL return -1 if key has no expire\r\n[\u001B[0;32;49mok\u001B[0m]: TTL / PTTL return -2 if key does not exit\r\n[\u001B[0;32;49mok\u001B[0m]: Redis should actively expire keys incrementally\r\n[\u001B[0;32;49mok\u001B[0m]: Redis should lazy expire keys\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE should not resurrect keys (issue #1026)\r\n[\u001B[0;32;49mok\u001B[0m]: 5 keys in, 5 keys out\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRE with empty string as TTL should report an error\r\n[\u001B[0;32;49mok\u001B[0m]: SET - use EX/PX option, TTL should not be reseted after loadaof\r\n[18/50 \u001B[0;33;49mdone\u001B[0m]: unit/expire (15 seconds)\r\n\u001B[1;37;49mTesting unit/other\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SAVE - make sure there are all the types as values\r\n[\u001B[0;32;49mok\u001B[0m]: FUZZ stresser with data model binary\r\n[\u001B[0;32;49mok\u001B[0m]: FUZZ stresser with data model alpha\r\n[\u001B[0;32;49mok\u001B[0m]: FUZZ stresser with data model compr\r\n[\u001B[0;32;49mok\u001B[0m]: BGSAVE\r\n[\u001B[0;32;49mok\u001B[0m]: SELECT an out of range DB\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRES after a reload (snapshot + append only file rewrite)\r\n[\u001B[0;32;49mok\u001B[0m]: EXPIRES after AOF reload (without rewrite)\r\n[\u001B[0;32;49mok\u001B[0m]: PIPELINING stresser (also a regression for the old epoll bug)\r\n[\u001B[0;32;49mok\u001B[0m]: APPEND basics\r\n[\u001B[0;32;49mok\u001B[0m]: APPEND basics, integer encoded values\r\n[\u001B[0;32;49mok\u001B[0m]: APPEND fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB\r\n[\u001B[0;32;49mok\u001B[0m]: Perform a final SAVE to leave a clean DB on disk\r\n[19/50 \u001B[0;33;49mdone\u001B[0m]: unit/other (9 seconds)\r\n\u001B[1;37;49mTesting unit/multi\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: MUTLI / EXEC basics\r\n[\u001B[0;32;49mok\u001B[0m]: DISCARD\r\n[\u001B[0;32;49mok\u001B[0m]: Nested MULTI are not allowed\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI where commands alter argc/argv\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH inside MULTI is not allowed\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fails if there are errors while queueing commands #1\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fails if there are errors while queueing commands #2\r\n[\u001B[0;32;49mok\u001B[0m]: If EXEC aborts, the client MULTI state is cleared\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC works on WATCHed key not modified\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fail on WATCHed key modified (1 key of 1 watched)\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fail on WATCHed key modified (1 key of 5 watched)\r\n[\u001B[0;32;49mok\u001B[0m]: EXEC fail on WATCHed key modified by SORT with STORE even if the result is empty\r\n[\u001B[0;32;49mok\u001B[0m]: After successful EXEC key is no longer watched\r\n[\u001B[0;32;49mok\u001B[0m]: After failed EXEC key is no longer watched\r\n[\u001B[0;32;49mok\u001B[0m]: It is possible to UNWATCH\r\n[\u001B[0;32;49mok\u001B[0m]: UNWATCH when there is nothing watched works as expected\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHALL is able to touch the watched keys\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHALL does not touch non affected keys\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB is able to touch the watched keys\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB does not touch non affected keys\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH is able to remember the DB a key belongs to\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH will consider touched keys target of EXPIRE\r\n[\u001B[0;32;49mok\u001B[0m]: WATCH will not consider touched expired keys\r\n[\u001B[0;32;49mok\u001B[0m]: DISCARD should clear the WATCH dirty flag on the client\r\n[\u001B[0;32;49mok\u001B[0m]: DISCARD should UNWATCH all the keys\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (single write command)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (empty transaction)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (read-only commands)\r\n[\u001B[0;32;49mok\u001B[0m]: MULTI / EXEC is propagated correctly (write command, no effect)\r\n[20/50 \u001B[0;33;49mdone\u001B[0m]: unit/multi (2 seconds)\r\n\u001B[1;37;49mTesting unit/quit\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: QUIT returns OK\r\n[\u001B[0;32;49mok\u001B[0m]: Pipelined commands after QUIT must not be executed\r\n[\u001B[0;32;49mok\u001B[0m]: Pipelined commands after QUIT that exceed read buffer size\r\n[21/50 \u001B[0;33;49mdone\u001B[0m]: unit/quit (0 seconds)\r\n\u001B[1;37;49mTesting unit/aofrw\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite during write load: RDB preamble=yes\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite during write load: RDB preamble=no\r\n[\u001B[0;32;49mok\u001B[0m]: Turning off AOF kills the background writing child if any\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of list with quicklist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of list with quicklist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with intset encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with hashtable encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with intset encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of set with hashtable encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with ziplist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with hashtable encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with ziplist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of hash with hashtable encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with ziplist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with skiplist encoding, string data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with ziplist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: AOF rewrite of zset with skiplist encoding, int data\r\n[\u001B[0;32;49mok\u001B[0m]: BGREWRITEAOF is delayed if BGSAVE is in progress\r\n[\u001B[0;32;49mok\u001B[0m]: BGREWRITEAOF is refused if already in progress\r\n[22/50 \u001B[0;33;49mdone\u001B[0m]: unit/aofrw (97 seconds)\r\n\u001B[1;37;49mTesting integration/block-repl\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication with blocking lists and sorted sets operations\r\n[23/50 \u001B[0;33;49mdone\u001B[0m]: integration/block-repl (27 seconds)\r\n\u001B[1;37;49mTesting integration/replication\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Slave enters handshake\r\n[\u001B[0;32;49mok\u001B[0m]: Slave is able to detect timeout during handshake\r\n[\u001B[0;32;49mok\u001B[0m]: Set instance A as slave of B\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH replication, when blocking against empty list\r\n[\u001B[0;32;49mok\u001B[0m]: BRPOPLPUSH replication, list exists\r\n[\u001B[0;32;49mok\u001B[0m]: BLPOP followed by role change, issue #2473\r\n[\u001B[0;32;49mok\u001B[0m]: Second server should have role master at first\r\n[\u001B[0;32;49mok\u001B[0m]: SLAVEOF should start with link status \"down\"\r\n[\u001B[0;32;49mok\u001B[0m]: The role should immediately be changed to \"replica\"\r\n[\u001B[0;32;49mok\u001B[0m]: Sync should have transferred keys from master\r\n[\u001B[0;32;49mok\u001B[0m]: The link status should be up\r\n[\u001B[0;32;49mok\u001B[0m]: SET on the master should immediately propagate\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHALL should replicate\r\n[\u001B[0;32;49mok\u001B[0m]: ROLE in master reports master with a slave\r\n[\u001B[0;32;49mok\u001B[0m]: ROLE in slave reports slave in connected state\r\n[\u001B[0;32;49mok\u001B[0m]: Connect multiple replicas at the same time (issue #141), diskless=no\r\n[\u001B[0;32;49mok\u001B[0m]: Connect multiple replicas at the same time (issue #141), diskless=yes\r\n[\u001B[0;32;49mok\u001B[0m]: Master stream is correctly processed while the replica has a script in -BUSY state\r\n[24/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication (148 seconds)\r\n\u001B[1;37;49mTesting integration/replication-2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: If min-slaves-to-write is honored, write is accepted\r\n[\u001B[0;32;49mok\u001B[0m]: No write if min-slaves-to-write is < attached slaves\r\n[\u001B[0;32;49mok\u001B[0m]: If min-slaves-to-write is honored, write is accepted (again)\r\n[\u001B[0;32;49mok\u001B[0m]: No write if min-slaves-max-lag is > of the slave lag\r\n[\u001B[0;32;49mok\u001B[0m]: min-slaves-to-write is ignored by slaves\r\n[\u001B[0;32;49mok\u001B[0m]: MASTER and SLAVE dataset should be identical after complex ops\r\n[25/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-2 (16 seconds)\r\n\u001B[1;37;49mTesting integration/replication-3\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: MASTER and SLAVE consistency with expire\r\n[\u001B[0;32;49mok\u001B[0m]: Slave is able to evict keys created in writable slaves\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: MASTER and SLAVE consistency with EVALSHA replication\r\n[\u001B[0;32;49mok\u001B[0m]: SLAVE can reload \"lua\" AUX RDB fields of duplicated scripts\r\n[26/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-3 (32 seconds)\r\n\u001B[1;37;49mTesting integration/replication-4\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication with parallel clients writing in differnet DBs\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: With min-slaves-to-write (1,3): master should be writable\r\n[\u001B[0;32;49mok\u001B[0m]: With min-slaves-to-write (2,3): master should not be writable\r\n[\u001B[0;32;49mok\u001B[0m]: With min-slaves-to-write: master not writable with lagged slave\r\n[\u001B[0;32;49mok\u001B[0m]: First server should have role slave after SLAVEOF\r\n[\u001B[0;32;49mok\u001B[0m]: Replication: commands with many arguments (issue #1221)\r\n[\u001B[0;32;49mok\u001B[0m]: Replication of SPOP command -- alsoPropagate() API\r\n[27/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-4 (34 seconds)\r\n\u001B[1;37;49mTesting integration/replication-psync\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no reconnection, just sync (diskless: no, reconnect: 0)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok psync (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no backlog (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok after delay (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: backlog expired (diskless: no, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no reconnection, just sync (diskless: yes, reconnect: 0)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok psync (diskless: yes, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: no backlog (diskless: yes, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: ok after delay (diskless: yes, reconnect: 1)\r\n[\u001B[0;32;49mok\u001B[0m]: Slave should be able to synchronize with the master\r\n[\u001B[0;32;49mok\u001B[0m]: Detect write load to master\r\n[\u001B[0;32;49mok\u001B[0m]: Test replication partial resync: backlog expired (diskless: yes, reconnect: 1)\r\n[28/50 \u001B[0;33;49mdone\u001B[0m]: integration/replication-psync (100 seconds)\r\n\u001B[1;37;49mTesting integration/aof\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Unfinished MULTI: Server should start if load-truncated is yes\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Server should start if load-truncated is yes\r\n[\u001B[0;32;49mok\u001B[0m]: Truncated AOF loaded: we expect foo to be equal to 5\r\n[\u001B[0;32;49mok\u001B[0m]: Append a new command after loading an incomplete AOF\r\n[\u001B[0;32;49mok\u001B[0m]: Short read + command: Server should start\r\n[\u001B[0;32;49mok\u001B[0m]: Truncated AOF loaded: we expect foo to be equal to 6 now\r\n[\u001B[0;32;49mok\u001B[0m]: Bad format: Server should have logged an error\r\n[\u001B[0;32;49mok\u001B[0m]: Unfinished MULTI: Server should have logged an error\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Server should have logged an error\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Utility should confirm the AOF is not valid\r\n[\u001B[0;32;49mok\u001B[0m]: Short read: Utility should be able to fix the AOF\r\n[\u001B[0;32;49mok\u001B[0m]: Fixed AOF: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: Fixed AOF: Keyspace should contain values that were parseable\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Set should have 1 member\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+SPOP: Set should have 1 member\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+EXPIRE: Server should have been started\r\n[\u001B[0;32;49mok\u001B[0m]: AOF+EXPIRE: List should be empty\r\n[\u001B[0;32;49mok\u001B[0m]: Redis should not try to convert DEL into EXPIREAT for EXPIRE -1\r\n[29/50 \u001B[0;33;49mdone\u001B[0m]: integration/aof (3 seconds)\r\n\u001B[1;37;49mTesting integration/rdb\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: RDB encoding loading test\r\n[\u001B[0;32;49mok\u001B[0m]: Server started empty with non-existing RDB file\r\n[\u001B[0;32;49mok\u001B[0m]: Server started empty with empty RDB file\r\n[\u001B[0;32;49mok\u001B[0m]: Test RDB stream encoding\r\n[\u001B[0;32;49mok\u001B[0m]: Server should not start if RDB is corrupted\r\n[30/50 \u001B[0;33;49mdone\u001B[0m]: integration/rdb (2 seconds)\r\n\u001B[1;37;49mTesting integration/convert-zipmap-hash-on-load\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: RDB load zipmap hash: converts to ziplist\r\n[\u001B[0;32;49mok\u001B[0m]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-entries is exceeded\r\n[\u001B[0;32;49mok\u001B[0m]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-value is exceeded\r\n[31/50 \u001B[0;33;49mdone\u001B[0m]: integration/convert-zipmap-hash-on-load (0 seconds)\r\n\u001B[1;37;49mTesting integration/logging\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Server is able to generate a stack trace on selected systems\r\n[32/50 \u001B[0;33;49mdone\u001B[0m]: integration/logging (1 seconds)\r\n\u001B[1;37;49mTesting integration/psync2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: --- CYCLE 1 ---\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #3 to replicate from #1\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #0 to replicate from #3\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #4 to replicate from #1\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #2 to replicate from #0\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after failover\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: generate load while killing replication links\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after load (x = 39955)\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: --- CYCLE 2 ---\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: [NEW LAYOUT] Set #2 as master\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #1 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #4 to replicate from #1\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #0 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #3 to replicate from #0\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after failover\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: generate load while killing replication links\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after load (x = 82245)\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: --- CYCLE 3 ---\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #2 to replicate from #0\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #3 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #1 to replicate from #2\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Set #4 to replicate from #3\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after failover\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: generate load while killing replication links\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: cluster is consistent after load (x = 128770)\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Bring the master back again for next test\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Partial resync after restart using RDB aux fields\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2: Replica RDB restart with EVALSHA in backlog issue #4483\r\n[33/50 \u001B[0;33;49mdone\u001B[0m]: integration/psync2 (28 seconds)\r\n\u001B[1;37;49mTesting integration/psync2-reg\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: setup\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill first replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: kill chained replica\r\n[\u001B[0;32;49mok\u001B[0m]: PSYNC2 #3899 regression: verify consistency\r\n[34/50 \u001B[0;33;49mdone\u001B[0m]: integration/psync2-reg (23 seconds)\r\n\u001B[1;37;49mTesting unit/pubsub\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Pub/Sub PING\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/SUBSCRIBE basics\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/SUBSCRIBE with two clients\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/SUBSCRIBE after UNSUBSCRIBE without arguments\r\n[\u001B[0;32;49mok\u001B[0m]: SUBSCRIBE to one channel more than once\r\n[\u001B[0;32;49mok\u001B[0m]: UNSUBSCRIBE from non-subscribed channels\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/PSUBSCRIBE basics\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/PSUBSCRIBE with two clients\r\n[\u001B[0;32;49mok\u001B[0m]: PUBLISH/PSUBSCRIBE after PUNSUBSCRIBE without arguments\r\n[\u001B[0;32;49mok\u001B[0m]: PUNSUBSCRIBE from non-subscribed channels\r\n[\u001B[0;32;49mok\u001B[0m]: NUMSUB returns numbers, not strings (#1561)\r\n[\u001B[0;32;49mok\u001B[0m]: Mix SUBSCRIBE and PSUBSCRIBE\r\n[\u001B[0;32;49mok\u001B[0m]: PUNSUBSCRIBE and UNSUBSCRIBE should always reply\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we receive keyspace notifications\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we receive keyevent notifications\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we can receive both kind of events\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: we are able to mask events\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: general events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: list events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: set events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: zset events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: hash events test\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: expired events (triggered expire)\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: expired events (background expire)\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: evicted events\r\n[\u001B[0;32;49mok\u001B[0m]: Keyspace notifications: test CONFIG GET/SET of event flags\r\n[35/50 \u001B[0;33;49mdone\u001B[0m]: unit/pubsub (0 seconds)\r\n\u001B[1;37;49mTesting unit/slowlog\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - check that it starts with an empty log\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - only logs commands taking more time than specified\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - max entries is correctly handled\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - GET optional argument to limit output len works\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - RESET subcommand works\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - logged entry sanity check\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - commands with too many arguments are trimmed\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - too long arguments are trimmed\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - EXEC is not logged, just executed commands\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - can clean older entires\r\n[\u001B[0;32;49mok\u001B[0m]: SLOWLOG - can be disabled\r\n[36/50 \u001B[0;33;49mdone\u001B[0m]: unit/slowlog (2 seconds)\r\n\u001B[1;37;49mTesting unit/scripting\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Does Lua interpreter replies to our requests?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua integer -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua string -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua true boolean -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua false boolean -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua status code reply -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua error reply -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Lua table -> Redis protocol type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Are the KEYS and ARGV arrays populated correctly?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - is Lua able to call Redis API?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Can we call a SHA1 if already defined?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Can we call a SHA1 in uppercase?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Do we get an error on invalid SHA1?\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA - Do we get an error on non defined SHA1?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis integer -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis bulk -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis multi bulk -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis status reply -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis error reply -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Redis nil bulk reply -> Lua type conversion\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Is the Lua client using the currently selected DB?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - SELECT inside Lua should not affect the caller\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Scripts can't run certain commands\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Scripts can't run certain commands\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - No arguments to redis.call/pcall is considered an error\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - JSON numeric decoding\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - JSON string decoding\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - cmsgpack can pack double?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - cmsgpack can pack negative int64?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - cmsgpack can pack and unpack circular references?\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Numerical sanity check from bitop\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Verify minimal bitop functionality\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL - Able to parse trailing comments\r\n[\u001B[0;32;49mok\u001B[0m]: SCRIPTING FLUSH - is able to clear the scripts cache?\r\n[\u001B[0;32;49mok\u001B[0m]: SCRIPT EXISTS - can detect already defined scripts?\r\n[\u001B[0;32;49mok\u001B[0m]: SCRIPT LOAD - is able to register scripts in the scripting cache\r\n[\u001B[0;32;49mok\u001B[0m]: In the context of Lua the output of random commands gets ordered\r\n[\u001B[0;32;49mok\u001B[0m]: SORT is normally not alpha re-ordered for the scripting engine\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY <constant> output gets ordered for scripting\r\n[\u001B[0;32;49mok\u001B[0m]: SORT BY <constant> with GET gets ordered for scripting\r\n[\u001B[0;32;49mok\u001B[0m]: redis.sha1hex() implementation\r\n[\u001B[0;32;49mok\u001B[0m]: Globals protection reading an undeclared global variable\r\n[\u001B[0;32;49mok\u001B[0m]: Globals protection setting an undeclared global*\r\n[\u001B[0;32;49mok\u001B[0m]: Test an example script DECR_IF_GT\r\n[\u001B[0;32;49mok\u001B[0m]: Scripting engine resets PRNG at every script execution\r\n[\u001B[0;32;49mok\u001B[0m]: Scripting engine PRNG can be seeded correctly\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL does not leak in the Lua stack\r\n[\u001B[0;32;49mok\u001B[0m]: EVAL processes writes from AOF in read-only slaves\r\n[\u001B[0;32;49mok\u001B[0m]: We can call scripts rewriting client->argv from Lua\r\n[\u001B[0;32;49mok\u001B[0m]: Call Redis command with many args from Lua (issue #1764)\r\n[\u001B[0;32;49mok\u001B[0m]: Number conversion precision test (issue #1118)\r\n[\u001B[0;32;49mok\u001B[0m]: String containing number precision test (regression of issue #1118)\r\n[\u001B[0;32;49mok\u001B[0m]: Verify negative arg count is error instead of crash (issue #1842)\r\n[\u001B[0;32;49mok\u001B[0m]: Correct handling of reused argv (issue #1939)\r\n[\u001B[0;32;49mok\u001B[0m]: Functions in the Redis namespace are able to report errors\r\n[\u001B[0;32;49mok\u001B[0m]: Timedout read-only scripts can be killed by SCRIPT KILL\r\n[\u001B[0;32;49mok\u001B[0m]: Timedout script link is still usable after Lua returns\r\n[\u001B[0;32;49mok\u001B[0m]: Timedout scripts that modified data can't be killed by SCRIPT KILL\r\n[\u001B[0;32;49mok\u001B[0m]: SHUTDOWN NOSAVE can kill a timedout script anyway\r\n[\u001B[0;32;49mok\u001B[0m]: Before the replica connects we issue two EVAL commands (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Connect a replica to the master instance (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Now use EVALSHA against the master, with both SHAs (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: If EVALSHA was replicated as EVAL, 'x' should be '4' (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Replication of script multiple pushes to list with BLPOP (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA replication when first call is readonly (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Lua scripts using SELECT are replicated correctly (scripts replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Before the replica connects we issue two EVAL commands (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Connect a replica to the master instance (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Now use EVALSHA against the master, with both SHAs (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: If EVALSHA was replicated as EVAL, 'x' should be '4' (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Replication of script multiple pushes to list with BLPOP (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: EVALSHA replication when first call is readonly (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Lua scripts using SELECT are replicated correctly (commmands replication)\r\n[\u001B[0;32;49mok\u001B[0m]: Connect a replica to the master instance\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.replicate_commands() must be issued before any write\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.replicate_commands() must be issued before any write (2)\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.set_repl() must be issued after replicate_commands()\r\n[\u001B[0;32;49mok\u001B[0m]: Redis.set_repl() don't accept invalid values\r\n[\u001B[0;32;49mok\u001B[0m]: Test selective replication of certain Redis commands from Lua\r\n[\u001B[0;32;49mok\u001B[0m]: PRNG is seeded randomly for command replication\r\n[\u001B[0;32;49mok\u001B[0m]: Using side effects is not a problem with command replication\r\n[37/50 \u001B[0;33;49mdone\u001B[0m]: unit/scripting (6 seconds)\r\n\u001B[1;37;49mTesting unit/maxmemory\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Without maxmemory small integers are shared\r\n[\u001B[0;32;49mok\u001B[0m]: With maxmemory and non-LRU policy integers are still shared\r\n[\u001B[0;32;49mok\u001B[0m]: With maxmemory and LRU policy integers are not shared\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy allkeys-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy allkeys-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy allkeys-lfu)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-lfu)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - is the memory limit honoured? (policy volatile-ttl)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-lru)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-random)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-ttl)\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-lru should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-lfu should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-random should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: maxmemory - policy volatile-ttl should only remove volatile keys.\r\n[\u001B[0;32;49mok\u001B[0m]: slave buffer are counted correctly\r\n[\u001B[0;32;49mok\u001B[0m]: replica buffer don't induce eviction\r\n[38/50 \u001B[0;33;49mdone\u001B[0m]: unit/maxmemory (43 seconds)\r\n\u001B[1;37;49mTesting unit/introspection\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT LIST\r\n[\u001B[0;32;49mok\u001B[0m]: MONITOR can log executed commands\r\n[\u001B[0;32;49mok\u001B[0m]: MONITOR can log commands issued by the scripting engine\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT GETNAME should return NIL if name is not assigned\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT LIST shows empty fields for unassigned names\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT SETNAME does not accept spaces\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT SETNAME can assign a name to this connection\r\n[\u001B[0;32;49mok\u001B[0m]: CLIENT SETNAME can change the name of an existing connection\r\n[\u001B[0;32;49mok\u001B[0m]: After CLIENT SETNAME, connection can still be closed\r\n[39/50 \u001B[0;33;49mdone\u001B[0m]: unit/introspection (0 seconds)\r\n\u001B[1;37;49mTesting unit/introspection-2\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: TTL and TYPYE do not alter the last access time of a key\r\n[\u001B[0;32;49mok\u001B[0m]: TOUCH alters the last access time of a key\r\n[\u001B[0;32;49mok\u001B[0m]: TOUCH returns the number of existing keys specified\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for GEOADD\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for EXPIRE\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for BRPOP\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for MULTI\r\n[\u001B[0;32;49mok\u001B[0m]: command stats for scripts\r\n[40/50 \u001B[0;33;49mdone\u001B[0m]: unit/introspection-2 (7 seconds)\r\n\u001B[1;37;49mTesting unit/limits\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Check if maxclients works refusing connections\r\n[41/50 \u001B[0;33;49mdone\u001B[0m]: unit/limits (1 seconds)\r\n\u001B[1;37;49mTesting unit/obuf-limits\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Client output buffer hard limit is enforced\r\n[\u001B[0;32;49mok\u001B[0m]: Client output buffer soft limit is not enforced if time is not overreached\r\n[\u001B[0;32;49mok\u001B[0m]: Client output buffer soft limit is enforced if time is overreached\r\n[42/50 \u001B[0;33;49mdone\u001B[0m]: unit/obuf-limits (168 seconds)\r\n\u001B[1;37;49mTesting unit/bitops\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT returns 0 against non existing key\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT returns 0 with out of range indexes\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT returns 0 with negative indexes where start > end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #1\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #2\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #3\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #4\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT against test vector #5\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT fuzzing without start/end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT fuzzing with start/end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT with start, end\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT syntax error #1\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT regression test for github issue #582\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT misaligned prefix\r\n[\u001B[0;32;49mok\u001B[0m]: BITCOUNT misaligned prefix + full words + remainder\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP NOT (empty string)\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP NOT (known string)\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP where dest and target are the same key\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP AND|OR|XOR don't change the string with single input key\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP missing key is considered a stream of zero\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP shorter keys are zero-padded to the key with max length\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP and fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP or fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP xor fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP NOT fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP with integer encoded source objects\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP with non string source key\r\n[\u001B[0;32;49mok\u001B[0m]: BITOP with empty string after non empty string (issue #529)\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 with empty key returns 0\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 with empty key returns -1\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 with string less than 1 word works\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 with string less than 1 word works\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 starting at unaligned address\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 starting at unaligned address\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 unaligned+full word+reminder\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 unaligned+full word+reminder\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 returns -1 if string is all 0 bits\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 works with intervals\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 works with intervals\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 changes behavior if end is given\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=1 fuzzy testing using SETBIT\r\n[\u001B[0;32;49mok\u001B[0m]: BITPOS bit=0 fuzzy testing using SETBIT\r\n[43/50 \u001B[0;33;49mdone\u001B[0m]: unit/bitops (4 seconds)\r\n\u001B[1;37;49mTesting unit/bitfield\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD signed SET and GET basics\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD unsigned SET and GET basics\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD #<idx> form\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD basic INCRBY form\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD chaining of multiple commands\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD unsigned overflow wrap\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD unsigned overflow sat\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD signed overflow wrap\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD signed overflow sat\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD overflow detection fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD overflow wrap fuzzing\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD regression for #3221\r\n[\u001B[0;32;49mok\u001B[0m]: BITFIELD regression for #3564\r\n[44/50 \u001B[0;33;49mdone\u001B[0m]: unit/bitfield (1 seconds)\r\n\u001B[1;37;49mTesting unit/geo\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD create\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD update\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD invalid coordinates\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD multi add\r\n[\u001B[0;32;49mok\u001B[0m]: Check geoset values\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS simple (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS withdist (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS with COUNT\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS with COUNT but missing integer argument\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS with COUNT DESC\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS HUGE, issue #2767\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUSBYMEMBER simple (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUSBYMEMBER withdist (sorted)\r\n[\u001B[0;32;49mok\u001B[0m]: GEOHASH is able to return geohash strings\r\n[\u001B[0;32;49mok\u001B[0m]: GEOPOS simple\r\n[\u001B[0;32;49mok\u001B[0m]: GEOPOS missing element\r\n[\u001B[0;32;49mok\u001B[0m]: GEODIST simple & unit\r\n[\u001B[0;32;49mok\u001B[0m]: GEODIST missing elements\r\n[\u001B[0;32;49mok\u001B[0m]: GEORADIUS STORE option: syntax error\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STORE option: incompatible options\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STORE option: plain usage\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STOREDIST option: plain usage\r\n[\u001B[0;32;49mok\u001B[0m]: GEORANGE STOREDIST option: COUNT ASC and DESC\r\n[\u001B[0;32;49mok\u001B[0m]: GEOADD + GEORANGE randomized test\r\n[45/50 \u001B[0;33;49mdone\u001B[0m]: unit/geo (21 seconds)\r\n\u001B[1;37;49mTesting unit/memefficiency\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 32\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 64\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 128\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 1024\r\n[\u001B[0;32;49mok\u001B[0m]: Memory efficiency with values in range 16384\r\n# Memory\r\nused_memory:104857512\r\nused_memory_human:100.00M\r\nused_memory_rss:167510016\r\nused_memory_rss_human:159.75M\r\nused_memory_peak:160476576\r\nused_memory_peak_human:153.04M\r\nused_memory_peak_perc:65.34%\r\nused_memory_overhead:25811926\r\nused_memory_startup:824224\r\nused_memory_dataset:79045586\r\nused_memory_dataset_perc:75.98%\r\nallocator_allocated:104998960\r\nallocator_active:133365760\r\nallocator_resident:166985728\r\ntotal_system_memory:10278404096\r\ntotal_system_memory_human:9.57G\r\nused_memory_lua:37888\r\nused_memory_lua_human:37.00K\r\nused_memory_scripts:0\r\nused_memory_scripts_human:0B\r\nnumber_of_cached_scripts:0\r\nmaxmemory:104857600\r\nmaxmemory_human:100.00M\r\nmaxmemory_policy:allkeys-lru\r\nallocator_frag_ratio:1.27\r\nallocator_frag_bytes:28366800\r\nallocator_rss_ratio:1.25\r\nallocator_rss_bytes:33619968\r\nrss_overhead_ratio:1.00\r\nrss_overhead_bytes:524288\r\nmem_fragmentation_ratio:1.60\r\nmem_fragmentation_bytes:62693528\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:0\r\nmem_clients_slaves:0\r\nmem_clients_normal:49694\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.1.0\r\nactive_defrag_running:67\r\nlazyfree_pending_objects:0\r\n\r\n___ Begin jemalloc statistics ___\r\nVersion: \"5.1.0-0-g0\"\r\nBuild-time option settings\r\n  config.cache_oblivious: true\r\n  config.debug: false\r\n  config.fill: true\r\n  config.lazy_lock: false\r\n  config.malloc_conf: \"\"\r\n  config.prof: false\r\n  config.prof_libgcc: false\r\n  config.prof_libunwind: false\r\n  config.stats: true\r\n  config.utrace: false\r\n  config.xmalloc: false\r\nRun-time option settings\r\n  opt.abort: false\r\n  opt.abort_conf: false\r\n  opt.retain: true\r\n  opt.dss: \"secondary\"\r\n  opt.narenas: 128\r\n  opt.percpu_arena: \"disabled\"\r\n  opt.metadata_thp: \"disabled\"\r\n  opt.background_thread: false (background_thread: false)\r\n  opt.dirty_decay_ms: 10000 (arenas.dirty_decay_ms: 10000)\r\n  opt.muzzy_decay_ms: 10000 (arenas.muzzy_decay_ms: 10000)\r\n  opt.junk: \"false\"\r\n  opt.zero: false\r\n  opt.tcache: true\r\n  opt.lg_tcache_max: 15\r\n  opt.thp: \"default\"\r\n  opt.stats_print: false\r\n  opt.stats_print_opts: \"\"\r\nArenas: 128\r\nQuantum size: 8\r\nPage size: 65536\r\nMaximum thread-cached size class: 229376\r\nNumber of bin size classes: 55\r\nNumber of thread-cache bin size classes: 55\r\nNumber of large size classes: 180\r\nAllocated: 105254960, active: 133693440, metadata: 5261600 (n_thp 0), resident: 166985728, mapped: 178520064, retained: 56360960\r\nBackground threads: 0, num_runs: 0, run_interval: 0 ns\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nbackground_thread                 380               0               0               1               0               0           0\r\nctl                               754               0               0               1               0               0           0\r\nprof                                0               0               0               0               0               0           0\r\narenas[0]:\r\nassigned threads: 1\r\nuptime: 22570024827\r\ndss allocation precedence: \"secondary\"\r\ndecaying:  time       npages       sweeps     madvises       purged\r\n   dirty: 10000          428           10           46          324\r\n   muzzy: 10000            0            0            0            0\r\n                            allocated     nmalloc     ndalloc   nrequests\r\nsmall:                       96538672     3799144     2132281     7311748\r\nlarge:                        8716288           2           0           2\r\ntotal:                      105254960     3799146     2132281     7311750\r\n                                     \r\nactive:                     133693440\r\nmapped:                     178520064\r\nretained:                    56360960\r\nbase:                         5204248\r\ninternal:                       57352\r\nmetadata_thp:                       0\r\ntcache_bytes:                  340088\r\nresident:                   166985728\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nlarge                             190               0               0               1               0               0           0\r\nextent_avail                     1242               0               0               3               0               0           0\r\nextents_dirty                    1586               0               0               3               0               0           0\r\nextents_muzzy                    1031               0               0               3               0               0           0\r\nextents_retained                 1917               0               0               3               0               0           0\r\ndecay_dirty                      3080               0               0               1               0               0           0\r\ndecay_muzzy                      3070               0               0               1               0               0           0\r\nbase                             1367               0               0               3               0               0           0\r\ntcache_list                       191               0               0               1               0               0           0\r\nbins:           size ind    allocated      nmalloc      ndalloc    nrequests      curregs     curslabs regs pgs   util       nfills     nflushes       nslabs     nreslabs      n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\n                   8   0         2208          319           43          445          276            1 8192   1  0.033            8            9            1            0             254               0               0              83               0               0           0\r\n                  16   1     13405920      1908683      1070813      3264459       837870          219 4096   1  0.934        16618         7219          345          293         4947917               0               0          786235               0               0           0\r\n                  24   2      9946560       948513       534073       948769       414440           74 8192   3  0.683         8158         3622           86           72         2471570               0               0          390949               0               0           0\r\n                  32   3          512          112           96      1904246           16            1 2048   1  0.007            3            7            1            0             201               0               0               1               0               0           0\r\n                  40   4          400          109           99           27           10            1 8192   5  0.001            3            7            1            0             201               0               0               1               0               0           0\r\n                  48   5         2832          162          103           57           59            1 4096   3  0.014            3            4            1            0             198               0               0               1               0               0           0\r\n                  56   6         1008          108           90       254614           18            1 8192   7  0.002            4            7            1            0             202               0               0               1               0               0           0\r\n                  64   7          192          100           97            6            3            1 1024   1  0.002            1            4            1            0             196               0               0               1               0               0           0\r\n                  80   8          240          100           97            4            3            1 4096   5  0.000            1            4            1            0             196               0               0               1               0               0           0\r\n                  96   9         9408          200          102          100           98            1 2048   3  0.047            3            4            1            0             198               0               0               1               0               0           0\r\n                 112  10          112          100           99            3            1            1 4096   7  0.000            1            4            1            0             196               0               0               1               0               0           0\r\n                 128  11            0          100          100            3            0            0  512   1      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 160  12     60006400       871006       495966       870857       375040          228 2048   5  0.803         7012         3517          342          230         2227528               0               0          341833               0               0           0\r\n                 192  13         1152          106          100            1            6            1 1024   3  0.005            2            4            2            0             199               0               0               1               0               0           0\r\n                 224  14            0          100          100            1            0            0 2048   7      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 256  15            0          100          100            4            0            0  256   1      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 320  16     12443520        68242        29356        68121        38886           47 1024   5  0.807          601          220           52           53          225985               0               0           31003               0               0           0\r\n                 384  17          384          100           99            1            1            1  512   3  0.001            1            4            1            0             196               0               0               1               0               0           0\r\n                 448  18            0          100          100            1            0            0 1024   7      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 512  19          512          100           99            4            1            1  128   1  0.007            1            4            1            0             196               0               0               1               0               0           0\r\n                 640  20            0          100          100            1            0            0  512   5      1            1            4            1            0             197               0               0               1               0               0           0\r\n                 768  21            0            0            0            0            0            0  256   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                 896  22            0            0            0            0            0            0  512   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n                1024  23         3072           64           61            4            3            1   64   1  0.046            1            3            1            0             195               0               0               1               0               0           0\r\n                1280  24         7680          106          100            1            6            1  256   5  0.023            2            4            2            0             199               0               0               1               0               0           0\r\n                1536  25         9216          115          109            4            6            1  128   3  0.046            5            8            2            0             206               0               0               1               0               0           0\r\n                1792  26            0            0            0            0            0            0  256   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n                2048  27        14336           36           29            4            7            1   32   1  0.218            2            3            1            0             196               0               0               1               0               0           0\r\n                2560  28       256000          100            0            0          100            1  128   5  0.781            1            0            1            0             192               0               0               1               0               0           0\r\n                3072  29            0            0            0            0            0            0   64   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n                3584  30        21504          106          100            1            6            1  128   7  0.046            2            4            2            0             199               0               0               1               0               0           0\r\n                4096  31            0            0            0            0            0            0   16   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n                5120  32            0            0            0            0            0            0   64   5      1            0            0            0            0             190               0               0               1               0               0           0\r\n                6144  33            0            0            0            0            0            0   32   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                7168  34            0            0            0            0            0            0   64   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                8192  35            0            0            0            0            0            0    8   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n               10240  36            0            0            0            0            0            0   32   5      1            0            0            0            0             190               0               0               1               0               0           0\r\n               12288  37            0            0            0            0            0            0   16   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n               14336  38            0            0            0            0            0            0   32   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               16384  39            0           10           10            1            0            0    4   1      1            1            2            3            0             199               0               0               1               0               0           0\r\n               20480  40        61440           16           13            4            3            1   16   5  0.187            1            2            1            0             194               0               0               1               0               0           0\r\n               24576  41            0            0            0            0            0            0    8   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n               28672  42            0            0            0            0            0            0   16   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n               32768  43            0            0            0            0            0            0    2   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               40960  44        40960           10            9            2            1            1    8   5  0.125            1            2            2            0             196               0               0               1               0               0           0\r\n               49152  45            0            0            0            0            0            0    4   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               57344  46        57344            1            0            1            1            1    8   7  0.125            0            0            1            0             192               0               0               1               0               0           0\r\n               65536  47            0            0            0            0            0            0    1   1      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n               81920  48        81920           10            9            1            1            1    4   5  0.250            1            2            3            0             198               0               0               1               0               0           0\r\n               98304  49            0            0            0            0            0            0    2   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n              114688  50            0            0            0            0            0            0    4   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n              131072  51            0            0            0            0            0            0    1   2      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\n              163840  52       163840           10            9            1            1            1    2   5  0.500            1            2            5            0             202               0               0               1               0               0           0\r\n              196608  53            0            0            0            0            0            0    1   3      1            0            0            0            0             190               0               0               1               0               0           0\r\n              229376  54            0            0            0            0            0            0    2   7      1            0            0            0            0             190               0               0               1               0               0           0\r\n                     ---\r\nlarge:          size ind    allocated      nmalloc      ndalloc    nrequests  curlextents\r\n                     ---\r\n              327680  56       327680            1            0            1            1\r\n                     ---\r\n             8388608  75      8388608            1            0            1            1\r\n                     ---\r\n--- End jemalloc statistics ---\r\n\r\n[\u001B[0;31;49merr\u001B[0m]: Active defrag in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\n# Memory\r\nused_memory:60252320\r\nused_memory_human:57.46M\r\nused_memory_rss:123863040\r\nused_memory_rss_human:118.12M\r\nused_memory_peak:160476576\r\nused_memory_peak_human:153.04M\r\nused_memory_peak_perc:37.55%\r\nused_memory_overhead:15085544\r\nused_memory_startup:824224\r\nused_memory_dataset:45166776\r\nused_memory_dataset_perc:76.00%\r\nallocator_allocated:60318880\r\nallocator_active:66453504\r\nallocator_resident:122028032\r\ntotal_system_memory:10278404096\r\ntotal_system_memory_human:9.57G\r\nused_memory_lua:37888\r\nused_memory_lua_human:37.00K\r\nused_memory_scripts:0\r\nused_memory_scripts_human:0B\r\nnumber_of_cached_scripts:0\r\nmaxmemory:0\r\nmaxmemory_human:0B\r\nmaxmemory_policy:allkeys-lru\r\nallocator_frag_ratio:1.10\r\nallocator_frag_bytes:6134624\r\nallocator_rss_ratio:1.84\r\nallocator_rss_bytes:55574528\r\nrss_overhead_ratio:1.02\r\nrss_overhead_bytes:1835008\r\nmem_fragmentation_ratio:2.06\r\nmem_fragmentation_bytes:63651744\r\nmem_not_counted_for_evict:0\r\nmem_replication_backlog:0\r\nmem_clients_slaves:0\r\nmem_clients_normal:66616\r\nmem_aof_buffer:0\r\nmem_allocator:jemalloc-5.1.0\r\nactive_defrag_running:65\r\nlazyfree_pending_objects:0\r\n\r\n___ Begin jemalloc statistics ___\r\nVersion: \"5.1.0-0-g0\"\r\nBuild-time option settings\r\n  config.cache_oblivious: true\r\n  config.debug: false\r\n  config.fill: true\r\n  config.lazy_lock: false\r\n  config.malloc_conf: \"\"\r\n  config.prof: false\r\n  config.prof_libgcc: false\r\n  config.prof_libunwind: false\r\n  config.stats: true\r\n  config.utrace: false\r\n  config.xmalloc: false\r\nRun-time option settings\r\n  opt.abort: false\r\n  opt.abort_conf: false\r\n  opt.retain: true\r\n  opt.dss: \"secondary\"\r\n  opt.narenas: 128\r\n  opt.percpu_arena: \"disabled\"\r\n  opt.metadata_thp: \"disabled\"\r\n  opt.background_thread: false (background_thread: false)\r\n  opt.dirty_decay_ms: 10000 (arenas.dirty_decay_ms: 10000)\r\n  opt.muzzy_decay_ms: 10000 (arenas.muzzy_decay_ms: 10000)\r\n  opt.junk: \"false\"\r\n  opt.zero: false\r\n  opt.tcache: true\r\n  opt.lg_tcache_max: 15\r\n  opt.thp: \"default\"\r\n  opt.stats_print: false\r\n  opt.stats_print_opts: \"\"\r\nArenas: 128\r\nQuantum size: 8\r\nPage size: 65536\r\nMaximum thread-cached size class: 229376\r\nNumber of bin size classes: 55\r\nNumber of thread-cache bin size classes: 55\r\nNumber of large size classes: 180\r\nAllocated: 60326560, active: 66453504, metadata: 5261600 (n_thp 0), resident: 122028032, mapped: 133562368, retained: 101318656\r\nBackground threads: 0, num_runs: 0, run_interval: 0 ns\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nbackground_thread                2213               0               0               1               0               0           0\r\nctl                              9784               0               0               1               0               0           0\r\nprof                                0               0               0               0               0               0           0\r\narenas[0]:\r\nassigned threads: 1\r\nuptime: 117400141402\r\ndss allocation precedence: \"secondary\"\r\ndecaying:  time       npages       sweeps     madvises       purged\r\n   dirty: 10000          768           32          194         1754\r\n   muzzy: 10000            0            0            0            0\r\n                            allocated     nmalloc     ndalloc   nrequests\r\nsmall:                       55804576     6588398     5486841    20565728\r\nlarge:                        4521984           7           5           7\r\ntotal:                       60326560     6588405     5486846    20565735\r\n                                     \r\nactive:                      66453504\r\nmapped:                     133562368\r\nretained:                   101318656\r\nbase:                         5204248\r\ninternal:                       57352\r\nmetadata_thp:                       0\r\ntcache_bytes:                   16880\r\nresident:                   122028032\r\n                           n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\nlarge                            1106               0               0               1               0               0           0\r\nextent_avail                     3177               0               0               3               0               0           0\r\nextents_dirty                    4734               0               0               3               0               0           0\r\nextents_muzzy                    2147               0               0               3               0               0           0\r\nextents_retained                 3491               0               0               3               0               0           0\r\ndecay_dirty                      8000               0               0               1               0               0           0\r\ndecay_muzzy                      7968               0               0               1               0               0           0\r\nbase                             3199               0               0               3               0               0           0\r\ntcache_list                      1107               0               0               1               0               0           0\r\nbins:           size ind    allocated      nmalloc      ndalloc    nrequests      curregs     curslabs regs pgs   util       nfills     nflushes       nslabs     nreslabs      n_lock_ops       n_waiting      n_spin_acq  n_owner_switch   total_wait_ns     max_wait_ns  max_n_thds\r\n                   8   0      2082272       682452       422168       737512       260284           33 8192   1  0.962         5729         2899           63           35         5292332               0               0          342741               0               0           0\r\n                  16   1      4198176      2585949      2323563      7404066       262386           66 4096   1  0.970        21738        18490          441          390        10099741               0               0         1131829               0               0           0\r\n                  24   2      7502400      1681985      1369385      3943160       312600           42 8192   3  0.908        13940        10656          109          156         8756245               0               0          734355               0               0           0\r\n                  32   3        64896         2520          492      6441884         2028            1 2048   1  0.990          133          110            1            0           39521               0               0             153               0               0           0\r\n                  40   4       300080         9578         2076        59531         7502            1 8192   5  0.915          180           76            1            0          143711               0               0             155               0               0           0\r\n                  48   5         2448          200          149         2339           51            1 4096   3  0.012           29           33            1            0            1169               0               0               1               0               0           0\r\n                  56   6       105728         2607          719       350162         1888            1 8192   7  0.230          116          104            1            0           36743               0               0              79               0               0           0\r\n                  64   7          320          114          109         2039            5            1 1024   1  0.004            8           12            1            0            1146               0               0              39               0               0           0\r\n                  80   8        40560         1010          503         4518          507            1 4096   5  0.123           89           93            1            0           10865               0               0              41               0               0           0\r\n                  96   9       191424         2762          768         4218         1994            1 2048   3  0.973           98          100            1            0           37291               0               0             193               0               0           0\r\n                 112  10       252336         4742         2489         2262         2253            1 4096   7  0.550           99           98            1            0           44092               0               0             117               0               0           0\r\n                 128  11          384          126          123           17            3            1  512   1  0.005           10           16            2            0            1192               0               0              41               0               0           0\r\n                 160  12     40000320      1543928      1293926      1543761       250002          123 2048   5  0.992        12149        10159          588          359         7336648               0               0          687995               0               0           0\r\n                 192  13          192          115          114          168            1            1 1024   3  0.000            9           13            9            0            1145               0               0               1               0               0           0\r\n                 224  14            0          114          114            8            0            0 2048   7      1            6           11            6            0            1135               0               0               1               0               0           0\r\n                 256  15            0          116          116           15            0            0  256   1      1            8           13            8            0            1143               0               0               1               0               0           0\r\n                 320  16         5120        68246        68230        68128           16            1 1024   5  0.015          605          699           52           55          227430               0               0           31003               0               0           0\r\n                 384  17          384          116          115            9            1            1  512   3  0.001            8           13            1            0            1128               0               0               1               0               0           0\r\n                 448  18            0          113          113            8            0            0 1024   7      1            7           12            7            0            1139               0               0               1               0               0           0\r\n                 512  19          512          113          112           15            1            1  128   1  0.007            9           14            1            0            1130               0               0               1               0               0           0\r\n                 640  20            0          113          113            8            0            0  512   5      1            7           12            7            0            1139               0               0               1               0               0           0\r\n                 768  21            0          113          113            8            0            0  256   3      1            7           12            7            0            1139               0               0               1               0               0           0\r\n                 896  22            0          110          110            7            0            0  512   7      1            6           11            6            0            1135               0               0               1               0               0           0\r\n                1024  23         3072           81           78           15            3            1   64   1  0.046            9           14            1            0            1130               0               0               1               0               0           0\r\n                1280  24         3840          125          122          563            3            1  256   5  0.011           11           15            4            0            1177               0               0              77               0               0           0\r\n                1536  25         4608          125          122          189            3            1  128   3  0.023           15           17            3            0            1143               0               0               1               0               0           0\r\n                1792  26            0          109          109            6            0            0  256   7      1            5           10            5            0            1131               0               0               1               0               0           0\r\n                2048  27         8192           46           42          173            4            1   32   1  0.125           11           14            1            0            1132               0               0               1               0               0           0\r\n                2560  28        17920          121          114            7            7            1  128   5  0.054            7           10            3            0            1204               0               0              39               0               0           0\r\n                3072  29            0           68           68            3            0            0   64   3      1            2            6            2            0            1118               0               0               1               0               0           0\r\n                3584  30         3584          115          114          592            1            1  128   7  0.007            5            9            5            0            1129               0               0               1               0               0           0\r\n                4096  31            0           21           21            5            0            0   16   1      1            3            6            2            0            1119               0               0               1               0               0           0\r\n                5120  32            0           64           64            1            0            0   64   5      1            1            4            1            0            1113               0               0               1               0               0           0\r\n                6144  33            0           36           36            2            0            0   32   3      1            2            5            2            0            1117               0               0               1               0               0           0\r\n                7168  34            0           64           64            1            0            0   64   7      1            1            4            1            0            1113               0               0               1               0               0           0\r\n                8192  35            0           15           15            5            0            0    8   1      1            4            6            4            0            1124               0               0               1               0               0           0\r\n               10240  36            0           32           32            1            0            0   32   5      1            1            3            1            0            1112               0               0               1               0               0           0\r\n               12288  37            0           18           18            2            0            0   16   3      1            2            5            2            0            1117               0               0               1               0               0           0\r\n               14336  38            0            0            0            0            0            0   32   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n               16384  39            0           15           15            5            0            0    4   1      1            4            6            5            0            1126               0               0               1               0               0           0\r\n               20480  40        81920           22           18            8            4            1   16   5  0.250            3            5            1            0            1115               0               0               1               0               0           0\r\n               24576  41            0           10           10            1            0            0    8   3      1            1            2            2            0            1113               0               0               1               0               0           0\r\n               28672  42            0            0            0            0            0            0   16   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n               32768  43            0           11           11            4            0            0    2   1      1            2            5            6            0            1125               0               0               1               0               0           0\r\n               40960  44        40960           13           12          291            1            1    8   5  0.125            3            5            2            1            1117               0               0               1               0               0           0\r\n               49152  45            0            0            0            0            0            0    4   3      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n               57344  46        57344            1            0            1            1            1    8   7  0.125            0            0            1            0            1108               0               0               1               0               0           0\r\n               65536  47       196608           12            9            4            3            3    1   1      1            2            4           12            0            1190               0               0             115               0               0           0\r\n               81920  48        81920           10            9            1            1            1    4   5  0.250            1            2            3            0            1114               0               0               1               0               0           0\r\n               98304  49            0            0            0            0            0            0    2   3      1            0            0            0            0            1106               0               0               1               0               0           0\r\n              114688  50            0            0            0            0            0            0    4   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\n              131072  51       393216           12            9            4            3            3    1   2      1            2            4           12            0            1190               0               0             115               0               0           0\r\n              163840  52       163840           10            9            1            1            1    2   5  0.500            1            2            5            0            1118               0               0               1               0               0           0\r\n              196608  53            0            0            0            0            0            0    1   3      1            0            0            0            0            1106               0               0               1               0               0           0\r\n              229376  54            0            0            0            0            0            0    2   7      1            0            0            0            0            1106               0               0               1               0               0           0\r\n                     ---\r\nlarge:          size ind    allocated      nmalloc      ndalloc    nrequests  curlextents\r\n              262144  55            0            1            1            1            0\r\n              327680  56       327680            1            0            1            1\r\n                     ---\r\n              524288  59            0            1            1            1            0\r\n                     ---\r\n             1048576  63            0            1            1            1            0\r\n                     ---\r\n             2097152  67            0            1            1            1            0\r\n                     ---\r\n             4194304  71      4194304            1            0            1            1\r\n                     ---\r\n             8388608  75            0            1            1            1            0\r\n                     ---\r\n--- End jemalloc statistics ---\r\n\r\n[\u001B[0;31;49merr\u001B[0m]: Active defrag big keys in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\n[46/50 \u001B[0;33;49mdone\u001B[0m]: unit/memefficiency (122 seconds)\r\n\u001B[1;37;49mTesting unit/hyperloglog\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: HyperLogLog self test passes\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD without arguments creates an HLL value\r\n[\u001B[0;32;49mok\u001B[0m]: Approximated cardinality after creation is zero\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD returns 1 when at least 1 reg was modified\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD returns 0 when no reg was modified\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD works with empty string (regression)\r\n[\u001B[0;32;49mok\u001B[0m]: PFCOUNT returns approximated cardinality of set\r\n[\u001B[0;32;49mok\u001B[0m]: HyperLogLogs are promote from sparse to dense\r\n[\u001B[0;32;49mok\u001B[0m]: HyperLogLog sparse encoding stress test\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted sparse HyperLogLogs are detected: Additionl at tail\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted sparse HyperLogLogs are detected: Broken magic\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted sparse HyperLogLogs are detected: Invalid encoding\r\n[\u001B[0;32;49mok\u001B[0m]: Corrupted dense HyperLogLogs are detected: Wrong length\r\n[\u001B[0;32;49mok\u001B[0m]: Fuzzing dense/sparse encoding: Redis should always detect errors\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD, PFCOUNT, PFMERGE type checking works\r\n[\u001B[0;32;49mok\u001B[0m]: PFMERGE results on the cardinality of union of sets\r\n[\u001B[0;32;49mok\u001B[0m]: PFCOUNT multiple-keys merge returns cardinality of union #1\r\n[\u001B[0;32;49mok\u001B[0m]: PFCOUNT multiple-keys merge returns cardinality of union #2\r\n[\u001B[0;32;49mok\u001B[0m]: PFDEBUG GETREG returns the HyperLogLog raw registers\r\n[\u001B[0;32;49mok\u001B[0m]: PFADD / PFCOUNT cache invalidation works\r\n[47/50 \u001B[0;33;49mdone\u001B[0m]: unit/hyperloglog (53 seconds)\r\n\u001B[1;37;49mTesting unit/lazyfree\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: UNLINK can reclaim memory in background\r\n[\u001B[0;32;49mok\u001B[0m]: FLUSHDB ASYNC can reclaim memory in background\r\n[48/50 \u001B[0;33;49mdone\u001B[0m]: unit/lazyfree (1 seconds)\r\n\u001B[1;37;49mTesting unit/wait\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: Setup slave\r\n[\u001B[0;32;49mok\u001B[0m]: WAIT should acknowledge 1 additional copy of the data\r\n[\u001B[0;32;49mok\u001B[0m]: WAIT should not acknowledge 2 additional copies of the data\r\n[\u001B[0;32;49mok\u001B[0m]: WAIT should not acknowledge 1 additional copy if slave is blocked\r\n[49/50 \u001B[0;33;49mdone\u001B[0m]: unit/wait (7 seconds)\r\n\u001B[1;37;49mTesting unit/pendingquerybuf\u001B[0m\r\n[\u001B[0;32;49mok\u001B[0m]: pending querybuf: check size of pending_querybuf after set a big value\r\n[50/50 \u001B[0;33;49mdone\u001B[0m]: unit/pendingquerybuf (7 seconds)\r\n\r\n                   The End\r\n\r\nExecution time of different units:\r\n  1 seconds - unit/printver\r\n  27 seconds - unit/dump\r\n  1 seconds - unit/auth\r\n  0 seconds - unit/protocol\r\n  2 seconds - unit/keyspace\r\n  8 seconds - unit/scan\r\n  12 seconds - unit/type/string\r\n  0 seconds - unit/type/incr\r\n  13 seconds - unit/type/list\r\n  17 seconds - unit/type/list-2\r\n  103 seconds - unit/type/list-3\r\n  7 seconds - unit/type/set\r\n  13 seconds - unit/type/zset\r\n  5 seconds - unit/type/hash\r\n  29 seconds - unit/type/stream\r\n  3 seconds - unit/type/stream-cgroups\r\n  9 seconds - unit/sort\r\n  15 seconds - unit/expire\r\n  9 seconds - unit/other\r\n  2 seconds - unit/multi\r\n  0 seconds - unit/quit\r\n  97 seconds - unit/aofrw\r\n  27 seconds - integration/block-repl\r\n  148 seconds - integration/replication\r\n  16 seconds - integration/replication-2\r\n  32 seconds - integration/replication-3\r\n  34 seconds - integration/replication-4\r\n  100 seconds - integration/replication-psync\r\n  3 seconds - integration/aof\r\n  2 seconds - integration/rdb\r\n  0 seconds - integration/convert-zipmap-hash-on-load\r\n  1 seconds - integration/logging\r\n  28 seconds - integration/psync2\r\n  23 seconds - integration/psync2-reg\r\n  0 seconds - unit/pubsub\r\n  2 seconds - unit/slowlog\r\n  6 seconds - unit/scripting\r\n  43 seconds - unit/maxmemory\r\n  0 seconds - unit/introspection\r\n  7 seconds - unit/introspection-2\r\n  1 seconds - unit/limits\r\n  168 seconds - unit/obuf-limits\r\n  4 seconds - unit/bitops\r\n  1 seconds - unit/bitfield\r\n  21 seconds - unit/geo\r\n  122 seconds - unit/memefficiency\r\n  53 seconds - unit/hyperloglog\r\n  1 seconds - unit/lazyfree\r\n  7 seconds - unit/wait\r\n  7 seconds - unit/pendingquerybuf\r\n\r\n\u001B[1;31;49m!!! WARNING\u001B[0m The following tests failed:\r\n\r\n*** [\u001B[0;31;49merr\u001B[0m]: Active defrag in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\n*** [\u001B[0;31;49merr\u001B[0m]: Active defrag big keys in tests/unit/memefficiency.tcl\r\ndefrag didn't stop.\r\nCleanup: may take some time... OK\r\n\r\n```","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/8265/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/8265/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"actor":{"login":"stefanschindler","id":786048,"node_id":"MDQ6VXNlcjc4NjA0OA==","avatar_url":"https://avatars.githubusercontent.com/u/786048?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanschindler","html_url":"https://github.com/stefanschindler","followers_url":"https://api.github.com/users/stefanschindler/followers","following_url":"https://api.github.com/users/stefanschindler/following{/other_user}","gists_url":"https://api.github.com/users/stefanschindler/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanschindler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanschindler/subscriptions","organizations_url":"https://api.github.com/users/stefanschindler/orgs","repos_url":"https://api.github.com/users/stefanschindler/repos","events_url":"https://api.github.com/users/stefanschindler/events{/privacy}","received_events_url":"https://api.github.com/users/stefanschindler/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-04-20T12:26:00Z","updated_at":"2021-04-20T12:26:00Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/8828","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/8828/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/8828/comments","events_url":"https://api.github.com/repos/redis/redis/issues/8828/events","html_url":"https://github.com/redis/redis/issues/8828","id":862763567,"node_id":"MDU6SXNzdWU4NjI3NjM1Njc=","number":8828,"title":"[BUG] `make test` fails on Ubuntu 18.04 (tests/unit/networking.tcl)","user":{"login":"stefanschindler","id":786048,"node_id":"MDQ6VXNlcjc4NjA0OA==","avatar_url":"https://avatars.githubusercontent.com/u/786048?v=4","gravatar_id":"","url":"https://api.github.com/users/stefanschindler","html_url":"https://github.com/stefanschindler","followers_url":"https://api.github.com/users/stefanschindler/followers","following_url":"https://api.github.com/users/stefanschindler/following{/other_user}","gists_url":"https://api.github.com/users/stefanschindler/gists{/gist_id}","starred_url":"https://api.github.com/users/stefanschindler/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/stefanschindler/subscriptions","organizations_url":"https://api.github.com/users/stefanschindler/orgs","repos_url":"https://api.github.com/users/stefanschindler/repos","events_url":"https://api.github.com/users/stefanschindler/events{/privacy}","received_events_url":"https://api.github.com/users/stefanschindler/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":13,"created_at":"2021-04-20T12:25:59Z","updated_at":"2021-04-27T15:09:49Z","closed_at":"2021-04-27T15:09:49Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"**Describe the bug**\r\n\r\n`make test` fails on Ubuntu 18.04 with error:\r\n\r\n```\r\n*** [err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\n```\r\n\r\nI tried to track down the issue and running just the failed test, but the output didn't help me either.\r\n\r\n**To reproduce**\r\n\r\n```\r\nwget http://download.redis.io/redis-stable.tar.gz\r\ntar xvzf redis-stable.tar.gz\r\ncd redis-stable\r\nmake test\r\n\r\n```\r\n\r\n**Expected behavior**\r\n\r\n`make test` does not fail\r\n\r\n**Additional information**\r\n\r\nUsing Ubuntu 18.04. I have some servers where it works, but one server always fails. All servers are set up similarly.\r\n\r\n<details>\r\n<summary>Whole Log Output:</summary>\r\n\r\n```\r\nCleanup: may take some time... OK\r\nStarting test server at port 21079\r\n[ready]: 6295\r\nTesting unit/printver\r\n[ready]: 6294\r\nTesting unit/dump\r\n[ready]: 6297\r\nTesting unit/auth\r\n[ready]: 6296\r\nTesting unit/protocol\r\n[ready]: 6298\r\nTesting unit/keyspace\r\n[ready]: 6299\r\nTesting unit/scan\r\n[ready]: 6301\r\nTesting unit/info\r\n[ready]: 6300\r\nTesting unit/type/string\r\n[ready]: 6302\r\nTesting unit/type/incr\r\n[ready]: 6303\r\nTesting unit/type/list\r\n[ready]: 6305\r\nTesting unit/type/list-2\r\n[ready]: 6307\r\nTesting unit/type/list-3\r\n[ready]: 6304\r\nTesting unit/type/set\r\n[ready]: 6309\r\nTesting unit/type/zset\r\n[ready]: 6306\r\nTesting unit/type/hash\r\n[ready]: 6308\r\nTesting unit/type/stream\r\n[ok]: AUTH fails if there is no password configured server side\r\n[ok]: Explicit regression for a list bug\r\n[ok]: LPOS basic usage\r\n[ok]: LPOS RANK (positive and negative rank) option\r\n[ok]: LPOS COUNT option\r\n[ok]: LPOS COUNT + RANK option\r\n[ok]: LPOS non existing key\r\n[ok]: LPOS no match\r\n[ok]: LPOS MAXLEN\r\n[ok]: LPOS when RANK is greater than matches\r\n[ok]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - ziplist\r\n[ok]: LPUSH, RPUSH, LLENGTH, LINDEX, LPOP - regular list\r\n[ok]: R/LPOP against empty list\r\n[ok]: R/LPOP with the optional count argument\r\n[ok]: Variadic RPUSH/LPUSH\r\n[ok]: DEL a list\r\n[ok]: BLPOP, BRPOP: single existing list - linkedlist\r\n[ok]: BLPOP, BRPOP: multiple existing lists - linkedlist\r\n[ok]: BLPOP, BRPOP: second list has an entry - linkedlist\r\n[ok]: BRPOPLPUSH - linkedlist\r\n[ok]: BLMOVE left left - linkedlist\r\n[ok]: BLMOVE left right - linkedlist\r\n[ok]: BLMOVE right left - linkedlist\r\n[ok]: BLMOVE right right - linkedlist\r\n[ok]: BLPOP, BRPOP: single existing list - ziplist\r\n[ok]: BLPOP, BRPOP: multiple existing lists - ziplist\r\n[ok]: BLPOP, BRPOP: second list has an entry - ziplist\r\n[ok]: BRPOPLPUSH - ziplist\r\n[ok]: BLMOVE left left - ziplist\r\n[ok]: BLMOVE left right - ziplist\r\n[ok]: BLMOVE right left - ziplist\r\n[ok]: BLMOVE right right - ziplist\r\n[ok]: BLPOP, LPUSH + DEL should not awake blocked client\r\n[ok]: DUMP / RESTORE are able to serialize / unserialize a simple key\r\n[ok]: RESTORE can set an arbitrary expire to the materialized key\r\n[ok]: RESTORE can set an expire that overflows a 32 bit integer\r\n[ok]: RESTORE can set an absolute expire\r\n[ok]: RESTORE with ABSTTL in the past\r\n[ok]: RESTORE can set LRU\r\n[ok]: RESTORE can set LFU\r\n[ok]: RESTORE returns an error of the key already exists\r\n[ok]: RESTORE can overwrite an existing key with REPLACE\r\n[ok]: RESTORE can detect a syntax error for unrecongized options\r\n[ok]: DUMP of non existing key returns nil\r\n[ok]: Regression for quicklist #3343 bug\r\n[ok]: HSET/HLEN - Small hash creation\r\n[ok]: DEL against a single item\r\n[ok]: Check encoding - ziplist\r\n[ok]: Vararg DEL\r\n[ok]: Is the small hash encoded with a ziplist?\r\n[ok]: ZSET basic ZADD and score update - ziplist\r\n[ok]: KEYS with pattern\r\n[ok]: KEYS to get all keys\r\n[ok]: ZSET element can't be set to NaN with ZADD - ziplist\r\n[ok]: DBSIZE\r\n[ok]: ZSET element can't be set to NaN with ZINCRBY - ziplist\r\n[ok]: ZADD with options syntax error with incomplete pair - ziplist\r\n[ok]: ZADD XX option without key - ziplist\r\n[ok]: DEL all keys\r\n[ok]: ZADD XX existing key - ziplist\r\n[ok]: ZADD XX returns the number of elements actually added - ziplist\r\n[ok]: ZADD XX updates existing elements score - ziplist\r\n[ok]: ZADD GT updates existing elements when new scores are greater - ziplist\r\n[ok]: SET and GET an item\r\n[ok]: ZADD LT updates existing elements when new scores are lower - ziplist\r\n[ok]: SET and GET an empty item\r\n[ok]: ZADD GT XX updates existing elements when new scores are greater and skips new elements - ziplist\r\n[ok]: ZADD LT XX updates existing elements when new scores are lower and skips new elements - ziplist\r\n[ok]: ZADD XX and NX are not compatible - ziplist\r\nTesting Redis version 6.2.2 (00000000)\r\n[ok]: ZADD NX with non existing key - ziplist\r\n[ok]: ZADD NX only add new elements without updating old ones - ziplist\r\n[ok]: ZADD GT and NX are not compatible - ziplist\r\n[ok]: ZADD LT and NX are not compatible - ziplist\r\n[ok]: ZADD LT and GT are not compatible - ziplist\r\n[ok]: HRANDFIELD - ziplist\r\n[ok]: ZADD INCR LT/GT replies with nill if score not updated - ziplist\r\n[ok]: ZADD INCR LT/GT with inf - ziplist\r\n[ok]: ZADD INCR works like ZINCRBY - ziplist\r\n[ok]: ZADD INCR works with a single score-elemenet pair - ziplist\r\n[ok]: ZADD CH option changes return value to all changed elements - ziplist\r\n[ok]: ZINCRBY calls leading to NaN result in error - ziplist\r\n[ok]: ZADD - Variadic version base case - $encoding\r\n[ok]: ZADD - Return value is the number of actually added items - $encoding\r\n[ok]: ZADD - Variadic version does not add nothing on single parsing err - $encoding\r\n[ok]: SADD, SCARD, SISMEMBER, SMISMEMBER, SMEMBERS basics - regular set\r\n[ok]: ZADD - Variadic version will raise error on missing arg - $encoding\r\n[ok]: AUTH fails when a wrong password is given\r\n[ok]: ZINCRBY does not work variadic even if shares ZADD implementation - $encoding\r\n[ok]: ZCARD basics - ziplist\r\n[ok]: INCR against non existing key\r\n[ok]: Arbitrary command gives an error when AUTH is required\r\n[ok]: AUTH succeeds when the right password is given\r\n[ok]: INCR against key created by incr itself\r\n[ok]: Once AUTH succeeded we can actually send commands to the server\r\n[ok]: ZREM removes key after last element is removed - ziplist\r\n[ok]: INCR against key originally set with SET\r\n[ok]: INCR over 32bit value\r\n[ok]: ZREM variadic version - ziplist\r\n[ok]: ZREM variadic version -- remove elements after key deletion - ziplist\r\n[ok]: INCRBY over 32bit value with over 32bit increment\r\n[ok]: INCR fails against key with spaces (left)\r\n[ok]: SCAN basic\r\n[ok]: INCR fails against key with spaces (right)\r\n[ok]: INCR fails against key with spaces (both)\r\n[ok]: ZRANGE basics - ziplist\r\n[ok]: HRANDFIELD - hashtable\r\n[ok]: INCR fails against a key holding a list\r\n[ok]: DECRBY over 32bit value with over 32bit increment, negative res\r\n[ok]: SADD, SCARD, SISMEMBER, SMISMEMBER, SMEMBERS basics - intset\r\n[ok]: HRANDFIELD with RESP3\r\n[ok]: SMISMEMBER against non set\r\n[ok]: INCR uses shared objects in the 0-9999 range\r\n[ok]: ZREVRANGE basics - ziplist\r\n[ok]: HRANDFIELD count of 0 is handled correctly\r\n[ok]: SMISMEMBER non existing key\r\n[ok]: INCR can modify objects in-place\r\n[ok]: HRANDFIELD with <count> against non existing key\r\n[ok]: ZRANK/ZREVRANK basics - ziplist\r\n[ok]: ZRANK - after deletion - ziplist\r\n[ok]: INCRBYFLOAT against non existing key\r\n[ok]: ZINCRBY - can create a new sorted set - ziplist\r\n[ok]: INCRBYFLOAT against key originally set with SET\r\n[ok]: INCRBYFLOAT over 32bit value\r\n[ok]: SMISMEMBER requires one or more members\r\n[ok]: ZINCRBY - increment and decrement - ziplist\r\n[ok]: INCRBYFLOAT over 32bit value with over 32bit increment\r\n[ok]: SADD against non set\r\n[ok]: ZINCRBY return value - ziplist\r\n[ok]: INCRBYFLOAT fails against key with spaces (left)\r\n[ok]: INCRBYFLOAT fails against key with spaces (right)\r\n[ok]: INCRBYFLOAT fails against key with spaces (both)\r\n[ok]: INCRBYFLOAT fails against a key holding a list\r\n[ok]: SADD a non-integer against an intset\r\n[ok]: INCRBYFLOAT does not allow NaN or Infinity\r\n[ok]: SADD an integer larger than 64 bits\r\n[ok]: INCRBYFLOAT decrement\r\n[ok]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics - ziplist\r\n[ok]: string to double with null terminator\r\n[ok]: ZRANGEBYSCORE with WITHSCORES - ziplist\r\n[ok]: No negative zero\r\n[ok]: ZRANGEBYSCORE with LIMIT - ziplist\r\n[ok]: ZRANGEBYSCORE with LIMIT and WITHSCORES - ziplist\r\n[ok]: ZRANGEBYSCORE with non-value min or max - ziplist\r\n[ok]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics - ziplist\r\n[ok]: BLPOP, LPUSH + DEL + SET should not awake blocked client\r\n[ok]: ZLEXCOUNT advanced - ziplist\r\n[ok]: BLPOP with same key multiple times should work (issue #801)\r\n[ok]: ZRANGEBYSLEX with LIMIT - ziplist\r\n[ok]: MULTI/EXEC is isolated from the point of view of BLPOP\r\n[ok]: ZRANGEBYLEX with invalid lex range specifiers - ziplist\r\n[ok]: errorstats: failed call authentication error\r\n[ok]: BLPOP with variadic LPUSH\r\n[ok]: BRPOPLPUSH with zero timeout should block indefinitely\r\n[ok]: errorstats: failed call within MULTI/EXEC\r\n[ok]: BLMOVE left left with zero timeout should block indefinitely\r\n[ok]: BLMOVE left right with zero timeout should block indefinitely\r\n[ok]: errorstats: failed call within LUA\r\n[ok]: BLMOVE right left with zero timeout should block indefinitely\r\n[ok]: BLMOVE right right with zero timeout should block indefinitely\r\n[ok]: errorstats: failed call NOSCRIPT error\r\n[ok]: ZREMRANGEBYSCORE basics - ziplist\r\n[ok]: ZREMRANGEBYSCORE with non-value min or max - ziplist\r\n[ok]: BLMOVE (left, left) with a client BLPOPing the target list\r\n[ok]: errorstats: failed call NOGROUP error\r\n[ok]: BLMOVE (left, right) with a client BLPOPing the target list\r\n[ok]: BLMOVE (right, left) with a client BLPOPing the target list\r\n[ok]: XADD can add entries into a stream that XRANGE can fetch\r\n[ok]: ZREMRANGEBYRANK basics - ziplist\r\n[ok]: XADD IDs are incremental\r\n[ok]: ZUNIONSTORE against non-existing key doesn't set destination - ziplist\r\n[ok]: BLMOVE (right, right) with a client BLPOPing the target list\r\n[ok]: XADD IDs are incremental when ms is the same as well\r\n[ok]: ZUNION/ZINTER/ZDIFF against non-existing key - ziplist\r\n[ok]: errorstats: rejected call unknown command\r\n[ok]: XADD IDs correctly report an error when overflowing\r\n[ok]: BRPOPLPUSH with wrong source type\r\n[ok]: ZUNIONSTORE with empty set - ziplist\r\n[ok]: ZUNION/ZINTER/ZDIFF with empty set - ziplist\r\n[ok]: ZUNIONSTORE basics - ziplist\r\n[ok]: BRPOPLPUSH with wrong destination type\r\n[ok]: errorstats: rejected call within MULTI/EXEC\r\n[ok]: BRPOPLPUSH maintains order of elements after failure\r\n[ok]: ZUNION/ZINTER/ZDIFF with integer members - ziplist\r\n[ok]: ZUNIONSTORE with weights - ziplist\r\n[ok]: SCAN COUNT\r\n[ok]: ZUNION with weights - ziplist\r\n[ok]: errorstats: rejected call due to wrong arity\r\n[ok]: Handle an empty query\r\n[ok]: BRPOPLPUSH with multiple blocked clients\r\n[ok]: ZUNIONSTORE with a regular set and weights - ziplist\r\n[ok]: ZUNIONSTORE with AGGREGATE MIN - ziplist\r\n[ok]: ZUNION/ZINTER with AGGREGATE MIN - ziplist\r\n[ok]: ZUNIONSTORE with AGGREGATE MAX - ziplist\r\n[ok]: errorstats: rejected call by OOM error\r\n[ok]: ZUNION/ZINTER with AGGREGATE MAX - ziplist\r\n[ok]: ZINTERSTORE basics - ziplist\r\n[ok]: ZINTER basics - ziplist\r\n[ok]: Linked LMOVEs\r\n[ok]: ZINTER RESP3 - ziplist\r\n[ok]: ZINTERSTORE with weights - ziplist\r\n[ok]: ZINTER with weights - ziplist\r\n[ok]: errorstats: rejected call by authorization error\r\n[ok]: ZINTERSTORE with a regular set and weights - ziplist\r\n[ok]: ZINTERSTORE with AGGREGATE MIN - ziplist\r\n[ok]: ZINTERSTORE with AGGREGATE MAX - ziplist\r\n[ok]: ZUNIONSTORE with +inf/-inf scores - ziplist\r\n[ok]: ZUNIONSTORE with NaN weights - ziplist\r\n[ok]: ZINTERSTORE with +inf/-inf scores - ziplist\r\n[ok]: ZINTERSTORE with NaN weights - ziplist\r\n[ok]: ZDIFFSTORE basics - ziplist\r\n[ok]: ZDIFF basics - ziplist\r\n[ok]: ZDIFFSTORE with a regular set - ziplist\r\n[ok]: ZDIFF subtracting set from itself - ziplist\r\n[ok]: ZDIFF algorithm 1 - ziplist\r\n[ok]: ZDIFF algorithm 2 - ziplist\r\n[ok]: Circular BRPOPLPUSH\r\n[ok]: Self-referential BRPOPLPUSH\r\n[ok]: SCAN MATCH\r\n[ok]: BRPOPLPUSH inside a transaction\r\n[ok]: PUSH resulting from BRPOPLPUSH affect WATCH\r\n[ok]: BRPOPLPUSH does not affect WATCH while still blocked\r\n[ok]: SADD overflows the maximum allowed integers in an intset\r\n[ok]: Variadic SADD\r\n[ok]: SCAN TYPE\r\n[ok]: SSCAN with encoding intset\r\n[ok]: Negative multibulk length\r\n[ok]: Out of range multibulk length\r\n[ok]: Wrong multibulk payload header\r\n[ok]: Negative multibulk payload length\r\n[ok]: Out of range multibulk payload length\r\n[ok]: Non-number multibulk payload length\r\n[ok]: Multi bulk request not followed by bulk arguments\r\n[ok]: Generic wrong number of args\r\n[ok]: Unbalanced number of quotes\r\n[ok]: Very big payload in GET/SET\r\n[ok]: SSCAN with encoding hashtable\r\n[ok]: HSCAN with encoding ziplist\r\n[ok]: XADD with MAXLEN option\r\n[1/64 done]: unit/printver (1 seconds)\r\nTesting unit/type/stream-cgroups\r\n[2/64 done]: unit/type/incr (1 seconds)\r\nTesting unit/sort\r\n[ok]: Set encoding after DEBUG RELOAD\r\n[ok]: Protocol desync regression test #1\r\n[ok]: SREM basics - regular set\r\n[ok]: SREM basics - intset\r\n[ok]: SREM with multiple arguments\r\n[ok]: SREM variadic version with more args needed to destroy the key\r\n[ok]: AUTH fails when binary password is wrong\r\n[ok]: AUTH succeeds when binary password is correct\r\n[ok]: HRANDFIELD with <count> - hashtable\r\n[ok]: XADD with MAXLEN option and the '=' argument\r\n[ok]: XGROUP CREATE: creation and duplicate group name detection\r\n[ok]: XGROUP CREATE: automatic stream creation fails without MKSTREAM\r\n[ok]: XGROUP CREATE: automatic stream creation works with MKSTREAM\r\n[ok]: MIGRATE is caching connections\r\n[ok]: XREADGROUP will return only new elements\r\n[ok]: XREADGROUP can read the history of the elements we own\r\n[ok]: XPENDING is able to return pending items\r\n[ok]: XPENDING can return single consumer items\r\n[ok]: XPENDING only group\r\n[ok]: Generated sets must be encoded as hashtable\r\n[ok]: SINTER with two sets - hashtable\r\n[ok]: SINTERSTORE with two sets - hashtable\r\n[ok]: XPENDING with IDLE\r\n[ok]: XPENDING with exclusive range intervals works as expected\r\n[ok]: XACK is able to remove items from the consumer/group PEL\r\n[ok]: XACK can't remove the same item multiple times\r\n[ok]: XACK is able to accept multiple arguments\r\n[ok]: XACK should fail if got at least one invalid ID\r\n[ok]: PEL NACK reassignment after XGROUP SETID event\r\n[ok]: XREADGROUP will not report data on empty history. Bug #5577\r\n[ok]: SINTERSTORE with two sets, after a DEBUG RELOAD - hashtable\r\n[ok]: XREADGROUP history reporting of deleted entries. Bug #5570\r\n[ok]: Protocol desync regression test #2\r\n[ok]: HSCAN with encoding hashtable\r\n[ok]: SUNION with two sets - hashtable\r\n[ok]: ZSCAN with encoding ziplist\r\n[ok]: SUNIONSTORE with two sets - hashtable\r\n[ok]: SINTER against three sets - hashtable\r\n[ok]: SINTERSTORE with three sets - hashtable\r\n[ok]: SUNION with non existing keys - hashtable\r\n[ok]: SDIFF with two sets - hashtable\r\n[ok]: SDIFF with three sets - hashtable\r\n[ok]: SDIFFSTORE with three sets - hashtable\r\n[ok]: Old Ziplist: SORT BY key\r\n[ok]: Old Ziplist: SORT BY key with limit\r\n[ok]: Unsafe command names are sanitized in INFO output\r\n[ok]: Old Ziplist: SORT BY hash field\r\n[ok]: XADD with MAXLEN option and the '~' argument\r\n[ok]: XADD with NOMKSTREAM option\r\n[ok]: HRANDFIELD with <count> - ziplist\r\n[ok]: Blocking XREADGROUP will not reply with an empty array\r\n[ok]: XGROUP DESTROY should unblock XREADGROUP with -NOGROUP\r\n[ok]: RENAME can unblock XREADGROUP with data\r\n[ok]: Protocol desync regression test #3\r\n[ok]: RENAME can unblock XREADGROUP with -NOGROUP\r\n[ok]: Generated sets must be encoded as intset\r\n[ok]: SINTER with two sets - intset\r\n[ok]: SINTERSTORE with two sets - intset\r\n[ok]: SINTERSTORE with two sets, after a DEBUG RELOAD - intset\r\n[ok]: SUNION with two sets - intset\r\n[ok]: SUNIONSTORE with two sets - intset\r\n[ok]: SINTER against three sets - intset\r\n[ok]: SINTERSTORE with three sets - intset\r\n[ok]: SUNION with non existing keys - intset\r\n[ok]: SDIFF with two sets - intset\r\n[ok]: SDIFF with three sets - intset\r\n[ok]: SDIFFSTORE with three sets - intset\r\n[ok]: SDIFF with first set empty\r\n[ok]: SDIFF with same set two times\r\n[ok]: ZSCAN with encoding skiplist\r\n[ok]: SCAN guarantees check under write load\r\n[ok]: SSCAN with integer encoded object (issue #1345)\r\n[ok]: SSCAN with PATTERN\r\n[ok]: HSCAN with PATTERN\r\n[ok]: ZSCAN with PATTERN\r\n[ok]: XADD with MINID option\r\n[ok]: XTRIM with MINID option\r\n[ok]: HSET/HLEN - Big hash creation\r\n[ok]: Is the big hash encoded with an hash table?\r\n[ok]: HGET against the small hash\r\n[ok]: Regression for a crash with blocking ops and pipelining\r\n[ok]: ZSCAN scores: regression test for issue #2175\r\n[ok]: HGET against the big hash\r\n[ok]: HGET against non existing key\r\n[ok]: HSET in update and insert mode\r\n[ok]: HSETNX target key missing - small hash\r\n[ok]: HSETNX target key exists - small hash\r\n[ok]: HSETNX target key missing - big hash\r\n[ok]: HSETNX target key exists - big hash\r\n[ok]: HMSET wrong number of args\r\n[ok]: HMSET - small hash\r\n[3/64 done]: unit/info (1 seconds)\r\nTesting unit/expire\r\n[ok]: Old Linked list: SORT BY key\r\n[ok]: Old Linked list: SORT BY key with limit\r\n[ok]: HMSET - big hash\r\n[ok]: HMGET against non existing key and fields\r\n[ok]: HMGET against wrong type\r\n[ok]: HMGET - small hash\r\n[ok]: Old Linked list: SORT BY hash field\r\n[4/64 done]: unit/protocol (1 seconds)\r\nTesting unit/other\r\n[ok]: EXPIRE - set timeouts multiple times\r\n[ok]: EXPIRE - It should be still possible to read 'x'\r\n[ok]: HMGET - big hash\r\n[ok]: HKEYS - small hash\r\n[ok]: HKEYS - big hash\r\n[ok]: HVALS - small hash\r\n[ok]: HVALS - big hash\r\n[ok]: HGETALL - small hash\r\n[ok]: HGETALL - big hash\r\n[ok]: HDEL and return value\r\n[ok]: HDEL - more than a single value\r\n[ok]: HDEL - hash becomes empty before deleting all specified fields\r\n[ok]: HEXISTS\r\n[ok]: Is a ziplist encoded Hash promoted on big payload?\r\n[ok]: HINCRBY against non existing database key\r\n[ok]: HINCRBY against non existing hash key\r\n[ok]: HINCRBY against hash key created by hincrby itself\r\n[ok]: HINCRBY against hash key originally set with HSET\r\n[ok]: HINCRBY over 32bit value\r\n[ok]: HINCRBY over 32bit value with over 32bit increment\r\n[ok]: HINCRBY fails against hash value with spaces (left)\r\n[ok]: HINCRBY fails against hash value with spaces (right)\r\n[ok]: HINCRBY can detect overflows\r\n[ok]: HINCRBYFLOAT against non existing database key\r\n[ok]: HINCRBYFLOAT against non existing hash key\r\n[ok]: HINCRBYFLOAT against hash key created by hincrby itself\r\n[ok]: HINCRBYFLOAT against hash key originally set with HSET\r\n[ok]: HINCRBYFLOAT over 32bit value\r\n[ok]: HINCRBYFLOAT over 32bit value with over 32bit increment\r\n[ok]: HINCRBYFLOAT fails against hash value with spaces (left)\r\n[ok]: HINCRBYFLOAT fails against hash value with spaces (right)\r\n[ok]: HINCRBYFLOAT fails against hash value that contains a null-terminator in the middle\r\n[ok]: HSTRLEN against the small hash\r\n[ok]: HSTRLEN against the big hash\r\n[ok]: HSTRLEN against non existing field\r\n[ok]: HSTRLEN corner cases\r\n[ok]: Hash ziplist regression test for large keys\r\n[ok]: SAVE - make sure there are all the types as values\r\n[ok]: Hash fuzzing #1 - 10 fields\r\n[ok]: Hash fuzzing #2 - 10 fields\r\n[ok]: XCLAIM can claim PEL items from another consumer\r\n[ok]: FUZZ stresser with data model binary\r\n[ok]: BRPOPLPUSH timeout\r\n[ok]: BLPOP when new key is moved into place\r\n[ok]: BLPOP when result key is created by SORT..STORE\r\n[ok]: BLPOP: with single empty list argument\r\n[ok]: BLPOP: with negative timeout\r\n[ok]: DEL against expired key\r\n[ok]: EXISTS\r\n[ok]: Zero length value in key. SET/GET/EXISTS\r\n[ok]: Commands pipelining\r\n[ok]: Non existing command\r\n[ok]: RENAME basic usage\r\n[ok]: RENAME source key should no longer exist\r\n[ok]: RENAME against already existing key\r\n[ok]: RENAMENX basic usage\r\n[ok]: RENAMENX against already existing key\r\n[ok]: RENAMENX against already existing key (2)\r\n[ok]: RENAME against non existing source key\r\n[ok]: RENAME where source and dest key are the same (existing)\r\n[ok]: RENAMENX where source and dest key are the same (existing)\r\n[ok]: RENAME where source and dest key are the same (non existing)\r\n[ok]: RENAME with volatile key, should move the TTL as well\r\n[ok]: RENAME with volatile key, should not inherit TTL of target key\r\n[ok]: DEL all keys again (DB 0)\r\n[ok]: DEL all keys again (DB 1)\r\n[ok]: COPY basic usage for string\r\n[ok]: COPY for string does not replace an existing key without REPLACE option\r\n[ok]: COPY for string can replace an existing key with REPLACE option\r\n[ok]: COPY for string ensures that copied data is independent of copying data\r\n[ok]: COPY for string does not copy data to no-integer DB\r\n[ok]: COPY can copy key expire metadata as well\r\n[ok]: COPY does not create an expire if it does not exist\r\n[ok]: COPY basic usage for list\r\n[ok]: COPY basic usage for intset set\r\n[ok]: COPY basic usage for hashtable set\r\n[ok]: COPY basic usage for ziplist sorted set\r\n[ok]: COPY basic usage for skiplist sorted set\r\n[ok]: COPY basic usage for ziplist hash\r\n[ok]: COPY basic usage for hashtable hash\r\n[ok]: COPY basic usage for stream\r\n[ok]: COPY basic usage for stream-cgroups\r\n[ok]: MOVE basic usage\r\n[ok]: MOVE against key existing in the target DB\r\n[ok]: MOVE against non-integer DB (#1428)\r\n[ok]: MOVE can move key expire metadata as well\r\n[ok]: MOVE does not create an expire if it does not exist\r\n[ok]: SET/GET keys in different DBs\r\n[ok]: RANDOMKEY\r\n[ok]: RANDOMKEY against empty DB\r\n[ok]: RANDOMKEY regression 1\r\n[ok]: KEYS * two times with long key, Github issue #1208\r\n[ok]: XCLAIM without JUSTID increments delivery count\r\n[5/64 done]: unit/keyspace (2 seconds)\r\nTesting unit/multi\r\n[ok]: MASTERAUTH test with binary password\r\n[ok]: MUTLI / EXEC basics\r\n[ok]: DISCARD\r\n[ok]: Nested MULTI are not allowed\r\n[ok]: MULTI where commands alter argc/argv\r\n[ok]: WATCH inside MULTI is not allowed\r\n[ok]: EXEC fails if there are errors while queueing commands #1\r\n[ok]: EXEC fails if there are errors while queueing commands #2\r\n[ok]: If EXEC aborts, the client MULTI state is cleared\r\n[ok]: EXEC works on WATCHed key not modified\r\n[ok]: EXEC fail on WATCHed key modified (1 key of 1 watched)\r\n[ok]: EXEC fail on WATCHed key modified (1 key of 5 watched)\r\n[ok]: EXEC fail on WATCHed key modified by SORT with STORE even if the result is empty\r\n[ok]: After successful EXEC key is no longer watched\r\n[ok]: After failed EXEC key is no longer watched\r\n[ok]: It is possible to UNWATCH\r\n[ok]: UNWATCH when there is nothing watched works as expected\r\n[ok]: FLUSHALL is able to touch the watched keys\r\n[ok]: FLUSHALL does not touch non affected keys\r\n[ok]: FLUSHDB is able to touch the watched keys\r\n[ok]: FLUSHDB does not touch non affected keys\r\n[ok]: SWAPDB is able to touch the watched keys that exist\r\n[ok]: SWAPDB is able to touch the watched keys that do not exist\r\n[ok]: WATCH is able to remember the DB a key belongs to\r\n[ok]: WATCH will consider touched keys target of EXPIRE\r\n[ok]: BLPOP: with non-integer timeout\r\n[ok]: XCLAIM same consumer\r\n[6/64 done]: unit/auth (2 seconds)\r\nTesting unit/quit\r\n[ok]: QUIT returns OK\r\n[ok]: Pipelined commands after QUIT must not be executed\r\n[ok]: Pipelined commands after QUIT that exceed read buffer size\r\n[ok]: FUZZ stresser with data model alpha\r\n[7/64 done]: unit/quit (0 seconds)\r\nTesting unit/aofrw\r\n[ok]: Hash fuzzing #1 - 512 fields\r\n[ok]: XAUTOCLAIM can claim PEL items from another consumer\r\n[ok]: FUZZ stresser with data model compr\r\n[ok]: XAUTOCLAIM as an iterator\r\n[ok]: XAUTOCLAIM COUNT must be > 0\r\n[ok]: XINFO FULL output\r\n[ok]: XGROUP CREATECONSUMER: create consumer if does not exist\r\n[ok]: XGROUP CREATECONSUMER: group must exist\r\n[ok]: BLPOP: with zero timeout should block indefinitely\r\n[ok]: BLPOP: second argument is not a list\r\n[ok]: XREADGROUP with NOACK creates consumer\r\n[ok]: WATCH will consider touched expired keys\r\n[ok]: DISCARD should clear the WATCH dirty flag on the client\r\n[ok]: DISCARD should UNWATCH all the keys\r\n[ok]: XADD mass insertion and XLEN\r\n[ok]: XADD with ID 0-0\r\n[ok]: XRANGE COUNT works as expected\r\n[ok]: XREVRANGE COUNT works as expected\r\n[ok]: Very big payload random access\r\n[ok]: EXPIRE - After 2.1 seconds the key should no longer be here\r\n[ok]: EXPIRE - write on expire should work\r\n[ok]: EXPIREAT - Check for EXPIRE alike behavior\r\n[ok]: SETEX - Set + Expire combo operation. Check for TTL\r\n[ok]: SETEX - Check value\r\n[ok]: SETEX - Overwrite old key\r\n[ok]: MULTI / EXEC is propagated correctly (single write command)\r\n[ok]: Old Big Linked list: SORT BY key\r\n[ok]: Old Big Linked list: SORT BY key with limit\r\n[ok]: MULTI / EXEC is propagated correctly (empty transaction)\r\n[ok]: MULTI / EXEC is propagated correctly (read-only commands)\r\n[ok]: MULTI / EXEC is propagated correctly (write command, no effect)\r\n[ok]: DISCARD should not fail during OOM\r\n[ok]: Old Big Linked list: SORT BY hash field\r\n[ok]: Intset: SORT BY key\r\n[ok]: Intset: SORT BY key with limit\r\n[ok]: Intset: SORT BY hash field\r\n[ok]: Hash fuzzing #2 - 512 fields\r\n[ok]: XRANGE can be used to iterate the whole stream\r\n[ok]: BGSAVE\r\n[ok]: SELECT an out of range DB\r\n[ok]: Hash table: SORT BY key\r\n[ok]: Hash table: SORT BY key with limit\r\n[ok]: Hash table: SORT BY hash field\r\n[ok]: MULTI and script timeout\r\n[ok]: SDIFF fuzzing\r\n[ok]: SINTER against non-set should throw error\r\n[ok]: SUNION against non-set should throw error\r\n[ok]: SINTER should handle non existing key as empty\r\n[ok]: SINTER with same integer elements but different encoding\r\n[ok]: SINTERSTORE against non existing keys should delete dstkey\r\n[ok]: SUNIONSTORE against non existing keys should delete dstkey\r\n[ok]: SPOP basics - hashtable\r\n[ok]: SPOP with <count>=1 - hashtable\r\n[ok]: SRANDMEMBER - hashtable\r\n[ok]: SPOP basics - intset\r\n[ok]: SPOP with <count>=1 - intset\r\n[ok]: SRANDMEMBER - intset\r\n[ok]: SPOP with <count>\r\n[ok]: SPOP with <count>\r\n[ok]: SPOP using integers, testing Knuth's and Floyd's algorithm\r\n[ok]: SPOP using integers with Knuth's algorithm\r\n[ok]: SPOP new implementation: code path #1\r\n[ok]: SPOP new implementation: code path #2\r\n[ok]: SPOP new implementation: code path #3\r\n[ok]: SRANDMEMBER with <count> against non existing key\r\n[ok]: SRANDMEMBER with <count> - hashtable\r\n[ok]: SRANDMEMBER with <count> - intset\r\n[ok]: SRANDMEMBER histogram distribution - hashtable\r\n[ok]: ZDIFF fuzzing - ziplist\r\n[ok]: Basic ZPOP with a single key - ziplist\r\n[ok]: ZPOP with count - ziplist\r\n[ok]: BZPOP with a single existing sorted set - ziplist\r\n[ok]: BZPOP with multiple existing sorted sets - ziplist\r\n[ok]: BZPOP second sorted set has members - ziplist\r\n[ok]: Check encoding - skiplist\r\n[ok]: ZSET basic ZADD and score update - skiplist\r\n[ok]: ZSET element can't be set to NaN with ZADD - skiplist\r\n[ok]: ZSET element can't be set to NaN with ZINCRBY - skiplist\r\n[ok]: ZADD with options syntax error with incomplete pair - skiplist\r\n[ok]: ZADD XX option without key - skiplist\r\n[ok]: ZADD XX existing key - skiplist\r\n[ok]: ZADD XX returns the number of elements actually added - skiplist\r\n[ok]: ZADD XX updates existing elements score - skiplist\r\n[ok]: ZADD GT updates existing elements when new scores are greater - skiplist\r\n[ok]: ZADD LT updates existing elements when new scores are lower - skiplist\r\n[ok]: BLPOP: timeout\r\n[ok]: ZADD GT XX updates existing elements when new scores are greater and skips new elements - skiplist\r\n[ok]: ZADD LT XX updates existing elements when new scores are lower and skips new elements - skiplist\r\n[ok]: ZADD XX and NX are not compatible - skiplist\r\n[ok]: ZADD NX with non existing key - skiplist\r\n[ok]: ZADD NX only add new elements without updating old ones - skiplist\r\n[ok]: ZADD GT and NX are not compatible - skiplist\r\n[ok]: BLPOP: arguments are empty\r\n[ok]: ZADD LT and NX are not compatible - skiplist\r\n[ok]: ZADD LT and GT are not compatible - skiplist\r\n[ok]: ZADD INCR LT/GT replies with nill if score not updated - skiplist\r\n[ok]: BRPOP: with single empty list argument\r\n[ok]: BRPOP: with negative timeout\r\n[ok]: ZADD INCR LT/GT with inf - skiplist\r\n[ok]: ZADD INCR works like ZINCRBY - skiplist\r\n[ok]: BRPOP: with non-integer timeout\r\n[ok]: ZADD INCR works with a single score-elemenet pair - skiplist\r\n[ok]: ZADD CH option changes return value to all changed elements - skiplist\r\n[ok]: ZINCRBY calls leading to NaN result in error - skiplist\r\n[ok]: ZADD - Variadic version base case - $encoding\r\n[ok]: ZADD - Return value is the number of actually added items - $encoding\r\n[ok]: ZADD - Variadic version does not add nothing on single parsing err - $encoding\r\n[ok]: ZADD - Variadic version will raise error on missing arg - $encoding\r\n[ok]: ZINCRBY does not work variadic even if shares ZADD implementation - $encoding\r\n[ok]: ZCARD basics - skiplist\r\n[ok]: ZREM removes key after last element is removed - skiplist\r\n[ok]: ZREM variadic version - skiplist\r\n[ok]: ZREM variadic version -- remove elements after key deletion - skiplist\r\n[ok]: ZRANGE basics - skiplist\r\n[ok]: ZREVRANGE basics - skiplist\r\n[ok]: ZRANK/ZREVRANK basics - skiplist\r\n[ok]: ZRANK - after deletion - skiplist\r\n[ok]: ZINCRBY - can create a new sorted set - skiplist\r\n[ok]: ZINCRBY - increment and decrement - skiplist\r\n[ok]: ZINCRBY return value - skiplist\r\n[ok]: ZRANGEBYSCORE/ZREVRANGEBYSCORE/ZCOUNT basics - skiplist\r\n[ok]: ZRANGEBYSCORE with WITHSCORES - skiplist\r\n[ok]: ZRANGEBYSCORE with LIMIT - skiplist\r\n[ok]: ZRANGEBYSCORE with LIMIT and WITHSCORES - skiplist\r\n[ok]: ZRANGEBYSCORE with non-value min or max - skiplist\r\n[ok]: ZRANGEBYLEX/ZREVRANGEBYLEX/ZLEXCOUNT basics - skiplist\r\n[ok]: ZLEXCOUNT advanced - skiplist\r\n[ok]: ZRANGEBYSLEX with LIMIT - skiplist\r\n[ok]: ZRANGEBYLEX with invalid lex range specifiers - skiplist\r\n[ok]: ZREMRANGEBYSCORE basics - skiplist\r\n[ok]: ZREMRANGEBYSCORE with non-value min or max - skiplist\r\n[ok]: ZREMRANGEBYRANK basics - skiplist\r\n[ok]: ZUNIONSTORE against non-existing key doesn't set destination - skiplist\r\n[ok]: ZUNION/ZINTER/ZDIFF against non-existing key - skiplist\r\n[ok]: ZUNIONSTORE with empty set - skiplist\r\n[ok]: ZUNION/ZINTER/ZDIFF with empty set - skiplist\r\n[ok]: ZUNIONSTORE basics - skiplist\r\n[ok]: ZUNION/ZINTER/ZDIFF with integer members - skiplist\r\n[ok]: ZUNIONSTORE with weights - skiplist\r\n[ok]: ZUNION with weights - skiplist\r\n[ok]: ZUNIONSTORE with a regular set and weights - skiplist\r\n[ok]: ZUNIONSTORE with AGGREGATE MIN - skiplist\r\n[ok]: ZUNION/ZINTER with AGGREGATE MIN - skiplist\r\n[ok]: SRANDMEMBER histogram distribution - intset\r\n[ok]: ZUNIONSTORE with AGGREGATE MAX - skiplist\r\n[ok]: Consumer without PEL is present in AOF after AOFRW\r\n[ok]: ZUNION/ZINTER with AGGREGATE MAX - skiplist\r\n[ok]: ZINTERSTORE basics - skiplist\r\n[ok]: ZINTER basics - skiplist\r\n[ok]: SMOVE basics - from regular set to intset\r\n[ok]: ZINTER RESP3 - skiplist\r\n[ok]: ZINTERSTORE with weights - skiplist\r\n[ok]: SMOVE basics - from intset to regular set\r\n[ok]: ZINTER with weights - skiplist\r\n[ok]: ZINTERSTORE with a regular set and weights - skiplist\r\n[ok]: SMOVE non existing key\r\n[ok]: ZINTERSTORE with AGGREGATE MIN - skiplist\r\n[ok]: ZINTERSTORE with AGGREGATE MAX - skiplist\r\n[ok]: SMOVE non existing src set\r\n[ok]: SMOVE from regular set to non existing destination set\r\n[ok]: ZUNIONSTORE with +inf/-inf scores - skiplist\r\n[ok]: ZUNIONSTORE with NaN weights - skiplist\r\n[ok]: SMOVE from intset to non existing destination set\r\n[ok]: SMOVE wrong src key type\r\n[ok]: SMOVE wrong dst key type\r\n[ok]: SMOVE with identical source and destination\r\n[ok]: ZINTERSTORE with +inf/-inf scores - skiplist\r\n[ok]: ZINTERSTORE with NaN weights - skiplist\r\n[ok]: ZDIFFSTORE basics - skiplist\r\n[ok]: ZDIFF basics - skiplist\r\n[ok]: ZDIFFSTORE with a regular set - skiplist\r\n[ok]: ZDIFF subtracting set from itself - skiplist\r\n[ok]: ZDIFF algorithm 1 - skiplist\r\n[ok]: ZDIFF algorithm 2 - skiplist\r\n[ok]: Check consistency of different data types after a reload\r\n[ok]: SETEX - Wait for the key to expire\r\n[ok]: SETEX - Wrong time parameter\r\n[ok]: PERSIST can undo an EXPIRE\r\n[ok]: PERSIST returns 0 against non existing or non volatile keys\r\n[ok]: EXEC and script timeout\r\n[ok]: Consumer group last ID propagation to slave (NOACK=0)\r\n[ok]: Consumer group last ID propagation to slave (NOACK=1)\r\n[ok]: SET 10000 numeric keys and access all them in reverse order\r\n[ok]: DBSIZE should be 10000 now\r\n[ok]: SETNX target key missing\r\n[ok]: SETNX target key exists\r\n[ok]: SETNX against not-expired volatile key\r\n[ok]: MULTI-EXEC body and script timeout\r\n[ok]: BRPOP: with zero timeout should block indefinitely\r\n[ok]: BRPOP: second argument is not a list\r\n[ok]: just EXEC and script timeout\r\n[ok]: exec with write commands and state change\r\n[ok]: exec with read commands and stale replica state change\r\n[ok]: EXEC with only read commands should not be rejected when OOM\r\n[ok]: EXEC with at least one use-memory command should fail\r\n[ok]: Blocking commands ignores the timeout\r\n[ok]: MULTI propagation of PUBLISH\r\n[ok]: Same dataset digest if saving/reloading as AOF?\r\n[ok]: Stress test the hash ziplist -> hashtable encoding conversion\r\n[ok]: Test HINCRBYFLOAT for correct float representation (issue #2846)\r\n[ok]: XREVRANGE returns the reverse of XRANGE\r\n[ok]: XRANGE exclusive ranges\r\n[ok]: XREAD with non empty stream\r\n[ok]: Non blocking XREAD with empty streams\r\n[ok]: XREAD with non empty second stream\r\n[ok]: Blocking XREAD waiting new data\r\n[ok]: Blocking XREAD waiting old data\r\n[ok]: MULTI propagation of SCRIPT LOAD\r\n[ok]: Hash ziplist of various encodings\r\n[ok]: Hash ziplist of various encodings - sanitize dump\r\n[ok]: Blocking XREAD will not reply with an empty array\r\n[ok]: XREAD: XADD + DEL should not awake client\r\n[ok]: XREAD: XADD + DEL + LPUSH should not awake client\r\n[ok]: XREAD with same stream name multiple times should work\r\n[ok]: XREAD + multiple XADD inside transaction\r\n[ok]: XDEL basic test\r\n[ok]: MULTI propagation of SCRIPT LOAD\r\n[8/64 done]: unit/type/hash (5 seconds)\r\nTesting unit/acl\r\n[ok]: MULTI propagation of XREADGROUP\r\n[ok]: Connections start with the default user\r\n[ok]: It is possible to create new users\r\n[ok]: New users start disabled\r\n[ok]: Enabling the user allows the login\r\n[ok]: Only the set of correct passwords work\r\n[ok]: It is possible to remove passwords from the set of valid ones\r\n[ok]: Test password hashes can be added\r\n[ok]: Test password hashes validate input\r\n[ok]: ACL GETUSER returns the password hash instead of the actual password\r\n[ok]: Test hashed passwords removal\r\n[ok]: By default users are not able to access any command\r\n[ok]: By default users are not able to access any key\r\n[ok]: It's possible to allow the access of a subset of keys\r\n[ok]: By default users are able to publish to any channel\r\n[ok]: By default users are able to subscribe to any channel\r\n[ok]: By default users are able to subscribe to any pattern\r\n[ok]: It's possible to allow publishing to a subset of channels\r\n[ok]: Validate subset of channels is prefixed with resetchannels flag\r\n[ok]: In transaction queue publish/subscribe/psubscribe to unauthorized channel will fail\r\n[ok]: It's possible to allow subscribing to a subset of channels\r\n[ok]: It's possible to allow subscribing to a subset of channel patterns\r\n[ok]: Subscribers are killed when revoked of channel permission\r\n[ok]: Subscribers are killed when revoked of pattern permission\r\n[ok]: Subscribers are pardoned if literal permissions are retained and/or gaining allchannels\r\n[ok]: Users can be configured to authenticate with any password\r\n[ok]: ACLs can exclude single commands\r\n[ok]: ACLs can include or exclude whole classes of commands\r\n[ok]: ACLs can include single subcommands\r\n[ok]: intsets implementation stress testing\r\n[ok]: ACLs set can include subcommands, if already full command exists\r\n[ok]: ACL GETUSER is able to translate back command permissions\r\n[ok]: ACL GETUSER provides reasonable results\r\n[ok]: ACL #5998 regression: memory leaks adding / removing subcommands\r\n[ok]: ACL LOG shows failed command executions at toplevel\r\n[ok]: ACL LOG is able to test similar events\r\n[ok]: ACL LOG is able to log keys access violations and key name\r\n[ok]: ACL LOG is able to log channel access violations and channel name\r\n[ok]: ACL LOG RESET is able to flush the entries in the log\r\n[ok]: ACL LOG can distinguish the transaction context (1)\r\n[ok]: ACL LOG can distinguish the transaction context (2)\r\n[ok]: ACL can log errors in the context of Lua scripting\r\n[ok]: ACL LOG can accept a numerical argument to show less entries\r\n[ok]: ACL LOG can log failed auth attempts\r\n[ok]: ACL LOG entries are limited to a maximum amount\r\n[ok]: When default user is off, new connections are not authenticated\r\n[ok]: When default user has no command permission, hello command still works for other users\r\n[ok]: ACL HELP should not have unexpected options\r\n[ok]: Delete a user that the client doesn't use\r\n[ok]: Delete a user that the client is using\r\n[9/64 done]: unit/multi (4 seconds)\r\nTesting unit/latency-monitor\r\n[10/64 done]: unit/type/set (6 seconds)\r\nTesting integration/block-repl\r\n[ok]: Empty stream with no lastid can be rewrite into AOF correctly\r\n[ok]: default: load from include file, can access any channels\r\n[ok]: default: with config acl-pubsub-default allchannels after reset, can access any channels\r\n[ok]: default: with config acl-pubsub-default resetchannels after reset, can not access any channels\r\n[ok]: Alice: can execute all command\r\n[ok]: Bob: just execute @set and acl command\r\n[ok]: ACL load and save\r\n[ok]: ACL load and save with restricted channels\r\n[11/64 done]: unit/type/stream-cgroups (5 seconds)\r\nTesting integration/replication\r\n[ok]: Big Hash table: SORT BY key\r\n[ok]: Big Hash table: SORT BY key with limit\r\n[ok]: Default user has access to all channels irrespective of flag\r\n[ok]: Update acl-pubsub-default, existing users shouldn't get affected\r\n[ok]: Single channel is valid\r\n[ok]: Single channel is not valid with allchannels\r\n[ok]: Slave enters handshake\r\n[ok]: BRPOP: timeout\r\n[ok]: BRPOP: arguments are empty\r\n[ok]: BLPOP inside a transaction\r\n[ok]: LPUSHX, RPUSHX - generic\r\n[ok]: LPUSHX, RPUSHX - linkedlist\r\n[ok]: LINSERT - linkedlist\r\n[ok]: LPUSHX, RPUSHX - ziplist\r\n[ok]: LINSERT - ziplist\r\n[ok]: LINSERT raise error on bad syntax\r\n[ok]: LINDEX consistency test - quicklist\r\n[ok]: LINDEX random access - quicklist\r\n[ok]: EXPIRES after a reload (snapshot + append only file rewrite)\r\n[ok]: Big Hash table: SORT BY hash field\r\n[ok]: SORT GET #\r\n[ok]: SORT GET <const>\r\n[ok]: SORT GET (key and hash) with sanity check\r\n[ok]: SORT BY key STORE\r\n[ok]: SORT BY hash field STORE\r\n[ok]: SORT extracts STORE correctly\r\n[ok]: SORT extracts multiple STORE correctly\r\n[ok]: SORT DESC\r\n[ok]: SORT ALPHA against integer encoded strings\r\n[ok]: SORT sorted set\r\n[ok]: EXPIRE precision is now the millisecond\r\n[ok]: SORT sorted set BY nosort should retain ordering\r\n[ok]: SORT sorted set BY nosort + LIMIT\r\n[ok]: SORT sorted set BY nosort works as expected from scripts\r\n[ok]: SORT sorted set: +inf and -inf handling\r\n[ok]: Only default user has access to all channels irrespective of flag\r\n[ok]: SORT regression for issue #19, sorting floats\r\n[ok]: SORT with STORE returns zero if result is empty (github issue 224)\r\n[ok]: SORT with STORE does not create empty lists (github issue 224)\r\n[ok]: SORT with STORE removes key if result is empty (github issue 227)\r\n[ok]: SORT with BY <constant> and STORE should still order output\r\n[ok]: SORT will complain with numerical sorting and bad doubles (1)\r\n[ok]: SORT will complain with numerical sorting and bad doubles (2)\r\n[ok]: SORT BY sub-sorts lexicographically if score is the same\r\n[ok]: SORT GET with pattern ending with just -> does not get hash field\r\n[ok]: SORT by nosort retains native order for lists\r\n[ok]: SORT by nosort plus store retains native order for lists\r\n[ok]: SORT by nosort with limit returns based on original list order\r\n[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[ok]: SORT speed, 100 element list BY key, 100 times\r\n[ok]: SORT speed, 100 element list BY hash field, 100 times\r\n[ok]: SORT speed, 100 element list directly, 100 times\r\n[ok]: SORT speed, 100 element list BY <const>, 100 times\r\n[ok]: LTRIM stress testing - linkedlist\r\n[ok]: LINDEX consistency test - quicklist\r\n[12/64 done]: unit/sort (5 seconds)\r\nTesting integration/replication-2\r\n[ok]: LINDEX random access - quicklist\r\n[ok]: default: load from config file, can access any channels\r\n[ok]: XDEL fuzz test\r\n[ok]: Check if list is still ok after a DEBUG RELOAD - quicklist\r\n[ok]: LLEN against non-list value error\r\n[ok]: LLEN against non existing key\r\n[ok]: LINDEX against non-list value error\r\n[ok]: LINDEX against non existing key\r\n[ok]: LPUSH against non-list value error\r\n[ok]: RPUSH against non-list value error\r\n[ok]: RPOPLPUSH base case - linkedlist\r\n[ok]: LMOVE left left base case - linkedlist\r\n[ok]: LMOVE left right base case - linkedlist\r\n[ok]: LMOVE right left base case - linkedlist\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: If min-slaves-to-write is honored, write is accepted\r\n[ok]: LMOVE right right base case - linkedlist\r\n[ok]: No write if min-slaves-to-write is < attached slaves\r\n[ok]: If min-slaves-to-write is honored, write is accepted (again)\r\n[ok]: RPOPLPUSH with the same list as src and dst - linkedlist\r\n[ok]: LMOVE left left with the same list as src and dst - linkedlist\r\n[ok]: LMOVE left right with the same list as src and dst - linkedlist\r\n[ok]: LMOVE right left with the same list as src and dst - linkedlist\r\n[ok]: LMOVE right right with the same list as src and dst - linkedlist\r\n[ok]: RPOPLPUSH with linkedlist source and existing target linkedlist\r\n[13/64 done]: unit/acl (2 seconds)\r\nTesting integration/replication-3\r\n[ok]: LMOVE left left with linkedlist source and existing target linkedlist\r\n[ok]: LMOVE left right with linkedlist source and existing target linkedlist\r\n[ok]: LMOVE right left with linkedlist source and existing target linkedlist\r\n[ok]: LMOVE right right with linkedlist source and existing target linkedlist\r\n[ok]: RPOPLPUSH with linkedlist source and existing target ziplist\r\n[ok]: LMOVE left left with linkedlist source and existing target ziplist\r\n[ok]: LMOVE left right with linkedlist source and existing target ziplist\r\n[ok]: LMOVE right left with linkedlist source and existing target ziplist\r\n[ok]: LMOVE right right with linkedlist source and existing target ziplist\r\n[ok]: RPOPLPUSH base case - ziplist\r\n[ok]: LMOVE left left base case - ziplist\r\n[ok]: LMOVE left right base case - ziplist\r\n[ok]: LMOVE right left base case - ziplist\r\n[ok]: LMOVE right right base case - ziplist\r\n[ok]: RPOPLPUSH with the same list as src and dst - ziplist\r\n[ok]: LMOVE left left with the same list as src and dst - ziplist\r\n[ok]: LMOVE left right with the same list as src and dst - ziplist\r\n[ok]: LMOVE right left with the same list as src and dst - ziplist\r\n[ok]: LMOVE right right with the same list as src and dst - ziplist\r\n[ok]: RPOPLPUSH with ziplist source and existing target linkedlist\r\n[ok]: LMOVE left left with ziplist source and existing target linkedlist\r\n[ok]: LMOVE left right with ziplist source and existing target linkedlist\r\n[ok]: LMOVE right left with ziplist source and existing target linkedlist\r\n[ok]: LMOVE right right with ziplist source and existing target linkedlist\r\n[ok]: RPOPLPUSH with ziplist source and existing target ziplist\r\n[ok]: LMOVE left left with ziplist source and existing target ziplist\r\n[ok]: LMOVE left right with ziplist source and existing target ziplist\r\n[ok]: LMOVE right left with ziplist source and existing target ziplist\r\n[ok]: LMOVE right right with ziplist source and existing target ziplist\r\n[ok]: RPOPLPUSH against non existing key\r\n[ok]: RPOPLPUSH against non list src key\r\n[ok]: RPOPLPUSH against non list dst key\r\n[ok]: RPOPLPUSH against non existing src key\r\n[ok]: Basic LPOP/RPOP - linkedlist\r\n[ok]: Basic LPOP/RPOP - ziplist\r\n[ok]: LPOP/RPOP against non list value\r\n[ok]: Mass RPOP/LPOP - quicklist\r\n[ok]: Mass RPOP/LPOP - quicklist\r\n[ok]: LRANGE basics - linkedlist\r\n[ok]: LRANGE inverted indexes - linkedlist\r\n[ok]: LRANGE out of range indexes including the full list - linkedlist\r\n[ok]: LRANGE out of range negative end index - linkedlist\r\n[ok]: LRANGE basics - ziplist\r\n[ok]: LRANGE inverted indexes - ziplist\r\n[ok]: LRANGE out of range indexes including the full list - ziplist\r\n[ok]: LRANGE out of range negative end index - ziplist\r\n[ok]: LRANGE against non existing key\r\n[ok]: LRANGE with start > end yields an empty array for backward compatibility\r\n[ok]: LTRIM basics - linkedlist\r\n[ok]: LTRIM out of range negative end index - linkedlist\r\n[ok]: LTRIM basics - ziplist\r\n[ok]: LTRIM out of range negative end index - ziplist\r\n[ok]: LSET - linkedlist\r\n[ok]: LSET out of range index - linkedlist\r\n[ok]: LSET - ziplist\r\n[ok]: LSET out of range index - ziplist\r\n[ok]: LSET against non existing key\r\n[ok]: LSET against non list value\r\n[ok]: LREM remove all the occurrences - linkedlist\r\n[ok]: LREM remove the first occurrence - linkedlist\r\n[ok]: LREM remove non existing element - linkedlist\r\n[ok]: LREM starting from tail with negative count - linkedlist\r\n[ok]: LREM starting from tail with negative count (2) - linkedlist\r\n[ok]: LREM deleting objects that may be int encoded - linkedlist\r\n[ok]: LREM remove all the occurrences - ziplist\r\n[ok]: LREM remove the first occurrence - ziplist\r\n[ok]: LREM remove non existing element - ziplist\r\n[ok]: LREM starting from tail with negative count - ziplist\r\n[ok]: LREM starting from tail with negative count (2) - ziplist\r\n[ok]: LREM deleting objects that may be int encoded - ziplist\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: SETNX against expired volatile key\r\n[ok]: GETEX EX option\r\n[ok]: GETEX PX option\r\n[ok]: GETEX EXAT option\r\n[ok]: GETEX PXAT option\r\n[ok]: GETEX PERSIST option\r\n[ok]: GETEX no option\r\n[ok]: GETEX syntax errors\r\n[ok]: GETEX no arguments\r\n[ok]: GETDEL command\r\n[ok]: GETDEL propagate as DEL command to replica\r\n[ok]: GETEX without argument does not propagate to replica\r\n[ok]: MGET\r\n[ok]: MGET against non existing key\r\n[ok]: MGET against non-string key\r\n[ok]: GETSET (set new value)\r\n[ok]: GETSET (replace old value)\r\n[ok]: MSET base case\r\n[ok]: MSET wrong number of args\r\n[ok]: MSETNX with already existent key\r\n[ok]: MSETNX with not existing keys\r\n[ok]: STRLEN against non-existing key\r\n[ok]: STRLEN against integer-encoded value\r\n[ok]: STRLEN against plain string\r\n[ok]: SETBIT against non-existing key\r\n[ok]: SETBIT against string-encoded key\r\n[ok]: SETBIT against integer-encoded key\r\n[ok]: SETBIT against key with wrong type\r\n[ok]: SETBIT with out of range bit offset\r\n[ok]: SETBIT with non-bit argument\r\n[ok]: PEXPIRE/PSETEX/PEXPIREAT can set sub-second expires\r\n[ok]: TTL returns time to live in seconds\r\n[ok]: PTTL returns time to live in milliseconds\r\n[ok]: TTL / PTTL return -1 if key has no expire\r\n[ok]: TTL / PTTL return -2 if key does not exit\r\n[ok]: ZDIFF fuzzing - skiplist\r\n[ok]: Basic ZPOP with a single key - skiplist\r\n[ok]: ZPOP with count - skiplist\r\n[ok]: BZPOP with a single existing sorted set - skiplist\r\n[ok]: BZPOP with multiple existing sorted sets - skiplist\r\n[ok]: BZPOP second sorted set has members - skiplist\r\n[ok]: ZINTERSTORE regression with two sets, intset+hashtable\r\n[ok]: ZUNIONSTORE regression, should not create NaN in scores\r\n[ok]: ZINTERSTORE #516 regression, mixed sets and ziplist zsets\r\n[ok]: SETBIT fuzzing\r\n[ok]: GETBIT against non-existing key\r\n[ok]: GETBIT against string-encoded key\r\n[ok]: GETBIT against integer-encoded key\r\n[ok]: SETRANGE against non-existing key\r\n[ok]: SETRANGE against string-encoded key\r\n[ok]: SETRANGE against integer-encoded key\r\n[ok]: SETRANGE against key with wrong type\r\n[ok]: SETRANGE with out of range offset\r\n[ok]: GETRANGE against non-existing key\r\n[ok]: GETRANGE against string value\r\n[ok]: GETRANGE against integer-encoded value\r\n[ok]: ZUNIONSTORE result is sorted\r\n[ok]: ZUNIONSTORE/ZINTERSTORE/ZDIFFSTORE error if using WITHSCORES \r\n[ok]: ZMSCORE retrieve\r\n[ok]: ZMSCORE retrieve from empty set\r\n[ok]: ZMSCORE retrieve with missing member\r\n[ok]: ZMSCORE retrieve single member\r\n[ok]: ZMSCORE retrieve requires one or more members\r\n[ok]: ZSET commands don't accept the empty strings as valid score\r\n[ok]: ZSCORE - ziplist\r\n[ok]: ZMSCORE - ziplist\r\n[ok]: ZSCORE after a DEBUG RELOAD - ziplist\r\n[ok]: ZSET sorting stresser - ziplist\r\n[ok]: Regression for bug 593 - chaining BRPOPLPUSH with other blocking cmds\r\n[ok]: client unblock tests\r\n[ok]: List ziplist of various encodings\r\n[ok]: List ziplist of various encodings - sanitize dump\r\n[ok]: SCAN regression test for issue #4906\r\n[14/64 done]: unit/type/list (8 seconds)\r\nTesting integration/replication-4\r\n[15/64 done]: unit/scan (8 seconds)\r\nTesting integration/replication-psync\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: no, disabled, reconnect: 0)\r\n[ok]: GETRANGE fuzzing\r\n[ok]: Extended SET can detect syntax errors\r\n[ok]: Extended SET NX option\r\n[ok]: Extended SET XX option\r\n[ok]: Extended SET GET option\r\n[ok]: Extended SET GET option with no previous value\r\n[ok]: Extended SET GET with NX option should result in syntax err\r\n[ok]: Extended SET GET with incorrect type should result in wrong type error\r\n[ok]: Extended SET EX option\r\n[ok]: Extended SET PX option\r\n[ok]: Extended SET EXAT option\r\n[ok]: Extended SET PXAT option\r\n[ok]: Extended SET using multiple options at once\r\n[ok]: GETRANGE with huge ranges, Github issue #1844\r\n[ok]: STRALGO LCS string output with STRINGS option\r\n[ok]: STRALGO LCS len\r\n[ok]: LCS with KEYS option\r\n[ok]: LCS indexes\r\n[ok]: LCS indexes with match len\r\n[ok]: LCS indexes with match len and minimum match len\r\n[ok]: Redis should actively expire keys incrementally\r\n[16/64 done]: unit/type/string (8 seconds)\r\nTesting integration/aof\r\n[ok]: Unfinished MULTI: Server should start if load-truncated is yes\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Short read: Server should start if load-truncated is yes\r\n[ok]: Truncated AOF loaded: we expect foo to be equal to 5\r\n[ok]: Append a new command after loading an incomplete AOF\r\n[ok]: Short read + command: Server should start\r\n[ok]: Truncated AOF loaded: we expect foo to be equal to 6 now\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: Test latency events logging\r\n[ok]: LATENCY HISTORY output is ok\r\n[ok]: LATENCY LATEST output is ok\r\n[ok]: LATENCY HISTORY / RESET with wrong event name is fine\r\n[ok]: LATENCY DOCTOR produces some output\r\n[ok]: LATENCY RESET is able to reset events\r\n[ok]: Bad format: Server should have logged an error\r\n[ok]: EXPIRES after AOF reload (without rewrite)\r\n[ok]: Unfinished MULTI: Server should have logged an error\r\n[ok]: Short read: Server should have logged an error\r\n[ok]: Short read: Utility should confirm the AOF is not valid\r\n[ok]: Short read: Utility should be able to fix the AOF\r\n[ok]: Fixed AOF: Server should have been started\r\n[ok]: Fixed AOF: Keyspace should contain values that were parseable\r\n[ok]: No write if min-slaves-max-lag is > of the slave lag\r\n[ok]: Redis should lazy expire keys\r\n[ok]: min-slaves-to-write is ignored by slaves\r\n[ok]: Detect write load to master\r\n[ok]: AOF+SPOP: Server should have been started\r\n[ok]: AOF+SPOP: Set should have 1 member\r\n[ok]: AOF+SPOP: Server should have been started\r\n[ok]: AOF+SPOP: Set should have 1 member\r\n[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[ok]: ZRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[ok]: AOF+EXPIRE: Server should have been started\r\n[ok]: AOF+EXPIRE: List should be empty\r\n[ok]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[ok]: ZSETs skiplist implementation backlink consistency test - ziplist\r\n[ok]: Redis should not try to convert DEL into EXPIREAT for EXPIRE -1\r\n[ok]: EXPIRE should not resurrect keys (issue #1026)\r\n[ok]: 5 keys in, 5 keys out\r\n[ok]: EXPIRE with empty string as TTL should report an error\r\n[ok]: SET with EX with big integer should report an error\r\n[ok]: SET with EX with smallest integer should report an error\r\n[ok]: GETEX with big integer should report an error\r\n[ok]: GETEX with smallest integer should report an error\r\n[ok]: EXPIRE with big integer overflows when converted to milliseconds\r\n[ok]: PEXPIRE with big integer overflow when basetime is added\r\n[ok]: EXPIRE with big negative integer\r\n[ok]: PEXPIREAT with big integer works\r\n[ok]: PEXPIREAT with big negative integer works\r\n[ok]: PIPELINING stresser (also a regression for the old epoll bug)\r\n[ok]: APPEND basics\r\n[ok]: APPEND basics, integer encoded values\r\n[ok]: APPEND fuzzing\r\n[ok]: FLUSHDB\r\n[ok]: Perform a final SAVE to leave a clean DB on disk\r\n[ok]: RESET clears client state\r\n[ok]: RESET clears MONITOR state\r\n[ok]: RESET clears and discards MULTI state\r\n[ok]: RESET clears Pub/Sub state\r\n[ok]: RESET clears authenticated state\r\n[ok]: ZSETs ZRANK augmented skip list stress testing - ziplist\r\n[ok]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[ok]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[ok]: BZPOPMIN with same key multiple times should work\r\n[ok]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[ok]: BZPOPMIN with variadic ZADD\r\n[ok]: Don't rehash if redis has child proecess\r\n[ok]: Process title set as expected\r\n[17/64 done]: unit/other (11 seconds)\r\nTesting integration/rdb\r\n[ok]: RDB encoding loading test\r\n[ok]: LTRIM stress testing - ziplist\r\n[ok]: BZPOPMIN with zero timeout should block indefinitely\r\n[ok]: ZSCORE - skiplist\r\n[ok]: ZMSCORE - skiplist\r\n[ok]: ZSCORE after a DEBUG RELOAD - skiplist\r\n[18/64 done]: unit/type/list-2 (12 seconds)\r\nTesting integration/corrupt-dump\r\n[ok]: ZSET sorting stresser - skiplist\r\n[ok]: Server started empty with non-existing RDB file\r\n[ok]: corrupt payload: #7445 - with sanitize\r\n[ok]: EXPIRE and SET/GETEX EX/PX/EXAT/PXAT option, TTL should not be reset after loadaof\r\n[ok]: Server started empty with empty RDB file\r\n[ok]: corrupt payload: #7445 - without sanitize - 1\r\n[ok]: EXPIRE relative and absolute propagation to replicas\r\n[ok]: SET command will remove expire\r\n[ok]: SET - use KEEPTTL option, TTL should not be removed\r\n[ok]: corrupt payload: #7445 - without sanitize - 2\r\n[ok]: Test RDB stream encoding\r\n[ok]: Test RDB stream encoding - sanitize dump\r\n[ok]: corrupt payload: hash with valid zip list header, invalid entry len\r\n[ok]: Server should not start if RDB is corrupted\r\n[ok]: corrupt payload: invalid zlbytes header\r\n[ok]: corrupt payload: valid zipped hash header, dup records\r\n[ok]: Test FLUSHALL aborts bgsave\r\n[ok]: bgsave resets the change counter\r\n[ok]: corrupt payload: quicklist big ziplist prev len\r\n[ok]: corrupt payload: quicklist small ziplist prev len\r\n[ok]: corrupt payload: quicklist ziplist wrong count\r\n[ok]: corrupt payload: #3080 - quicklist\r\n[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: corrupt payload: #3080 - ziplist\r\n[ok]: corrupt payload: load corrupted rdb with no CRC - #3505\r\n[ok]: ZRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: corrupt payload: listpack invalid size header\r\n[ok]: corrupt payload: listpack too long entry len\r\n[ok]: ZREMRANGEBYLEX fuzzy test, 100 ranges in 100 element sorted set - skiplist\r\n[ok]: ZSETs skiplist implementation backlink consistency test - skiplist\r\n[ok]: corrupt payload: listpack very long entry len\r\n[ok]: corrupt payload: listpack too long entry prev len\r\n[ok]: SET - use KEEPTTL option, TTL should not be removed after loadaof\r\n[ok]: GETEX use of PERSIST option should remove TTL\r\n[ok]: corrupt payload: hash ziplist with duplicate records\r\n[ok]: MASTER and SLAVE consistency with expire\r\n[ok]: corrupt payload: hash ziplist uneven record count\r\n[ok]: ZSETs ZRANK augmented skip list stress testing - skiplist\r\n[ok]: BZPOPMIN, ZADD + DEL should not awake blocked client\r\n[ok]: BZPOPMIN, ZADD + DEL + SET should not awake blocked client\r\n[ok]: BZPOPMIN with same key multiple times should work\r\n[ok]: MULTI/EXEC is isolated from the point of view of BZPOPMIN\r\n[ok]: BZPOPMIN with variadic ZADD\r\n[ok]: corrupt payload: hash dupliacte records\r\n[ok]: Test replication with parallel clients writing in different DBs\r\n[ok]: corrupt payload: fuzzer findings - NPD in streamIteratorGetID\r\n[ok]: LATENCY of expire events are correctly collected\r\n[ok]: LATENCY HELP should not have unexpected options\r\n[ok]: corrupt payload: fuzzer findings - listpack NPD on invalid stream\r\n[ok]: corrupt payload: fuzzer findings - NPD in quicklistIndex\r\n[ok]: corrupt payload: fuzzer findings - invalid read in ziplistFind\r\n[19/64 done]: unit/latency-monitor (9 seconds)\r\nTesting integration/corrupt-dump-fuzzer\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: With min-slaves-to-write (1,3): master should be writable\r\n[ok]: With min-slaves-to-write (2,3): master should not be writable\r\n[ok]: corrupt payload: fuzzer findings - invalid ziplist encoding\r\n[ok]: MIGRATE cached connections are released after some time\r\n[ok]: corrupt payload: fuzzer findings - hash crash\r\n[ok]: MIGRATE is able to migrate a key between two instances\r\n[ok]: corrupt payload: fuzzer findings - uneven entry count in hash\r\n[ok]: Slave is able to detect timeout during handshake\r\n[ok]: BZPOPMIN with zero timeout should block indefinitely\r\n[ok]: MASTER and SLAVE dataset should be identical after complex ops\r\n[ok]: AOF fsync always barrier issue\r\n[ok]: MIGRATE is able to copy a key between two instances\r\n[ok]: corrupt payload: fuzzer findings - invalid read in lzf_decompress\r\n[ok]: client freed during loading\r\n[ok]: GETEX should not append to AOF\r\n[20/64 done]: integration/replication-2 (10 seconds)\r\nTesting integration/convert-zipmap-hash-on-load\r\n[ok]: RDB load zipmap hash: converts to ziplist\r\n[ok]: MIGRATE will not overwrite existing keys, unless REPLACE is used\r\n[ok]: corrupt payload: fuzzer findings - leak in rdbloading due to dup entry in set\r\n[21/64 done]: integration/aof (8 seconds)\r\nTesting integration/logging\r\n[ok]: corrupt payload: fuzzer findings - empty intset div by zero\r\n[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-entries is exceeded\r\n[ok]: Set instance A as slave of B\r\n[ok]: corrupt payload: fuzzer findings - valgrind ziplist - crash report prints freed memory\r\n[ok]: Test replication partial resync: ok psync (diskless: no, disabled, reconnect: 1)\r\n[ok]: MIGRATE propagates TTL correctly\r\n[ok]: corrupt payload: fuzzer findings - valgrind ziplist prevlen reaches outside the ziplist\r\n[ok]: RDB load zipmap hash: converts to hash table when hash-max-ziplist-value is exceeded\r\n[ok]: ZSET skiplist order consistency when elements are moved\r\n[ok]: ZRANGESTORE basic\r\n[ok]: ZRANGESTORE RESP3\r\n[ok]: ZRANGESTORE range\r\n[ok]: ZRANGESTORE BYLEX\r\n[ok]: ZRANGESTORE BYSCORE\r\n[ok]: ZRANGESTORE BYSCORE LIMIT\r\n[ok]: ZRANGESTORE BYSCORE REV LIMIT\r\n[ok]: ZRANGE BYSCORE REV LIMIT\r\n[ok]: ZRANGESTORE - empty range\r\n[ok]: ZRANGESTORE BYLEX - empty range\r\n[ok]: ZRANGESTORE BYSCORE - empty range\r\n[ok]: ZRANGE BYLEX\r\n[ok]: ZRANGESTORE invalid syntax\r\n[ok]: ZRANGE invalid syntax\r\n[ok]: Server is able to generate a stack trace on selected systems\r\n[ok]: ZRANDMEMBER - ziplist\r\n[ok]: ZRANDMEMBER - skiplist\r\n[ok]: ZRANDMEMBER with RESP3\r\n[ok]: ZRANDMEMBER count of 0 is handled correctly\r\n[ok]: ZRANDMEMBER with <count> against non existing key\r\n[22/64 done]: integration/convert-zipmap-hash-on-load (1 seconds)\r\nTesting integration/psync2\r\n[ok]: GETEX use of PERSIST option should remove TTL after loadaof\r\n[ok]: corrupt payload: fuzzer findings - valgrind - bad rdbLoadDoubleValue\r\n[ok]: corrupt payload: fuzzer findings - valgrind ziplist prev too big\r\n[ok]: GETEX propagate as to replica as PERSIST, DEL, or nothing\r\n[ok]: ZRANDMEMBER with <count> - skiplist\r\n[ok]: ZRANDMEMBER with <count> - ziplist\r\n[23/64 done]: unit/expire (16 seconds)\r\nTesting integration/psync2-reg\r\n[24/64 done]: unit/type/zset (17 seconds)\r\nTesting integration/psync2-pingoff\r\n[ok]: Crash report generated on SIGABRT\r\n[ok]: AOF rewrite during write load: RDB preamble=yes\r\n[ok]: corrupt payload: fuzzer findings - lzf decompression fails, avoid valgrind invalid read\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: PSYNC2: --- CYCLE 1 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[ok]: PSYNC2: Set #4 to replicate from #1\r\n[ok]: PSYNC2: Set #0 to replicate from #1\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #2 to replicate from #4\r\n[ok]: corrupt payload: fuzzer findings - stream bad lp_count\r\n[25/64 done]: integration/logging (1 seconds)\r\nTesting integration/failover\r\n[ok]: INCRBYFLOAT replication, should not remove expire\r\n[ok]: GETSET replication\r\n[ok]: BRPOPLPUSH replication, when blocking against empty list\r\n[ok]: corrupt payload: fuzzer findings - stream bad lp_count - unsanitized\r\n[ok]: failover command fails without connected replica\r\n[ok]: corrupt payload: fuzzer findings - stream integrity check issue\r\n[ok]: setup replication for following tests\r\n[ok]: failover command fails with invalid host\r\n[ok]: failover command fails with invalid port\r\n[ok]: failover command fails with just force and timeout\r\n[ok]: failover command fails when sent to a replica\r\n[ok]: failover command fails with force without timeout\r\n[ok]: corrupt payload: fuzzer findings - infinite loop\r\n[ok]: corrupt payload: fuzzer findings - hash convert asserts on RESTORE with shallow sanitization\r\n[ok]: PSYNC2 pingoff: setup\r\n[ok]: PSYNC2 pingoff: write and wait replication\r\n[ok]: PSYNC2 #3899 regression: setup\r\n[ok]: corrupt payload: OOM in rdbGenericLoadStringObject\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: BRPOPLPUSH replication, list exists\r\n[ok]: BLMOVE (left, left) replication, when blocking against empty list\r\n[ok]: With min-slaves-to-write: master not writable with lagged slave\r\n[ok]: corrupt payload: fuzzer findings - OOM in dictExpand\r\n[ok]: corrupt payload: fuzzer findings - invalid tail offset after removal\r\n[ok]: failover command to specific replica works\r\n[ok]: corrupt payload: fuzzer findings - negative reply length\r\n[ok]: corrupt payload: fuzzer findings - valgrind negative malloc\r\n[ok]: Test child sending info\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: BLMOVE (left, left) replication, list exists\r\n[ok]: BLMOVE (left, right) replication, when blocking against empty list\r\n[26/64 done]: integration/rdb (7 seconds)\r\nTesting integration/redis-cli\r\n[ok]: corrupt payload: fuzzer findings - valgrind invalid read\r\n[ok]: Interactive CLI: INFO response should be printed raw\r\n[ok]: Interactive CLI: Status reply\r\n[ok]: failover command to any replica works\r\n[ok]: Interactive CLI: Integer reply\r\n[ok]: Interactive CLI: Bulk reply\r\n[ok]: Interactive CLI: Multi-bulk reply\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: corrupt payload: fuzzer findings - HRANDFIELD on bad ziplist\r\n[ok]: Interactive CLI: Parsing quotes\r\n[ok]: Non-interactive TTY CLI: Status reply\r\n[ok]: Non-interactive TTY CLI: Integer reply\r\n[ok]: Non-interactive TTY CLI: Bulk reply\r\n[ok]: corrupt payload: fuzzer findings - stream with no records\r\n[ok]: Non-interactive TTY CLI: Multi-bulk reply\r\n[27/64 done]: integration/corrupt-dump (8 seconds)\r\nTesting integration/redis-benchmark\r\n[ok]: Non-interactive TTY CLI: Read last argument from pipe\r\n[ok]: Non-interactive TTY CLI: Read last argument from file\r\n[ok]: Non-interactive non-TTY CLI: Status reply\r\n[ok]: Non-interactive non-TTY CLI: Integer reply\r\n[ok]: failover to a replica with force works\r\n[ok]: Non-interactive non-TTY CLI: Bulk reply\r\n[ok]: Non-interactive non-TTY CLI: Multi-bulk reply\r\n[ok]: Non-interactive non-TTY CLI: Quoted input arguments\r\n[ok]: Non-interactive non-TTY CLI: No accidental unquoting of input arguments\r\n[ok]: Non-interactive non-TTY CLI: Invalid quoted input arguments\r\n[ok]: benchmark: set,get\r\n[ok]: Non-interactive non-TTY CLI: Read last argument from pipe\r\n[ok]: Non-interactive non-TTY CLI: Read last argument from file\r\n[ok]: benchmark: full test suite\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: BLMOVE (left, right) replication, list exists\r\n[ok]: BLMOVE (right, left) replication, when blocking against empty list\r\n[ok]: failover with timeout aborts if replica never catches up\r\n[ok]: failovers can be aborted\r\n[ok]: Slave is able to evict keys created in writable slaves\r\n[ok]: benchmark: multi-thread set,get\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: benchmark: pipelined full set,get\r\n[ok]: benchmark: arbitrary command\r\n[ok]: BLMOVE (right, left) replication, list exists\r\n[ok]: BLMOVE (right, right) replication, when blocking against empty list\r\n[ok]: benchmark: keyspace length\r\n[ok]: failover aborts if target rejects sync request\r\n[28/64 done]: integration/redis-benchmark (2 seconds)\r\nTesting unit/pubsub\r\n[ok]: Pub/Sub PING\r\n[ok]: PUBLISH/SUBSCRIBE basics\r\n[ok]: PUBLISH/SUBSCRIBE with two clients\r\n[ok]: PUBLISH/SUBSCRIBE after UNSUBSCRIBE without arguments\r\n[ok]: SUBSCRIBE to one channel more than once\r\n[ok]: UNSUBSCRIBE from non-subscribed channels\r\n[ok]: PUBLISH/PSUBSCRIBE basics\r\n[ok]: PUBLISH/PSUBSCRIBE with two clients\r\n[ok]: PUBLISH/PSUBSCRIBE after PUNSUBSCRIBE without arguments\r\n[ok]: PUNSUBSCRIBE from non-subscribed channels\r\n[ok]: NUMSUB returns numbers, not strings (#1561)\r\n[ok]: Mix SUBSCRIBE and PSUBSCRIBE\r\n[ok]: PUNSUBSCRIBE and UNSUBSCRIBE should always reply\r\n[ok]: Keyspace notifications: we receive keyspace notifications\r\n[ok]: Keyspace notifications: we receive keyevent notifications\r\n[ok]: Keyspace notifications: we can receive both kind of events\r\n[ok]: Keyspace notifications: we are able to mask events\r\n[ok]: Keyspace notifications: general events test\r\n[ok]: Keyspace notifications: list events test\r\n[ok]: Keyspace notifications: set events test\r\n[ok]: Keyspace notifications: zset events test\r\n[ok]: Keyspace notifications: hash events test\r\n[ok]: XRANGE fuzzing\r\n[ok]: XREVRANGE regression test for issue #5006\r\n[ok]: XREAD streamID edge (no-blocking)\r\n[ok]: XREAD streamID edge (blocking)\r\n[ok]: XADD streamID edge\r\n[ok]: XTRIM with MAXLEN option basic test\r\n[ok]: XADD with LIMIT consecutive calls\r\n[ok]: XTRIM with ~ is limited\r\n[ok]: XTRIM without ~ is not limited\r\n[ok]: XTRIM without ~ and with LIMIT\r\n[ok]: Keyspace notifications: expired events (triggered expire)\r\n[ok]: Keyspace notifications: expired events (background expire)\r\n[ok]: Keyspace notifications: evicted events\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: Keyspace notifications: test CONFIG GET/SET of event flags\r\n[29/64 done]: integration/failover (5 seconds)\r\nTesting unit/slowlog\r\n[ok]: SLOWLOG - check that it starts with an empty log\r\n[30/64 done]: unit/pubsub (0 seconds)\r\nTesting unit/scripting\r\n[ok]: EVAL - Does Lua interpreter replies to our requests?\r\n[ok]: EVAL - Lua integer -> Redis protocol type conversion\r\n[ok]: EVAL - Lua string -> Redis protocol type conversion\r\n[ok]: EVAL - Lua true boolean -> Redis protocol type conversion\r\n[ok]: EVAL - Lua false boolean -> Redis protocol type conversion\r\n[ok]: EVAL - Lua status code reply -> Redis protocol type conversion\r\n[ok]: EVAL - Lua error reply -> Redis protocol type conversion\r\n[ok]: EVAL - Lua table -> Redis protocol type conversion\r\n[ok]: XADD with MAXLEN > xlen can propagate correctly\r\n[ok]: EVAL - Are the KEYS and ARGV arrays populated correctly?\r\n[ok]: EVAL - is Lua able to call Redis API?\r\n[ok]: EVALSHA - Can we call a SHA1 if already defined?\r\n[ok]: EVALSHA - Can we call a SHA1 in uppercase?\r\n[ok]: EVALSHA - Do we get an error on invalid SHA1?\r\n[ok]: EVALSHA - Do we get an error on non defined SHA1?\r\n[ok]: EVAL - Redis integer -> Lua type conversion\r\n[ok]: EVAL - Redis bulk -> Lua type conversion\r\n[ok]: EVAL - Redis multi bulk -> Lua type conversion\r\n[ok]: EVAL - Redis status reply -> Lua type conversion\r\n[ok]: EVAL - Redis error reply -> Lua type conversion\r\n[ok]: EVAL - Redis nil bulk reply -> Lua type conversion\r\n[ok]: EVAL - Is the Lua client using the currently selected DB?\r\n[ok]: EVAL - SELECT inside Lua should not affect the caller\r\n[ok]: EVAL - Scripts can't run blpop command\r\n[ok]: EVAL - Scripts can't run brpop command\r\n[ok]: EVAL - Scripts can't run brpoplpush command\r\n[ok]: EVAL - Scripts can't run blmove command\r\n[ok]: EVAL - Scripts can't run bzpopmin command\r\n[ok]: EVAL - Scripts can't run bzpopmax command\r\n[ok]: EVAL - Scripts can't run XREAD and XREADGROUP with BLOCK option\r\n[ok]: EVAL - Scripts can't run certain commands\r\n[ok]: EVAL - No arguments to redis.call/pcall is considered an error\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - redis.call variant raises a Lua error on Redis cmd error (1)\r\n[ok]: EVAL - JSON numeric decoding\r\n[ok]: EVAL - JSON string decoding\r\n[ok]: EVAL - cmsgpack can pack double?\r\n[ok]: EVAL - cmsgpack can pack negative int64?\r\n[ok]: EVAL - cmsgpack can pack and unpack circular references?\r\n[ok]: EVAL - Numerical sanity check from bitop\r\n[ok]: EVAL - Verify minimal bitop functionality\r\n[ok]: EVAL - Able to parse trailing comments\r\n[ok]: SCRIPTING FLUSH - is able to clear the scripts cache?\r\n[ok]: SCRIPTING FLUSH ASYNC\r\n[ok]: SCRIPT EXISTS - can detect already defined scripts?\r\n[ok]: SCRIPT LOAD - is able to register scripts in the scripting cache\r\n[ok]: In the context of Lua the output of random commands gets ordered\r\n[ok]: SORT is normally not alpha re-ordered for the scripting engine\r\n[ok]: SORT BY <constant> output gets ordered for scripting\r\n[ok]: SORT BY <constant> with GET gets ordered for scripting\r\n[ok]: redis.sha1hex() implementation\r\n[ok]: Globals protection reading an undeclared global variable\r\n[ok]: Globals protection setting an undeclared global*\r\n[ok]: Test an example script DECR_IF_GT\r\n[ok]: Scripting engine resets PRNG at every script execution\r\n[ok]: Scripting engine PRNG can be seeded correctly\r\n[ok]: SLOWLOG - only logs commands taking more time than specified\r\n[ok]: SLOWLOG - max entries is correctly handled\r\n[ok]: SLOWLOG - GET optional argument to limit output len works\r\n[ok]: SLOWLOG - RESET subcommand works\r\n[ok]: BLMOVE (right, right) replication, list exists\r\n[ok]: BLPOP followed by role change, issue #2473\r\n[ok]: SLOWLOG - logged entry sanity check\r\n[ok]: SLOWLOG - Certain commands are omitted that contain sensitive information\r\n[ok]: SLOWLOG - Rewritten commands are logged as their original command\r\n[ok]: SLOWLOG - commands with too many arguments are trimmed\r\n[ok]: SLOWLOG - too long arguments are trimmed\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: XADD with MINID > lastid can propagate correctly\r\n[ok]: SLOWLOG - EXEC is not logged, just executed commands\r\n[ok]: SLOWLOG - can clean older entries\r\n[ok]: PSYNC2 pingoff: pause replica and promote it\r\n[ok]: XADD with ~ MAXLEN can propagate correctly\r\n[ok]: EVAL does not leak in the Lua stack\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 29410)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 2 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #1 as master\r\n[ok]: PSYNC2: Set #4 to replicate from #1\r\n[ok]: PSYNC2: Set #2 to replicate from #1\r\n[ok]: PSYNC2: Set #3 to replicate from #1\r\n[ok]: PSYNC2: Set #0 to replicate from #4\r\n[ok]: EVAL processes writes from AOF in read-only slaves\r\n[ok]: Second server should have role master at first\r\n[ok]: SLAVEOF should start with link status \"down\"\r\n[ok]: The role should immediately be changed to \"replica\"\r\n[ok]: MIGRATE can correctly transfer large values\r\n[ok]: SLOWLOG - can be disabled\r\n[ok]: Dumping an RDB\r\n[ok]: XADD with ~ MAXLEN and LIMIT can propagate correctly\r\n[ok]: Sync should have transferred keys from master\r\n[ok]: The link status should be up\r\n[ok]: SET on the master should immediately propagate\r\n[ok]: FLUSHALL should replicate\r\n[ok]: ROLE in master reports master with a slave\r\n[ok]: ROLE in slave reports slave in connected state\r\n[ok]: Scan mode\r\n[31/64 done]: unit/slowlog (2 seconds)\r\nTesting unit/maxmemory\r\n[ok]: MIGRATE can correctly transfer hashes\r\n[ok]: Without maxmemory small integers are shared\r\n[ok]: With maxmemory and non-LRU policy integers are still shared\r\n[ok]: With maxmemory and LRU policy integers are not shared\r\n[ok]: XADD with ~ MINID can propagate correctly\r\n[ok]: XADD with ~ MINID and LIMIT can propagate correctly\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-random)\r\n[ok]: Make the old master a replica of the new one and check conditions\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: XTRIM with ~ MAXLEN can propagate correctly\r\n[ok]: MIGRATE timeout actually works\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-lru)\r\n[ok]: Connecting as a replica\r\n[ok]: XADD can CREATE an empty stream\r\n[ok]: XSETID can set a specific ID\r\n[ok]: XSETID cannot SETID with smaller ID\r\n[ok]: XSETID cannot SETID on non-existent key\r\n[ok]: Fuzzer corrupt restore payloads - sanitize_dump: no\r\n[ok]: MIGRATE can migrate multiple keys at once\r\n[ok]: MIGRATE with multiple keys must have empty key arg\r\n[ok]: MIGRATE with multiple keys migrate just existing ones\r\n[ok]: maxmemory - is the memory limit honoured? (policy allkeys-lfu)\r\n[ok]: MIGRATE with multiple keys: stress command rewriting\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-lru)\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: MIGRATE with multiple keys: delete just ack keys\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: MIGRATE AUTH: correct and wrong password cases\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-lfu)\r\n[32/64 done]: unit/dump (26 seconds)\r\nTesting unit/introspection\r\n[ok]: CLIENT LIST\r\n[ok]: CLIENT LIST with IDs\r\n[ok]: CLIENT INFO\r\n[ok]: MONITOR can log executed commands\r\n[ok]: MONITOR can log commands issued by the scripting engine\r\n[ok]: CLIENT GETNAME should return NIL if name is not assigned\r\n[ok]: CLIENT LIST shows empty fields for unassigned names\r\n[ok]: CLIENT SETNAME does not accept spaces\r\n[ok]: CLIENT SETNAME can assign a name to this connection\r\n[ok]: CLIENT SETNAME can change the name of an existing connection\r\n[ok]: After CLIENT SETNAME, connection can still be closed\r\n[ok]: Empty stream can be rewrite into AOF correctly\r\n[ok]: Test replication partial resync: no backlog (diskless: no, disabled, reconnect: 1)\r\n[ok]: CONFIG save params special case handled properly\r\n[ok]: CONFIG sanity\r\n[ok]: Piping raw protocol\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-random)\r\n[ok]: CONFIG REWRITE sanity\r\n[33/64 done]: integration/redis-cli (8 seconds)\r\nTesting unit/introspection-2\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: maxmemory - is the memory limit honoured? (policy volatile-ttl)\r\n[ok]: Stream can be rewrite into AOF correctly after XDEL lastid\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: XGROUP HELP should not have unexpected options\r\n[ok]: test various edge cases of repl topology changes with missing pings at the end\r\n[34/64 done]: unit/type/stream (28 seconds)\r\nTesting unit/limits\r\n[ok]: CONFIG REWRITE handles save properly\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-random)\r\n[35/64 done]: unit/introspection (2 seconds)\r\nTesting unit/obuf-limits\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (allkeys-lru)\r\n[ok]: PSYNC2 #3899 regression: kill first replica\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: Check if maxclients works refusing connections\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-lru)\r\n[36/64 done]: unit/limits (1 seconds)\r\nTesting unit/bitops\r\n[ok]: EVAL timeout from AOF\r\n[ok]: We can call scripts rewriting client->argv from Lua\r\n[ok]: Call Redis command with many args from Lua (issue #1764)\r\n[ok]: Number conversion precision test (issue #1118)\r\n[ok]: String containing number precision test (regression of issue #1118)\r\n[ok]: Verify negative arg count is error instead of crash (issue #1842)\r\n[ok]: Correct handling of reused argv (issue #1939)\r\n[ok]: Functions in the Redis namespace are able to report errors\r\n[ok]: Script with RESP3 map\r\n[ok]: BITCOUNT returns 0 against non existing key\r\n[ok]: BITCOUNT returns 0 with out of range indexes\r\n[ok]: BITCOUNT returns 0 with negative indexes where start > end\r\n[ok]: BITCOUNT against test vector #1\r\n[ok]: BITCOUNT against test vector #2\r\n[ok]: BITCOUNT against test vector #3\r\n[ok]: BITCOUNT against test vector #4\r\n[ok]: BITCOUNT against test vector #5\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-random)\r\n[ok]: BITCOUNT fuzzing without start/end\r\n[ok]: Timedout read-only scripts can be killed by SCRIPT KILL\r\n[ok]: Timedout read-only scripts can be killed by SCRIPT KILL even when use pcall\r\n[ok]: maxmemory - only allkeys-* should remove non-volatile keys (volatile-ttl)\r\n[ok]: TTL, TYPE and EXISTS do not alter the last access time of a key\r\n[ok]: Timedout script does not cause a false dead client\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: BITCOUNT fuzzing with start/end\r\n[ok]: BITCOUNT with start, end\r\n[ok]: BITCOUNT syntax error #1\r\n[ok]: BITCOUNT regression test for github issue #582\r\n[ok]: BITCOUNT misaligned prefix\r\n[ok]: BITCOUNT misaligned prefix + full words + remainder\r\n[ok]: BITOP NOT (empty string)\r\n[ok]: BITOP NOT (known string)\r\n[ok]: BITOP where dest and target are the same key\r\n[ok]: BITOP AND|OR|XOR don't change the string with single input key\r\n[ok]: BITOP missing key is considered a stream of zero\r\n[ok]: BITOP shorter keys are zero-padded to the key with max length\r\n[ok]: maxmemory - policy volatile-lru should only remove volatile keys.\r\n[ok]: Timedout script link is still usable after Lua returns\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 57900)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 3 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[ok]: PSYNC2: Set #3 to replicate from #0\r\n[ok]: PSYNC2: Set #4 to replicate from #3\r\n[ok]: PSYNC2: Set #1 to replicate from #0\r\n[ok]: PSYNC2: Set #2 to replicate from #1\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Timedout scripts that modified data can't be killed by SCRIPT KILL\r\n[ok]: SHUTDOWN NOSAVE can kill a timedout script anyway\r\n[ok]: maxmemory - policy volatile-lfu should only remove volatile keys.\r\n[ok]: Before the replica connects we issue two EVAL commands (scripts replication)\r\n[ok]: BITOP and fuzzing\r\n[ok]: maxmemory - policy volatile-random should only remove volatile keys.\r\n[ok]: Connect a replica to the master instance (scripts replication)\r\n[ok]: Now use EVALSHA against the master, with both SHAs (scripts replication)\r\n[ok]: If EVALSHA was replicated as EVAL, 'x' should be '4' (scripts replication)\r\n[ok]: Replication of script multiple pushes to list with BLPOP (scripts replication)\r\n[ok]: EVALSHA replication when first call is readonly (scripts replication)\r\n[ok]: Lua scripts using SELECT are replicated correctly (scripts replication)\r\n[ok]: maxmemory - policy volatile-ttl should only remove volatile keys.\r\n[ok]: BITOP or fuzzing\r\n[ok]: Before the replica connects we issue two EVAL commands (commands replication)\r\n[ok]: Connect a replica to the master instance (commands replication)\r\n[ok]: Now use EVALSHA against the master, with both SHAs (commands replication)\r\n[ok]: If EVALSHA was replicated as EVAL, 'x' should be '4' (commands replication)\r\n[ok]: Replication of script multiple pushes to list with BLPOP (commands replication)\r\n[ok]: EVALSHA replication when first call is readonly (commands replication)\r\n[ok]: Lua scripts using SELECT are replicated correctly (commands replication)\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: Chained replicas disconnect when replica re-connect with the same master\r\n[ok]: BITOP xor fuzzing\r\n[ok]: BITOP NOT fuzzing\r\n[ok]: BITOP with integer encoded source objects\r\n[ok]: BITOP with non string source key\r\n[ok]: BITOP with empty string after non empty string (issue #529)\r\n[ok]: BITPOS bit=0 with empty key returns 0\r\n[ok]: BITPOS bit=1 with empty key returns -1\r\n[ok]: BITPOS bit=0 with string less than 1 word works\r\n[ok]: BITPOS bit=1 with string less than 1 word works\r\n[ok]: BITPOS bit=0 starting at unaligned address\r\n[ok]: BITPOS bit=1 starting at unaligned address\r\n[ok]: BITPOS bit=0 unaligned+full word+reminder\r\n[ok]: BITPOS bit=1 unaligned+full word+reminder\r\n[ok]: BITPOS bit=1 returns -1 if string is all 0 bits\r\n[ok]: BITPOS bit=0 works with intervals\r\n[ok]: BITPOS bit=1 works with intervals\r\n[ok]: BITPOS bit=0 changes behavior if end is given\r\n[ok]: Test replication with blocking lists and sorted sets operations\r\n[ok]: BITPOS bit=1 fuzzy testing using SETBIT\r\n[37/64 done]: integration/psync2-pingoff (15 seconds)\r\nTesting unit/bitfield\r\n[ok]: Connect a replica to the master instance\r\n[ok]: Redis.replicate_commands() must be issued before any write\r\n[ok]: Redis.replicate_commands() must be issued before any write (2)\r\n[ok]: Redis.set_repl() must be issued after replicate_commands()\r\n[ok]: Redis.set_repl() don't accept invalid values\r\n[ok]: Test selective replication of certain Redis commands from Lua\r\n[ok]: PRNG is seeded randomly for command replication\r\n[ok]: Using side effects is not a problem with command replication\r\n[ok]: BITFIELD signed SET and GET basics\r\n[ok]: BITFIELD unsigned SET and GET basics\r\n[ok]: BITFIELD #<idx> form\r\n[ok]: BITFIELD basic INCRBY form\r\n[ok]: BITFIELD chaining of multiple commands\r\n[ok]: BITFIELD unsigned overflow wrap\r\n[ok]: BITFIELD unsigned overflow sat\r\n[ok]: BITFIELD signed overflow wrap\r\n[ok]: BITFIELD signed overflow sat\r\n[ok]: BITPOS bit=0 fuzzy testing using SETBIT\r\n[38/64 done]: integration/block-repl (26 seconds)\r\nTesting unit/geo\r\n[39/64 done]: unit/bitops (4 seconds)\r\nTesting unit/memefficiency\r\n[ok]: GEOADD create\r\n[ok]: GEOADD update\r\n[ok]: GEOADD update with CH option\r\n[ok]: GEOADD update with NX option\r\n[ok]: GEOADD update with XX option\r\n[ok]: GEOADD update with CH NX option\r\n[ok]: GEOADD update with CH XX option\r\n[ok]: GEOADD update with XX NX option will return syntax error\r\n[ok]: GEOADD update with invalid option\r\n[ok]: GEOADD invalid coordinates\r\n[ok]: GEOADD multi add\r\n[ok]: Check geoset values\r\n[ok]: GEORADIUS simple (sorted)\r\n[ok]: GEOSEARCH simple (sorted)\r\n[ok]: GEOSEARCH FROMLONLAT and FROMMEMBER cannot exist at the same time\r\n[ok]: GEOSEARCH FROMLONLAT and FROMMEMBER one must exist\r\n[ok]: GEOSEARCH BYRADIUS and BYBOX cannot exist at the same time\r\n[ok]: GEOSEARCH BYRADIUS and BYBOX one must exist\r\n[ok]: GEOSEARCH with STOREDIST option\r\n[ok]: GEORADIUS withdist (sorted)\r\n[ok]: GEOSEARCH withdist (sorted)\r\n[ok]: GEORADIUS with COUNT\r\n[ok]: GEORADIUS with ANY not sorted by default\r\n[ok]: GEORADIUS with ANY sorted by ASC\r\n[ok]: GEORADIUS with ANY but no COUNT\r\n[ok]: GEORADIUS with COUNT but missing integer argument\r\n[ok]: GEORADIUS with COUNT DESC\r\n[ok]: GEORADIUS HUGE, issue #2767\r\n[ok]: GEORADIUSBYMEMBER simple (sorted)\r\n[ok]: GEOSEARCH FROMMEMBER simple (sorted)\r\n[ok]: GEOSEARCH vs GEORADIUS\r\n[ok]: GEOSEARCH non square, long and narrow\r\n[ok]: GEOSEARCH corner point test\r\n[ok]: GEORADIUSBYMEMBER withdist (sorted)\r\n[ok]: GEOHASH is able to return geohash strings\r\n[ok]: GEOPOS simple\r\n[ok]: GEOPOS missing element\r\n[ok]: GEODIST simple & unit\r\n[ok]: GEODIST missing elements\r\n[ok]: GEORADIUS STORE option: syntax error\r\n[ok]: GEOSEARCHSTORE STORE option: syntax error\r\n[ok]: GEORANGE STORE option: incompatible options\r\n[ok]: GEORANGE STORE option: plain usage\r\n[ok]: GEOSEARCHSTORE STORE option: plain usage\r\n[ok]: GEORANGE STOREDIST option: plain usage\r\n[ok]: GEOSEARCHSTORE STOREDIST option: plain usage\r\n[ok]: GEORANGE STOREDIST option: COUNT ASC and DESC\r\n[ok]: GEOSEARCH the box spans -180 or 180\r\n[ok]: BITFIELD overflow detection fuzzing\r\n[ok]: TOUCH alters the last access time of a key\r\n[ok]: TOUCH returns the number of existing keys specified\r\n[ok]: command stats for GEOADD\r\n[ok]: command stats for EXPIRE\r\n[ok]: command stats for BRPOP\r\n[ok]: command stats for MULTI\r\n[ok]: command stats for scripts\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[40/64 done]: unit/scripting (11 seconds)\r\nTesting unit/hyperloglog\r\n[41/64 done]: unit/introspection-2 (6 seconds)\r\nTesting unit/lazyfree\r\n[ok]: BITFIELD overflow wrap fuzzing\r\n[ok]: BITFIELD regression for #3221\r\n[ok]: BITFIELD regression for #3564\r\n[ok]: Memory efficiency with values in range 32\r\n[ok]: BITFIELD: setup slave\r\n[ok]: BITFIELD: write on master, read on slave\r\n[ok]: BITFIELD_RO fails when write option is used\r\n[ok]: UNLINK can reclaim memory in background\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[42/64 done]: unit/bitfield (2 seconds)\r\nTesting unit/wait\r\n[ok]: FLUSHDB ASYNC can reclaim memory in background\r\n[ok]: Memory efficiency with values in range 64\r\n[43/64 done]: unit/lazyfree (2 seconds)\r\nTesting unit/pendingquerybuf\r\n[ok]: Setup slave\r\n[ok]: WAIT should acknowledge 1 additional copy of the data\r\n[ok]: Fuzzer corrupt restore payloads - sanitize_dump: yes\r\n[44/64 done]: integration/corrupt-dump-fuzzer (20 seconds)\r\nTesting unit/tls\r\n[ok]: Memory efficiency with values in range 128\r\n[ok]: HyperLogLog self test passes\r\n[ok]: PFADD without arguments creates an HLL value\r\n[ok]: Approximated cardinality after creation is zero\r\n[ok]: PFADD returns 1 when at least 1 reg was modified\r\n[ok]: PFADD returns 0 when no reg was modified\r\n[ok]: PFADD works with empty string (regression)\r\n[ok]: PFCOUNT returns approximated cardinality of set\r\n[45/64 done]: unit/tls (0 seconds)\r\nTesting unit/tracking\r\n[ok]: Clients are able to enable tracking and redirect it\r\n[ok]: The other connection is able to get invalidations\r\n[ok]: The client is now able to disable tracking\r\n[ok]: Clients can enable the BCAST mode with the empty prefix\r\n[ok]: The connection gets invalidation messages about all the keys\r\n[ok]: Clients can enable the BCAST mode with prefixes\r\n[ok]: Adding prefixes to BCAST mode works\r\n[ok]: Tracking NOLOOP mode in standard mode works\r\n[ok]: Tracking NOLOOP mode in BCAST mode works\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 91881)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 4 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #4 as master\r\n[ok]: PSYNC2: Set #2 to replicate from #4\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #1 to replicate from #3\r\n[ok]: PSYNC2: Set #0 to replicate from #4\r\n[ok]: Memory efficiency with values in range 1024\r\n[ok]: HyperLogLogs are promote from sparse to dense\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: WAIT should not acknowledge 2 additional copies of the data\r\n[ok]: Tracking gets notification of expired keys\r\n[ok]: HELLO 3 reply is correct\r\n[ok]: HELLO without protover\r\n[ok]: RESP3 based basic invalidation\r\n[ok]: RESP3 tracking redirection\r\n[ok]: Invalidations of previous keys can be redirected after switching to RESP3\r\n[ok]: Invalidations of new keys can be redirected after switching to RESP3\r\n[ok]: RESP3 Client gets tracking-redir-broken push message after cached key changed when rediretion client is terminated\r\n[ok]: Different clients can redirect to the same connection\r\n[ok]: Different clients using different protocols can track the same key\r\n[ok]: No invalidation message when using OPTIN option\r\n[ok]: Invalidation message sent when using OPTIN option with CLIENT CACHING yes\r\n[ok]: Invalidation message sent when using OPTOUT option\r\n[ok]: No invalidation message when using OPTOUT option with CLIENT CACHING no\r\n[ok]: Able to redirect to a RESP3 client\r\n[ok]: After switching from normal tracking to BCAST mode, no invalidation message is produced for pre-BCAST keys\r\n[ok]: BCAST with prefix collisions throw errors\r\n[ok]: Tracking gets notification on tracking table key eviction\r\n[ok]: Invalidation message received for flushall\r\n[ok]: Invalidation message received for flushdb\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: HyperLogLog sparse encoding stress test\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Additional at tail\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Broken magic\r\n[ok]: Corrupted sparse HyperLogLogs are detected: Invalid encoding\r\n[ok]: Corrupted dense HyperLogLogs are detected: Wrong length\r\n[ok]: Server is able to evacuate enough keys when num of keys surpasses limit by more than defined initial effort\r\n[ok]: Tracking info is correct\r\n[ok]: CLIENT GETREDIR provides correct client id\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking off\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking on\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking on with options\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking optin\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking optout\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking bcast mode\r\n[ok]: CLIENT TRACKINGINFO provides reasonable results when tracking redir broken\r\n[ok]: Memory efficiency with values in range 16384\r\n[46/64 done]: unit/tracking (1 seconds)\r\nTesting unit/oom-score-adj\r\n[ok]: PSYNC2 #3899 regression: kill chained replica\r\n[ok]: CONFIG SET oom-score-adj works as expected\r\n[47/64 done]: unit/memefficiency (4 seconds)\r\nTesting unit/shutdown\r\n[ok]: WAIT should not acknowledge 1 additional copy if slave is blocked\r\n[ok]: Temp rdb will be deleted if we use bg_unlink when shutdown\r\n[ok]: Temp rdb will be deleted in signal handle\r\n[48/64 done]: unit/shutdown (0 seconds)\r\nTesting unit/networking\r\n[ok]: MASTER and SLAVE consistency with EVALSHA replication\r\n[ok]: CONFIG SET port number\r\n[ok]: Test replication partial resync: ok after delay (diskless: no, disabled, reconnect: 1)\r\n[err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\n[49/64 done]: unit/networking (1 seconds)\r\n[50/64 done]: unit/oom-score-adj (2 seconds)\r\n[ok]: WAIT implicitly blocks on client pause since ACKs aren't sent\r\n[ok]: PSYNC2 #3899 regression: verify consistency\r\n[51/64 done]: unit/wait (4 seconds)\r\n[ok]: Slave should be able to synchronize with the master\r\n[52/64 done]: integration/psync2-reg (22 seconds)\r\n[ok]: Detect write load to master\r\n[ok]: pending querybuf: check size of pending_querybuf after set a big value\r\n[ok]: SLAVE can reload \"lua\" AUX RDB fields of duplicated scripts\r\n[53/64 done]: unit/pendingquerybuf (6 seconds)\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 125895)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 5 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[ok]: PSYNC2: Set #2 to replicate from #0\r\n[ok]: PSYNC2: Set #4 to replicate from #2\r\n[ok]: PSYNC2: Set #3 to replicate from #2\r\n[ok]: PSYNC2: Set #1 to replicate from #3\r\n[54/64 done]: integration/replication-3 (34 seconds)\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Client output buffer hard limit is enforced\r\n[ok]: Replication: commands with many arguments (issue #1221)\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 190238)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 6 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #4 as master\r\n[ok]: PSYNC2: Set #3 to replicate from #4\r\n[ok]: PSYNC2: Set #1 to replicate from #4\r\n[ok]: PSYNC2: Set #2 to replicate from #3\r\n[ok]: PSYNC2: Set #0 to replicate from #2\r\n[ok]: Replication of SPOP command -- alsoPropagate() API\r\n[55/64 done]: integration/replication-4 (40 seconds)\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Test replication partial resync: backlog expired (diskless: no, disabled, reconnect: 1)\r\n[ok]: Client output buffer soft limit is not enforced if time is not overreached\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: no, swapdb, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: slave buffer are counted correctly\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 257556)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: PSYNC2: --- CYCLE 7 ---\r\n[ok]: PSYNC2: [NEW LAYOUT] Set #0 as master\r\n[ok]: PSYNC2: Set #1 to replicate from #0\r\n[ok]: PSYNC2: Set #2 to replicate from #1\r\n[ok]: PSYNC2: Set #3 to replicate from #2\r\n[ok]: PSYNC2: Set #4 to replicate from #0\r\n[ok]: PSYNC2: cluster is consistent after failover\r\n[ok]: Client output buffer soft limit is enforced if time is overreached\r\n[ok]: No response for single command if client output buffer hard limit is enforced\r\n[ok]: No response for multi commands in pipeline if client output buffer limit is enforced\r\n[ok]: Execute transactions completely even if client output buffer limit is enforced\r\n[56/64 done]: unit/obuf-limits (27 seconds)\r\n[ok]: AOF rewrite during write load: RDB preamble=no\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=no, replica diskless=disabled\r\n[ok]: Turning off AOF kills the background writing child if any\r\n[ok]: replica buffer don't induce eviction\r\n[ok]: PSYNC2: generate load while killing replication links\r\n[ok]: PSYNC2: cluster is consistent after load (x = 310403)\r\n[ok]: PSYNC2: total sum of full synchronizations is exactly 4\r\n[ok]: Test replication partial resync: ok psync (diskless: no, swapdb, reconnect: 1)\r\n[ok]: AOF rewrite of list with quicklist encoding, string data\r\n[ok]: GEOSEARCH fuzzy test - byradius\r\n[ok]: Don't rehash if used memory exceeds maxmemory after rehash\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: PSYNC2: Bring the master back again for next test\r\n[ok]: PSYNC2: Partial resync after restart using RDB aux fields\r\n[ok]: AOF rewrite of list with quicklist encoding, int data\r\n[ok]: Detect write load to master\r\n[ok]: client tracking don't cause eviction feedback loop\r\n[57/64 done]: unit/maxmemory (36 seconds)\r\n[ok]: PSYNC2: Replica RDB restart with EVALSHA in backlog issue #4483\r\n[ok]: AOF rewrite of set with intset encoding, string data\r\n[58/64 done]: integration/psync2 (44 seconds)\r\n[ok]: AOF rewrite of set with hashtable encoding, string data\r\n[ok]: AOF rewrite of set with intset encoding, int data\r\n[ok]: AOF rewrite of set with hashtable encoding, int data\r\n[ok]: AOF rewrite of hash with ziplist encoding, string data\r\n[ok]: AOF rewrite of hash with hashtable encoding, string data\r\n[ok]: AOF rewrite of hash with ziplist encoding, int data\r\n[ok]: AOF rewrite of hash with hashtable encoding, int data\r\n[ok]: Test replication partial resync: no backlog (diskless: no, swapdb, reconnect: 1)\r\n[ok]: AOF rewrite of zset with ziplist encoding, string data\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: AOF rewrite of zset with skiplist encoding, string data\r\n[ok]: AOF rewrite of zset with ziplist encoding, int data\r\n[ok]: AOF rewrite of zset with skiplist encoding, int data\r\n[ok]: BGREWRITEAOF is delayed if BGSAVE is in progress\r\n[ok]: BGREWRITEAOF is refused if already in progress\r\n[59/64 done]: unit/aofrw (71 seconds)\r\n[ok]: GEOSEARCH fuzzy test - bybox\r\n[ok]: GEOSEARCH box edges fuzzy test\r\n[60/64 done]: north (43 seconds)\r\n[ok]: Fuzzing dense/sparse encoding: Redis should always detect errors\r\n[ok]: PFADD, PFCOUNT, PFMERGE type checking works\r\n[ok]: PFMERGE results on the cardinality of union of sets\r\n[ok]: Test replication partial resync: ok after delay (diskless: no, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Stress tester for #3343-alike bugs\r\n[ok]: PFCOUNT multiple-keys merge returns cardinality of union #1\r\n[ok]: PFCOUNT multiple-keys merge returns cardinality of union #2\r\n[ok]: PFDEBUG GETREG returns the HyperLogLog raw registers\r\n[ok]: PFADD / PFCOUNT cache invalidation works\r\n[61/64 done]: unit/hyperloglog (53 seconds)\r\n[ok]: Test replication partial resync: backlog expired (diskless: no, swapdb, reconnect: 1)\r\n[ok]: ziplist implementation: value encoding and backlink\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: yes, disabled, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=no, replica diskless=swapdb\r\n[ok]: ziplist implementation: encoding stress testing\r\n[62/64 done]: unit/type/list-3 (98 seconds)\r\n[ok]: Test replication partial resync: ok psync (diskless: yes, disabled, reconnect: 1)\r\nWaiting for process 11961 to exit...\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no backlog (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: ok after delay (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: backlog expired (diskless: yes, disabled, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no reconnection, just sync (diskless: yes, swapdb, reconnect: 0)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=yes, replica diskless=disabled\r\n[ok]: Test replication partial resync: ok psync (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: no backlog (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: ok after delay (diskless: yes, swapdb, reconnect: 1)\r\n[ok]: Slave should be able to synchronize with the master\r\n[ok]: Detect write load to master\r\n[ok]: Test replication partial resync: backlog expired (diskless: yes, swapdb, reconnect: 1)\r\n[63/64 done]: integration/replication-psync (172 seconds)\r\n[ok]: Connect multiple replicas at the same time (issue #141), master diskless=yes, replica diskless=swapdb\r\n[ok]: Master stream is correctly processed while the replica has a script in -BUSY state\r\n[ok]: slave fails full sync and diskless load swapdb recovers it\r\n[ok]: diskless loading short read\r\n[ok]: diskless no replicas drop during rdb pipe\r\n[ok]: diskless slow replicas drop during rdb pipe\r\n[ok]: diskless fast replicas drop during rdb pipe\r\n[ok]: diskless all replicas drop during rdb pipe\r\n[ok]: diskless timeout replicas drop during rdb pipe\r\n[ok]: diskless replication child being killed is collected\r\n[ok]: replicaof right after disconnection\r\n[ok]: Kill rdb child process if its dumping RDB is not useful\r\n[64/64 done]: integration/replication (257 seconds)\r\nTesting solo test\r\n[ok]: Active defrag\r\n[ok]: Active defrag big keys\r\n[ok]: Active defrag big list\r\n[ok]: Active defrag edge case\r\n[64/64 done]: defrag (98 seconds)\r\n\r\n                   The End\r\n\r\nExecution time of different units:\r\n  1 seconds - unit/printver\r\n  1 seconds - unit/type/incr\r\n  1 seconds - unit/info\r\n  1 seconds - unit/protocol\r\n  2 seconds - unit/keyspace\r\n  2 seconds - unit/auth\r\n  0 seconds - unit/quit\r\n  5 seconds - unit/type/hash\r\n  4 seconds - unit/multi\r\n  6 seconds - unit/type/set\r\n  5 seconds - unit/type/stream-cgroups\r\n  5 seconds - unit/sort\r\n  2 seconds - unit/acl\r\n  8 seconds - unit/type/list\r\n  8 seconds - unit/scan\r\n  8 seconds - unit/type/string\r\n  11 seconds - unit/other\r\n  12 seconds - unit/type/list-2\r\n  9 seconds - unit/latency-monitor\r\n  10 seconds - integration/replication-2\r\n  8 seconds - integration/aof\r\n  1 seconds - integration/convert-zipmap-hash-on-load\r\n  16 seconds - unit/expire\r\n  17 seconds - unit/type/zset\r\n  1 seconds - integration/logging\r\n  7 seconds - integration/rdb\r\n  8 seconds - integration/corrupt-dump\r\n  2 seconds - integration/redis-benchmark\r\n  5 seconds - integration/failover\r\n  0 seconds - unit/pubsub\r\n  2 seconds - unit/slowlog\r\n  26 seconds - unit/dump\r\n  8 seconds - integration/redis-cli\r\n  28 seconds - unit/type/stream\r\n  2 seconds - unit/introspection\r\n  1 seconds - unit/limits\r\n  15 seconds - integration/psync2-pingoff\r\n  26 seconds - integration/block-repl\r\n  4 seconds - unit/bitops\r\n  11 seconds - unit/scripting\r\n  6 seconds - unit/introspection-2\r\n  2 seconds - unit/bitfield\r\n  2 seconds - unit/lazyfree\r\n  20 seconds - integration/corrupt-dump-fuzzer\r\n  0 seconds - unit/tls\r\n  1 seconds - unit/tracking\r\n  4 seconds - unit/memefficiency\r\n  0 seconds - unit/shutdown\r\n  1 seconds - unit/networking\r\n  2 seconds - unit/oom-score-adj\r\n  4 seconds - unit/wait\r\n  22 seconds - integration/psync2-reg\r\n  6 seconds - unit/pendingquerybuf\r\n  34 seconds - integration/replication-3\r\n  40 seconds - integration/replication-4\r\n  27 seconds - unit/obuf-limits\r\n  36 seconds - unit/maxmemory\r\n  44 seconds - integration/psync2\r\n  71 seconds - unit/aofrw\r\n  43 seconds - north\r\n  53 seconds - unit/hyperloglog\r\n  98 seconds - unit/type/list-3\r\n  172 seconds - integration/replication-psync\r\n  257 seconds - integration/replication\r\n  98 seconds - defrag\r\n\r\n!!! WARNING The following tests failed:\r\n\r\n*** [err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\nCleanup: may take some time... OK\r\nMakefile:387: recipe for target 'test' failed\r\nmake[1]: *** [test] Error 1\r\nmake[1]: Leaving directory '/tmp/redis-stable/src'\r\nMakefile:6: recipe for target 'test' failed\r\nmake: *** [test] Error 2\r\n\r\n```\r\n</details>\r\n\r\n<details>\r\n<summary>Output of `./runtest --single unit/networking`</summary>\r\n\r\n```\r\nCleanup: may take some time... OK\r\nStarting test server at port 21079\r\n[ready]: 16821\r\nTesting unit/networking\r\n[ready]: 16822\r\n[ready]: 16823\r\n[ready]: 16824\r\n[ready]: 16825\r\n[ready]: 16826\r\n[ready]: 16827\r\n[ready]: 16828\r\n[ready]: 16830\r\n[ready]: 16829\r\n[ready]: 16831\r\n[ready]: 16832\r\n[ready]: 16833\r\n[ready]: 16834\r\n[ready]: 16835\r\n[ready]: 16836\r\n[ok]: CONFIG SET port number\r\n[err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\n[1/1 done]: unit/networking (1 seconds)\r\n\r\n                   The End\r\n\r\nExecution time of different units:\r\n  1 seconds - unit/networking\r\n\r\n!!! WARNING The following tests failed:\r\n\r\n*** [err]: CONFIG SET bind address in tests/unit/networking.tcl\r\nExpected 'OK' to match '*Failed to bind to specified addresses*' (context: type eval line 4 cmd {assert_match {*Failed to bind to specified addresses*} $e} proc ::start_server)\r\nCleanup: may take some time... OK\r\n\r\n```\r\n</details>","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/8828/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/8828/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"actor":{"login":"ddknight","id":7845121,"node_id":"MDQ6VXNlcjc4NDUxMjE=","avatar_url":"https://avatars.githubusercontent.com/u/7845121?v=4","gravatar_id":"","url":"https://api.github.com/users/ddknight","html_url":"https://github.com/ddknight","followers_url":"https://api.github.com/users/ddknight/followers","following_url":"https://api.github.com/users/ddknight/following{/other_user}","gists_url":"https://api.github.com/users/ddknight/gists{/gist_id}","starred_url":"https://api.github.com/users/ddknight/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ddknight/subscriptions","organizations_url":"https://api.github.com/users/ddknight/orgs","repos_url":"https://api.github.com/users/ddknight/repos","events_url":"https://api.github.com/users/ddknight/events{/privacy}","received_events_url":"https://api.github.com/users/ddknight/received_events","type":"User","user_view_type":"public","site_admin":false},"created_at":"2021-09-30T02:01:56Z","updated_at":"2021-09-30T02:01:56Z","source":{"type":"issue","issue":{"url":"https://api.github.com/repos/redis/redis/issues/9568","repository_url":"https://api.github.com/repos/redis/redis","labels_url":"https://api.github.com/repos/redis/redis/issues/9568/labels{/name}","comments_url":"https://api.github.com/repos/redis/redis/issues/9568/comments","events_url":"https://api.github.com/repos/redis/redis/issues/9568/events","html_url":"https://github.com/redis/redis/issues/9568","id":1011612215,"node_id":"I_kwDOAAJhcs48S_o3","number":9568,"title":"[REPORT]CentOS 7.9 redis 6.2.5 make test faild","user":{"login":"ddknight","id":7845121,"node_id":"MDQ6VXNlcjc4NDUxMjE=","avatar_url":"https://avatars.githubusercontent.com/u/7845121?v=4","gravatar_id":"","url":"https://api.github.com/users/ddknight","html_url":"https://github.com/ddknight","followers_url":"https://api.github.com/users/ddknight/followers","following_url":"https://api.github.com/users/ddknight/following{/other_user}","gists_url":"https://api.github.com/users/ddknight/gists{/gist_id}","starred_url":"https://api.github.com/users/ddknight/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ddknight/subscriptions","organizations_url":"https://api.github.com/users/ddknight/orgs","repos_url":"https://api.github.com/users/ddknight/repos","events_url":"https://api.github.com/users/ddknight/events{/privacy}","received_events_url":"https://api.github.com/users/ddknight/received_events","type":"User","user_view_type":"public","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2021-09-30T02:01:56Z","updated_at":"2021-09-30T02:23:15Z","closed_at":"2021-09-30T02:23:15Z","author_association":"NONE","type":null,"active_lock_reason":null,"sub_issues_summary":{"total":0,"completed":0,"percent_completed":0},"issue_dependencies_summary":{"blocked_by":0,"total_blocked_by":0,"blocking":0,"total_blocking":0},"repository":{"id":156018,"node_id":"MDEwOlJlcG9zaXRvcnkxNTYwMTg=","name":"redis","full_name":"redis/redis","private":false,"owner":{"login":"redis","id":1529926,"node_id":"MDEyOk9yZ2FuaXphdGlvbjE1Mjk5MjY=","avatar_url":"https://avatars.githubusercontent.com/u/1529926?v=4","gravatar_id":"","url":"https://api.github.com/users/redis","html_url":"https://github.com/redis","followers_url":"https://api.github.com/users/redis/followers","following_url":"https://api.github.com/users/redis/following{/other_user}","gists_url":"https://api.github.com/users/redis/gists{/gist_id}","starred_url":"https://api.github.com/users/redis/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/redis/subscriptions","organizations_url":"https://api.github.com/users/redis/orgs","repos_url":"https://api.github.com/users/redis/repos","events_url":"https://api.github.com/users/redis/events{/privacy}","received_events_url":"https://api.github.com/users/redis/received_events","type":"Organization","user_view_type":"public","site_admin":false},"html_url":"https://github.com/redis/redis","description":"For developers, who are building real-time data-driven applications, Redis is the preferred, fastest, and most feature-rich cache, data structure server, and document and vector query engine.","fork":false,"url":"https://api.github.com/repos/redis/redis","forks_url":"https://api.github.com/repos/redis/redis/forks","keys_url":"https://api.github.com/repos/redis/redis/keys{/key_id}","collaborators_url":"https://api.github.com/repos/redis/redis/collaborators{/collaborator}","teams_url":"https://api.github.com/repos/redis/redis/teams","hooks_url":"https://api.github.com/repos/redis/redis/hooks","issue_events_url":"https://api.github.com/repos/redis/redis/issues/events{/number}","events_url":"https://api.github.com/repos/redis/redis/events","assignees_url":"https://api.github.com/repos/redis/redis/assignees{/user}","branches_url":"https://api.github.com/repos/redis/redis/branches{/branch}","tags_url":"https://api.github.com/repos/redis/redis/tags","blobs_url":"https://api.github.com/repos/redis/redis/git/blobs{/sha}","git_tags_url":"https://api.github.com/repos/redis/redis/git/tags{/sha}","git_refs_url":"https://api.github.com/repos/redis/redis/git/refs{/sha}","trees_url":"https://api.github.com/repos/redis/redis/git/trees{/sha}","statuses_url":"https://api.github.com/repos/redis/redis/statuses/{sha}","languages_url":"https://api.github.com/repos/redis/redis/languages","stargazers_url":"https://api.github.com/repos/redis/redis/stargazers","contributors_url":"https://api.github.com/repos/redis/redis/contributors","subscribers_url":"https://api.github.com/repos/redis/redis/subscribers","subscription_url":"https://api.github.com/repos/redis/redis/subscription","commits_url":"https://api.github.com/repos/redis/redis/commits{/sha}","git_commits_url":"https://api.github.com/repos/redis/redis/git/commits{/sha}","comments_url":"https://api.github.com/repos/redis/redis/comments{/number}","issue_comment_url":"https://api.github.com/repos/redis/redis/issues/comments{/number}","contents_url":"https://api.github.com/repos/redis/redis/contents/{+path}","compare_url":"https://api.github.com/repos/redis/redis/compare/{base}...{head}","merges_url":"https://api.github.com/repos/redis/redis/merges","archive_url":"https://api.github.com/repos/redis/redis/{archive_format}{/ref}","downloads_url":"https://api.github.com/repos/redis/redis/downloads","issues_url":"https://api.github.com/repos/redis/redis/issues{/number}","pulls_url":"https://api.github.com/repos/redis/redis/pulls{/number}","milestones_url":"https://api.github.com/repos/redis/redis/milestones{/number}","notifications_url":"https://api.github.com/repos/redis/redis/notifications{?since,all,participating}","labels_url":"https://api.github.com/repos/redis/redis/labels{/name}","releases_url":"https://api.github.com/repos/redis/redis/releases{/id}","deployments_url":"https://api.github.com/repos/redis/redis/deployments","created_at":"2009-03-21T22:32:25Z","updated_at":"2025-12-13T04:51:44Z","pushed_at":"2025-12-11T09:07:47Z","git_url":"git://github.com/redis/redis.git","ssh_url":"git@github.com:redis/redis.git","clone_url":"https://github.com/redis/redis.git","svn_url":"https://github.com/redis/redis","homepage":"http://redis.io","size":205841,"stargazers_count":72116,"watchers_count":72116,"language":"C","has_issues":true,"has_projects":true,"has_downloads":true,"has_wiki":false,"has_pages":false,"has_discussions":true,"forks_count":24380,"mirror_url":null,"archived":false,"disabled":false,"open_issues_count":2735,"license":{"key":"other","name":"Other","spdx_id":"NOASSERTION","url":null,"node_id":"MDc6TGljZW5zZTA="},"allow_forking":true,"is_template":false,"web_commit_signoff_required":false,"topics":["cache","caching","database","distributed-systems","in-memory","in-memory-database","json","key-value","key-value-store","message-broker","message-queue","no-sql","nosql","open-source","real-time","realtime","redis","time-series","vector-databases","vector-search"],"visibility":"public","forks":24380,"open_issues":2735,"watchers":72116,"default_branch":"unstable","permissions":{"admin":false,"maintain":false,"push":false,"triage":false,"pull":true}},"body":"> [12/64 done]: unit/type/string (10 seconds)\r\nTesting integration/replication-2\r\n[ok]: ZDIFF fuzzing - skiplist\r\n[ok]: Basic ZPOP with a single key - skiplist\r\n[ok]: ZPOP with count - skiplist\r\n[ok]: BZPOP with a single existing sorted set - skiplist\r\n[ok]: BZPOP with multiple existing sorted sets - skiplist\r\n[ok]: BZPOP second sorted set has members - skiplist\r\n[ok]: Basic ZPOP - skiplist RESP3\r\n[ok]: ZPOP with count - skiplist RESP3\r\n[ok]: BZPOP - skiplist RESP3\r\n[ok]: ZINTERSTORE regression with two sets, intset+hashtable\r\n[ok]: ZUNIONSTORE regression, should not create NaN in scores\r\n[ok]: ZINTERSTORE #516 regression, mixed sets and ziplist zsets\r\n[ok]: default: load from include file, can access any channels\r\n[ok]: default: with config acl-pubsub-default allchannels after reset, can access any channels\r\n[ok]: default: with config acl-pubsub-default resetchannels after reset, can not access any channels\r\n[ok]: Alice: can execute all command\r\n[ok]: Bob: just execute @set and acl command\r\n[ok]: ACL load and save\r\n[ok]: ACL load and save with restricted channels\r\n[ok]: Slave enters handshake\r\n[ok]: ZUNIONSTORE result is sorted\r\n[ok]: ZUNIONSTORE/ZINTERSTORE/ZDIFFSTORE error if using WITHSCORES \r\n[ok]: ZMSCORE retrieve\r\n[ok]: ZMSCORE retrieve from empty set\r\n[ok]: ZMSCORE retrieve with missing member\r\n[ok]: ZMSCORE retrieve single member\r\n[ok]: ZMSCORE retrieve requires one or more members\r\n[ok]: ZSET commands don't accept the empty strings as valid score\r\n[ok]: ZSCORE - ziplist\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: MULTI-EXEC body and script timeout\r\n[ok]: If min-slaves-to-write is honored, write is accepted\r\n[ok]: No write if min-slaves-to-write is < attached slaves\r\n[ok]: If min-slaves-to-write is honored, write is accepted (again)\r\n[ok]: ZMSCORE - ziplist\r\n[ok]: ZSCORE after a DEBUG RELOAD - ziplist\r\n[ok]: ZSET sorting stresser - ziplist\r\n[ok]: EXPIRES after a reload (snapshot + append only file rewrite)\r\n[ok]: First server should have role slave after SLAVEOF\r\n[ok]: Empty stream with no lastid can be rewrite into AOF correctly\r\n[ok]: just EXEC and script timeout\r\n[ok]: exec with write commands and state change\r\n[ok]: exec with read commands and stale replica state change\r\n[ok]: EXEC with only read commands should not be rejected when OOM\r\n[ok]: EXEC with at least one use-memory command should fail\r\n[ok]: Blocking commands ignores the timeout\r\n[ok]: Default user has access to all channels irrespective of flag\r\n[ok]: Update acl-pubsub-default, existing users shouldn't get affected\r\n[ok]: Single channel is valid\r\n[ok]: Single channel is not valid with allchannels\r\n[ok]: MULTI propagation of PUBLISH\r\n[ok]: MULTI propagation of SCRIPT LOAD\r\n[ok]: MULTI propagation of SCRIPT LOAD\r\n[ok]: MULTI propagation of XREADGROUP\r\n[ok]: Only default user has access to all channels irrespective of flag\r\n[ok]: Test latency events logging\r\n**[err]: LATENCY HISTORY output is ok in tests/unit/latency-monitor.tcl\r\nExpected 999 >= 450 && 999 <= 650 (context: type eval line 7 cmd {assert {$latency >= $min && $latency <= $max}} proc ::test)\r\n[err]: LATENCY LATEST output is ok in tests/unit/latency-monitor.tcl\r\nExpected 999 >= 450 & 999 <= 650 (context: type eval line 6 cmd {assert {$max >= 450 & $max <= 650}} proc ::test)**\r\n[ok]: LATENCY HISTORY / RESET with wrong event name is fine\r\n[ok]: LATENCY DOCTOR produces some output\r\n[ok]: LATENCY RESET is able to reset events\r\n[ok]: ZRANGEBYSCORE fuzzy test, 100 ranges in 128 element sorted set - ziplist\r\n[13/64 done]: unit/multi (14 seconds)\r\n\r\nHost OS: CentOS 7.9\r\nBuild GCC Version: gcc version 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC)\r\n","reactions":{"url":"https://api.github.com/repos/redis/redis/issues/9568/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/redis/redis/issues/9568/timeline","performed_via_github_app":null,"state_reason":"completed"}},"event":"cross-referenced"},{"id":18844706232,"node_id":"REFE_lADOAAJhcs4AR8G-zwAAAARjO2W4","url":"https://api.github.com/repos/redis/redis/issues/events/18844706232","actor":{"login":"sundb","id":965798,"node_id":"MDQ6VXNlcjk2NTc5OA==","avatar_url":"https://avatars.githubusercontent.com/u/965798?v=4","gravatar_id":"","url":"https://api.github.com/users/sundb","html_url":"https://github.com/sundb","followers_url":"https://api.github.com/users/sundb/followers","following_url":"https://api.github.com/users/sundb/following{/other_user}","gists_url":"https://api.github.com/users/sundb/gists{/gist_id}","starred_url":"https://api.github.com/users/sundb/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sundb/subscriptions","organizations_url":"https://api.github.com/users/sundb/orgs","repos_url":"https://api.github.com/users/sundb/repos","events_url":"https://api.github.com/users/sundb/events{/privacy}","received_events_url":"https://api.github.com/users/sundb/received_events","type":"User","user_view_type":"public","site_admin":false},"event":"referenced","commit_id":"d52c8f30e0b4730115ed1cd0cdf36637aca7fef7","commit_url":"https://api.github.com/repos/sundb/redis/commits/d52c8f30e0b4730115ed1cd0cdf36637aca7fef7","created_at":"2025-07-28T03:39:37Z","performed_via_github_app":null}]